{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric-Chung-0511/Learning-Record/blob/main/Data%20Science%20Projects/VisionScout/(YOLO_CLIP_Llama_Places365)_Vision_Scout_Model_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZc4F5T9e9t-"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = userdata.get(\"HF_TOKEN\")  # 已新增至Secret\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVpfCYfq0HUe",
        "outputId": "4100e0f2-0352-4fd5-c4e4-1357111d7114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxiomUThoEN",
        "outputId": "427dd928-1cc7-4eca-ed3a-270c6bb25b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.5.22-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Downloading yt_dlp-2025.5.22-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.5.22\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0477JcxwzrHV",
        "outputId": "3429a9f5-5467-4a48-81cc-0038793ae2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-chsn8qyx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-chsn8qyx\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting clip\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=9c637415683c831e6847dffaa7e99485e25125af1d4b4f8c3e764ecf3af6a52e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z0lkhc67/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch clip git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCodZ3KyPKQ",
        "outputId": "fd982d50-34a0-4df7-dd51-538a9bfdf7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.3.128\n",
            "  Downloading ultralytics-8.3.128-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.3.128)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.128) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.128) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.128) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.128) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.128) (3.0.2)\n",
            "Downloading ultralytics-8.3.128-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.128 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.3.128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5Wbwj0j1FQ",
        "outputId": "97777dfc-8242-4c9f-b875-fa514c57c566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, bitsandbytes, accelerate\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.6.0\n",
            "    Uninstalling accelerate-1.6.0:\n",
            "      Successfully uninstalled accelerate-1.6.0\n",
            "Successfully installed accelerate-1.7.0 bitsandbytes-0.45.5 transformers-4.52.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers accelerate bitsandbytes sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te0fPfkgvPKa",
        "outputId": "bb1a8d9a-7e7d-44ea-c683-dc4d2bc291a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-wICk4sFeRA",
        "outputId": "7211dfef-31c1-4997-a623-01ee31379029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# %%writefile detection_model.py\n",
        "from ultralytics import YOLO\n",
        "from typing import Any, List, Dict, Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class DetectionModel:\n",
        "    \"\"\"Core detection model class for object detection using YOLOv8\"\"\"\n",
        "\n",
        "    # Model information dictionary\n",
        "    MODEL_INFO = {\n",
        "        \"yolov8n.pt\": {\n",
        "            \"name\": \"YOLOv8n (Nano)\",\n",
        "            \"description\": \"Fastest model with smallest size (3.2M parameters). Best for speed-critical applications.\",\n",
        "            \"size_mb\": 6,\n",
        "            \"inference_speed\": \"Very Fast\"\n",
        "        },\n",
        "        \"yolov8m.pt\": {\n",
        "            \"name\": \"YOLOv8m (Medium)\",\n",
        "            \"description\": \"Balanced model with good accuracy-speed tradeoff (25.9M parameters). Recommended for general use.\",\n",
        "            \"size_mb\": 25,\n",
        "            \"inference_speed\": \"Medium\"\n",
        "        },\n",
        "        \"yolov8x.pt\": {\n",
        "            \"name\": \"YOLOv8x (XLarge)\",\n",
        "            \"description\": \"Most accurate but slower model (68.2M parameters). Best for accuracy-critical applications.\",\n",
        "            \"size_mb\": 68,\n",
        "            \"inference_speed\": \"Slower\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def __init__(self, model_name: str = 'yolov8m.pt', confidence: float = 0.25, iou: float = 0.25):\n",
        "        \"\"\"\n",
        "        Initialize the detection model\n",
        "\n",
        "        Args:\n",
        "            model_name: Model name or path, default is yolov8m.pt\n",
        "            confidence: Confidence threshold, default is 0.25\n",
        "            iou: IoU threshold for non-maximum suppression, default is 0.45\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.confidence = confidence\n",
        "        self.iou = iou\n",
        "        self.model = None\n",
        "        self.class_names = {}\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Load model on initialization\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the YOLO model\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading model: {self.model_name}\")\n",
        "            self.model = YOLO(self.model_name)\n",
        "            self.class_names = self.model.names\n",
        "            self.is_model_loaded = True\n",
        "            print(f\"Successfully loaded model: {self.model_name}\")\n",
        "            print(f\"Number of classes the model can recognize: {len(self.class_names)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred when loading the model: {e}\")\n",
        "            self.is_model_loaded = False\n",
        "\n",
        "    def change_model(self, new_model_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        Change the currently loaded model\n",
        "\n",
        "        Args:\n",
        "            new_model_name: Name of the new model to load\n",
        "\n",
        "        Returns:\n",
        "            bool: True if model changed successfully, False otherwise\n",
        "        \"\"\"\n",
        "        if self.model_name == new_model_name and self.is_model_loaded:\n",
        "            print(f\"Model {new_model_name} is already loaded\")\n",
        "            return True\n",
        "\n",
        "        print(f\"Changing model from {self.model_name} to {new_model_name}\")\n",
        "\n",
        "        # Unload current model to free memory\n",
        "        if self.model is not None:\n",
        "            del self.model\n",
        "            self.model = None\n",
        "\n",
        "            # Clean GPU memory if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Update model name and load new model\n",
        "        self.model_name = new_model_name\n",
        "        self._load_model()\n",
        "\n",
        "        return self.is_model_loaded\n",
        "\n",
        "    def reload_model(self):\n",
        "        \"\"\"Reload the model (useful for changing model or after error)\"\"\"\n",
        "        if self.model is not None:\n",
        "            del self.model\n",
        "            self.model = None\n",
        "\n",
        "            # Clean GPU memory if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        self._load_model()\n",
        "\n",
        "    def detect(self, image_input: Any) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Perform object detection on a single image\n",
        "\n",
        "        Args:\n",
        "            image_input: Image path (str), PIL Image, or numpy array\n",
        "\n",
        "        Returns:\n",
        "            Detection result object or None if error occurred\n",
        "        \"\"\"\n",
        "        if self.model is None or not self.is_model_loaded:\n",
        "            print(\"Model not found or not loaded. Attempting to reload...\")\n",
        "            self._load_model()\n",
        "            if self.model is None or not self.is_model_loaded:\n",
        "                print(\"Failed to load model. Cannot perform detection.\")\n",
        "                return None\n",
        "\n",
        "        try:\n",
        "            results = self.model(image_input, conf=self.confidence, iou=self.iou)\n",
        "            return results[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred during detection: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_class_names(self, class_id: int) -> str:\n",
        "        \"\"\"Get class name for a given class ID\"\"\"\n",
        "        return self.class_names.get(class_id, \"Unknown Class\")\n",
        "\n",
        "    def get_supported_classes(self) -> Dict[int, str]:\n",
        "        \"\"\"Get all supported classes as a dictionary of {id: class_name}\"\"\"\n",
        "        return self.class_names\n",
        "\n",
        "    @classmethod\n",
        "    def get_available_models(cls) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get list of available models with their information\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries containing model information\n",
        "        \"\"\"\n",
        "        models = []\n",
        "        for model_file, info in cls.MODEL_INFO.items():\n",
        "            models.append({\n",
        "                \"model_file\": model_file,\n",
        "                \"name\": info[\"name\"],\n",
        "                \"description\": info[\"description\"],\n",
        "                \"size_mb\": info[\"size_mb\"],\n",
        "                \"inference_speed\": info[\"inference_speed\"]\n",
        "            })\n",
        "        return models\n",
        "\n",
        "    @classmethod\n",
        "    def get_model_description(cls, model_name: str) -> str:\n",
        "        \"\"\"Get description for a specific model\"\"\"\n",
        "        if model_name in cls.MODEL_INFO:\n",
        "            info = cls.MODEL_INFO[model_name]\n",
        "            return f\"{info['name']}: {info['description']} (Size: ~{info['size_mb']}MB, Speed: {info['inference_speed']})\"\n",
        "        return \"Model information not available\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BApUce5S87og"
      },
      "outputs": [],
      "source": [
        "# %%writefile color_mapper.py\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Union, Any\n",
        "\n",
        "class ColorMapper:\n",
        "    \"\"\"\n",
        "    A class for consistent color mapping of object detection classes\n",
        "    Provides color schemes for visualization in both RGB and hex formats\n",
        "    \"\"\"\n",
        "\n",
        "    # Class categories for better organization\n",
        "    CATEGORIES = {\n",
        "        \"person\": [0],\n",
        "        \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "        \"traffic\": [9, 10, 11, 12],\n",
        "        \"animals\": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
        "        \"outdoor\": [13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
        "        \"sports\": [34, 35, 36, 37, 38],\n",
        "        \"kitchen\": [39, 40, 41, 42, 43, 44, 45],\n",
        "        \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "        \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "        \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "        \"household\": [71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
        "    }\n",
        "\n",
        "    # Base colors for each category (in HSV for easier variation)\n",
        "    # HSV:  Hue, Saturation, Value\n",
        "    CATEGORY_COLORS = {\n",
        "        \"person\": (0, 0.8, 0.9),       # Red\n",
        "        \"vehicles\": (210, 0.8, 0.9),   # Blue\n",
        "        \"traffic\": (45, 0.8, 0.9),     # Orange\n",
        "        \"animals\": (120, 0.7, 0.8),    # Green\n",
        "        \"outdoor\": (180, 0.7, 0.9),    # Cyan\n",
        "        \"sports\": (270, 0.7, 0.8),     # Purple\n",
        "        \"kitchen\": (30, 0.7, 0.9),     # Light Orange\n",
        "        \"food\": (330, 0.7, 0.85),      # Pink\n",
        "        \"furniture\": (150, 0.5, 0.85), # Light Green\n",
        "        \"electronics\": (240, 0.6, 0.9), # Light Blue\n",
        "        \"household\": (60, 0.6, 0.9)    # Yellow\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the ColorMapper with COCO class mappings\"\"\"\n",
        "        self.class_names = self._get_coco_classes()\n",
        "        self.color_map = self._generate_color_map()\n",
        "\n",
        "    def _get_coco_classes(self) -> Dict[int, str]:\n",
        "        \"\"\"Get the standard COCO class names with their IDs\"\"\"\n",
        "        return {\n",
        "            0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',\n",
        "            5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
        "            10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
        "            14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
        "            20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',\n",
        "            25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',\n",
        "            30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat',\n",
        "            35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket',\n",
        "            39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife',\n",
        "            44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich',\n",
        "            49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',\n",
        "            54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',\n",
        "            59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop',\n",
        "            64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave',\n",
        "            69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book',\n",
        "            74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier',\n",
        "            79: 'toothbrush'\n",
        "        }\n",
        "\n",
        "    def _hsv_to_rgb(self, h: float, s: float, v: float) -> Tuple[int, int, int]:\n",
        "        \"\"\"\n",
        "        Convert HSV color to RGB\n",
        "\n",
        "        Args:\n",
        "            h: Hue (0-360)\n",
        "            s: Saturation (0-1)\n",
        "            v: Value (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (R, G, B) values (0-255)\n",
        "        \"\"\"\n",
        "        h = h / 60\n",
        "        i = int(h)\n",
        "        f = h - i\n",
        "        p = v * (1 - s)\n",
        "        q = v * (1 - s * f)\n",
        "        t = v * (1 - s * (1 - f))\n",
        "\n",
        "        if i == 0:\n",
        "            r, g, b = v, t, p\n",
        "        elif i == 1:\n",
        "            r, g, b = q, v, p\n",
        "        elif i == 2:\n",
        "            r, g, b = p, v, t\n",
        "        elif i == 3:\n",
        "            r, g, b = p, q, v\n",
        "        elif i == 4:\n",
        "            r, g, b = t, p, v\n",
        "        else:\n",
        "            r, g, b = v, p, q\n",
        "\n",
        "        return (int(r * 255), int(g * 255), int(b * 255))\n",
        "\n",
        "    def _rgb_to_hex(self, rgb: Tuple[int, int, int]) -> str:\n",
        "        \"\"\"\n",
        "        Convert RGB color to hex color code\n",
        "\n",
        "        Args:\n",
        "            rgb: Tuple of (R, G, B) values (0-255)\n",
        "\n",
        "        Returns:\n",
        "            Hex color code (e.g. '#FF0000')\n",
        "        \"\"\"\n",
        "        return f'#{rgb[0]:02x}{rgb[1]:02x}{rgb[2]:02x}'\n",
        "\n",
        "    def _find_category(self, class_id: int) -> str:\n",
        "        \"\"\"\n",
        "        Find the category for a given class ID\n",
        "\n",
        "        Args:\n",
        "            class_id: Class ID (0-79)\n",
        "\n",
        "        Returns:\n",
        "            Category name\n",
        "        \"\"\"\n",
        "        for category, ids in self.CATEGORIES.items():\n",
        "            if class_id in ids:\n",
        "                return category\n",
        "        return \"other\"  # Fallback\n",
        "\n",
        "    def _generate_color_map(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate a color map for all 80 COCO classes\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping class IDs and names to color values\n",
        "        \"\"\"\n",
        "        color_map = {\n",
        "            'by_id': {},      # Map class ID to RGB and hex\n",
        "            'by_name': {},    # Map class name to RGB and hex\n",
        "            'categories': {}  # Map category to base color\n",
        "        }\n",
        "\n",
        "        # Generate colors for categories\n",
        "        for category, hsv in self.CATEGORY_COLORS.items():\n",
        "            rgb = self._hsv_to_rgb(hsv[0], hsv[1], hsv[2])\n",
        "            hex_color = self._rgb_to_hex(rgb)\n",
        "            color_map['categories'][category] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color\n",
        "            }\n",
        "\n",
        "        # Generate variations for each class within a category\n",
        "        for class_id, class_name in self.class_names.items():\n",
        "            category = self._find_category(class_id)\n",
        "            base_hsv = self.CATEGORY_COLORS.get(category, (0, 0, 0.8))  # Default gray\n",
        "\n",
        "            # Slightly vary the hue and saturation within the category\n",
        "            ids_in_category = self.CATEGORIES.get(category, [])\n",
        "            if ids_in_category:\n",
        "                position = ids_in_category.index(class_id) if class_id in ids_in_category else 0\n",
        "                variation = position / max(1, len(ids_in_category) - 1)  # 0 to 1\n",
        "\n",
        "                # Vary hue slightly (±15°) and saturation\n",
        "                h_offset = 30 * variation - 15  # -15 to +15\n",
        "                s_offset = 0.2 * variation  # 0 to 0.2\n",
        "\n",
        "                h = (base_hsv[0] + h_offset) % 360\n",
        "                s = min(1.0, base_hsv[1] + s_offset)\n",
        "                v = base_hsv[2]\n",
        "            else:\n",
        "                h, s, v = base_hsv\n",
        "\n",
        "            rgb = self._hsv_to_rgb(h, s, v)\n",
        "            hex_color = self._rgb_to_hex(rgb)\n",
        "\n",
        "            # Store in both mappings\n",
        "            color_map['by_id'][class_id] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color,\n",
        "                'category': category\n",
        "            }\n",
        "\n",
        "            color_map['by_name'][class_name] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color,\n",
        "                'category': category\n",
        "            }\n",
        "\n",
        "        return color_map\n",
        "\n",
        "    def get_color(self, class_identifier: Union[int, str], format: str = 'hex') -> Any:\n",
        "        \"\"\"\n",
        "        Get color for a specific class\n",
        "\n",
        "        Args:\n",
        "            class_identifier: Class ID (int) or name (str)\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Color in requested format\n",
        "        \"\"\"\n",
        "        # Determine if identifier is an ID or name\n",
        "        if isinstance(class_identifier, int):\n",
        "            color_info = self.color_map['by_id'].get(class_identifier)\n",
        "        else:\n",
        "            color_info = self.color_map['by_name'].get(class_identifier)\n",
        "\n",
        "        if not color_info:\n",
        "            # Fallback color if not found\n",
        "            return '#CCCCCC' if format == 'hex' else (204, 204, 204)\n",
        "\n",
        "        if format == 'hex':\n",
        "            return color_info['hex']\n",
        "        elif format == 'rgb':\n",
        "            return color_info['rgb']\n",
        "        elif format == 'bgr':\n",
        "            # Convert RGB to BGR for OpenCV\n",
        "            r, g, b = color_info['rgb']\n",
        "            return (b, g, r)\n",
        "        else:\n",
        "            return color_info['rgb']\n",
        "\n",
        "    def get_all_colors(self, format: str = 'hex') -> Dict:\n",
        "        \"\"\"\n",
        "        Get all colors in the specified format\n",
        "\n",
        "        Args:\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping class names to colors\n",
        "        \"\"\"\n",
        "        result = {}\n",
        "        for class_id, class_name in self.class_names.items():\n",
        "            result[class_name] = self.get_color(class_id, format)\n",
        "        return result\n",
        "\n",
        "    def get_category_colors(self, format: str = 'hex') -> Dict:\n",
        "        \"\"\"\n",
        "        Get base colors for each category\n",
        "\n",
        "        Args:\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping categories to colors\n",
        "        \"\"\"\n",
        "        result = {}\n",
        "        for category, color_info in self.color_map['categories'].items():\n",
        "            if format == 'hex':\n",
        "                result[category] = color_info['hex']\n",
        "            elif format == 'bgr':\n",
        "                r, g, b = color_info['rgb']\n",
        "                result[category] = (b, g, r)\n",
        "            else:\n",
        "                result[category] = color_info['rgb']\n",
        "        return result\n",
        "\n",
        "    def get_category_for_class(self, class_identifier: Union[int, str]) -> str:\n",
        "        \"\"\"\n",
        "        Get the category for a specific class\n",
        "\n",
        "        Args:\n",
        "            class_identifier: Class ID (int) or name (str)\n",
        "\n",
        "        Returns:\n",
        "            Category name\n",
        "        \"\"\"\n",
        "        if isinstance(class_identifier, int):\n",
        "            return self.color_map['by_id'].get(class_identifier, {}).get('category', 'other')\n",
        "        else:\n",
        "            return self.color_map['by_name'].get(class_identifier, {}).get('category', 'other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZMzmZVD-r6E"
      },
      "outputs": [],
      "source": [
        "# %%writefile visualization_helper.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from typing import Any, List, Dict, Tuple, Optional\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "class VisualizationHelper:\n",
        "    \"\"\"Helper class for visualizing detection results\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_detection(image: Any, result: Any, color_mapper: Optional[Any] = None,\n",
        "                            figsize: Tuple[int, int] = (12, 12),\n",
        "                            return_pil: bool = False,\n",
        "                            filter_classes: Optional[List[int]] = None) -> Optional[Image.Image]:\n",
        "        \"\"\"\n",
        "        Visualize detection results on a single image\n",
        "\n",
        "        Args:\n",
        "            image: Image path or numpy array\n",
        "            result: Detection result object\n",
        "            color_mapper: ColorMapper instance for consistent colors\n",
        "            figsize: Figure size\n",
        "            return_pil: If True, returns a PIL Image object\n",
        "\n",
        "        Returns:\n",
        "            PIL Image if return_pil is True, otherwise displays the plot\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            print('No data for visualization')\n",
        "            return None\n",
        "\n",
        "        # Read image if path is provided\n",
        "        if isinstance(image, str):\n",
        "            img = cv2.imread(image)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            img = image\n",
        "            if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "                # Check if BGR format (OpenCV) and convert to RGB if needed\n",
        "                if isinstance(img, np.ndarray):\n",
        "                    # Assuming BGR format from OpenCV\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # Get bounding boxes, classes and confidences\n",
        "        boxes = result.boxes.xyxy.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy()\n",
        "        confs = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Get class names\n",
        "        names = result.names\n",
        "\n",
        "        # Create a default color mapper if none is provided\n",
        "        if color_mapper is None:\n",
        "            # For backward compatibility, fallback to a simple color function\n",
        "            from matplotlib import colormaps\n",
        "            cmap = colormaps['tab10']\n",
        "            def get_color(class_id):\n",
        "                return cmap(class_id % 10)\n",
        "        else:\n",
        "            # Use the provided color mapper\n",
        "            def get_color(class_id):\n",
        "                hex_color = color_mapper.get_color(class_id)\n",
        "                # Convert hex to RGB float values for matplotlib\n",
        "                hex_color = hex_color.lstrip('#')\n",
        "                return tuple(int(hex_color[i:i+2], 16) / 255 for i in (0, 2, 4)) + (1.0,)\n",
        "\n",
        "        # Draw detection results\n",
        "        for box, cls, conf in zip(boxes, classes, confs):\n",
        "            x1, y1, x2, y2 = box\n",
        "            cls_id = int(cls)\n",
        "\n",
        "            if filter_classes and cls_id not in filter_classes:\n",
        "                continue\n",
        "\n",
        "            cls_name = names[cls_id]\n",
        "\n",
        "            # Get color for this class\n",
        "            box_color = get_color(cls_id)\n",
        "\n",
        "            box_width = x2 - x1\n",
        "            box_height = y2 - y1\n",
        "            box_area = box_width * box_height\n",
        "\n",
        "            # 根據框大小調整字體大小，但有限制\n",
        "            adaptive_fontsize = max(10, min(14, int(10 + box_area / 10000)))\n",
        "\n",
        "\n",
        "            ax.text(x1, y1 - 8, f'{cls_name}: {conf:.2f}',\n",
        "                    color='white', fontsize=adaptive_fontsize, fontweight=\"bold\",\n",
        "                    bbox=dict(facecolor=box_color[:3], alpha=0.85, pad=3, boxstyle=\"round,pad=0.3\"),\n",
        "                    path_effects=[path_effects.withStroke(linewidth=1.5, foreground=\"black\")])\n",
        "\n",
        "            # Add bounding box\n",
        "            ax.add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                    fill=False, edgecolor=box_color[:3], linewidth=2))\n",
        "\n",
        "        ax.axis('off')\n",
        "        # ax.set_title('Detection Result')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if return_pil:\n",
        "            # Convert plot to PIL Image\n",
        "            buf = io.BytesIO()\n",
        "            fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
        "            buf.seek(0)\n",
        "            pil_img = Image.open(buf)\n",
        "            plt.close(fig)\n",
        "            return pil_img\n",
        "        else:\n",
        "            plt.show()\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def create_summary(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Create a summary of detection results\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with detection summary statistics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get classes and confidences\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "        names = result.names\n",
        "\n",
        "        # Count detections by class\n",
        "        class_counts = {}\n",
        "        for cls, conf in zip(classes, confidences):\n",
        "            cls_name = names[int(cls)]\n",
        "            if cls_name not in class_counts:\n",
        "                class_counts[cls_name] = {\"count\": 0, \"confidences\": []}\n",
        "\n",
        "            class_counts[cls_name][\"count\"] += 1\n",
        "            class_counts[cls_name][\"confidences\"].append(float(conf))\n",
        "\n",
        "        # Calculate average confidence for each class\n",
        "        for cls_name, stats in class_counts.items():\n",
        "            if stats[\"confidences\"]:\n",
        "                stats[\"average_confidence\"] = float(np.mean(stats[\"confidences\"]))\n",
        "                stats.pop(\"confidences\")  # Remove detailed confidences list to keep summary concise\n",
        "\n",
        "        # Prepare summary\n",
        "        summary = {\n",
        "            \"total_objects\": len(classes),\n",
        "            \"class_counts\": class_counts,\n",
        "            \"unique_classes\": len(class_counts)\n",
        "        }\n",
        "\n",
        "        return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxZyG9wX80Og"
      },
      "outputs": [],
      "source": [
        "# %%writefile evaluation_metrics.py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"Class for computing detection metrics, generating statistics and visualization data\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_basic_stats(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate basic statistics for a single detection result\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with basic statistics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get classes and confidences\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "        names = result.names\n",
        "\n",
        "        # Count by class\n",
        "        class_counts = {}\n",
        "        for cls, conf in zip(classes, confidences):\n",
        "            cls_name = names[int(cls)]\n",
        "            if cls_name not in class_counts:\n",
        "                class_counts[cls_name] = {\"count\": 0, \"total_confidence\": 0, \"confidences\": []}\n",
        "\n",
        "            class_counts[cls_name][\"count\"] += 1\n",
        "            class_counts[cls_name][\"total_confidence\"] += float(conf)\n",
        "            class_counts[cls_name][\"confidences\"].append(float(conf))\n",
        "\n",
        "        # Calculate average confidence\n",
        "        for cls_name, stats in class_counts.items():\n",
        "            if stats[\"count\"] > 0:\n",
        "                stats[\"average_confidence\"] = stats[\"total_confidence\"] / stats[\"count\"]\n",
        "                stats[\"confidence_std\"] = float(np.std(stats[\"confidences\"])) if len(stats[\"confidences\"]) > 1 else 0\n",
        "                stats.pop(\"total_confidence\")  # Remove intermediate calculation\n",
        "\n",
        "        # Prepare summary\n",
        "        stats = {\n",
        "            \"total_objects\": len(classes),\n",
        "            \"class_statistics\": class_counts,\n",
        "            \"average_confidence\": float(np.mean(confidences)) if len(confidences) > 0 else 0\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_visualization_data(result: Any, class_colors: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate structured data suitable for visualization\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "            class_colors: Dictionary mapping class names to color codes (optional)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with visualization-ready data\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get basic stats first\n",
        "        stats = EvaluationMetrics.calculate_basic_stats(result)\n",
        "\n",
        "        # Create visualization-specific data structure\n",
        "        viz_data = {\n",
        "            \"total_objects\": stats[\"total_objects\"],\n",
        "            \"average_confidence\": stats[\"average_confidence\"],\n",
        "            \"class_data\": []\n",
        "        }\n",
        "\n",
        "        # Sort classes by count (descending)\n",
        "        sorted_classes = sorted(\n",
        "            stats[\"class_statistics\"].items(),\n",
        "            key=lambda x: x[1][\"count\"],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Create class-specific visualization data\n",
        "        for cls_name, cls_stats in sorted_classes:\n",
        "            class_id = -1\n",
        "            # Find the class ID based on the name\n",
        "            for idx, name in result.names.items():\n",
        "                if name == cls_name:\n",
        "                    class_id = idx\n",
        "                    break\n",
        "\n",
        "            cls_data = {\n",
        "                \"name\": cls_name,\n",
        "                \"class_id\": class_id,\n",
        "                \"count\": cls_stats[\"count\"],\n",
        "                \"average_confidence\": cls_stats.get(\"average_confidence\", 0),\n",
        "                \"confidence_std\": cls_stats.get(\"confidence_std\", 0),\n",
        "                \"color\": class_colors.get(cls_name, \"#CCCCCC\") if class_colors else \"#CCCCCC\"\n",
        "            }\n",
        "\n",
        "            viz_data[\"class_data\"].append(cls_data)\n",
        "\n",
        "        return viz_data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_stats_plot(viz_data: Dict, figsize: Tuple[int, int] = (10, 7), max_classes: int = 30) -> plt.Figure:\n",
        "        \"\"\"\n",
        "        Create a horizontal bar chart showing detection statistics\n",
        "\n",
        "        Args:\n",
        "            viz_data: Visualization data generated by generate_visualization_data\n",
        "            figsize: Figure size (width, height) in inches\n",
        "            max_classes: Maximum number of classes to display\n",
        "\n",
        "        Returns:\n",
        "            Matplotlib figure object\n",
        "        \"\"\"\n",
        "        # Use the enhanced version\n",
        "        return EvaluationMetrics.create_enhanced_stats_plot(viz_data, figsize, max_classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_enhanced_stats_plot(viz_data: Dict, figsize: Tuple[int, int] = (10, 7), max_classes: int = 30) -> plt.Figure:\n",
        "        \"\"\"\n",
        "        Create an enhanced horizontal bar chart with larger fonts and better styling\n",
        "\n",
        "        Args:\n",
        "            viz_data: Visualization data dictionary\n",
        "            figsize: Figure size (width, height) in inches\n",
        "            max_classes: Maximum number of classes to display\n",
        "\n",
        "        Returns:\n",
        "            Matplotlib figure with enhanced styling\n",
        "        \"\"\"\n",
        "        if \"error\" in viz_data:\n",
        "            # Create empty plot if error\n",
        "            fig, ax = plt.subplots(figsize=figsize)\n",
        "            ax.text(0.5, 0.5, viz_data[\"error\"],\n",
        "                    ha='center', va='center', fontsize=14)\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "\n",
        "        if \"class_data\" not in viz_data or not viz_data[\"class_data\"]:\n",
        "            # Create empty plot if no data\n",
        "            fig, ax = plt.subplots(figsize=figsize)\n",
        "            ax.text(0.5, 0.5, \"No detection data available\",\n",
        "                    ha='center', va='center', fontsize=14)\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "\n",
        "        # Limit to max_classes\n",
        "        class_data = viz_data[\"class_data\"][:max_classes]\n",
        "\n",
        "        # Extract data for plotting\n",
        "        class_names = [item[\"name\"] for item in class_data]\n",
        "        counts = [item[\"count\"] for item in class_data]\n",
        "        colors = [item[\"color\"] for item in class_data]\n",
        "\n",
        "        # Create figure and horizontal bar chart with improved styling\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "        # Set background color to white\n",
        "        fig.patch.set_facecolor('white')\n",
        "        ax.set_facecolor('white')\n",
        "\n",
        "        y_pos = np.arange(len(class_names))\n",
        "\n",
        "        # Create horizontal bars with class-specific colors\n",
        "        bars = ax.barh(y_pos, counts, color=colors, alpha=0.8, height=0.6)\n",
        "\n",
        "        # Add count values at end of each bar with larger font\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            conf = class_data[i][\"average_confidence\"]\n",
        "            ax.text(width + 0.3, bar.get_y() + bar.get_height()/2,\n",
        "                    f\"{width:.0f} (conf: {conf:.2f})\",\n",
        "                    va='center', fontsize=12)\n",
        "\n",
        "        # Customize axis and labels with larger fonts\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(class_names, fontsize=14)\n",
        "        ax.invert_yaxis()  # Labels read top-to-bottom\n",
        "        ax.set_xlabel('Count', fontsize=14)\n",
        "        ax.set_title(f'Objects Detected: {viz_data[\"total_objects\"]} Total',\n",
        "                    fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Add grid for better readability\n",
        "        ax.set_axisbelow(True)\n",
        "        ax.grid(axis='x', linestyle='--', alpha=0.7, color='#E5E7EB')\n",
        "\n",
        "        # Increase tick label font size\n",
        "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "        # Add detection summary as a text box with improved styling\n",
        "        summary_text = (\n",
        "            f\"Total Objects: {viz_data['total_objects']}\\n\"\n",
        "            f\"Average Confidence: {viz_data['average_confidence']:.2f}\\n\"\n",
        "            f\"Unique Classes: {len(viz_data['class_data'])}\"\n",
        "        )\n",
        "        plt.figtext(0.02, 0.02, summary_text, fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.5',\n",
        "                            edgecolor='#E5E7EB'))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def format_detection_summary(viz_data: Dict) -> str:\n",
        "        if \"error\" in viz_data:\n",
        "            return viz_data[\"error\"]\n",
        "\n",
        "        if \"total_objects\" not in viz_data:\n",
        "            return \"No detection data available.\"\n",
        "\n",
        "        total_objects = viz_data[\"total_objects\"]\n",
        "        avg_confidence = viz_data[\"average_confidence\"]\n",
        "\n",
        "        lines = [\n",
        "            f\"Detected {total_objects} objects.\",\n",
        "            f\"Average confidence: {avg_confidence:.2f}\",\n",
        "            \"Objects by class:\"\n",
        "        ]\n",
        "\n",
        "        if \"class_data\" in viz_data and viz_data[\"class_data\"]:\n",
        "            for item in viz_data[\"class_data\"]:\n",
        "                count = item['count']\n",
        "                item_text = \"item\" if count == 1 else \"items\"\n",
        "                lines.append(f\"• {item['name']}: {count} {item_text} (Confidence: {item['average_confidence']:.2f})\")\n",
        "        else:\n",
        "            lines.append(\"No class information available.\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_distance_metrics(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate distance-related metrics for detected objects\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with distance metrics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        boxes = result.boxes.xyxy.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        names = result.names\n",
        "\n",
        "        # Initialize metrics\n",
        "        metrics = {\n",
        "            \"proximity\": {},  # Classes that appear close to each other\n",
        "            \"spatial_distribution\": {},  # Distribution across the image\n",
        "            \"size_distribution\": {}  # Size distribution of objects\n",
        "        }\n",
        "\n",
        "        # Calculate image dimensions (assuming normalized coordinates or extract from result)\n",
        "        img_width, img_height = 1, 1\n",
        "        if hasattr(result, \"orig_shape\"):\n",
        "            img_height, img_width = result.orig_shape[:2]\n",
        "\n",
        "        # Calculate bounding box areas and centers\n",
        "        areas = []\n",
        "        centers = []\n",
        "        class_names = []\n",
        "\n",
        "        for box, cls in zip(boxes, classes):\n",
        "            x1, y1, x2, y2 = box\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            area = width * height\n",
        "            center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "            areas.append(area)\n",
        "            centers.append((center_x, center_y))\n",
        "            class_names.append(names[int(cls)])\n",
        "\n",
        "        # Calculate spatial distribution\n",
        "        if centers:\n",
        "            x_coords = [c[0] for c in centers]\n",
        "            y_coords = [c[1] for c in centers]\n",
        "\n",
        "            metrics[\"spatial_distribution\"] = {\n",
        "                \"x_mean\": float(np.mean(x_coords)) / img_width,\n",
        "                \"y_mean\": float(np.mean(y_coords)) / img_height,\n",
        "                \"x_std\": float(np.std(x_coords)) / img_width,\n",
        "                \"y_std\": float(np.std(y_coords)) / img_height\n",
        "            }\n",
        "\n",
        "        # Calculate size distribution\n",
        "        if areas:\n",
        "            metrics[\"size_distribution\"] = {\n",
        "                \"mean_area\": float(np.mean(areas)) / (img_width * img_height),\n",
        "                \"std_area\": float(np.std(areas)) / (img_width * img_height),\n",
        "                \"min_area\": float(np.min(areas)) / (img_width * img_height),\n",
        "                \"max_area\": float(np.max(areas)) / (img_width * img_height)\n",
        "            }\n",
        "\n",
        "        # Calculate proximity between different classes\n",
        "        class_centers = {}\n",
        "        for cls_name, center in zip(class_names, centers):\n",
        "            if cls_name not in class_centers:\n",
        "                class_centers[cls_name] = []\n",
        "            class_centers[cls_name].append(center)\n",
        "\n",
        "        # Find classes that appear close to each other\n",
        "        proximity_pairs = []\n",
        "        for i, cls1 in enumerate(class_centers.keys()):\n",
        "            for j, cls2 in enumerate(class_centers.keys()):\n",
        "                if i >= j:  # Avoid duplicate pairs and self-comparison\n",
        "                    continue\n",
        "\n",
        "                # Calculate minimum distance between any two objects of these classes\n",
        "                min_distance = float('inf')\n",
        "                for center1 in class_centers[cls1]:\n",
        "                    for center2 in class_centers[cls2]:\n",
        "                        dist = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
        "                        min_distance = min(min_distance, dist)\n",
        "\n",
        "                # Normalize by image diagonal\n",
        "                img_diagonal = np.sqrt(img_width**2 + img_height**2)\n",
        "                norm_distance = min_distance / img_diagonal\n",
        "\n",
        "                proximity_pairs.append({\n",
        "                    \"class1\": cls1,\n",
        "                    \"class2\": cls2,\n",
        "                    \"distance\": float(norm_distance)\n",
        "                })\n",
        "\n",
        "        # Sort by distance and keep the closest pairs\n",
        "        proximity_pairs.sort(key=lambda x: x[\"distance\"])\n",
        "        metrics[\"proximity\"] = proximity_pairs[:5]  # Keep top 5 closest pairs\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHIMZpcZwWGU"
      },
      "outputs": [],
      "source": [
        "# %%writefile style.py\n",
        "\n",
        "class Style:\n",
        "\n",
        "    @staticmethod\n",
        "    def get_css():\n",
        "\n",
        "        css = \"\"\"\n",
        "        /* Base styles and typography */\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            background: linear-gradient(135deg, #f0f9ff, #e1f5fe);\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            min-height: 100vh;\n",
        "        }\n",
        "\n",
        "        /* Typography improvements */\n",
        "        h1, h2, h3, h4, h5, h6, p, span, div, label, button {\n",
        "            font-family: Arial, sans-serif;\n",
        "        }\n",
        "\n",
        "        /* Container styling */\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "            margin: auto !important;\n",
        "            padding: 1rem;\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* Header area styling with gradient background */\n",
        "        .app-header {\n",
        "            text-align: center;\n",
        "            margin-bottom: 2rem;\n",
        "            background: linear-gradient(135deg, #f8f9fa, #e9ecef);\n",
        "            padding: 1.5rem;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        .app-title {\n",
        "            color: #2D3748;\n",
        "            font-size: 2.5rem;\n",
        "            margin-bottom: 0.5rem;\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "\n",
        "        .app-subtitle {\n",
        "            color: #4A5568;\n",
        "            font-size: 1.2rem;\n",
        "            font-weight: normal;\n",
        "            margin-top: 0.25rem;\n",
        "        }\n",
        "\n",
        "        .app-divider {\n",
        "            width: 80px;\n",
        "            height: 3px;\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1);\n",
        "            margin: 1rem auto;\n",
        "        }\n",
        "\n",
        "        /* Panel styling - gradient background */\n",
        "        .input-panel, .output-panel {\n",
        "            background: white;\n",
        "            border-radius: 10px;\n",
        "            padding: 1.5rem;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\n",
        "            margin: 0 auto 1rem auto;\n",
        "        }\n",
        "\n",
        "        /* 修改輸出面板確保內容能夠完整顯示 */\n",
        "        .output-panel {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            width: 100%;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 確保輸出面板內的元素寬度可以適應面板 */\n",
        "        .output-panel > * {\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* How-to-use section with gradient background */\n",
        "        .how-to-use {\n",
        "            background: linear-gradient(135deg, #f8fafc, #e8f4fd);\n",
        "            border-radius: 10px;\n",
        "            padding: 1.5rem;\n",
        "            margin-top: 1rem;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "            color: #2d3748;\n",
        "        }\n",
        "\n",
        "        /* Detection button styling */\n",
        "        .detect-btn {\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1) !important;\n",
        "            color: white !important;\n",
        "            border: none !important;\n",
        "            border-radius: 8px !important;\n",
        "            transition: transform 0.3s, box-shadow 0.3s !important;\n",
        "            font-weight: bold !important;\n",
        "            letter-spacing: 0.5px !important;\n",
        "            padding: 0.75rem 1.5rem !important;\n",
        "            width: 100%;\n",
        "            margin: 1rem auto !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "        }\n",
        "\n",
        "        .detect-btn:hover {\n",
        "            transform: translateY(-2px) !important;\n",
        "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        .detect-btn:active {\n",
        "            transform: translateY(1px) !important;\n",
        "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        /* JSON display improvements */\n",
        "        .json-display {\n",
        "            width: 98% !important;\n",
        "            margin: 0.5rem auto 1.5rem auto !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            background-color: white !important;\n",
        "            border: 1px solid #E2E8F0 !important;\n",
        "            box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.05) !important;\n",
        "        }\n",
        "\n",
        "        .json-key {\n",
        "            color: #e53e3e;\n",
        "        }\n",
        "\n",
        "        .json-value {\n",
        "            color: #2b6cb0;\n",
        "        }\n",
        "\n",
        "        .json-string {\n",
        "            color: #38a169;\n",
        "        }\n",
        "\n",
        "        /* Chart/plot styling improvements */\n",
        "        .plot-container {\n",
        "            background: white;\n",
        "            border-radius: 8px;\n",
        "            padding: 0.5rem;\n",
        "            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);\n",
        "        }\n",
        "\n",
        "        /* Larger font for plots */\n",
        "        .plot-container text {\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "        }\n",
        "\n",
        "        /* Title styling for charts */\n",
        "        .plot-title {\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 16px !important;\n",
        "            font-weight: bold !important;\n",
        "        }\n",
        "\n",
        "        /* Tab styling with subtle gradient */\n",
        "        .tabs {\n",
        "            width: 100%;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "        }\n",
        "\n",
        "        .tabs > div:first-child {\n",
        "            background: linear-gradient(to right, #f8fafc, #e8f4fd) !important;\n",
        "            border-radius: 8px 8px 0 0;\n",
        "        }\n",
        "\n",
        "        /* Tab content styling - 確保內容區域有足夠寬度 */\n",
        "        .tab-content {\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* Footer styling with gradient background */\n",
        "        .footer {\n",
        "            text-align: center;\n",
        "            margin-top: 2rem;\n",
        "            font-size: 0.9rem;\n",
        "            color: #4A5568;\n",
        "            padding: 1rem;\n",
        "            background: linear-gradient(135deg, #f8f9fa, #e1effe);\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* Ensure centering works for all elements */\n",
        "        .container, .gr-container, .gr-row, .gr-col {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* 統一文本框樣式，確保寬度一致 */\n",
        "        .gr-textbox, .gr-textarea, .gr-text-input {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 確保文本區域可以適應容器寬度 */\n",
        "        textarea.gr-textarea, .gr-textbox textarea, .gr-text-input textarea {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 16px !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            line-height: 1.6 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            word-break: normal !important;\n",
        "        }\n",
        "\n",
        "        /* 特別針對場景描述文本框樣式增強 */\n",
        "        #scene-description-text, #detection-details {\n",
        "            width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 16px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            border-radius: 8px !important;\n",
        "            min-height: 250px !important;\n",
        "            overflow-y: auto !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            background-color: white !important;\n",
        "            display: block !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 針對場景描述容器的樣式 */\n",
        "        .scene-description-container {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* Scene Understanding Tab 特定樣式 */\n",
        "        .scene-understanding-tab .result-details-box {\n",
        "            display: flex !important;\n",
        "            flex-direction: column !important;\n",
        "            align-items: stretch !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 場景分析描述區域樣式 */\n",
        "        .scene-description-box {\n",
        "            background-color: #f8f9fa !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 15px !important;\n",
        "            margin: 10px 0 20px 0 !important;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            line-height: 1.7 !important;\n",
        "            color: #2D3748 !important;\n",
        "            font-size: 16px !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        #scene_analysis_description_text {\n",
        "            background-color: #f0f0f0 !important; /* 淺灰色背景 */\n",
        "            padding: 15px !important;             /* 內邊距，讓文字和邊框有點空間 */\n",
        "            border-radius: 8px !important;        /* 圓角 */\n",
        "            margin: 10px 0 20px 0 !important;     /* 其他元素的間距，特別是上下的part */\n",
        "            display: block !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        #scene_analysis_description_text p {\n",
        "            margin: 0 !important;\n",
        "            color: #2D3748 !important; /* 確保文字顏色 */\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 16px !important; /* 你可以調整文字大小 */\n",
        "            line-height: 1.7 !important;\n",
        "        }\n",
        "\n",
        "        /* 結果容器樣式 */\n",
        "        .result-container {\n",
        "            width: 100% !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #E2E8F0 !important;\n",
        "            margin-bottom: 1.5rem !important;\n",
        "            background-color: #F8FAFC !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 結果文本框的樣式 */\n",
        "        .wide-result-text {\n",
        "            width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 片段標題樣式 */\n",
        "        .section-heading {\n",
        "            font-size: 1.25rem !important;\n",
        "            font-weight: 600 !important;\n",
        "            color: #2D3748 !important;\n",
        "            margin: 1rem auto !important;\n",
        "            padding: 0.75rem 1rem !important;\n",
        "            background: linear-gradient(to right, #e6f3fc, #f0f9ff) !important;\n",
        "            border-radius: 8px !important;\n",
        "            width: 98% !important;\n",
        "            display: inline-block !important;\n",
        "            box-sizing: border-box !important;\n",
        "            text-align: center !important;\n",
        "            overflow: visible !important;\n",
        "            line-height: 1.5 !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "        }\n",
        "\n",
        "        /* JSON 顯示區域樣式 */\n",
        "        .json-box {\n",
        "            width: 100% !important;\n",
        "            min-height: 200px !important;\n",
        "            overflow-y: auto !important;\n",
        "            background: white !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 欄佈局調整 */\n",
        "        .plot-column, .stats-column {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            padding: 1rem;\n",
        "            box-sizing: border-box !important;\n",
        "            width: 100% !important;\n",
        "        }\n",
        "\n",
        "        /* statistics plot */\n",
        "        .large-plot-container {\n",
        "            width: 100% !important;\n",
        "            min-height: 400px !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 增強 JSON 顯示 */\n",
        "        .enhanced-json-display {\n",
        "            background: white !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 1rem !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            width: 100% !important;\n",
        "            min-height: 300px !important;\n",
        "            max-height: 500px !important;\n",
        "            overflow-y: auto !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 確保全寬元素真正占滿整個寬度 */\n",
        "        .full-width-element {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* Video summary HTML 容器與內容樣式 */\n",
        "        #video-summary-html-output {\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        .video-summary-content-wrapper {\n",
        "            width: 100% !important;\n",
        "            padding: 16px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            border-radius: 8px !important;\n",
        "            min-height: 250px !important;\n",
        "            max-height: 600px !important;\n",
        "            overflow-y: auto !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            background-color: white !important;\n",
        "            display: block !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        .video-summary-content-wrapper pre {\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            margin: 0 !important;\n",
        "            padding: 0 !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            color: #2D3748 !important;\n",
        "        }\n",
        "\n",
        "        /* 視頻結果面板相關樣式 */\n",
        "        .video-result-panel {\n",
        "            padding: 1rem !important;\n",
        "            background: white !important;\n",
        "            border-radius: 10px !important;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08) !important;\n",
        "        }\n",
        "\n",
        "        .video-output-container {\n",
        "            width: 100% !important;\n",
        "            margin-bottom: 1.5rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            overflow: hidden !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "        }\n",
        "\n",
        "        /* 視頻統計資料顯示增強 */\n",
        "        .video-stats-display {\n",
        "            background: white !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 1rem !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            width: 100% !important;\n",
        "            min-height: 200px !important;\n",
        "            max-height: 400px !important;\n",
        "            overflow-y: auto !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "            color: #2D3748 !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input {\n",
        "            width: 100% !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input textarea {\n",
        "            width: 100% !important;\n",
        "            min-height: 120px !important;\n",
        "            padding: 15px !important;\n",
        "            font-size: 16px !important;\n",
        "            line-height: 1.6 !important;\n",
        "            background-color: #F7FAFC !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "            border: 2px solid #CBD5E0 !important;\n",
        "            border-radius: 8px !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input textarea:focus {\n",
        "            border-color: #4299E1 !important;\n",
        "            box-shadow: 0 0 0 3px rgba(66, 153, 225, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        /* 輸入框容器100%寬度 */\n",
        "        .custom-video-url-input > div {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "        }\n",
        "\n",
        "        /* LLM 增強描述樣式 */\n",
        "        #llm_enhanced_description_text {\n",
        "            padding: 15px !important;\n",
        "            background-color: #ffffff !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            margin-bottom: 20px !important;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            line-height: 1.7 !important;\n",
        "            color: #2D3748 !important;\n",
        "            font-size: 16px !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            min-height: 200px !important;\n",
        "        }\n",
        "\n",
        "        /* 原始描述折疊區域樣式 */\n",
        "        #original_scene_analysis_accordion {\n",
        "            margin-top: 10px !important;\n",
        "            margin-bottom: 20px !important;\n",
        "            background-color: #f8f9fa !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "        }\n",
        "\n",
        "        /* 確保折疊區域內容與頁面樣式協調 */\n",
        "        #original_scene_analysis_accordion > div:nth-child(2) {\n",
        "            padding: 15px !important;\n",
        "        }\n",
        "\n",
        "        /* 動畫效果, 增加互動感 */\n",
        "        @keyframes fadeIn {\n",
        "            from { opacity: 0; }\n",
        "            to { opacity: 1; }\n",
        "        }\n",
        "\n",
        "        .video-result-panel > * {\n",
        "            animation: fadeIn 0.5s ease-in-out;\n",
        "        }\n",
        "\n",
        "        /* 響應式調整 */\n",
        "        @media (max-width: 768px) {\n",
        "            .app-title {\n",
        "                font-size: 2rem;\n",
        "            }\n",
        "\n",
        "            .app-subtitle {\n",
        "                font-size: 1rem;\n",
        "            }\n",
        "\n",
        "            .gradio-container {\n",
        "                padding: 0.5rem;\n",
        "            }\n",
        "\n",
        "            /* 在小螢幕上調整文本區域的高度 */\n",
        "            #scene-description-text, #detection-details {\n",
        "                min-height: 150px !important;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        \"\"\"\n",
        "        return css"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBOELeMbrVBS"
      },
      "outputs": [],
      "source": [
        "# %%writefile scene_type.py\n",
        "\n",
        "SCENE_TYPES = {\n",
        "    \"living_room\": {\n",
        "        \"name\": \"Living Room\",\n",
        "        \"required_objects\": [57, 62],  # couch, tv\n",
        "        \"optional_objects\": [56, 60, 73, 75],  # chair, dining table, book, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A living room area with furniture for relaxation and entertainment\"\n",
        "    },\n",
        "    \"bedroom\": {\n",
        "        \"name\": \"Bedroom\",\n",
        "        \"required_objects\": [59],  # bed\n",
        "        \"optional_objects\": [56, 60, 73, 74, 75],  # chair, dining table, book, clock, vase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A bedroom with sleeping furniture\"\n",
        "    },\n",
        "    \"dining_area\": {\n",
        "        \"name\": \"Dining Area\",\n",
        "        \"required_objects\": [60],  # dining table\n",
        "        \"optional_objects\": [56, 39, 41, 42, 43, 44, 45],  # chair, bottle, cup, fork, knife, spoon, bowl\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A dining area for meals\"\n",
        "    },\n",
        "    \"kitchen\": {\n",
        "        \"name\": \"Kitchen\",\n",
        "        \"required_objects\": [72, 68, 69, 71],  # refrigerator, microwave, oven, sink\n",
        "        \"optional_objects\": [39, 41, 42, 43, 44, 45],  # bottle, cup, fork, knife, spoon, bowl\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A kitchen area for food preparation\"\n",
        "    },\n",
        "    \"office_workspace\": {\n",
        "        \"name\": \"Office Workspace\",\n",
        "        \"required_objects\": [56, 63, 66, 64, 73],  # chair, laptop, keyboard, mouse, book\n",
        "        \"optional_objects\": [60, 74, 75, 67],  # dining table, clock, vase, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A workspace with computer equipment for office work\"\n",
        "    },\n",
        "    \"meeting_room\": {\n",
        "        \"name\": \"Meeting Room\",\n",
        "        \"required_objects\": [56, 60],  # chair, dining table\n",
        "        \"optional_objects\": [63, 62, 67],  # laptop, tv, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A room set up for meetings with multiple seating\"\n",
        "    },\n",
        "    \"city_street\": {\n",
        "        \"name\": \"City Street\",\n",
        "        \"required_objects\": [0, 1, 2, 3, 5, 7, 9],  # person, bicycle, car, motorcycle, bus, truck, traffic light\n",
        "        \"optional_objects\": [10, 11, 12, 24, 25, 26, 28],  # fire hydrant, stop sign, parking meter, backpack, umbrella, handbag, suitcase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A city street with traffic and pedestrians\"\n",
        "    },\n",
        "    \"parking_lot\": {\n",
        "        \"name\": \"Parking Lot\",\n",
        "        \"required_objects\": [2, 3, 5, 7],  # car, motorcycle, bus, truck\n",
        "        \"optional_objects\": [0, 11, 12],  # person, stop sign, parking meter\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A parking area with multiple vehicles\"\n",
        "    },\n",
        "    \"park_area\": {\n",
        "        \"name\": \"Park or Recreation Area\",\n",
        "        \"required_objects\": [0, 13],  # person, bench\n",
        "        \"optional_objects\": [1, 14, 16, 25, 33],  # bicycle, bird, dog, umbrella, kite\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An outdoor recreational area for leisure activities\"\n",
        "    },\n",
        "    \"retail_store\": {\n",
        "        \"name\": \"Retail Store\",\n",
        "        \"required_objects\": [0, 24, 26, 28],  # person, backpack, handbag, suitcase\n",
        "        \"optional_objects\": [39, 45, 67],  # bottle, bowl, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A retail environment with shoppers and merchandise\"\n",
        "    },\n",
        "    \"supermarket\": {\n",
        "        \"name\": \"Supermarket\",\n",
        "        \"required_objects\": [0, 24, 39, 46, 47, 49],  # person, backpack, bottle, banana, apple, orange\n",
        "        \"optional_objects\": [26, 37, 45, 48, 51, 52, 53, 54, 55],  # handbag, surfboard, bowl, sandwich, carrot, hot dog, pizza, donut, cake\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A supermarket with food items and shoppers\"\n",
        "    },\n",
        "    \"classroom\": {\n",
        "        \"name\": \"Classroom\",\n",
        "        \"required_objects\": [56, 60, 73],  # chair, dining table, book\n",
        "        \"optional_objects\": [63, 66, 67],  # laptop, keyboard, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A classroom environment set up for educational activities\"\n",
        "    },\n",
        "    \"conference_room\": {\n",
        "        \"name\": \"Conference Room\",\n",
        "        \"required_objects\": [56, 60, 63],  # chair, dining table, laptop\n",
        "        \"optional_objects\": [62, 67, 73],  # tv, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A conference room designed for meetings and presentations\"\n",
        "    },\n",
        "    \"cafe\": {\n",
        "        \"name\": \"Cafe\",\n",
        "        \"required_objects\": [56, 60, 41],  # chair, dining table, cup\n",
        "        \"optional_objects\": [39, 40, 63, 67, 73],  # bottle, wine glass, laptop, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A cafe setting with seating and beverages\"\n",
        "    },\n",
        "    \"library\": {\n",
        "        \"name\": \"Library\",\n",
        "        \"required_objects\": [56, 60, 73],  # chair, dining table, book\n",
        "        \"optional_objects\": [63, 67, 75],  # laptop, cell phone, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A library with books and reading areas\"\n",
        "    },\n",
        "    \"gym\": {\n",
        "        \"name\": \"Gym\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [24, 25, 28, 38],  # backpack, umbrella, suitcase, tennis racket\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A gym or fitness area for physical activities\"\n",
        "    },\n",
        "    \"beach\": {\n",
        "        \"name\": \"Beach\",\n",
        "        \"required_objects\": [0, 25, 29, 33, 37],  # person, umbrella, frisbee, kite, surfboard\n",
        "        \"optional_objects\": [1, 24, 26, 38],  # bicycle, backpack, handbag, tennis racket\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A beach area with people and recreational items\"\n",
        "    },\n",
        "    \"restaurant\": {\n",
        "        \"name\": \"Restaurant\",\n",
        "        \"required_objects\": [56, 60, 41, 42, 43, 44, 45],  # chair, dining table, cup, fork, knife, spoon, bowl\n",
        "        \"optional_objects\": [39, 40, 48, 49, 50, 51, 52, 53, 54, 55],  # bottle, wine glass, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A restaurant setting for dining with tables and eating utensils\"\n",
        "    },\n",
        "    \"train_station\": {\n",
        "        \"name\": \"Train Station\",\n",
        "        \"required_objects\": [0, 6],  # person, train\n",
        "        \"optional_objects\": [1, 2, 24, 28, 67],  # bicycle, car, backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A train station with train and passengers\"\n",
        "    },\n",
        "    \"airport\": {\n",
        "        \"name\": \"Airport\",\n",
        "        \"required_objects\": [0, 4, 28],  # person, airplane, suitcase\n",
        "        \"optional_objects\": [24, 25, 26, 67],  # backpack, umbrella, handbag, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An airport with planes and travelers carrying luggage\"\n",
        "    },\n",
        "      \"upscale_dining\": {\n",
        "        \"name\": \"Upscale Dining Area\",\n",
        "        \"required_objects\": [56, 60, 40, 41],  # chair, dining table, wine glass, cup\n",
        "        \"optional_objects\": [39, 42, 43, 44, 45, 62, 75],  # bottle, fork, knife, spoon, bowl, tv, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An elegantly designed dining space with refined furniture and decorative elements\"\n",
        "    },\n",
        "    \"asian_commercial_street\": {\n",
        "        \"name\": \"Asian Commercial Street\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 2, 3, 24, 25, 26, 28],  # bicycle, car, motorcycle, backpack, umbrella, handbag, suitcase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A bustling commercial street with shops, signage, and pedestrians in an Asian urban setting\"\n",
        "    },\n",
        "    \"financial_district\": {\n",
        "        \"name\": \"Financial District\",\n",
        "        \"required_objects\": [2, 5, 7, 9],  # car, bus, truck, traffic light\n",
        "        \"optional_objects\": [0, 1, 3, 8],  # person, bicycle, motorcycle, boat\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A major thoroughfare in a business district with high-rise buildings and traffic\"\n",
        "    },\n",
        "    \"urban_intersection\": {\n",
        "        \"name\": \"Urban Intersection\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A busy urban crossroad with pedestrian crossings and multiple traffic flows\"\n",
        "    },\n",
        "    \"transit_hub\": {\n",
        "        \"name\": \"Transit Hub\",\n",
        "        \"required_objects\": [0, 5, 6, 7],  # person, bus, train, truck\n",
        "        \"optional_objects\": [1, 2, 3, 9, 24, 28],  # bicycle, car, motorcycle, traffic light, backpack, suitcase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A transportation center where multiple modes of transit converge\"\n",
        "    },\n",
        "    \"shopping_district\": {\n",
        "        \"name\": \"Shopping District\",\n",
        "        \"required_objects\": [0, 24, 26],  # person, backpack, handbag\n",
        "        \"optional_objects\": [1, 2, 3, 25, 27, 28, 39, 67],  # bicycle, car, motorcycle, umbrella, tie, suitcase, bottle, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A retail-focused area with shops, pedestrians, and commercial activity\"\n",
        "    },\n",
        "     \"bus_stop\": {\n",
        "        \"name\": \"Bus Stop\",\n",
        "        \"required_objects\": [0, 5],  # person, bus\n",
        "        \"optional_objects\": [1, 2, 7, 24],  # bicycle, car, truck, backpack\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A roadside bus stop with waiting passengers and buses\"\n",
        "    },\n",
        "    \"bus_station\": {\n",
        "        \"name\": \"Bus Station\",\n",
        "        \"required_objects\": [0, 5, 7],  # person, bus, truck\n",
        "        \"optional_objects\": [24, 28, 67],  # backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A bus terminal with multiple buses and travelers\"\n",
        "    },\n",
        "    \"zoo\": {\n",
        "        \"name\": \"Zoo\",\n",
        "        \"required_objects\": [20, 22, 23],  # elephant, zebra, giraffe\n",
        "        \"optional_objects\": [0, 14, 16],  # person, bird, dog\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A zoo environment featuring large animal exhibits and visitors\"\n",
        "    },\n",
        "    \"harbor\": {\n",
        "        \"name\": \"Harbor\",\n",
        "        \"required_objects\": [8],  # boat\n",
        "        \"optional_objects\": [0, 2, 3, 39],  # person, car, motorcycle, bottle\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A harbor area with boats docked and surrounding traffic\"\n",
        "    },\n",
        "    \"playground\": {\n",
        "        \"name\": \"Playground\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [33, 24, 1],  # kite, backpack, bicycle\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An outdoor playground with people playing sports and games\"\n",
        "    },\n",
        "    \"sports_field\": {\n",
        "        \"name\": \"Sports Field\",\n",
        "        \"required_objects\": [32],  # sports ball\n",
        "        \"optional_objects\": [38, 34, 35],  # tennis racket, baseball bat, baseball glove\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A sports field set up for various ball games\"\n",
        "    },\n",
        "     \"narrow_commercial_alley\": {\n",
        "        \"name\": \"Narrow Commercial Alley\",\n",
        "        \"required_objects\": [0, 3],  # person, motorcycle\n",
        "        \"optional_objects\": [2, 7, 24, 26],  # car, truck, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A tight urban alley lined with shops, with pedestrians and light vehicles\"\n",
        "    },\n",
        "    \"daytime_shopping_street\": {\n",
        "        \"name\": \"Daytime Shopping Street\",\n",
        "        \"required_objects\": [0, 2],  # person, car\n",
        "        \"optional_objects\": [1, 3, 24, 26],  # bicycle, motorcycle, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A busy pedestrian street during daytime, featuring shops, vehicles, and shoppers\"\n",
        "    },\n",
        "    \"urban_pedestrian_crossing\": {\n",
        "        \"name\": \"Urban Pedestrian Crossing\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [2, 3, 5],  # car, motorcycle, bus\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A city street crossing with pedestrians and traffic signals\"\n",
        "    },\n",
        "    \"aerial_view_intersection\": {\n",
        "    \"name\": \"Aerial View Intersection\",\n",
        "    \"required_objects\": [0, 9],  # person, traffic light\n",
        "    \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "    \"minimum_required\": 1,\n",
        "    \"description\": \"An intersection viewed from above, showing crossing patterns and pedestrian movement\"\n",
        "    },\n",
        "    \"aerial_view_commercial_area\": {\n",
        "        \"name\": \"Aerial View Commercial Area\",\n",
        "        \"required_objects\": [0, 2],  # person, car\n",
        "        \"optional_objects\": [1, 3, 5, 7, 24, 26],  # bicycle, motorcycle, bus, truck, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A commercial or shopping area viewed from above showing pedestrians and urban layout\"\n",
        "    },\n",
        "    \"aerial_view_plaza\": {\n",
        "        \"name\": \"Aerial View Plaza\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [1, 2, 24, 25, 26],  # bicycle, car, backpack, umbrella, handbag\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An urban plaza or public square viewed from above with pedestrian activity\"\n",
        "    },\n",
        "\n",
        "    # specific cultural item\n",
        "    \"asian_night_market\": {\n",
        "        \"name\": \"Asian Night Market\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 3, 24, 26, 39, 41],  # bicycle, motorcycle, backpack, handbag, bottle, cup\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A vibrant night market scene typical in Asian cities with food stalls and crowds\"\n",
        "    },\n",
        "    \"asian_temple_area\": {\n",
        "        \"name\": \"Asian Temple Area\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 25, 26, 67, 75],  # backpack, umbrella, handbag, cell phone, vase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A traditional Asian temple complex with visitors and cultural elements\"\n",
        "    },\n",
        "\n",
        "    # specific time item\n",
        "    \"nighttime_street\": {\n",
        "        \"name\": \"Nighttime Street\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7, 67],  # bicycle, car, motorcycle, bus, truck, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An urban street at night with artificial lighting and nighttime activity\"\n",
        "    },\n",
        "    \"nighttime_commercial_district\": {\n",
        "        \"name\": \"Nighttime Commercial District\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 2, 3, 24, 26],  # bicycle, car, motorcycle, backpack, handbag\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A commercial district illuminated at night with neon signs and evening activity\"\n",
        "    },\n",
        "\n",
        "    # mixture enviroment item\n",
        "    \"indoor_outdoor_cafe\": {\n",
        "        \"name\": \"Indoor-Outdoor Cafe\",\n",
        "        \"required_objects\": [56, 60, 41],  # chair, dining table, cup\n",
        "        \"optional_objects\": [39, 40, 63, 67, 73],  # bottle, wine glass, laptop, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A cafe setting with both indoor elements and outdoor patio or sidewalk seating\"\n",
        "    },\n",
        "    \"transit_station_platform\": {\n",
        "        \"name\": \"Transit Station Platform\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [5, 6, 7, 24, 28, 67],  # bus, train, truck, backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A transit platform with waiting passengers and arriving/departing vehicles\"\n",
        "    },\n",
        "    \"sports_stadium\": {\n",
        "        \"name\": \"Sports Stadium\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [24, 38, 39, 41, 67],  # backpack, tennis racket, bottle, cup, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A sports stadium or arena with spectators and athletic activities\"\n",
        "    },\n",
        "    \"construction_site\": {\n",
        "        \"name\": \"Construction Site\",\n",
        "        \"required_objects\": [0, 7],  # person, truck\n",
        "        \"optional_objects\": [2, 3, 11, 76, 77, 78],  # car, motorcycle, fire hydrant, scissors, teddy bear, hair drier\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A construction site with workers, equipment, and building materials\"\n",
        "    },\n",
        "    \"medical_facility\": {\n",
        "        \"name\": \"Medical Facility\",\n",
        "        \"required_objects\": [0, 56, 60],  # person, chair, dining table\n",
        "        \"optional_objects\": [63, 64, 66, 67, 73],  # laptop, mouse, keyboard, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A medical facility such as hospital, clinic or doctor's office with medical staff and patients\"\n",
        "    },\n",
        "    \"educational_setting\": {\n",
        "        \"name\": \"Educational Setting\",\n",
        "        \"required_objects\": [0, 56, 60, 73],  # person, chair, dining table, book\n",
        "        \"optional_objects\": [63, 64, 66, 67, 74],  # laptop, mouse, keyboard, cell phone, clock\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An educational environment such as classroom, lecture hall or study area\"\n",
        "    },\n",
        "    \"aerial_view_intersection\": {\n",
        "        \"name\": \"Aerial View Intersection\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An intersection viewed from above, showing crossing patterns and pedestrian movement\",\n",
        "        \"viewpoint_indicator\": \"aerial\", # view side\n",
        "        \"key_features\": [\"crosswalk_pattern\", \"pedestrian_flow\", \"intersection_layout\"],  # key feature\n",
        "        \"detection_priority\": 10  # priority\n",
        "    },\n",
        "    \"perpendicular_crosswalk_intersection\": {\n",
        "        \"name\": \"Perpendicular Crosswalk Intersection\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7, 9],  # bicycle, car, motorcycle, bus, truck, traffic light\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An intersection with perpendicular crosswalks where pedestrians cross in multiple directions\",\n",
        "        \"viewpoint_indicator\": \"aerial\",\n",
        "        \"key_features\": [\"perpendicular_crosswalks\", \"pedestrian_crossing\", \"multi_directional_movement\"],\n",
        "        \"pattern_detection\": True, # specific pattern\n",
        "        \"detection_priority\": 15  #\n",
        "    },\n",
        "    \"beach_water_recreation\": {\n",
        "    \"name\": \"Beach/Water Recreation Area\",\n",
        "    \"required_objects\": [0, 37],  # person, surfboard\n",
        "    \"optional_objects\": [25, 33, 1, 8, 29, 24, 26, 39, 41],  # umbrella, kite, bicycle, boat, frisbee, backpack, handbag, bottle, cup\n",
        "    \"minimum_required\": 2,\n",
        "    \"description\": \"A beach or water recreation area with water sports equipment and beach accessories\"\n",
        "    },\n",
        "    \"sports_venue\": {\n",
        "    \"name\": \"Sports Venue\",\n",
        "    \"required_objects\": [0, 32],  # person, sports ball\n",
        "    \"optional_objects\": [34, 35, 38, 25, 24, 26, 39, 41],  # baseball bat, baseball glove, tennis racket, umbrella, backpack, handbag, bottle, cup\n",
        "    \"minimum_required\": 2,\n",
        "    \"description\": \"A professional sports venue with specialized sports equipment and spectator areas\"\n",
        "    },\n",
        "    \"professional_kitchen\": {\n",
        "    \"name\": \"Professional Kitchen\",\n",
        "    \"required_objects\": [43, 44, 45],  # knife, spoon, bowl\n",
        "    \"optional_objects\": [42, 39, 41, 68, 69, 71, 72, 0],  # fork, bottle, cup, microwave, oven, sink, refrigerator, person\n",
        "    \"minimum_required\": 3,\n",
        "    \"description\": \"A commercial kitchen with professional cooking equipment and food preparation areas\"\n",
        "    },\n",
        "    \"tourist_landmark\": {\n",
        "        \"name\": \"Tourist Landmark\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,  # 可能沒有人，但仍然是地標\n",
        "        \"description\": \"A location featuring a famous landmark with tourist activity\",\n",
        "        \"priority\": 1.2  # 提高優先級\n",
        "    },\n",
        "    \"natural_landmark\": {\n",
        "        \"name\": \"Natural Landmark\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,\n",
        "        \"description\": \"A natural landmark site with scenic views\",\n",
        "        \"priority\": 1.2\n",
        "    },\n",
        "    \"historical_monument\": {\n",
        "        \"name\": \"Historical Monument\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,\n",
        "        \"description\": \"A historical monument or heritage site\",\n",
        "        \"priority\": 1.2\n",
        "    },\n",
        "    \"general_indoor_space\": {\n",
        "        \"name\": \"General Indoor Space\",\n",
        "        \"required_objects\": [], # No strict required objects, depends on combination\n",
        "        \"optional_objects\": [\n",
        "            56, # chair\n",
        "            57, # couch\n",
        "            58, # potted plant\n",
        "            59, # bed\n",
        "            60, # dining table\n",
        "            61, # toilet\n",
        "            62, # tv\n",
        "            63, # laptop\n",
        "            66, # keyboard\n",
        "            67, # cell phone\n",
        "            73, # book\n",
        "            74, # clock\n",
        "            75, # vase\n",
        "            39, # bottle\n",
        "            41, # cup\n",
        "        ],\n",
        "        \"minimum_required\": 2, # Needs at least a few common indoor items\n",
        "        \"description\": \"An indoor area with various common household or functional items.\",\n",
        "        \"priority\": 0.8 # Lower priority than more specific scenes\n",
        "    },\n",
        "    \"generic_street_view\": {\n",
        "        \"name\": \"Generic Street View\",\n",
        "        \"required_objects\": [], # More about the combination\n",
        "        \"optional_objects\": [\n",
        "            0,  # person\n",
        "            1,  # bicycle\n",
        "            2,  # car\n",
        "            3,  # motorcycle\n",
        "            5,  # bus\n",
        "            7,  # truck\n",
        "            9,  # traffic light\n",
        "            10, # fire hydrant\n",
        "            11, # stop sign\n",
        "            13, # bench\n",
        "            # Consider adding building if YOLO detects it (not a standard COCO class for YOLOv8, but some custom models might)\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., a car and a person, or multiple vehicles\n",
        "        \"description\": \"An outdoor street view, likely in an urban or suburban setting, with vehicles and/or pedestrians.\",\n",
        "        \"priority\": 0.85\n",
        "    },\n",
        "    \"desk_area_workspace\": {\n",
        "        \"name\": \"Desk Area / Workspace\",\n",
        "        \"required_objects\": [\n",
        "            63, # laptop or 62 (tv as monitor) or 66 (keyboard)\n",
        "        ],\n",
        "        \"optional_objects\": [\n",
        "            56, # chair\n",
        "            60, # dining table (often used as a desk)\n",
        "            64, # mouse\n",
        "            66, # keyboard\n",
        "            73, # book\n",
        "            41, # cup\n",
        "            67, # cell phone\n",
        "            74, # clock\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., laptop and chair, or table and keyboard\n",
        "        \"description\": \"A workspace or desk area, typically featuring a computer and related accessories.\",\n",
        "        \"priority\": 0.9\n",
        "    },\n",
        "    \"outdoor_gathering_spot\": {\n",
        "        \"name\": \"Outdoor Gathering Spot\",\n",
        "        \"required_objects\": [\n",
        "            0,  # person\n",
        "        ],\n",
        "        \"optional_objects\": [\n",
        "            13, # bench\n",
        "            32, # sports ball\n",
        "            24, # backpack\n",
        "            25, # umbrella\n",
        "            29, # frisbee\n",
        "            33, # kite\n",
        "            58, # potted plant (if in a more structured park area)\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., person and bench, or multiple people\n",
        "        \"description\": \"An outdoor area where people might gather for leisure or activity.\",\n",
        "        \"priority\": 0.8\n",
        "    },\n",
        "    \"kitchen_counter_or_utility_area\": {\n",
        "        \"name\": \"Kitchen Counter or Utility Area\",\n",
        "        \"required_objects\": [],\n",
        "        \"optional_objects\": [\n",
        "            39, # bottle\n",
        "            41, # cup\n",
        "            44, # spoon\n",
        "            45, # bowl\n",
        "            68, # microwave\n",
        "            69, # oven\n",
        "            70, # toaster\n",
        "            71, # sink\n",
        "            72, # refrigerator\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., sink and microwave, or refrigerator and bottles\n",
        "        \"description\": \"An area likely used for food preparation or kitchen utilities.\",\n",
        "        \"priority\": 0.9\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDHYIPUCXGMF"
      },
      "outputs": [],
      "source": [
        "# %%writefile confifence_templates.py\n",
        "\n",
        "CONFIDENCE_TEMPLATES = {\n",
        "    \"high\": \"{description} {details}\",\n",
        "    \"medium\": \"This appears to be {description} {details}\",\n",
        "    \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUwQa_4KqHbm"
      },
      "outputs": [],
      "source": [
        "# %%writefile scene_detail_templates.py\n",
        "\n",
        "SCENE_DETAIL_TEMPLATES = {\n",
        "            \"living_room\": [\n",
        "                \"The space is arranged for relaxation with {furniture}.\",\n",
        "                \"There is {electronics} for entertainment.\",\n",
        "                \"The room has a seating area with {seating}.\"\n",
        "            ],\n",
        "            \"bedroom\": [\n",
        "                \"The room contains {bed_type} in the {bed_location}.\",\n",
        "                \"This sleeping area has {bed_description}.\",\n",
        "                \"A personal space with {bed_type} and {extras}.\"\n",
        "            ],\n",
        "            \"dining_area\": [\n",
        "                \"A space set up for meals with {table_setup}.\",\n",
        "                \"The dining area contains {table_description}.\",\n",
        "                \"A place for eating with {dining_items}.\"\n",
        "            ],\n",
        "            \"kitchen\": [\n",
        "                \"A food preparation area with {appliances}.\",\n",
        "                \"The kitchen contains {kitchen_items}.\",\n",
        "                \"A cooking space equipped with {cooking_equipment}.\"\n",
        "            ],\n",
        "            \"office_workspace\": [\n",
        "                \"A work environment with {office_equipment}.\",\n",
        "                \"A space designed for productivity with {desk_setup}.\",\n",
        "                \"A workspace containing {computer_equipment}.\"\n",
        "            ],\n",
        "            \"city_street\": [\n",
        "                \"An urban thoroughfare with {traffic_description}.\",\n",
        "                \"A street scene with {people_and_vehicles}.\",\n",
        "                \"A city path with {street_elements}.\"\n",
        "            ],\n",
        "            \"park_area\": [\n",
        "                \"An outdoor recreational space with {park_features}.\",\n",
        "                \"A leisure area featuring {outdoor_elements}.\",\n",
        "                \"A public outdoor space with {park_description}.\"\n",
        "            ],\n",
        "            \"retail_store\": [\n",
        "                \"A shopping environment with {store_elements}.\",\n",
        "                \"A commercial space where {shopping_activity}.\",\n",
        "                \"A retail area containing {store_items}.\"\n",
        "            ],\n",
        "            \"upscale_dining\": [\n",
        "            \"The space features {furniture} with {design_elements} for an elegant dining experience.\",\n",
        "            \"This sophisticated dining area includes {lighting} illuminating {table_setup}.\",\n",
        "            \"A stylish dining environment with {seating} arranged around {table_description}.\"\n",
        "            ],\n",
        "            \"asian_commercial_street\": [\n",
        "                \"A vibrant street lined with {storefront_features} and filled with {pedestrian_flow}.\",\n",
        "                \"This urban commercial area displays {asian_elements} with {cultural_elements}.\",\n",
        "                \"A lively shopping street characterized by {signage} and busy with {street_activities}.\"\n",
        "            ],\n",
        "            \"financial_district\": [\n",
        "                \"A canyon of {buildings} with {traffic_elements} moving through the urban landscape.\",\n",
        "                \"This business district features {skyscrapers} along {road_features}.\",\n",
        "                \"A downtown corridor with {architectural_elements} framing views of {city_landmarks}.\"\n",
        "            ],\n",
        "            \"urban_intersection\": [\n",
        "                \"A busy crossroad with {crossing_pattern} where {pedestrian_behavior} is observed.\",\n",
        "                \"This urban junction features {pedestrian_density} navigating the {traffic_pattern}.\",\n",
        "                \"A well-marked intersection designed for {pedestrian_flow} across multiple directions.\"\n",
        "            ],\n",
        "            \"transit_hub\": [\n",
        "                \"A transportation nexus where {transit_vehicles} arrive and depart amid {passenger_activity}.\",\n",
        "                \"This transit center accommodates {transportation_modes} with facilities for {passenger_needs}.\",\n",
        "                \"A busy transport hub featuring {transit_infrastructure} and areas for {passenger_movement}.\"\n",
        "            ],\n",
        "            \"shopping_district\": [\n",
        "                \"A commercial zone filled with {retail_elements} and {shopping_activity}.\",\n",
        "                \"This shopping area features {store_types} along {walkway_features}.\",\n",
        "                \"A retail district characterized by {commercial_signage} and {consumer_behavior}.\"\n",
        "            ],\n",
        "            \"bus_stop\": [\n",
        "                \"Passengers waiting at a roadside stop served by {transit_vehicles}.\",\n",
        "                \"A designated bus stop with shelters and {passenger_activity}.\",\n",
        "                \"Commuters boarding or alighting from {transit_vehicles} at the curb.\"\n",
        "            ],\n",
        "            \"bus_station\": [\n",
        "                \"Multiple buses parked in a terminal where {passenger_activity}.\",\n",
        "                \"A busy station hub featuring {transit_vehicles} and traveler luggage.\",\n",
        "                \"A transit center with waiting areas and various {transportation_modes}.\"\n",
        "            ],\n",
        "            \"zoo\": [\n",
        "                \"Enclosures showcasing elephants, zebras, and giraffes with visitors observing.\",\n",
        "                \"A wildlife exhibit area where families watch animal displays.\",\n",
        "                \"A recreational space featuring large animal exhibits and strolling guests.\"\n",
        "            ],\n",
        "            \"harbor\": [\n",
        "                \"Boats docked along the waterfront with nearby vehicular traffic.\",\n",
        "                \"A maritime area where vessels anchor beside roads busy with cars and motorcycles.\",\n",
        "                \"A coastal dock featuring moored boats and passing traffic elements.\"\n",
        "            ],\n",
        "            \"playground\": [\n",
        "                \"An open play area equipped with balls and recreational structures.\",\n",
        "                \"People engaging in games and sports in a communal space.\",\n",
        "                \"A leisure area featuring playground equipment and active participants.\"\n",
        "            ],\n",
        "            \"sports_field\": [\n",
        "                \"An athletic field marked for various ball games and matches.\",\n",
        "                \"Players using equipment like bats, gloves, and rackets on a grassy pitch.\",\n",
        "                \"A designated sports area with goalposts or markings for competitive play.\"\n",
        "            ],\n",
        "            \"narrow_commercial_alley\": [\n",
        "                \"A tight alley lined with {storefront_features} and light vehicles.\",\n",
        "                \"Pedestrians navigate a confined lane flanked by shops and {street_activities}.\",\n",
        "                \"An urban passage featuring {storefront_features} with {people_and_vehicles}.\"\n",
        "            ],\n",
        "            \"daytime_shopping_street\": [\n",
        "                \"A bustling street during daytime with {storefront_features} and {pedestrian_flow}.\",\n",
        "                \"Shoppers and vehicles move along a retail strip marked by {signage}.\",\n",
        "                \"An open commercial avenue filled with {people_and_vehicles} amid shops.\"\n",
        "            ],\n",
        "            \"urban_pedestrian_crossing\": [\n",
        "                \"A marked crosswalk with {crossing_pattern} under {lighting_modifier} sky.\",\n",
        "                \"Pedestrians use designated crossing with {traffic_pattern} at the intersection.\",\n",
        "                \"People waiting at a signal-controlled crossing next to {street_elements}.\"\n",
        "            ],\n",
        "            \"aerial_view_intersection\": [\n",
        "                \"The crossing pattern shows {crossing_pattern} with {pedestrian_flow} across multiple directions.\",\n",
        "                \"From above, this intersection reveals {traffic_pattern} with {pedestrian_density} navigating through defined paths.\",\n",
        "                \"This bird's-eye view shows {street_elements} converging at a junction where {pedestrian_behavior} is visible.\"\n",
        "            ],\n",
        "            \"aerial_view_commercial_area\": [\n",
        "                \"From above, this commercial zone shows {storefront_features} with {pedestrian_flow} moving between establishments.\",\n",
        "                \"This overhead view reveals {shopping_activity} amid {walkway_features} connecting different businesses.\",\n",
        "                \"The aerial perspective captures {retail_elements} organized along {commercial_layout} with visible customer activity.\"\n",
        "            ],\n",
        "            \"aerial_view_plaza\": [\n",
        "                \"This overhead view of the plaza shows {pedestrian_pattern} across an open public space.\",\n",
        "                \"From above, the plaza reveals {gathering_features} where people congregate in {movement_pattern}.\",\n",
        "                \"The aerial perspective captures {urban_elements} arranged around a central area where {public_activity} occurs.\"\n",
        "            ],\n",
        "            \"asian_night_market\": [\n",
        "                \"This bustling night market features {stall_elements} illuminated by {lighting_features} with crowds enjoying {food_elements}.\",\n",
        "                \"Rows of {vendor_stalls} line this vibrant market where {nighttime_activity} continues under {cultural_lighting}.\",\n",
        "                \"The market atmosphere is created by {asian_elements} and {night_market_sounds} amid {evening_crowd_behavior}.\"\n",
        "            ],\n",
        "            \"asian_temple_area\": [\n",
        "                \"This sacred space features {architectural_elements} displaying {cultural_symbols} with visitors engaging in {ritual_activities}.\",\n",
        "                \"The temple area contains {religious_structures} adorned with {decorative_features} where people practice {cultural_practices}.\",\n",
        "                \"Traditional {temple_architecture} creates a spiritual atmosphere enhanced by {sensory_elements} and {visitor_activities}.\"\n",
        "            ],\n",
        "            \"european_plaza\": [\n",
        "                \"This historic plaza is framed by {architectural_style} surrounding an open space where {public_activities} take place.\",\n",
        "                \"The European square features {historic_elements} and {urban_design} creating a space for {social_behaviors}.\",\n",
        "                \"Classical {european_features} define this public space where {tourist_activities} blend with {local_customs}.\"\n",
        "            ],\n",
        "            \"nighttime_street\": [\n",
        "                \"The night transforms this street with {lighting_effects} casting {shadow_patterns} across {urban_features}.\",\n",
        "                \"After dark, this urban corridor is defined by {illuminated_elements} with {evening_activities} visible in the artificial light.\",\n",
        "                \"The nocturnal street scene captures {light_sources} creating contrast between {lit_areas} and {shadowed_zones}.\"\n",
        "            ],\n",
        "            \"nighttime_commercial_district\": [\n",
        "                \"After sunset, this commercial area comes alive with {illuminated_signage} and {evening_activities} under {colorful_lighting}.\",\n",
        "                \"The district's nighttime character is defined by {neon_elements} highlighting {storefront_features} amid {night_crowd_behavior}.\",\n",
        "                \"Evening transforms this zone through {light_displays} that accentuate {building_features} and frame {nightlife_activities}.\"\n",
        "            ],\n",
        "            \"indoor_outdoor_cafe\": [\n",
        "                \"This cafe blends indoor comfort with outdoor atmosphere through {transitional_elements} connecting {indoor_features} with {outdoor_setting}.\",\n",
        "                \"Customers enjoy both {interior_amenities} and {exterior_features} in this space that bridges indoor comfort and outdoor ambiance.\",\n",
        "                \"The cafe design creates flow between {inside_elements} and {outside_spaces} allowing patrons to experience {dual_environment_benefits}.\"\n",
        "            ],\n",
        "            \"transit_station_platform\": [\n",
        "                \"This transit platform combines covered areas with open sections where {passenger_activities} occur while awaiting {transportation_types}.\",\n",
        "                \"The station design balances {sheltered_elements} with {exposed_areas} for passengers engaged in {waiting_behaviors}.\",\n",
        "                \"Commuters navigate between {indoor_facilities} and {platform_features} while {transit_routines} unfold around arriving vehicles.\"\n",
        "            ],\n",
        "            \"sports_stadium\": [\n",
        "                \"This athletic venue features {seating_arrangement} surrounding {playing_surface} where {sporting_activities} take place.\",\n",
        "                \"The stadium design incorporates {spectator_facilities} overlooking {competition_space} designed for {sports_events}.\",\n",
        "                \"Fans occupy {viewing_areas} arranged to maximize visibility of {field_elements} where athletes engage in {game_activities}.\"\n",
        "            ],\n",
        "            \"construction_site\": [\n",
        "                \"This development area shows {construction_equipment} amid {building_materials} where workers conduct {construction_activities}.\",\n",
        "                \"The construction process is visible through {work_elements} positioned around {structural_components} in various stages of completion.\",\n",
        "                \"Workers utilize {site_equipment} to transform {raw_materials} following {construction_process} stages.\"\n",
        "            ],\n",
        "            \"medical_facility\": [\n",
        "                \"This healthcare environment features {medical_elements} arranged to support {clinical_activities} in a {facility_design}.\",\n",
        "                \"The medical space incorporates {healthcare_features} where {patient_interactions} occur in a controlled environment.\",\n",
        "                \"Professional medical staff utilize {equipment_types} while conducting {care_procedures} in specialized {treatment_spaces}.\"\n",
        "            ],\n",
        "            \"educational_setting\": [\n",
        "                \"This learning environment contains {educational_furniture} arranged to facilitate {learning_activities} through {instructional_design}.\",\n",
        "                \"The educational space features {classroom_elements} organized for {teaching_methods} and {student_engagement}.\",\n",
        "                \"Students and educators interact within {learning_spaces} equipped with {educational_tools} supporting {knowledge_transfer}.\"\n",
        "            ],\n",
        "            \"beach_water_recreation\": [\n",
        "                \"A coastal recreation area with {beach_equipment} and people enjoying {water_activities}.\",\n",
        "                \"This shoreline space features {beach_equipment} where visitors engage in {water_activities}.\",\n",
        "                \"An outdoor water recreation zone with {beach_equipment} set up for {water_activities}.\"\n",
        "            ],\n",
        "            \"sports_venue\": [\n",
        "                \"A professional sports facility with {sports_equipment} arranged for {competitive_activities}.\",\n",
        "                \"This athletics venue features {sports_equipment} with spaces designated for {competitive_activities}.\",\n",
        "                \"A specialized sports arena containing {sports_equipment} designed for {competitive_activities}.\"\n",
        "            ],\n",
        "            \"professional_kitchen\": [\n",
        "                \"A commercial cooking space with {kitchen_equipment} organized for {food_preparation}.\",\n",
        "                \"This professional culinary area contains {kitchen_equipment} arranged in stations for {food_preparation}.\",\n",
        "                \"An industrial kitchen featuring {kitchen_equipment} designed for efficient {food_preparation}.\"\n",
        "            ],\n",
        "            \"tourist_landmark\": [\n",
        "                \"This notable landmark attracts visitors who come to see {landmark_features} and experience {tourist_activities}.\",\n",
        "                \"A famous landmark site where tourists can observe {landmark_features} and engage in {tourist_activities}.\",\n",
        "                \"This iconic landmark showcases {landmark_features} and is a popular destination for {tourist_activities}.\"\n",
        "            ],\n",
        "            \"natural_landmark\": [\n",
        "                \"This natural landmark features {landmark_features} and offers opportunities for {outdoor_activities}.\",\n",
        "                \"A scenic natural formation with {landmark_features} where visitors enjoy {outdoor_activities}.\",\n",
        "                \"This impressive natural landmark displays {landmark_features} and attracts nature enthusiasts for {outdoor_activities}.\"\n",
        "            ],\n",
        "            \"historical_monument\": [\n",
        "                \"This historical monument exhibits {landmark_features} and has significance related to {historical_elements}.\",\n",
        "                \"An important historical site featuring {landmark_features} and representing {historical_elements}.\",\n",
        "                \"This heritage monument showcases {landmark_features} and commemorates {historical_elements}.\"\n",
        "            ]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jraYFP_PXgVU"
      },
      "outputs": [],
      "source": [
        "# %%writefile object_template_fillers.py\n",
        "\n",
        "OBJECT_TEMPLATE_FILLERS = {\n",
        "                \"furniture\": [\"designer chairs\", \"wooden dining table\", \"stylish seating\", \"upholstered armchairs\", \"elegant dining furniture\"],\n",
        "                \"design_elements\": [\"art pieces\", \"decorative wreaths\", \"statement lighting\", \"seasonal decorations\", \"sophisticated decor\"],\n",
        "                \"lighting\": [\"pendant lights\", \"decorative fixtures\", \"geometric lighting\", \"modern chandeliers\", \"ambient illumination\"],\n",
        "                \"table_setup\": [\"elegantly set table\", \"tabletop decorations\", \"seasonal centerpieces\", \"formal place settings\", \"floral arrangements\"],\n",
        "                \"seating\": [\"upholstered chairs\", \"accent armchairs\", \"mixed seating styles\", \"designer dining chairs\", \"comfortable dining seats\"],\n",
        "                \"table_description\": [\"solid wood table\", \"designer dining table\", \"expansive dining surface\", \"artisanal table\", \"statement dining table\"],\n",
        "\n",
        "                \"storefront_features\": [\"multi-story shops\", \"illuminated signs\", \"merchandise displays\", \"compact storefronts\", \"vertical retail spaces\"],\n",
        "                \"pedestrian_flow\": [\"people walking\", \"shoppers\", \"pedestrians\", \"locals and tourists\", \"urban foot traffic\"],\n",
        "                \"asian_elements\": [\"Asian language signage\", \"decorative lanterns\", \"local storefronts\", \"character-based text\", \"regional design elements\"],\n",
        "                \"cultural_elements\": [\"red lanterns\", \"local typography\", \"distinctive architecture\", \"cultural symbols\", \"traditional decorations\"],\n",
        "                \"signage\": [\"bright store signs\", \"multilingual text\", \"vertical signboards\", \"neon displays\", \"electronic advertisements\"],\n",
        "                \"street_activities\": [\"shopping\", \"commuting\", \"socializing\", \"vendor transactions\", \"urban navigation\"],\n",
        "\n",
        "                \"buildings\": [\"high-rise office buildings\", \"corporate towers\", \"skyscrapers\", \"financial institutions\", \"commercial headquarters\"],\n",
        "                \"traffic_elements\": [\"vehicle lights\", \"trams/street cars\", \"lane markers\", \"traffic signals\", \"urban transit\"],\n",
        "                \"skyscrapers\": [\"glass and steel buildings\", \"tall structures\", \"modern architecture\", \"office towers\", \"urban high-rises\"],\n",
        "                \"road_features\": [\"wide avenues\", \"tram tracks\", \"traffic lanes\", \"median dividers\", \"urban throughways\"],\n",
        "                \"architectural_elements\": [\"contemporary buildings\", \"urban design\", \"varied architectural styles\", \"corporate architecture\", \"city planning features\"],\n",
        "                \"city_landmarks\": [\"distant bridge\", \"skyline features\", \"iconic structures\", \"urban monuments\", \"signature buildings\"],\n",
        "\n",
        "                \"crossing_pattern\": [\"zebra crosswalks\", \"pedestrian walkways\", \"crosswalk markings\", \"intersection design\", \"safety stripes\"],\n",
        "                \"pedestrian_density\": [\"groups of people\", \"commuters\", \"diverse pedestrians\", \"urban crowds\", \"varying foot traffic\"],\n",
        "                \"pedestrian_behavior\": [\"walking in different directions\", \"crossing together\", \"waiting for signals\", \"navigating intersections\", \"following traffic rules\"],\n",
        "                \"traffic_pattern\": [\"four-way intersection\", \"crossroad\", \"junction\", \"multi-directional traffic\", \"regulated crossing\"],\n",
        "                \"pedestrian_flow\": [\"people crossing\", \"directional movement\", \"coordinated crossing\", \"timed pedestrian traffic\", \"intersection navigation\"],\n",
        "\n",
        "                \"transit_vehicles\": [\"buses\", \"trams\", \"trains\", \"taxis\", \"shuttles\"],\n",
        "                \"passenger_activity\": [\"boarding\", \"waiting\", \"exiting vehicles\", \"checking schedules\", \"navigating stations\"],\n",
        "                \"transportation_modes\": [\"public transit\", \"private vehicles\", \"ride services\", \"light rail\", \"bus systems\"],\n",
        "                \"passenger_needs\": [\"waiting areas\", \"information displays\", \"ticketing services\", \"transit connections\", \"seating\"],\n",
        "                \"transit_infrastructure\": [\"stations\", \"platforms\", \"boarding areas\", \"transit lanes\", \"signaling systems\"],\n",
        "                \"passenger_movement\": [\"transfers\", \"entrances and exits\", \"queueing\", \"platform access\", \"terminal navigation\"],\n",
        "\n",
        "                \"retail_elements\": [\"storefronts\", \"display windows\", \"shopping bags\", \"merchandise\", \"retail signage\"],\n",
        "                \"shopping_activity\": [\"browsing\", \"carrying purchases\", \"window shopping\", \"social shopping\", \"consumer activities\"],\n",
        "                \"store_types\": [\"boutiques\", \"brand stores\", \"local shops\", \"chain retailers\", \"specialty stores\"],\n",
        "                \"walkway_features\": [\"pedestrian paths\", \"shopping promenades\", \"retail corridors\", \"commercial walkways\", \"shopping streets\"],\n",
        "                \"commercial_signage\": [\"brand logos\", \"sale announcements\", \"store names\", \"advertising displays\", \"digital signage\"],\n",
        "                \"consumer_behavior\": [\"shopping in groups\", \"individual browsing\", \"carrying bags\", \"examining products\", \"moving between stores\"],\n",
        "\n",
        "                \"beach_equipment\": [\"beach umbrellas\", \"surfboards\", \"beach towels\", \"sun protection\", \"recreational equipment\"],\n",
        "                \"water_activities\": [\"water sports\", \"surfing\", \"beach recreation\", \"sun bathing\", \"coastal leisure\"],\n",
        "                \"sports_equipment\": [\"game balls\", \"professional equipment\", \"athletic gear\", \"sports apparatus\", \"competition items\"],\n",
        "                \"competitive_activities\": [\"team sports\", \"athletic contests\", \"competitive games\", \"sporting events\", \"professional matches\"],\n",
        "                \"kitchen_equipment\": [\"professional appliances\", \"cooking stations\", \"preparation surfaces\", \"culinary tools\", \"industrial equipment\"],\n",
        "                \"food_preparation\": [\"meal production\", \"culinary operations\", \"food service preparation\", \"commercial cooking\", \"kitchen workflow\"],\n",
        "\n",
        "                \"crossing_pattern\": [\"grid-like pedestrian crossings\", \"multi-directional crosswalks\", \"cross-shaped intersection design\", \"perpendicular crossing lanes\", \"zebra-striped crosswalks viewed from above\"],\n",
        "                \"pedestrian_pattern\": [\"scattered distribution of people\", \"organized flow of pedestrians\", \"clustered gatherings\", \"radial movement patterns\", \"linear procession of individuals\"],\n",
        "                \"commercial_layout\": [\"parallel shopping streets\", \"interconnected shopping blocks\", \"radial marketplace design\", \"grid-like retail arrangement\", \"meandering commercial pathways\"],\n",
        "                \"movement_pattern\": [\"circular crowd motion\", \"directional pedestrian flow\", \"scattered individual movement\", \"converging foot traffic\", \"diverging pedestrian patterns\"],\n",
        "\n",
        "                \"stall_elements\": [\"food vendors with steaming woks\", \"trinket sellers with colorful displays\", \"lantern-lit stalls\", \"bamboo-framed shops\", \"canvas-covered market stands\"],\n",
        "                \"asian_elements\": [\"hanging red lanterns\", \"character-based signage\", \"ornate temple decorations\", \"traditional paper decorations\", \"stylized gateway arches\"],\n",
        "                \"cultural_lighting\": [\"paper lantern illumination\", \"neon character signs\", \"strung festival lights\", \"hanging light chains\", \"colorful shop front lighting\"],\n",
        "                \"architectural_elements\": [\"tiered pagoda roofs\", \"ornate dragon sculptures\", \"stone guardian statues\", \"intricately carved railings\", \"traditional wooden beams\"],\n",
        "                \"cultural_symbols\": [\"dharma wheels\", \"lotus motifs\", \"yin-yang symbols\", \"zodiac animal representations\", \"traditional calligraphy\"],\n",
        "                \"architectural_style\": [\"Baroque facades\", \"Gothic spires\", \"Renaissance colonnades\", \"Neoclassical pediments\", \"Medieval archways\"],\n",
        "                \"european_features\": [\"cobblestone paving\", \"ornate fountains\", \"bronze statuary\", \"wrought iron lampposts\", \"cafe terraces\"],\n",
        "\n",
        "                \"lighting_effects\": [\"streetlamp pools of light\", \"neon sign glow\", \"illuminated window squares\", \"headlight streams\", \"traffic signal flashes\"],\n",
        "                \"illuminated_elements\": [\"lit storefront windows\", \"glowing traffic signals\", \"illuminated advertising\", \"headlight-lit streets\", \"backlit silhouettes\"],\n",
        "                \"neon_elements\": [\"colorful shop signs\", \"animated light displays\", \"illuminated brand logos\", \"glowing storefront outlines\", \"digital advertising screens\"],\n",
        "                \"illuminated_signage\": [\"bright LED displays\", \"glowing brand names\", \"projected light advertisements\", \"illuminated menu boards\", \"digital information screens\"],\n",
        "                \"colorful_lighting\": [\"multi-colored neon\", \"warm ambient illumination\", \"cool blue accent lights\", \"festive string lighting\", \"dynamic color-changing displays\"],\n",
        "\n",
        "                \"transitional_elements\": [\"retractable glass walls\", \"indoor-outdoor bar counters\", \"terraced seating areas\", \"threshold planters\", \"partial canopy coverage\"],\n",
        "                \"indoor_features\": [\"climate-controlled spaces\", \"soft seating arrangements\", \"interior decor accents\", \"mood lighting fixtures\", \"sound-dampened areas\"],\n",
        "                \"outdoor_setting\": [\"sidewalk tables\", \"patio seating\", \"garden furniture\", \"open-air counters\", \"courtyard arrangements\"],\n",
        "                \"seating_arrangement\": [\"tiered spectator stands\", \"premium viewing boxes\", \"courtside seating\", \"general admission benches\", \"stadium chair rows\"],\n",
        "                \"playing_surface\": [\"marked court boundaries\", \"manicured field turf\", \"running tracks\", \"competition equipment\", \"sports field markers\"],\n",
        "                \"construction_equipment\": [\"tower cranes\", \"excavators\", \"cement mixers\", \"scaffolding structures\", \"construction barriers\"],\n",
        "                \"medical_elements\": [\"examination furniture\", \"monitoring equipment\", \"sanitation stations\", \"privacy screens\", \"medical supply carts\"],\n",
        "                \"educational_furniture\": [\"student desks\", \"lecture podiums\", \"laboratory benches\", \"learning stations\", \"collaborative workspace tables\"],\n",
        "\n",
        "                \"landmark_features\": [\"distinctive architecture\", \"iconic structural elements\", \"famous design features\", \"recognized silhouette\", \"impressive proportions\"],\n",
        "                \"tourist_activities\": [\"sightseeing\", \"guided tours\", \"photography\",  \"cultural exploration\", \"souvenir shopping\"],\n",
        "                \"outdoor_activities\": [\"nature photography\", \"hiking\",  \"scenic viewing\", \"wildlife observation\", \"outdoor exploration\"],\n",
        "                \"historical_elements\": [\"cultural heritage\", \"historical events\", \"architectural periods\", \"traditional craftsmanship\", \"significant achievements\"]\n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY-fgRtuXgTP"
      },
      "outputs": [],
      "source": [
        "# %%writefile safety_templates.py\n",
        "SAFETY_TEMPLATES = {\n",
        "    \"general\": \"Pay attention to {safety_element}.\",\n",
        "    \"warning\": \"Be cautious of {hazard} in this environment.\",\n",
        "    \"notice\": \"Note the presence of {element_of_interest}.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqOJTYVxXgQo"
      },
      "outputs": [],
      "source": [
        "# %%writefile activity_templates.py\n",
        "\n",
        "ACTIVITY_TEMPLATES = {\n",
        "            \"living_room\": [\n",
        "                \"Watching TV\",\n",
        "                \"Relaxing on the sofa\",\n",
        "                \"Reading\",\n",
        "                \"Socializing\"\n",
        "            ],\n",
        "            \"bedroom\": [\n",
        "                \"Sleeping\",\n",
        "                \"Resting\",\n",
        "                \"Getting dressed\",\n",
        "                \"Reading in bed\"\n",
        "            ],\n",
        "            \"dining_area\": [\n",
        "                \"Eating a meal\",\n",
        "                \"Having a conversation\",\n",
        "                \"Working at table\"\n",
        "            ],\n",
        "            \"kitchen\": [\n",
        "                \"Cooking\",\n",
        "                \"Food preparation\",\n",
        "                \"Cleaning dishes\"\n",
        "            ],\n",
        "            \"office_workspace\": [\n",
        "                \"Working on computer\",\n",
        "                \"Office work\",\n",
        "                \"Virtual meetings\",\n",
        "                \"Reading documents\"\n",
        "            ],\n",
        "            \"meeting_room\": [\n",
        "                \"Group meeting\",\n",
        "                \"Presentation\",\n",
        "                \"Team discussion\",\n",
        "                \"Collaboration\"\n",
        "            ],\n",
        "            \"city_street\": [\n",
        "                \"Walking\",\n",
        "                \"Commuting\",\n",
        "                \"Shopping\",\n",
        "                \"Waiting for transportation\"\n",
        "            ],\n",
        "            \"parking_lot\": [\n",
        "                \"Parking vehicles\",\n",
        "                \"Loading/unloading items\",\n",
        "                \"Entering/exiting vehicles\"\n",
        "            ],\n",
        "            \"park_area\": [\n",
        "                \"Walking\",\n",
        "                \"Relaxing outdoors\",\n",
        "                \"Exercising\",\n",
        "                \"Social gathering\"\n",
        "            ],\n",
        "            \"retail_store\": [\n",
        "                \"Shopping\",\n",
        "                \"Browsing products\",\n",
        "                \"Purchasing items\"\n",
        "            ],\n",
        "            \"supermarket\": [\n",
        "                \"Grocery shopping\",\n",
        "                \"Selecting products\",\n",
        "                \"Checking out\"\n",
        "            ],\n",
        "            \"upscale_dining\": [\n",
        "                \"Fine dining\",\n",
        "                \"Social gathering\",\n",
        "                \"Special occasion meal\",\n",
        "                \"Family dinner\",\n",
        "                \"Business meeting\",\n",
        "                \"Celebratory meal\"\n",
        "            ],\n",
        "            \"asian_commercial_street\": [\n",
        "                \"Shopping\",\n",
        "                \"Sightseeing\",\n",
        "                \"Walking to destinations\",\n",
        "                \"Visiting local shops\",\n",
        "                \"Cultural exploration\",\n",
        "                \"Urban commuting\",\n",
        "                \"Meeting friends\"\n",
        "            ],\n",
        "            \"financial_district\": [\n",
        "                \"Commuting\",\n",
        "                \"Business travel\",\n",
        "                \"Urban transit\",\n",
        "                \"Sightseeing\",\n",
        "                \"City navigation\",\n",
        "                \"Professional activities\",\n",
        "                \"Corporate meetings\"\n",
        "            ],\n",
        "            \"urban_intersection\": [\n",
        "                \"Street crossing\",\n",
        "                \"Waiting for signals\",\n",
        "                \"Urban navigation\",\n",
        "                \"Commuting\",\n",
        "                \"Group movement\",\n",
        "                \"Following traffic patterns\",\n",
        "                \"Pedestrian coordination\"\n",
        "            ],\n",
        "            \"transit_hub\": [\n",
        "                \"Commuting\",\n",
        "                \"Waiting for transportation\",\n",
        "                \"Transferring between vehicles\",\n",
        "                \"Starting/ending journeys\",\n",
        "                \"Meeting travelers\",\n",
        "                \"Checking transit schedules\",\n",
        "                \"Urban transportation\"\n",
        "            ],\n",
        "            \"shopping_district\": [\n",
        "                \"Retail shopping\",\n",
        "                \"Window browsing\",\n",
        "                \"Social shopping\",\n",
        "                \"Product comparison\",\n",
        "                \"Making purchases\",\n",
        "                \"Brand exploration\",\n",
        "                \"Recreational shopping\"\n",
        "            ],\n",
        "            \"bus_stop\": [\n",
        "                \"Waiting for the bus\",\n",
        "                \"Checking schedules\",\n",
        "                \"Boarding or alighting\",\n",
        "                \"Standing under shelter\"\n",
        "            ],\n",
        "            \"bus_station\": [\n",
        "                \"Navigating between platforms\",\n",
        "                \"Handling luggage\",\n",
        "                \"Boarding buses\",\n",
        "                \"Gathering at waiting areas\"\n",
        "            ],\n",
        "            \"zoo\": [\n",
        "                \"Watching animal exhibits\",\n",
        "                \"Taking photos of wildlife\",\n",
        "                \"Walking along enclosures\",\n",
        "                \"Reading informational signs\"\n",
        "            ],\n",
        "            \"harbor\": [\n",
        "                \"Observing docked boats\",\n",
        "                \"Commuting by watercraft\",\n",
        "                \"Loading or unloading cargo\",\n",
        "                \"Strolling along the pier\"\n",
        "            ],\n",
        "            \"playground\": [\n",
        "                \"Playing ball games\",\n",
        "                \"Swinging or sliding\",\n",
        "                \"Running around\",\n",
        "                \"Socializing with friends\"\n",
        "            ],\n",
        "            \"sports_field\": [\n",
        "                \"Practicing ball drills\",\n",
        "                \"Competing in matches\",\n",
        "                \"Warming up or stretching\",\n",
        "                \"Team training sessions\"\n",
        "            ],\n",
        "            \"narrow_commercial_alley\": [\n",
        "                \"Walking through alley\",\n",
        "                \"Browsing storefronts\",\n",
        "                \"Navigating light traffic\",\n",
        "                \"Carrying shopping bags\"\n",
        "            ],\n",
        "            \"daytime_shopping_street\": [\n",
        "                \"Shopping\",\n",
        "                \"Window browsing\",\n",
        "                \"Street photography\",\n",
        "                \"Commuting by vehicle\"\n",
        "            ],\n",
        "            \"urban_pedestrian_crossing\": [\n",
        "                \"Crossing the street\",\n",
        "                \"Waiting for signal\",\n",
        "                \"Following traffic rules\",\n",
        "                \"Checking for vehicles\"\n",
        "            ],\n",
        "            \"aerial_view_intersection\": [\n",
        "                \"Crossing multiple directions\",\n",
        "                \"Following traffic signals\",\n",
        "                \"Navigating pedestrian paths\",\n",
        "                \"Traffic management\",\n",
        "                \"Multi-directional movement\",\n",
        "                \"Organized crossing patterns\",\n",
        "                \"Waiting at signals\"\n",
        "            ],\n",
        "            \"aerial_view_commercial_area\": [\n",
        "                \"Shopping district navigation\",\n",
        "                \"Retail browsing\",\n",
        "                \"Store-to-store movement\",\n",
        "                \"Commercial zone foot traffic\",\n",
        "                \"Shopping center traversal\",\n",
        "                \"Retail area engagement\",\n",
        "                \"Walking between stores\"\n",
        "            ],\n",
        "            \"aerial_view_plaza\": [\n",
        "                \"Public gathering\",\n",
        "                \"Open space traversal\",\n",
        "                \"Community congregation\",\n",
        "                \"Plaza navigation\",\n",
        "                \"Public square activities\",\n",
        "                \"Urban space utilization\"\n",
        "            ],\n",
        "            \"asian_night_market\": [\n",
        "                \"Street food sampling\",\n",
        "                \"Night market browsing\",\n",
        "                \"Evening shopping\",\n",
        "                \"Cultural food exploration\",\n",
        "                \"Vendor interaction\",\n",
        "                \"Social night dining\",\n",
        "                \"Market stall hopping\"\n",
        "            ],\n",
        "            \"asian_temple_area\": [\n",
        "                \"Temple visiting\",\n",
        "                \"Cultural site exploration\",\n",
        "                \"Spiritual observance\",\n",
        "                \"Traditional rituals\",\n",
        "                \"Historical site appreciation\",\n",
        "                \"Religious tourism\",\n",
        "                \"Cultural photography\"\n",
        "            ],\n",
        "            \"european_plaza\": [\n",
        "                \"Urban sightseeing\",\n",
        "                \"Historical appreciation\",\n",
        "                \"Tourist photography\",\n",
        "                \"Public space relaxation\",\n",
        "                \"Casual strolling\"\n",
        "            ],\n",
        "            \"nighttime_street\": [\n",
        "                \"Evening commuting\",\n",
        "                \"Night walking\",\n",
        "                \"After-hours travel\",\n",
        "                \"Nighttime navigation\",\n",
        "                \"Evening errands\",\n",
        "                \"Late-night transportation\",\n",
        "                \"Nocturnal urban movement\"\n",
        "            ],\n",
        "            \"nighttime_commercial_district\": [\n",
        "                \"Evening shopping\",\n",
        "                \"Nightlife participation\",\n",
        "                \"Nighttime entertainment\",\n",
        "                \"After-dark dining\",\n",
        "                \"Evening social gathering\",\n",
        "                \"Night market browsing\",\n",
        "                \"Illumination appreciation\"\n",
        "            ],\n",
        "            \"indoor_outdoor_cafe\": [\n",
        "                \"Al fresco dining\",\n",
        "                \"Sidewalk coffee enjoyment\",\n",
        "                \"Indoor-outdoor socializing\",\n",
        "                \"Patio relaxation\",\n",
        "                \"Open-air refreshment\",\n",
        "                \"Transitional space usage\",\n",
        "                \"Weather-dependent positioning\"\n",
        "            ],\n",
        "            \"transit_station_platform\": [\n",
        "                \"Transit waiting\",\n",
        "                \"Platform navigation\",\n",
        "                \"Boarding preparation\",\n",
        "                \"Arrival monitoring\",\n",
        "                \"Schedule checking\",\n",
        "                \"Departure positioning\",\n",
        "                \"Platform traversal\"\n",
        "            ],\n",
        "            \"sports_stadium\": [\n",
        "                \"Spectator viewing\",\n",
        "                \"Sports fan cheering\",\n",
        "                \"Game attendance\",\n",
        "                \"Stadium navigation\",\n",
        "                \"Athletic event watching\",\n",
        "                \"Audience participation\",\n",
        "                \"Sports appreciation\"\n",
        "            ],\n",
        "            \"construction_site\": [\n",
        "                \"Construction work\",\n",
        "                \"Building development\",\n",
        "                \"Site management\",\n",
        "                \"Material handling\",\n",
        "                \"Construction supervision\",\n",
        "                \"Safety monitoring\",\n",
        "                \"Building process\"\n",
        "            ],\n",
        "            \"medical_facility\": [\n",
        "                \"Healthcare consultation\",\n",
        "                \"Medical treatment\",\n",
        "                \"Patient waiting\",\n",
        "                \"Healthcare delivery\",\n",
        "                \"Medical examination\",\n",
        "                \"Professional care\",\n",
        "                \"Health monitoring\"\n",
        "            ],\n",
        "            \"educational_setting\": [\n",
        "                \"Classroom learning\",\n",
        "                \"Educational instruction\",\n",
        "                \"Student participation\",\n",
        "                \"Academic engagement\",\n",
        "                \"Knowledge acquisition\",\n",
        "                \"Educational discussion\",\n",
        "                \"Scholastic activities\"\n",
        "            ],\n",
        "            \"beach_water_recreation\": [\n",
        "                \"Surfing\",\n",
        "                \"Sunbathing\",\n",
        "                \"Beach volleyball\",\n",
        "                \"Swimming\",\n",
        "                \"Relaxing by the water\",\n",
        "                \"Flying beach kites\",\n",
        "                \"Beach picnicking\",\n",
        "                \"Coastal walking\"\n",
        "            ],\n",
        "            \"sports_venue\": [\n",
        "                \"Professional game playing\",\n",
        "                \"Sports competition\",\n",
        "                \"Athletic training\",\n",
        "                \"Team practice\",\n",
        "                \"Spectator viewing\",\n",
        "                \"Sports coaching\",\n",
        "                \"Tournament participation\",\n",
        "                \"Athletic performance\"\n",
        "            ],\n",
        "            \"professional_kitchen\": [\n",
        "                \"Professional cooking\",\n",
        "                \"Food preparation\",\n",
        "                \"Meal service coordination\",\n",
        "                \"Kitchen operations\",\n",
        "                \"Culinary production\",\n",
        "                \"Chef activities\",\n",
        "                \"Commercial food handling\",\n",
        "                \"Restaurant meal preparation\"\n",
        "            ],\n",
        "            \"tourist_landmark\": [\n",
        "                \"Sightseeing\",\n",
        "                \"Photography\",\n",
        "                \"Guided tours\",\n",
        "                \"Learning about landmark history\",\n",
        "                \"Souvenir shopping\",\n",
        "                \"Cultural appreciation\",\n",
        "                \"Architectural observation\"\n",
        "            ],\n",
        "            \"natural_landmark\": [\n",
        "                \"Nature photography\",\n",
        "                \"Scenic viewing\",\n",
        "                \"Hiking\",\n",
        "                \"Nature appreciation\",\n",
        "                \"Wildlife watching\",\n",
        "                \"Outdoor recreation\",\n",
        "                \"Environmental education\"\n",
        "            ],\n",
        "            \"historical_monument\": [\n",
        "                \"Historical tours\",\n",
        "                \"Cultural heritage appreciation\",\n",
        "                \"Educational visits\",\n",
        "                \"Historical photography\",\n",
        "                \"Learning about past events\",\n",
        "                \"Architectural study\",\n",
        "                \"Heritage tourism\"\n",
        "            ],\n",
        "             \"general_indoor_space\": [\n",
        "                \"Engaging in general indoor activities\",\n",
        "                \"Resting or relaxing in an indoor setting\",\n",
        "                \"Possibly having a conversation or reading\"\n",
        "            ],\n",
        "            \"generic_street_view\": [\n",
        "                \"People walking or commuting\",\n",
        "                \"Vehicles driving on the road\",\n",
        "                \"Observing street traffic and urban activity\",\n",
        "                \"Waiting at a crosswalk or bus stop (if applicable objects present)\"\n",
        "            ],\n",
        "            \"desk_area_workspace\": [\n",
        "                \"Working on a computer or laptop\",\n",
        "                \"Studying or reading documents\",\n",
        "                \"Writing or taking notes\",\n",
        "                \"Participating in an online meeting (if computer present)\"\n",
        "            ],\n",
        "            \"outdoor_gathering_spot\": [\n",
        "                \"People socializing outdoors\",\n",
        "                \"Relaxing on a bench or in a park-like setting\",\n",
        "                \"Engaging in light recreational activities\",\n",
        "                \"Having a picnic (if food items or backpacks are present)\"\n",
        "            ],\n",
        "            \"kitchen_counter_or_utility_area\": [\n",
        "                \"Preparing food or drinks\",\n",
        "                \"Using kitchen appliances like a microwave or toaster\",\n",
        "                \"Washing dishes or cleaning\",\n",
        "                \"Storing food items\"\n",
        "            ]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDPI2oYww-eh"
      },
      "outputs": [],
      "source": [
        "# %%writefile object_categories.py\n",
        "OBJECT_CATEGORIES = {\n",
        "                \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "                \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "                \"kitchen_items\": [39, 40, 41, 42, 43, 44, 45],\n",
        "                \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "                \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "                \"personal_items\": [24, 25, 26, 27, 28, 73, 78, 79]\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslRwREno-GS"
      },
      "outputs": [],
      "source": [
        "# %%writefile lighting_conditions.py\n",
        "\n",
        "LIGHTING_CONDITIONS = {\n",
        "    \"time_descriptions\": {\n",
        "        \"day_clear\": {\n",
        "        \"general\": \"The scene is captured during clear daylight hours with bright natural lighting.\",\n",
        "        \"bright\": \"The scene is brightly lit with strong, clear daylight.\",\n",
        "        \"medium\": \"The scene is illuminated with moderate daylight under clear conditions.\",\n",
        "        \"dim\": \"The scene is captured in soft daylight on a clear day.\"\n",
        "        },\n",
        "        \"day_cloudy\": {\n",
        "        \"general\": \"The scene is captured during daytime under overcast conditions.\",\n",
        "        \"bright\": \"The scene has the diffused bright lighting of an overcast day.\",\n",
        "        \"medium\": \"The scene has even, soft lighting typical of a cloudy day.\",\n",
        "        \"dim\": \"The scene has the muted lighting of a heavily overcast day.\"\n",
        "        },\n",
        "         \"day_cloudy_gray\": {\n",
        "        \"general\": \"The scene is captured during an overcast day with muted gray lighting.\",\n",
        "        \"bright\": \"The scene has bright but diffused gray daylight from heavy cloud cover.\",\n",
        "        \"medium\": \"The scene has even, muted lighting typical of a gray, overcast day.\",\n",
        "        \"dim\": \"The scene has subdued lighting under thick gray clouds.\"\n",
        "        },\n",
        "        \"indoor_residential_natural\": {\n",
        "            \"general\": \"The scene is captured in a residential setting with natural window lighting.\",\n",
        "            \"bright\": \"The residential space is brightly lit with abundant natural light from windows.\",\n",
        "            \"medium\": \"The home interior has comfortable natural lighting complemented by artificial sources.\",\n",
        "            \"dim\": \"The residential space has soft natural lighting creating a cozy atmosphere.\"\n",
        "        },\n",
        "        \"indoor_designer_residential\": {\n",
        "            \"general\": \"The scene is captured in a well-designed residential space with curated lighting.\",\n",
        "            \"bright\": \"The residential interior features bright, designer lighting creating an elegant atmosphere.\",\n",
        "            \"medium\": \"The home space has thoughtfully planned lighting balancing aesthetics and functionality.\",\n",
        "            \"dim\": \"The residential area has sophisticated mood lighting enhancing the design elements.\"\n",
        "        },\n",
        "        \"indoor_bright_natural_mix\": {\n",
        "            \"general\": \"The scene is captured indoors with a blend of natural and artificial lighting.\",\n",
        "            \"bright\": \"The indoor space combines bright natural window light with artificial illumination.\",\n",
        "            \"medium\": \"The interior has balanced mixed lighting from windows and electric sources.\",\n",
        "            \"dim\": \"The indoor area has gentle mixed lighting creating comfortable illumination.\"\n",
        "        },\n",
        "        \"indoor_restaurant_bar\": {\n",
        "            \"general\": \"The scene is captured inside a restaurant or bar with characteristic warm lighting.\",\n",
        "            \"bright\": \"The dining establishment is well-lit with warm illumination emphasizing ambiance.\",\n",
        "            \"medium\": \"The restaurant/bar has moderate warm lighting creating a comfortable social atmosphere.\",\n",
        "            \"dim\": \"The establishment features soft, warm lighting creating an intimate dining or social atmosphere.\"\n",
        "        },\n",
        "        \"sunset/sunrise\": {\n",
        "        \"general\": \"The scene is captured during golden hour with warm lighting.\",\n",
        "        \"bright\": \"The scene is illuminated with bright golden hour light with long shadows.\",\n",
        "        \"medium\": \"The scene has the warm orange-yellow glow typical of sunset or sunrise.\",\n",
        "        \"dim\": \"The scene has soft, warm lighting characteristic of early sunrise or late sunset.\"\n",
        "        },\n",
        "        \"night\": {\n",
        "        \"general\": \"The scene is captured at night with limited natural lighting.\",\n",
        "        \"bright\": \"The scene is captured at night but well-lit with artificial lighting.\",\n",
        "        \"medium\": \"The scene is captured at night with moderate artificial lighting.\",\n",
        "        \"dim\": \"The scene is captured in low-light night conditions with minimal illumination.\"\n",
        "        },\n",
        "        \"indoor_bright\": {\n",
        "        \"general\": \"The scene is captured indoors with ample lighting.\",\n",
        "        \"bright\": \"The indoor space is brightly lit, possibly with natural light from windows.\",\n",
        "        \"medium\": \"The indoor space has good lighting conditions.\",\n",
        "        \"dim\": \"The indoor space has adequate lighting.\"\n",
        "        },\n",
        "        \"indoor_moderate\": {\n",
        "        \"general\": \"The scene is captured indoors with moderate lighting.\",\n",
        "        \"bright\": \"The indoor space has comfortable, moderate lighting.\",\n",
        "        \"medium\": \"The indoor space has standard interior lighting.\",\n",
        "        \"dim\": \"The indoor space has somewhat subdued lighting.\"\n",
        "        },\n",
        "        \"indoor_dim\": {\n",
        "        \"general\": \"The scene is captured indoors with dim or mood lighting.\",\n",
        "        \"bright\": \"The indoor space has dim but sufficient lighting.\",\n",
        "        \"medium\": \"The indoor space has low, atmospheric lighting.\",\n",
        "        \"dim\": \"The indoor space has very dim, possibly mood-oriented lighting.\"\n",
        "        },\n",
        "        \"beach_daylight\": {\n",
        "            \"general\": \"The scene is captured during daytime at a beach with bright natural sunlight.\",\n",
        "            \"bright\": \"The beach scene is intensely illuminated by direct sunlight.\",\n",
        "            \"medium\": \"The coastal area has even natural daylight.\",\n",
        "            \"dim\": \"The beach has softer lighting, possibly from a partially cloudy sky.\"\n",
        "        },\n",
        "        \"sports_arena\": {\n",
        "            \"general\": \"The scene is captured in a sports venue with specialized arena lighting.\",\n",
        "            \"bright\": \"The sports facility is brightly illuminated with powerful overhead lights.\",\n",
        "            \"medium\": \"The venue has standard sports event lighting providing clear visibility.\",\n",
        "            \"dim\": \"The sports area has reduced illumination, possibly before or after an event.\"\n",
        "        },\n",
        "        \"kitchen_working\": {\n",
        "            \"general\": \"The scene is captured in a professional kitchen with task-oriented lighting.\",\n",
        "            \"bright\": \"The kitchen is intensely illuminated with clear, functional lighting.\",\n",
        "            \"medium\": \"The culinary space has standard working lights focused on preparation areas.\",\n",
        "            \"dim\": \"The kitchen has reduced lighting, possibly during off-peak hours.\"\n",
        "        },\n",
        "        \"unknown\": {\n",
        "        \"general\": \"The lighting conditions in this scene are not easily determined.\"\n",
        "        }\n",
        "    },\n",
        "    \"template_modifiers\": {\n",
        "        \"day_clear\": \"brightly-lit\",\n",
        "        \"day_cloudy\": \"softly-lit\",\n",
        "        \"sunset/sunrise\": \"warmly-lit\",\n",
        "        \"night\": \"night-time\",\n",
        "        \"indoor_bright\": \"well-lit indoor\",\n",
        "        \"indoor_moderate\": \"indoor\",\n",
        "        \"indoor_dim\": \"dimly-lit indoor\",\n",
        "        \"indoor_commercial\": \"retail-lit\",\n",
        "        \"indoor_restaurant\": \"atmospherically-lit\",\n",
        "        \"neon_night\": \"neon-illuminated\",\n",
        "        \"stadium_lighting\": \"flood-lit\",\n",
        "        \"mixed_lighting\": \"transitionally-lit\",\n",
        "        \"beach_lighting\": \"sun-drenched\",\n",
        "        \"sports_venue_lighting\": \"arena-lit\",\n",
        "        \"professional_kitchen_lighting\": \"kitchen-task lit\",\n",
        "        \"day_cloudy_gray\": \"gray-lit\",\n",
        "        \"indoor_residential_natural\": \"naturally-lit residential\",\n",
        "        \"indoor_designer_residential\": \"designer-lit residential\",\n",
        "        \"indoor_bright_natural_mix\": \"mixed-lit indoor\",\n",
        "        \"unknown\": \"\"\n",
        "    },\n",
        "    \"activity_modifiers\": {\n",
        "        \"day_clear\": [\"active\", \"lively\", \"busy\"],\n",
        "        \"day_cloudy\": [\"calm\", \"relaxed\", \"casual\"],\n",
        "        \"sunset/sunrise\": [\"peaceful\", \"transitional\", \"atmospheric\"],\n",
        "        \"night\": [\"quiet\", \"subdued\", \"nocturnal\"],\n",
        "        \"indoor_bright\": [\"focused\", \"productive\", \"engaged\"],\n",
        "        \"indoor_moderate\": [\"comfortable\", \"social\", \"casual\"],\n",
        "        \"indoor_dim\": [\"intimate\", \"relaxed\", \"private\"],\n",
        "        \"indoor_commercial\": [\"shopping\", \"browsing\", \"consumer-oriented\"],\n",
        "        \"indoor_restaurant\": [\"dining\", \"social\", \"culinary\"],\n",
        "        \"neon_night\": [\"vibrant\", \"energetic\", \"night-life\"],\n",
        "        \"stadium_lighting\": [\"event-focused\", \"spectator-oriented\", \"performance-based\"],\n",
        "        \"mixed_lighting\": [\"transitional\", \"adaptable\", \"variable\"],\n",
        "        \"unknown\": []\n",
        "    },\n",
        "    \"indoor_commercial\": {\n",
        "    \"general\": \"The scene is captured inside a commercial setting with retail-optimized lighting.\",\n",
        "    \"bright\": \"The space is brightly illuminated with commercial display lighting to highlight merchandise.\",\n",
        "    \"medium\": \"The commercial interior has standard retail lighting that balances visibility and ambiance.\",\n",
        "    \"dim\": \"The commercial space has subdued lighting creating an upscale or intimate shopping atmosphere.\"\n",
        "    },\n",
        "    \"indoor_restaurant\": {\n",
        "        \"general\": \"The scene is captured inside a restaurant with characteristic dining lighting.\",\n",
        "        \"bright\": \"The restaurant is well-lit with clear illumination emphasizing food presentation.\",\n",
        "        \"medium\": \"The dining space has moderate lighting striking a balance between functionality and ambiance.\",\n",
        "        \"dim\": \"The restaurant features soft, low lighting creating an intimate dining atmosphere.\"\n",
        "    },\n",
        "    \"neon_night\": {\n",
        "        \"general\": \"The scene is captured at night with colorful neon lighting typical of entertainment districts.\",\n",
        "        \"bright\": \"The night scene is illuminated by vibrant neon signs creating a lively, colorful atmosphere.\",\n",
        "        \"medium\": \"The evening setting features moderate neon lighting creating a characteristic urban nightlife scene.\",\n",
        "        \"dim\": \"The night area has subtle neon accents against the darkness, creating a moody urban atmosphere.\"\n",
        "    },\n",
        "    \"stadium_lighting\": {\n",
        "        \"general\": \"The scene is captured under powerful stadium lights designed for spectator events.\",\n",
        "        \"bright\": \"The venue is intensely illuminated by stadium floodlights creating daylight-like conditions.\",\n",
        "        \"medium\": \"The sports facility has standard event lighting providing clear visibility across the venue.\",\n",
        "        \"dim\": \"The stadium has reduced illumination typical of pre-event or post-event conditions.\"\n",
        "    },\n",
        "    \"mixed_lighting\": {\n",
        "        \"general\": \"The scene features a mix of indoor and outdoor lighting creating transitional illumination.\",\n",
        "        \"bright\": \"The space blends bright natural and artificial light sources across indoor-outdoor boundaries.\",\n",
        "        \"medium\": \"The area combines moderate indoor lighting with outdoor illumination in a balanced way.\",\n",
        "        \"dim\": \"The transition space features subtle lighting gradients between indoor and outdoor zones.\"\n",
        "    },\n",
        "    \"stadium_or_floodlit_area\": {\n",
        "    \"general\": \"The scene is captured under powerful floodlights creating uniform bright illumination.\",\n",
        "    \"bright\": \"The area is intensely illuminated by floodlights, similar to stadium conditions.\",\n",
        "    \"medium\": \"The space has even, powerful lighting typical of sports facilities or outdoor events.\",\n",
        "    \"dim\": \"The area has moderate floodlight illumination providing consistent lighting across the space.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noAkFOxfchU0"
      },
      "outputs": [],
      "source": [
        "# %%writefile viewpoint_templates.py\n",
        "\n",
        "VIEWPOINT_TEMPLATES = {\n",
        "    \"eye_level\": {\n",
        "        \"prefix\": \"From a standard eye-level perspective, \",\n",
        "        \"observation\": \"the scene shows {scene_elements} arranged in a typical front-facing view.\"\n",
        "    },\n",
        "    \"aerial\": {\n",
        "        \"prefix\": \"From an aerial perspective, \",\n",
        "        \"observation\": \"the scene shows {scene_elements} as viewed from above, revealing the spatial layout.\"\n",
        "    },\n",
        "    \"elevated\": {\n",
        "        \"prefix\": \"From an elevated viewpoint, \",\n",
        "        \"observation\": \"the scene presents {scene_elements} with a slight downward angle.\"\n",
        "    },\n",
        "    \"low_angle\": {\n",
        "        \"prefix\": \"From a low angle, \",\n",
        "        \"observation\": \"the scene depicts {scene_elements} from below, emphasizing vertical elements.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay8jbYNpchSj"
      },
      "outputs": [],
      "source": [
        "# %%writefile cultural_templates.py\n",
        "\n",
        "CULTURAL_TEMPLATES = {\n",
        "    \"asian\": {\n",
        "        \"elements\": [\"character signage\", \"lanterns\", \"dense urban layout\"],\n",
        "        \"description\": \"The scene shows distinctive Asian cultural elements such as {elements}.\"\n",
        "    },\n",
        "    \"european\": {\n",
        "        \"elements\": [\"classical architecture\", \"cobblestone streets\", \"café terraces\"],\n",
        "        \"description\": \"The environment has European characteristics including {elements}.\"\n",
        "    },\n",
        "    \"middle_eastern\": {\n",
        "        \"elements\": [\"ornate archways\", \"geometric patterns\", \"domed structures\"],\n",
        "        \"description\": \"The scene contains Middle Eastern architectural features such as {elements}.\"\n",
        "    },\n",
        "    \"north_american\": {\n",
        "        \"elements\": [\"grid street pattern\", \"modern skyscrapers\", \"wide boulevards\"],\n",
        "        \"description\": \"The layout shows typical North American urban design with {elements}.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNbiE_7aW_WA"
      },
      "outputs": [],
      "source": [
        "# %%writefile spatial_analyzer.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from enhance_scene_describer import EnhancedSceneDescriber\n",
        "\n",
        "class SpatialAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes spatial relationships between objects in an image.\n",
        "    Handles region assignment, object positioning, and functional zone identification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, object_categories=None):\n",
        "        \"\"\"Initialize the spatial analyzer with image regions\"\"\"\n",
        "        # Define regions of the image (3x3 grid)\n",
        "        self.regions = {\n",
        "            \"top_left\": (0, 0, 1/3, 1/3),\n",
        "            \"top_center\": (1/3, 0, 2/3, 1/3),\n",
        "            \"top_right\": (2/3, 0, 1, 1/3),\n",
        "            \"middle_left\": (0, 1/3, 1/3, 2/3),\n",
        "            \"middle_center\": (1/3, 1/3, 2/3, 2/3),\n",
        "            \"middle_right\": (2/3, 1/3, 1, 2/3),\n",
        "            \"bottom_left\": (0, 2/3, 1/3, 1),\n",
        "            \"bottom_center\": (1/3, 2/3, 2/3, 1),\n",
        "            \"bottom_right\": (2/3, 2/3, 1, 1)\n",
        "        }\n",
        "\n",
        "        self.class_names = class_names\n",
        "        self.OBJECT_CATEGORIES = object_categories or {}\n",
        "        self.enhance_descriptor = EnhancedSceneDescriber(scene_types=SCENE_TYPES)\n",
        "\n",
        "        # Distances thresholds for proximity analysis (normalized)\n",
        "        self.proximity_threshold = 0.2\n",
        "\n",
        "\n",
        "    def _determine_region(self, x: float, y: float) -> str:\n",
        "        \"\"\"\n",
        "        Determine which region a point falls into.\n",
        "\n",
        "        Args:\n",
        "            x: Normalized x-coordinate (0-1)\n",
        "            y: Normalized y-coordinate (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Region name\n",
        "        \"\"\"\n",
        "        for region_name, (x1, y1, x2, y2) in self.regions.items():\n",
        "            if x1 <= x < x2 and y1 <= y < y2:\n",
        "                return region_name\n",
        "\n",
        "        return \"unknown\"\n",
        "\n",
        "    def _analyze_regions(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze object distribution across image regions.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects with position information\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with region analysis\n",
        "        \"\"\"\n",
        "        # Count objects in each region\n",
        "        region_counts = {region: 0 for region in self.regions.keys()}\n",
        "        region_objects = {region: [] for region in self.regions.keys()}\n",
        "\n",
        "        for obj in detected_objects:\n",
        "            region = obj[\"region\"]\n",
        "            if region in region_counts:\n",
        "                region_counts[region] += 1\n",
        "                region_objects[region].append({\n",
        "                    \"class_id\": obj[\"class_id\"],\n",
        "                    \"class_name\": obj[\"class_name\"]\n",
        "                })\n",
        "\n",
        "        # Determine main focus regions (top 1-2 regions by object count)\n",
        "        sorted_regions = sorted(region_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        main_regions = [region for region, count in sorted_regions if count > 0][:2]\n",
        "\n",
        "        return {\n",
        "            \"counts\": region_counts,\n",
        "            \"main_focus\": main_regions,\n",
        "            \"objects_by_region\": region_objects\n",
        "        }\n",
        "\n",
        "    def _extract_detected_objects(self, detection_result: Any, confidence_threshold: float = 0.25) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Extract detected objects from detection result with position information.\n",
        "\n",
        "        Args:\n",
        "            detection_result: Detection result from YOLOv8\n",
        "            confidence_threshold: Minimum confidence threshold\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries with detected object information\n",
        "        \"\"\"\n",
        "        boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
        "        classes = detection_result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = detection_result.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Image dimensions\n",
        "        img_height, img_width = detection_result.orig_shape[:2]\n",
        "\n",
        "        detected_objects = []\n",
        "        for box, class_id, confidence in zip(boxes, classes, confidences):\n",
        "            # Skip objects with confidence below threshold\n",
        "            if confidence < confidence_threshold:\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = box\n",
        "            width = x2 - x1\n",
        "            height = y2 - y1\n",
        "\n",
        "            # Center point\n",
        "            center_x = (x1 + x2) / 2\n",
        "            center_y = (y1 + y2) / 2\n",
        "\n",
        "            # Normalized positions (0-1)\n",
        "            norm_x = center_x / img_width\n",
        "            norm_y = center_y / img_height\n",
        "            norm_width = width / img_width\n",
        "            norm_height = height / img_height\n",
        "\n",
        "            # Area calculation\n",
        "            area = width * height\n",
        "            norm_area = area / (img_width * img_height)\n",
        "\n",
        "            # Region determination\n",
        "            object_region = self._determine_region(norm_x, norm_y)\n",
        "\n",
        "            detected_objects.append({\n",
        "                \"class_id\": int(class_id),\n",
        "                \"class_name\": self.class_names[int(class_id)],\n",
        "                \"confidence\": float(confidence),\n",
        "                \"box\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                \"center\": [float(center_x), float(center_y)],\n",
        "                \"normalized_center\": [float(norm_x), float(norm_y)],\n",
        "                \"size\": [float(width), float(height)],\n",
        "                \"normalized_size\": [float(norm_width), float(norm_height)],\n",
        "                \"area\": float(area),\n",
        "                \"normalized_area\": float(norm_area),\n",
        "                \"region\": object_region\n",
        "            })\n",
        "\n",
        "        return detected_objects\n",
        "\n",
        "\n",
        "    def _detect_scene_viewpoint(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        檢測場景視角並識別特殊場景模式。\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含視角和場景模式信息的字典\n",
        "        \"\"\"\n",
        "        if not detected_objects:\n",
        "            return {\"viewpoint\": \"eye_level\", \"patterns\": []}\n",
        "\n",
        "        # 從物體位置中提取信息\n",
        "        patterns = []\n",
        "\n",
        "        # 檢測行人位置模式\n",
        "        pedestrian_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "\n",
        "        # 檢查是否有足夠的行人來識別模式\n",
        "        if len(pedestrian_objs) >= 4:\n",
        "            pedestrian_positions = [obj[\"normalized_center\"] for obj in pedestrian_objs]\n",
        "\n",
        "            # 檢測十字交叉模式\n",
        "            if self._detect_cross_pattern(pedestrian_positions):\n",
        "                patterns.append(\"crosswalk_intersection\")\n",
        "\n",
        "            # 檢測多方向行人流\n",
        "            directions = self._analyze_movement_directions(pedestrian_positions)\n",
        "            if len(directions) >= 2:\n",
        "                patterns.append(\"multi_directional_movement\")\n",
        "\n",
        "        # 檢查物體的大小一致性 - 在空中俯視圖中，物體大小通常更一致\n",
        "        if len(detected_objects) >= 5:\n",
        "            sizes = [obj.get(\"normalized_area\", 0) for obj in detected_objects]\n",
        "            size_variance = np.var(sizes) / (np.mean(sizes) ** 2)  # 標準化變異數，不會受到平均值影響\n",
        "\n",
        "            if size_variance < 0.3:  # 低變異表示大小一致\n",
        "                patterns.append(\"consistent_object_size\")\n",
        "\n",
        "        # 基本視角檢測\n",
        "        viewpoint = self.enhance_descriptor._detect_viewpoint(detected_objects)\n",
        "\n",
        "        # 根據檢測到的模式增強視角判斷\n",
        "        if \"crosswalk_intersection\" in patterns and viewpoint != \"aerial\":\n",
        "            # 如果檢測到斑馬線交叉但視角判斷不是空中視角，優先採用模式判斷\n",
        "            viewpoint = \"aerial\"\n",
        "\n",
        "        return {\n",
        "            \"viewpoint\": viewpoint,\n",
        "            \"patterns\": patterns\n",
        "        }\n",
        "\n",
        "    def _detect_cross_pattern(self, positions):\n",
        "        \"\"\"\n",
        "        檢測位置中的十字交叉模式\n",
        "\n",
        "        Args:\n",
        "            positions: 位置列表 [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否檢測到十字交叉模式\n",
        "        \"\"\"\n",
        "        if len(positions) < 8:  # 需要足夠多的點\n",
        "            return False\n",
        "\n",
        "        # 提取 x 和 y 坐標\n",
        "        x_coords = [pos[0] for pos in positions]\n",
        "        y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "        # 檢測 x 和 y 方向的聚類\n",
        "        x_clusters = []\n",
        "        y_clusters = []\n",
        "\n",
        "        # 簡化的聚類分析\n",
        "        x_mean = np.mean(x_coords)\n",
        "        y_mean = np.mean(y_coords)\n",
        "\n",
        "        # 計算在中心線附近的點\n",
        "        near_x_center = sum(1 for x in x_coords if abs(x - x_mean) < 0.1)\n",
        "        near_y_center = sum(1 for y in y_coords if abs(y - y_mean) < 0.1)\n",
        "\n",
        "        # 如果有足夠的點在中心線附近，可能是十字交叉\n",
        "        return near_x_center >= 3 and near_y_center >= 3\n",
        "\n",
        "    def _analyze_movement_directions(self, positions):\n",
        "        \"\"\"\n",
        "        分析位置中的移動方向\n",
        "\n",
        "        Args:\n",
        "            positions: 位置列表 [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "        Returns:\n",
        "            list: 檢測到的主要方向\n",
        "        \"\"\"\n",
        "        if len(positions) < 6:\n",
        "            return []\n",
        "\n",
        "        # extract x 和 y 坐標\n",
        "        x_coords = [pos[0] for pos in positions]\n",
        "        y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "        directions = []\n",
        "\n",
        "        # horizontal move (left --> right)\n",
        "        x_std = np.std(x_coords)\n",
        "        x_range = max(x_coords) - min(x_coords)\n",
        "\n",
        "        # vertical move(up --> down)\n",
        "        y_std = np.std(y_coords)\n",
        "        y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "        # 足夠大的範圍表示該方向有運動\n",
        "        if x_range > 0.4:\n",
        "            directions.append(\"horizontal\")\n",
        "        if y_range > 0.4:\n",
        "            directions.append(\"vertical\")\n",
        "\n",
        "        return directions\n",
        "\n",
        "    def _identify_functional_zones(self, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones within the scene with improved detection for different viewpoints\n",
        "        and cultural contexts.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Identified scene type\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of functional zones with their descriptions\n",
        "        \"\"\"\n",
        "        # Group objects by category and region\n",
        "        category_regions = {}\n",
        "\n",
        "        if not getattr(self, 'enable_landmark', True):\n",
        "            detected_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "\n",
        "        # 過濾地標相關場景類型\n",
        "        if scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "            scene_type = \"city_street\"\n",
        "\n",
        "        # MODIFIED: Smart threshold evaluation instead of fixed values\n",
        "        should_identify = self._evaluate_zone_identification_feasibility(detected_objects, scene_type)\n",
        "\n",
        "        if not should_identify:\n",
        "            return {}\n",
        "\n",
        "        # MODIFIED: Build category_regions mapping (was missing in original)\n",
        "        for obj in detected_objects:\n",
        "            category = self._categorize_object(obj)\n",
        "            if not category:\n",
        "                continue\n",
        "\n",
        "            if category not in category_regions:\n",
        "                category_regions[category] = {}\n",
        "\n",
        "            region = obj.get(\"region\", \"center\")\n",
        "            if region not in category_regions[category]:\n",
        "                category_regions[category][region] = []\n",
        "\n",
        "            category_regions[category][region].append(obj)\n",
        "\n",
        "        # Identify zones based on object groupings\n",
        "        zones = {}\n",
        "\n",
        "        # Detect viewpoint to adjust zone identification strategy\n",
        "        viewpoint = self._detect_scene_viewpoint(detected_objects)\n",
        "\n",
        "        # Choose appropriate zone identification strategy based on scene type and viewpoint\n",
        "        if scene_type in [\"living_room\", \"bedroom\", \"dining_area\", \"kitchen\", \"office_workspace\", \"meeting_room\"]:\n",
        "            # Indoor scenes\n",
        "            zones.update(self._identify_indoor_zones(category_regions, detected_objects, scene_type))\n",
        "        elif scene_type in [\"city_street\", \"parking_lot\", \"park_area\"]:\n",
        "            # Outdoor general scenes\n",
        "            zones.update(self._identify_outdoor_general_zones(category_regions, detected_objects, scene_type))\n",
        "        elif \"aerial\" in scene_type or viewpoint == \"aerial\":\n",
        "            # Aerial viewpoint scenes\n",
        "            zones.update(self._identify_aerial_view_zones(category_regions, detected_objects, scene_type))\n",
        "        elif \"asian\" in scene_type:\n",
        "            # Asian cultural context scenes\n",
        "            zones.update(self._identify_asian_cultural_zones(category_regions, detected_objects, scene_type))\n",
        "        elif scene_type == \"urban_intersection\":\n",
        "            # Specific urban intersection logic\n",
        "            zones.update(self._identify_intersection_zones(category_regions, detected_objects, viewpoint))\n",
        "        elif scene_type == \"financial_district\":\n",
        "            # Financial district specific logic\n",
        "            zones.update(self._identify_financial_district_zones(category_regions, detected_objects))\n",
        "        elif scene_type == \"upscale_dining\":\n",
        "            # Upscale dining specific logic\n",
        "            zones.update(self._identify_upscale_dining_zones(category_regions, detected_objects))\n",
        "        elif scene_type == \"tourist_landmark\" or \"landmark\" in scene_type:\n",
        "            # 處理地標場景類型\n",
        "            landmark_objects = [obj for obj in detected_objects if obj.get(\"is_landmark\", False)]\n",
        "            if landmark_objects:\n",
        "                landmark_zones = self._identify_landmark_zones(landmark_objects)\n",
        "                zones.update(landmark_zones)\n",
        "        else:\n",
        "            # Default zone identification for other scene types\n",
        "            zones.update(self._identify_default_zones(category_regions, detected_objects))\n",
        "\n",
        "        # 檢查是否有地標物體但場景類型不是地標類型\n",
        "        if scene_type != \"tourist_landmark\" and \"landmark\" not in scene_type:\n",
        "            landmark_objects = [obj for obj in detected_objects if obj.get(\"is_landmark\", False)]\n",
        "            if landmark_objects:\n",
        "                # 添加地標功能區，但不覆蓋已有的功能區\n",
        "                landmark_zones = self._identify_landmark_zones(landmark_objects)\n",
        "                # 確保地標區域不會覆蓋已識別的其他重要功能區\n",
        "                for zone_id, zone_info in landmark_zones.items():\n",
        "                    if zone_id not in zones:\n",
        "                        zones[zone_id] = zone_info\n",
        "\n",
        "        # MODIFIED: Enhanced fallback strategy - try simplified identification if no zones found\n",
        "        if not zones:\n",
        "            zones.update(self._identify_default_zones(category_regions, detected_objects))\n",
        "\n",
        "            # Final fallback: create basic zones from high-confidence objects\n",
        "            if not zones:\n",
        "                zones.update(self._create_basic_zones_from_objects(detected_objects, scene_type))\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_core_objects_for_scene(self, detected_objects: List[Dict], scene_type: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Identify core objects that define a particular scene type.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Scene type\n",
        "\n",
        "        Returns:\n",
        "            List of core objects for the scene\n",
        "        \"\"\"\n",
        "        core_objects = []\n",
        "\n",
        "        scene_core_mapping = {\n",
        "            \"bedroom\": [59],  # bed\n",
        "            \"kitchen\": [68, 69, 71, 72],  # microwave, oven, sink, refrigerator\n",
        "            \"living_room\": [57, 58, 62],  # sofa, chair, tv\n",
        "            \"dining_area\": [60, 46, 47],  # dining table, fork, knife\n",
        "            \"office_workspace\": [63, 64, 66, 73]  # laptop, mouse, keyboard, book\n",
        "        }\n",
        "\n",
        "        if scene_type in scene_core_mapping:\n",
        "            core_class_ids = scene_core_mapping[scene_type]\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in core_class_ids and obj.get(\"confidence\", 0) >= 0.4:\n",
        "                    core_objects.append(obj)\n",
        "\n",
        "        return core_objects\n",
        "\n",
        "    def _get_object_categories(self, detected_objects: List[Dict]) -> set:\n",
        "        \"\"\"Get unique object categories from detected objects.\"\"\"\n",
        "        object_categories = set()\n",
        "        for obj in detected_objects:\n",
        "            category = self._categorize_object(obj)\n",
        "            if category:\n",
        "                object_categories.add(category)\n",
        "        return object_categories\n",
        "\n",
        "    def _create_basic_zones_from_objects(self, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Create basic functional zones from individual high-confidence objects.\n",
        "        This is a fallback when standard zone identification fails.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Scene type\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of basic zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Focus on high-confidence objects\n",
        "        high_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.6]\n",
        "\n",
        "        if not high_conf_objects:\n",
        "            high_conf_objects = detected_objects  # Fallback to all objects\n",
        "\n",
        "        # Create zones based on individual important objects\n",
        "        for i, obj in enumerate(high_conf_objects[:3]):  # Limit to top 3 objects\n",
        "            class_name = obj[\"class_name\"]\n",
        "            region = obj.get(\"region\", \"center\")\n",
        "\n",
        "            # Create descriptive zone based on object type\n",
        "            zone_description = self._get_basic_zone_description(class_name, scene_type)\n",
        "\n",
        "            if zone_description:\n",
        "                zones[f\"functional_area_{i+1}\"] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": [class_name],\n",
        "                    \"description\": zone_description\n",
        "                }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _get_basic_zone_description(self, class_name: str, scene_type: str) -> str:\n",
        "        \"\"\"Generate basic zone description based on object and scene type.\"\"\"\n",
        "\n",
        "        # Object-specific descriptions\n",
        "        descriptions = {\n",
        "            \"bed\": \"Sleeping and rest area\",\n",
        "            \"sofa\": \"Seating and relaxation area\",\n",
        "            \"chair\": \"Seating area\",\n",
        "            \"dining table\": \"Dining and meal area\",\n",
        "            \"tv\": \"Entertainment and media area\",\n",
        "            \"laptop\": \"Work and computing area\",\n",
        "            \"potted plant\": \"Decorative and green space area\",\n",
        "            \"refrigerator\": \"Food storage and kitchen area\",\n",
        "            \"car\": \"Vehicle and transportation area\",\n",
        "            \"person\": \"Activity and social area\"\n",
        "        }\n",
        "\n",
        "        return descriptions.get(class_name, f\"Functional area with {class_name}\")\n",
        "\n",
        "    def _categorize_object(self, obj: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Categorize detected objects into functional categories for zone identification.\n",
        "        \"\"\"\n",
        "        class_id = obj.get(\"class_id\", -1)\n",
        "        class_name = obj.get(\"class_name\", \"\").lower()\n",
        "\n",
        "        # Use existing category mapping if available\n",
        "        if hasattr(self, 'OBJECT_CATEGORIES') and self.OBJECT_CATEGORIES:\n",
        "            for category, ids in self.OBJECT_CATEGORIES.items():\n",
        "                if class_id in ids:\n",
        "                    return category\n",
        "\n",
        "        # Fallback categorization based on class names for common COCO classes\n",
        "        furniture_items = [\"chair\", \"couch\", \"bed\", \"dining table\", \"toilet\"]\n",
        "        plant_items = [\"potted plant\"]\n",
        "        electronic_items = [\"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\"]\n",
        "        vehicle_items = [\"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\"]\n",
        "        person_items = [\"person\"]\n",
        "        kitchen_items = [\"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
        "                        \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\n",
        "                        \"pizza\", \"donut\", \"cake\", \"refrigerator\", \"oven\", \"toaster\", \"sink\", \"microwave\"]\n",
        "        sports_items = [\"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "                    \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\"]\n",
        "        personal_items = [\"handbag\", \"tie\", \"suitcase\", \"umbrella\", \"backpack\"]\n",
        "\n",
        "        if any(item in class_name for item in furniture_items):\n",
        "            return \"furniture\"\n",
        "        elif any(item in class_name for item in plant_items):\n",
        "            return \"plant\"\n",
        "        elif any(item in class_name for item in electronic_items):\n",
        "            return \"electronics\"\n",
        "        elif any(item in class_name for item in vehicle_items):\n",
        "            return \"vehicle\"\n",
        "        elif any(item in class_name for item in person_items):\n",
        "            return \"person\"\n",
        "        elif any(item in class_name for item in kitchen_items):\n",
        "            return \"kitchen_items\"\n",
        "        elif any(item in class_name for item in sports_items):\n",
        "            return \"sports\"\n",
        "        elif any(item in class_name for item in personal_items):\n",
        "            return \"personal_items\"\n",
        "        else:\n",
        "            return \"misc\"\n",
        "\n",
        "    def _evaluate_zone_identification_feasibility(self, detected_objects: List[Dict], scene_type: str) -> bool:\n",
        "        \"\"\"\n",
        "        基於物件關聯性和分布特徵的彈性可行性評估\n",
        "        \"\"\"\n",
        "        if len(detected_objects) < 2:\n",
        "            return False\n",
        "\n",
        "        # 計算不同置信度層級的物件分布\n",
        "        high_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.6]\n",
        "        medium_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "        # 基礎條件：至少需要一定數量的可信物件\n",
        "        if len(medium_conf_objects) < 2:\n",
        "            return False\n",
        "\n",
        "        # evalure relationships\n",
        "        functional_relationships = self._calculate_functional_relationships(detected_objects)\n",
        "\n",
        "        # 評估space的分布多樣性\n",
        "        spatial_diversity = self._calculate_spatial_diversity(detected_objects)\n",
        "\n",
        "        # 綜合評分機制\n",
        "        feasibility_score = 0\n",
        "\n",
        "        # 物件數量的貢獻值（權重30%）\n",
        "        object_count_score = min(len(detected_objects) / 5.0, 1.0) * 0.3\n",
        "\n",
        "        # 信心度質量貢獻（權重25%）\n",
        "        confidence_score = len(high_conf_objects) / max(len(detected_objects), 1) * 0.25\n",
        "\n",
        "        # 功能關聯性貢獻（權重25%）\n",
        "        relationship_score = functional_relationships * 0.25\n",
        "\n",
        "        # space多樣性貢獻（權重20%）\n",
        "        diversity_score = spatial_diversity * 0.20\n",
        "\n",
        "        feasibility_score = object_count_score + confidence_score + relationship_score + diversity_score\n",
        "\n",
        "        # 動態閾值：基於場景複雜度調整\n",
        "        complexity_threshold = self._get_complexity_threshold(scene_type)\n",
        "\n",
        "        return feasibility_score >= complexity_threshold\n",
        "\n",
        "    def _calculate_functional_relationships(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件間的功能關聯性評分\n",
        "        基於常見的物件組合模式評估功能相關性\n",
        "        \"\"\"\n",
        "        relationship_pairs = {\n",
        "            # 家具組合關係\n",
        "            frozenset([56, 60]): 1.0,  # 椅子+桌子 (dining/work area)\n",
        "            frozenset([57, 62]): 0.9,  # 沙發+電視 (living area)\n",
        "            frozenset([59, 58]): 0.7,  # 床+植物 (bedroom decor)\n",
        "\n",
        "            # 工作相關組合\n",
        "            frozenset([63, 66]): 0.9,  # 筆電+鍵盤 (workspace)\n",
        "            frozenset([63, 64]): 0.8,  # 筆電+滑鼠 (workspace)\n",
        "            frozenset([60, 63]): 0.8,  # 桌子+筆電 (workspace)\n",
        "\n",
        "            # 廚房相關組合\n",
        "            frozenset([68, 72]): 0.9,  # 微波爐+冰箱 (kitchen)\n",
        "            frozenset([69, 71]): 0.8,  # 烤箱+水槽 (kitchen)\n",
        "\n",
        "            # 用餐相關組合\n",
        "            frozenset([60, 40]): 0.8,  # 桌子+酒杯 (dining)\n",
        "            frozenset([60, 41]): 0.8,  # 桌子+杯子 (dining)\n",
        "            frozenset([56, 40]): 0.7,  # 椅子+酒杯 (dining)\n",
        "\n",
        "            # 交通相關組合\n",
        "            frozenset([2, 9]): 0.8,   # 汽車+交通燈 (traffic)\n",
        "            frozenset([0, 9]): 0.7,   # 行人+交通燈 (crosswalk)\n",
        "        }\n",
        "\n",
        "        detected_class_ids = set(obj[\"class_id\"] for obj in detected_objects)\n",
        "        max_possible_score = 0\n",
        "        actual_score = 0\n",
        "\n",
        "        for pair, score in relationship_pairs.items():\n",
        "            max_possible_score += score\n",
        "            if pair.issubset(detected_class_ids):\n",
        "                actual_score += score\n",
        "\n",
        "        return actual_score / max_possible_score if max_possible_score > 0 else 0\n",
        "\n",
        "    def _calculate_spatial_diversity(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件空間分布的多樣性\n",
        "        評估物件是否分散在不同區域，避免所有物件集中在單一區域\n",
        "        \"\"\"\n",
        "        regions = set(obj.get(\"region\", \"center\") for obj in detected_objects)\n",
        "        unique_regions = len(regions)\n",
        "\n",
        "        return min(unique_regions / 2.0, 1.0)\n",
        "\n",
        "    def _get_complexity_threshold(self, scene_type: str) -> float:\n",
        "        \"\"\"\n",
        "        可根據場景類型返回適當的複雜度閾值\n",
        "        平衡不同場景的區域劃分需求\n",
        "        \"\"\"\n",
        "        # 較簡單場景需要較高分數才進行區域劃分\n",
        "        simple_scenes = [\"bedroom\", \"bathroom\", \"closet\"]\n",
        "        # 較複雜場景可以較低分數進行區域劃分\n",
        "        complex_scenes = [\"living_room\", \"kitchen\", \"office_workspace\", \"dining_area\"]\n",
        "\n",
        "        if scene_type in simple_scenes:\n",
        "            return 0.65  # 較高閾值，避免過度細分\n",
        "        elif scene_type in complex_scenes:\n",
        "            return 0.45  # 較低閾值，允許合理劃分\n",
        "        else:\n",
        "            return 0.55  # 中等閾值，平衡策略\n",
        "\n",
        "    def _identify_indoor_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        平衡化的室內功能區域識別\n",
        "        採用通用的物件關聯性分析，避免場景特定的硬編碼\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # 辨識到主要功能區域（基於物件關聯性而非場景類型）\n",
        "        primary_zone = self._identify_primary_functional_area(detected_objects)\n",
        "        if primary_zone:\n",
        "            zones[\"primary_area\"] = primary_zone\n",
        "\n",
        "        # 只有明確證據且物件數量足夠時創建次要功能區域\n",
        "        if len(zones) >= 1 and len(detected_objects) >= 6:\n",
        "            secondary_zone = self._identify_secondary_functional_area(detected_objects, zones)\n",
        "            if secondary_zone:\n",
        "                zones[\"secondary_area\"] = secondary_zone\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_primary_functional_area(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識主要功能區域，基於最強的物件關聯性組合\n",
        "        採用通用邏輯處理各種室內場景\n",
        "        \"\"\"\n",
        "        # 用餐區域檢測（桌椅組合）\n",
        "        dining_area = self._detect_functional_combination(\n",
        "            detected_objects,\n",
        "            primary_objects=[60],  # dining table\n",
        "            supporting_objects=[56, 40, 41, 42, 43],  # chair, wine glass, cup, fork, knife\n",
        "            min_supporting=2,\n",
        "            description_template=\"Dining area with table and seating arrangement\"\n",
        "        )\n",
        "        if dining_area:\n",
        "            return dining_area\n",
        "\n",
        "        # 休息區域檢測（沙發電視組合或床）\n",
        "        seating_area = self._detect_functional_combination(\n",
        "            detected_objects,\n",
        "            primary_objects=[57, 59],  # sofa, bed\n",
        "            supporting_objects=[62, 58, 56],  # tv, potted plant, chair\n",
        "            min_supporting=1,\n",
        "            description_template=\"Seating and relaxation area\"\n",
        "        )\n",
        "        if seating_area:\n",
        "            return seating_area\n",
        "\n",
        "        # 工作區域檢測（電子設備與家具組合）\n",
        "        work_area = self._detect_functional_combination(\n",
        "            detected_objects,\n",
        "            primary_objects=[63, 66],  # laptop, keyboard\n",
        "            supporting_objects=[60, 56, 64],  # dining table, chair, mouse\n",
        "            min_supporting=2,\n",
        "            description_template=\"Workspace area with electronics and furniture\"\n",
        "        )\n",
        "        if work_area:\n",
        "            return work_area\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _identify_secondary_functional_area(self, detected_objects: List[Dict], existing_zones: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        識別次要功能區域，避免與主要區域重疊\n",
        "        \"\"\"\n",
        "        # 獲取已使用的區域\n",
        "        used_regions = set(zone[\"region\"] for zone in existing_zones.values())\n",
        "\n",
        "        # 裝飾區域檢測（植物集中區域）\n",
        "        decorative_area = self._detect_functional_combination(\n",
        "            detected_objects,\n",
        "            primary_objects=[58],  # potted plant\n",
        "            supporting_objects=[75],  # vase\n",
        "            min_supporting=0,\n",
        "            min_primary=3,  # 至少需要3個植物\n",
        "            description_template=\"Decorative area with plants and ornamental items\",\n",
        "            exclude_regions=used_regions\n",
        "        )\n",
        "        if decorative_area:\n",
        "            return decorative_area\n",
        "\n",
        "        # 儲存區域檢測（廚房電器組合）\n",
        "        storage_area = self._detect_functional_combination(\n",
        "            detected_objects,\n",
        "            primary_objects=[72, 68, 69],  # refrigerator, microwave, oven\n",
        "            supporting_objects=[71],  # sink\n",
        "            min_supporting=0,\n",
        "            min_primary=2,\n",
        "            description_template=\"Kitchen appliance and storage area\",\n",
        "            exclude_regions=used_regions\n",
        "        )\n",
        "        if storage_area:\n",
        "            return storage_area\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _detect_functional_combination(self, detected_objects: List[Dict], primary_objects: List[int],\n",
        "                                    supporting_objects: List[int], min_supporting: int,\n",
        "                                    description_template: str, min_primary: int = 1,\n",
        "                                    exclude_regions: set = None) -> Dict:\n",
        "        \"\"\"\n",
        "        通用的功能組合檢測方法\n",
        "        基於主要物件和支持物件的組合判斷功能區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            primary_objects: 主要物件的class_id列表\n",
        "            supporting_objects: 支持物件的class_id列表\n",
        "            min_supporting: 最少需要的支持物件數量\n",
        "            description_template: 描述模板\n",
        "            min_primary: 最少需要的主要物件數量\n",
        "            exclude_regions: 需要排除的區域集合\n",
        "\n",
        "        Returns:\n",
        "            Dict: 功能區域資訊，如果不符合條件則返回None\n",
        "        \"\"\"\n",
        "        if exclude_regions is None:\n",
        "            exclude_regions = set()\n",
        "\n",
        "        # 收集主要物件\n",
        "        primary_objs = [obj for obj in detected_objects\n",
        "                    if obj[\"class_id\"] in primary_objects and obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "        # 收集支持物件\n",
        "        supporting_objs = [obj for obj in detected_objects\n",
        "                        if obj[\"class_id\"] in supporting_objects and obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "        # 檢查是否滿足最少數量要求\n",
        "        if len(primary_objs) < min_primary or len(supporting_objs) < min_supporting:\n",
        "            return None\n",
        "\n",
        "        # 按區域組織物件\n",
        "        region_combinations = {}\n",
        "        all_relevant_objs = primary_objs + supporting_objs\n",
        "\n",
        "        for obj in all_relevant_objs:\n",
        "            region = obj[\"region\"]\n",
        "\n",
        "            # 排除指定區域\n",
        "            if region in exclude_regions:\n",
        "                continue\n",
        "\n",
        "            if region not in region_combinations:\n",
        "                region_combinations[region] = {\"primary\": [], \"supporting\": [], \"all\": []}\n",
        "\n",
        "            region_combinations[region][\"all\"].append(obj)\n",
        "\n",
        "            if obj[\"class_id\"] in primary_objects:\n",
        "                region_combinations[region][\"primary\"].append(obj)\n",
        "            else:\n",
        "                region_combinations[region][\"supporting\"].append(obj)\n",
        "\n",
        "        # 找到最佳區域組合\n",
        "        best_region = None\n",
        "        best_score = 0\n",
        "\n",
        "        for region, objs in region_combinations.items():\n",
        "            # 計算該區域的評分\n",
        "            primary_count = len(objs[\"primary\"])\n",
        "            supporting_count = len(objs[\"supporting\"])\n",
        "\n",
        "            # 必須滿足最低要求\n",
        "            if primary_count < min_primary or supporting_count < min_supporting:\n",
        "                continue\n",
        "\n",
        "            # 計算組合評分（主要物件權重較高）\n",
        "            score = primary_count * 2 + supporting_count\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_region = region\n",
        "\n",
        "        if best_region is None:\n",
        "            return None\n",
        "\n",
        "        best_combination = region_combinations[best_region]\n",
        "        all_objects = [obj[\"class_name\"] for obj in best_combination[\"all\"]]\n",
        "\n",
        "        return {\n",
        "            \"region\": best_region,\n",
        "            \"objects\": all_objects,\n",
        "            \"description\": description_template\n",
        "        }\n",
        "\n",
        "    def _identify_intersection_zones(self, category_regions: Dict, detected_objects: List[Dict], viewpoint: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for urban intersections with enhanced spatial awareness.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "            viewpoint: Detected viewpoint\n",
        "\n",
        "        Returns:\n",
        "            Dict: Refined intersection functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Get pedestrians, vehicles and traffic signals\n",
        "        pedestrian_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "        vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 7]]  # bicycle, car, motorcycle, bus, truck\n",
        "        traffic_light_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 9]\n",
        "\n",
        "        # Create distribution maps for better spatial understanding\n",
        "        regions_distribution = self._create_distribution_map(detected_objects)\n",
        "\n",
        "        # Analyze pedestrian crossing patterns\n",
        "        crossing_zones = self._analyze_crossing_patterns(pedestrian_objs, traffic_light_objs, regions_distribution)\n",
        "        zones.update(crossing_zones)\n",
        "\n",
        "        # Analyze vehicle traffic zones with directional awareness\n",
        "        traffic_zones = self._analyze_traffic_zones(vehicle_objs, regions_distribution)\n",
        "        zones.update(traffic_zones)\n",
        "\n",
        "        # Identify traffic control zones based on signal placement\n",
        "        if traffic_light_objs:\n",
        "            # Group traffic lights by region for better organization\n",
        "            signal_regions = {}\n",
        "            for obj in traffic_light_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in signal_regions:\n",
        "                    signal_regions[region] = []\n",
        "                signal_regions[region].append(obj)\n",
        "\n",
        "            # Create traffic control zones for each region with signals\n",
        "            for idx, (region, signals) in enumerate(signal_regions.items()):\n",
        "                # Check if this region has a directional name\n",
        "                direction = self._get_directional_description(region)\n",
        "\n",
        "                zones[f\"traffic_control_zone_{idx+1}\"] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": [\"traffic light\"] * len(signals),\n",
        "                    \"description\": f\"Traffic control area with {len(signals)} traffic signals\" +\n",
        "                                (f\" in {direction} area\" if direction else \"\")\n",
        "                }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_landmark_zones(self, landmark_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別與地標相關的功能區域\n",
        "\n",
        "        Args:\n",
        "            landmark_objects: 被識別為地標的物體列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標相關的功能區域\n",
        "        \"\"\"\n",
        "        landmark_zones = {}\n",
        "\n",
        "        if not landmark_objects:\n",
        "            print(\"Warning: No landmark objects provided to _identify_landmark_zones\")\n",
        "            return landmark_zones\n",
        "\n",
        "        try:\n",
        "            for i, landmark in enumerate(landmark_objects):\n",
        "                if not isinstance(landmark, dict):\n",
        "                    print(f\"Warning: Landmark object at index {i} is not a dictionary: {type(landmark)}\")\n",
        "                    continue\n",
        "\n",
        "                landmark_id = landmark.get(\"landmark_id\")\n",
        "                if not landmark_id:\n",
        "                    print(f\"Warning: Missing landmark_id for landmark at index {i}\")\n",
        "                    landmark_id = f\"unknown_landmark_{i}\"\n",
        "\n",
        "                landmark_name = landmark.get(\"class_name\", \"Landmark\")\n",
        "                landmark_type = landmark.get(\"landmark_type\", \"architectural\")\n",
        "                landmark_region = landmark.get(\"region\", \"middle_center\")\n",
        "\n",
        "                # 為地標創建主要觀景區\n",
        "                zone_id = f\"landmark_zone_{i+1}\"\n",
        "                zone_name = f\"{landmark_name} Viewing Area\"\n",
        "\n",
        "                # 根據地標類型調整描述\n",
        "                if landmark_type == \"natural\":\n",
        "                    zone_description = f\"Scenic viewpoint for observing {landmark_name}, a notable natural landmark in {landmark.get('location', 'this area')}.\"\n",
        "                    primary_function = \"Nature observation and photography\"\n",
        "                elif landmark_type == \"monument\":\n",
        "                    zone_description = f\"Viewing area around {landmark_name}, a significant monument in {landmark.get('location', 'this area')}.\"\n",
        "                    primary_function = \"Historical appreciation and cultural tourism\"\n",
        "                else:  # architectural\n",
        "                    zone_description = f\"Area centered around {landmark_name}, where visitors can observe and appreciate this iconic structure in {landmark.get('location', 'this area')}.\"\n",
        "                    primary_function = \"Architectural tourism and photography\"\n",
        "\n",
        "                # 確定與地標相關的物體\n",
        "                related_objects = [\"person\", \"camera\", \"cell phone\", \"backpack\"]\n",
        "\n",
        "                # 創建功能區域\n",
        "                landmark_zones[zone_id] = {\n",
        "                    \"name\": zone_name,\n",
        "                    \"description\": zone_description,\n",
        "                    \"objects\": [\"landmark\"] + [obj for obj in related_objects if obj in [o.get(\"class_name\") for o in landmark_objects]],\n",
        "                    \"region\": landmark_region,\n",
        "                    \"primary_function\": primary_function\n",
        "                }\n",
        "\n",
        "                # 如果有建造年份信息，加到描述中\n",
        "                if \"year_built\" in landmark:\n",
        "                    landmark_zones[zone_id][\"description\"] += f\" Built in {landmark['year_built']}.\"\n",
        "\n",
        "                # 如果有建築風格信息，加到描述中\n",
        "                if \"architectural_style\" in landmark:\n",
        "                    landmark_zones[zone_id][\"description\"] += f\" Features {landmark['architectural_style']} architectural style.\"\n",
        "\n",
        "                # 如果有重要性信息，加到描述中\n",
        "                if \"significance\" in landmark:\n",
        "                    landmark_zones[zone_id][\"description\"] += f\" {landmark['significance']}.\"\n",
        "\n",
        "                try:\n",
        "                    # 創建照相區\n",
        "                    photo_region = landmark_region  # 默認與地標在同一區域\n",
        "\n",
        "                    # 根據地標位置調整照相區位置（地標前方通常是照相區）\n",
        "                    region_mapping = {\n",
        "                        \"top_left\": \"bottom_right\",\n",
        "                        \"top_center\": \"bottom_center\",\n",
        "                        \"top_right\": \"bottom_left\",\n",
        "                        \"middle_left\": \"middle_right\",\n",
        "                        \"middle_center\": \"bottom_center\",\n",
        "                        \"middle_right\": \"middle_left\",\n",
        "                        \"bottom_left\": \"top_right\",\n",
        "                        \"bottom_center\": \"top_center\",\n",
        "                        \"bottom_right\": \"top_left\"\n",
        "                    }\n",
        "\n",
        "                    if landmark_region in region_mapping:\n",
        "                        photo_region = region_mapping[landmark_region]\n",
        "\n",
        "                    landmark_zones[f\"photo_spot_{i+1}\"] = {\n",
        "                        \"name\": f\"{landmark_name} Photography Spot\",\n",
        "                        \"description\": f\"Popular position for photographing {landmark_name} with optimal viewing angle.\",\n",
        "                        \"objects\": [\"camera\", \"person\", \"cell phone\"],\n",
        "                        \"region\": photo_region,\n",
        "                        \"primary_function\": \"Tourist photography\"\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error creating photo spot zone: {e}\")\n",
        "\n",
        "                try:\n",
        "                    # 如果是著名地標，可能有紀念品販售區\n",
        "                    if landmark.get(\"confidence\", 0) > 0.7:  # 高置信度地標更可能有紀念品區\n",
        "                        # 根據地標位置找到適合的紀念品區位置（通常在地標附近但不直接在地標上）\n",
        "                        adjacent_regions = {\n",
        "                            \"top_left\": [\"top_center\", \"middle_left\"],\n",
        "                            \"top_center\": [\"top_left\", \"top_right\"],\n",
        "                            \"top_right\": [\"top_center\", \"middle_right\"],\n",
        "                            \"middle_left\": [\"top_left\", \"bottom_left\"],\n",
        "                            \"middle_center\": [\"middle_left\", \"middle_right\"],\n",
        "                            \"middle_right\": [\"top_right\", \"bottom_right\"],\n",
        "                            \"bottom_left\": [\"middle_left\", \"bottom_center\"],\n",
        "                            \"bottom_center\": [\"bottom_left\", \"bottom_right\"],\n",
        "                            \"bottom_right\": [\"bottom_center\", \"middle_right\"]\n",
        "                        }\n",
        "\n",
        "                        if landmark_region in adjacent_regions:\n",
        "                            souvenir_region = adjacent_regions[landmark_region][0]  # 選擇第一個相鄰區域\n",
        "\n",
        "                            landmark_zones[f\"souvenir_area_{i+1}\"] = {\n",
        "                                \"name\": f\"{landmark_name} Souvenir Area\",\n",
        "                                \"description\": f\"Area where visitors can purchase souvenirs and memorabilia related to {landmark_name}.\",\n",
        "                                \"objects\": [\"person\", \"handbag\", \"backpack\"],\n",
        "                                \"region\": souvenir_region,\n",
        "                                \"primary_function\": \"Tourism commerce\"\n",
        "                            }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error creating souvenir area zone: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in _identify_landmark_zones: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "        return landmark_zones\n",
        "\n",
        "    def _analyze_crossing_patterns(self, pedestrians: List[Dict], traffic_lights: List[Dict],\n",
        "                                region_distribution: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze pedestrian crossing patterns to identify crosswalk zones.\n",
        "\n",
        "        Args:\n",
        "            pedestrians: List of pedestrian objects\n",
        "            traffic_lights: List of traffic light objects\n",
        "            region_distribution: Distribution of objects by region\n",
        "\n",
        "        Returns:\n",
        "            Dict: Identified crossing zones\n",
        "        \"\"\"\n",
        "        crossing_zones = {}\n",
        "\n",
        "        if not pedestrians:\n",
        "            return crossing_zones\n",
        "\n",
        "        # Group pedestrians by region\n",
        "        pedestrian_regions = {}\n",
        "        for p in pedestrians:\n",
        "            region = p[\"region\"]\n",
        "            if region not in pedestrian_regions:\n",
        "                pedestrian_regions[region] = []\n",
        "            pedestrian_regions[region].append(p)\n",
        "\n",
        "        # Sort regions by pedestrian count to find main crossing areas\n",
        "        sorted_regions = sorted(pedestrian_regions.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "\n",
        "        # Create crossing zones for regions with pedestrians\n",
        "        for idx, (region, peds) in enumerate(sorted_regions[:2]):  # Focus on top 2 regions\n",
        "            # Check if there are traffic lights nearby to indicate a crosswalk\n",
        "            has_nearby_signals = any(t[\"region\"] == region for t in traffic_lights)\n",
        "\n",
        "            # Create crossing zone with descriptive naming\n",
        "            zone_name = f\"crossing_zone_{idx+1}\"\n",
        "            direction = self._get_directional_description(region)\n",
        "\n",
        "            description = f\"Pedestrian crossing area with {len(peds)} \"\n",
        "            description += \"person\" if len(peds) == 1 else \"people\"\n",
        "            if direction:\n",
        "                description += f\" in {direction} direction\"\n",
        "            if has_nearby_signals:\n",
        "                description += \" near traffic signals\"\n",
        "\n",
        "            crossing_zones[zone_name] = {\n",
        "                \"region\": region,\n",
        "                \"objects\": [\"pedestrian\"] * len(peds),\n",
        "                \"description\": description\n",
        "            }\n",
        "\n",
        "        return crossing_zones\n",
        "\n",
        "    def _analyze_traffic_zones(self, vehicles: List[Dict], region_distribution: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze vehicle distribution to identify traffic zones with directional awareness.\n",
        "\n",
        "        Args:\n",
        "            vehicles: List of vehicle objects\n",
        "            region_distribution: Distribution of objects by region\n",
        "\n",
        "        Returns:\n",
        "            Dict: Identified traffic zones\n",
        "        \"\"\"\n",
        "        traffic_zones = {}\n",
        "\n",
        "        if not vehicles:\n",
        "            return traffic_zones\n",
        "\n",
        "        # 把運輸工具歸成一區\n",
        "        vehicle_regions = {}\n",
        "        for v in vehicles:\n",
        "            region = v[\"region\"]\n",
        "            if region not in vehicle_regions:\n",
        "                vehicle_regions[region] = []\n",
        "            vehicle_regions[region].append(v)\n",
        "\n",
        "        # Create traffic zones for regions with vehicles\n",
        "        main_traffic_region = max(vehicle_regions.items(), key=lambda x: len(x[1]), default=(None, []))\n",
        "\n",
        "        if main_traffic_region[0] is not None:\n",
        "            region = main_traffic_region[0]\n",
        "            vehicles_in_region = main_traffic_region[1]\n",
        "\n",
        "            # Get a list of vehicle types for description\n",
        "            vehicle_types = [v[\"class_name\"] for v in vehicles_in_region]\n",
        "            unique_types = list(set(vehicle_types))\n",
        "\n",
        "            # Get directional description\n",
        "            direction = self._get_directional_description(region)\n",
        "\n",
        "            # Create descriptive zone\n",
        "            traffic_zones[\"vehicle_zone\"] = {\n",
        "                \"region\": region,\n",
        "                \"objects\": vehicle_types,\n",
        "                \"description\": f\"Vehicle traffic area with {', '.join(unique_types[:3])}\" +\n",
        "                            (f\" in {direction} area\" if direction else \"\")\n",
        "            }\n",
        "\n",
        "            # If vehicles are distributed across multiple regions, create secondary zones\n",
        "            if len(vehicle_regions) > 1:\n",
        "                # Get second most populated region\n",
        "                sorted_regions = sorted(vehicle_regions.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "                if len(sorted_regions) > 1:\n",
        "                    second_region, second_vehicles = sorted_regions[1]\n",
        "                    direction = self._get_directional_description(second_region)\n",
        "                    vehicle_types = [v[\"class_name\"] for v in second_vehicles]\n",
        "                    unique_types = list(set(vehicle_types))\n",
        "\n",
        "                    traffic_zones[\"secondary_vehicle_zone\"] = {\n",
        "                        \"region\": second_region,\n",
        "                        \"objects\": vehicle_types,\n",
        "                        \"description\": f\"Secondary traffic area with {', '.join(unique_types[:2])}\" +\n",
        "                                    (f\" in {direction} direction\" if direction else \"\")\n",
        "                    }\n",
        "\n",
        "        return traffic_zones\n",
        "\n",
        "    def _get_directional_description(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        把方向轉換成方位(東西南北)\n",
        "\n",
        "        Args:\n",
        "            region: Region name from the grid\n",
        "\n",
        "        Returns:\n",
        "            str: Directional description\n",
        "        \"\"\"\n",
        "        if \"top\" in region and \"left\" in region:\n",
        "            return \"northwest\"\n",
        "        elif \"top\" in region and \"right\" in region:\n",
        "            return \"northeast\"\n",
        "        elif \"bottom\" in region and \"left\" in region:\n",
        "            return \"southwest\"\n",
        "        elif \"bottom\" in region and \"right\" in region:\n",
        "            return \"southeast\"\n",
        "        elif \"top\" in region:\n",
        "            return \"north\"\n",
        "        elif \"bottom\" in region:\n",
        "            return \"south\"\n",
        "        elif \"left\" in region:\n",
        "            return \"west\"\n",
        "        elif \"right\" in region:\n",
        "            return \"east\"\n",
        "        else:\n",
        "            return \"central\"\n",
        "\n",
        "    def _create_distribution_map(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Create a distribution map of objects across regions for spatial analysis.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            Dict: Distribution map of objects by region and class\n",
        "        \"\"\"\n",
        "        distribution = {}\n",
        "\n",
        "        # Initialize all regions\n",
        "        for region in self.regions.keys():\n",
        "            distribution[region] = {\n",
        "                \"total\": 0,\n",
        "                \"objects\": {},\n",
        "                \"density\": 0\n",
        "            }\n",
        "\n",
        "        # Populate the distribution\n",
        "        for obj in detected_objects:\n",
        "            region = obj[\"region\"]\n",
        "            class_id = obj[\"class_id\"]\n",
        "            class_name = obj[\"class_name\"]\n",
        "\n",
        "            distribution[region][\"total\"] += 1\n",
        "\n",
        "            if class_id not in distribution[region][\"objects\"]:\n",
        "                distribution[region][\"objects\"][class_id] = {\n",
        "                    \"name\": class_name,\n",
        "                    \"count\": 0,\n",
        "                    \"positions\": []\n",
        "                }\n",
        "\n",
        "            distribution[region][\"objects\"][class_id][\"count\"] += 1\n",
        "\n",
        "            # Store position for spatial relationship analysis\n",
        "            if \"normalized_center\" in obj:\n",
        "                distribution[region][\"objects\"][class_id][\"positions\"].append(obj[\"normalized_center\"])\n",
        "\n",
        "        # Calculate object density for each region\n",
        "        for region, data in distribution.items():\n",
        "            # Assuming all regions are equal size in the grid\n",
        "            data[\"density\"] = data[\"total\"] / 1\n",
        "\n",
        "        return distribution\n",
        "\n",
        "    def _identify_asian_cultural_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for scenes with Asian cultural context.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Specific scene type\n",
        "\n",
        "        Returns:\n",
        "            Dict: Asian cultural functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Identify storefront zone\n",
        "        storefront_items = []\n",
        "        storefront_regions = {}\n",
        "\n",
        "        # Since storefronts aren't directly detectable, infer from context\n",
        "        # For example, look for regions with signs, people, and smaller objects\n",
        "        sign_regions = set()\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] == 0:  # Person\n",
        "                region = obj[\"region\"]\n",
        "                if region not in storefront_regions:\n",
        "                    storefront_regions[region] = []\n",
        "                storefront_regions[region].append(obj)\n",
        "\n",
        "                # Add regions with people as potential storefront areas\n",
        "                sign_regions.add(region)\n",
        "\n",
        "        # Use the areas with most people as storefront zones\n",
        "        if storefront_regions:\n",
        "            main_storefront_regions = sorted(storefront_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        reverse=True)[:2]  # Top 2 regions\n",
        "\n",
        "            for idx, (region, objs) in enumerate(main_storefront_regions):\n",
        "                zones[f\"commercial_zone_{idx+1}\"] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": [obj[\"class_name\"] for obj in objs],\n",
        "                    \"description\": f\"Asian commercial storefront with pedestrian activity\"\n",
        "                }\n",
        "\n",
        "        # Identify pedestrian pathway - enhanced to better detect linear pathways\n",
        "        pathway_items = []\n",
        "        pathway_regions = {}\n",
        "\n",
        "        # Extract people for pathway analysis\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "\n",
        "        # Analyze if people form a line (typical of shopping streets)\n",
        "        people_positions = [obj[\"normalized_center\"] for obj in people_objs]\n",
        "\n",
        "        structured_path = False\n",
        "        if len(people_positions) >= 3:\n",
        "            # Check if people are arranged along a similar y-coordinate (horizontal path)\n",
        "            y_coords = [pos[1] for pos in people_positions]\n",
        "            y_mean = sum(y_coords) / len(y_coords)\n",
        "            y_variance = sum((y - y_mean)**2 for y in y_coords) / len(y_coords)\n",
        "\n",
        "            horizontal_path = y_variance < 0.05  # Low variance indicates horizontal alignment\n",
        "\n",
        "            # Check if people are arranged along a similar x-coordinate (vertical path)\n",
        "            x_coords = [pos[0] for pos in people_positions]\n",
        "            x_mean = sum(x_coords) / len(x_coords)\n",
        "            x_variance = sum((x - x_mean)**2 for x in x_coords) / len(x_coords)\n",
        "\n",
        "            vertical_path = x_variance < 0.05  # Low variance indicates vertical alignment\n",
        "\n",
        "            structured_path = horizontal_path or vertical_path\n",
        "            path_direction = \"horizontal\" if horizontal_path else \"vertical\" if vertical_path else \"meandering\"\n",
        "\n",
        "        # Collect pathway objects (people, bicycles, motorcycles in middle area)\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [0, 1, 3]:  # Person, bicycle, motorcycle\n",
        "                y_pos = obj[\"normalized_center\"][1]\n",
        "                # Group by vertical position (middle of image likely pathway)\n",
        "                if 0.25 <= y_pos <= 0.75:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in pathway_regions:\n",
        "                        pathway_regions[region] = []\n",
        "                    pathway_regions[region].append(obj)\n",
        "                    pathway_items.append(obj[\"class_name\"])\n",
        "\n",
        "        if pathway_items:\n",
        "            path_desc = \"Pedestrian walkway with people moving through the commercial area\"\n",
        "            if structured_path:\n",
        "                path_desc = f\"{path_direction.capitalize()} pedestrian walkway with organized foot traffic\"\n",
        "\n",
        "            zones[\"pedestrian_pathway\"] = {\n",
        "                \"region\": \"middle_center\",  # Assumption: pathway often in middle\n",
        "                \"objects\": list(set(pathway_items)),\n",
        "                \"description\": path_desc\n",
        "            }\n",
        "\n",
        "        # Identify vendor zone (small stalls/shops - inferred from context)\n",
        "        has_small_objects = any(obj[\"class_id\"] in [24, 26, 39, 41] for obj in detected_objects)  # bags, bottles, cups\n",
        "        has_people = any(obj[\"class_id\"] == 0 for obj in detected_objects)\n",
        "\n",
        "        if has_small_objects and has_people:\n",
        "            # Likely vendor areas are where people and small objects cluster\n",
        "            small_obj_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [24, 26, 39, 41, 67]:  # bags, bottles, cups, phones\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in small_obj_regions:\n",
        "                        small_obj_regions[region] = []\n",
        "                    small_obj_regions[region].append(obj)\n",
        "\n",
        "            if small_obj_regions:\n",
        "                main_vendor_region = max(small_obj_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_vendor_region[0] is not None:\n",
        "                    vendor_items = [obj[\"class_name\"] for obj in main_vendor_region[1]]\n",
        "                    zones[\"vendor_zone\"] = {\n",
        "                        \"region\": main_vendor_region[0],\n",
        "                        \"objects\": list(set(vendor_items)),\n",
        "                        \"description\": \"Vendor or market stall area with small merchandise\"\n",
        "                    }\n",
        "\n",
        "        # For night markets, identify illuminated zones\n",
        "        if scene_type == \"asian_night_market\":\n",
        "            # Night markets typically have bright spots for food stalls\n",
        "            # This would be enhanced with lighting analysis integration\n",
        "            zones[\"food_stall_zone\"] = {\n",
        "                \"region\": \"middle_center\",\n",
        "                \"objects\": [\"inferred food stalls\"],\n",
        "                \"description\": \"Food stall area typical of Asian night markets\"\n",
        "            }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_upscale_dining_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for upscale dining settings.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            Dict: Upscale dining functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Identify dining table zone\n",
        "        dining_items = []\n",
        "        dining_regions = {}\n",
        "\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [40, 41, 42, 43, 44, 45, 60]:  # Wine glass, cup, fork, knife, spoon, bowl, table\n",
        "                region = obj[\"region\"]\n",
        "                if region not in dining_regions:\n",
        "                    dining_regions[region] = []\n",
        "                dining_regions[region].append(obj)\n",
        "                dining_items.append(obj[\"class_name\"])\n",
        "\n",
        "        if dining_items:\n",
        "            main_dining_region = max(dining_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "            if main_dining_region[0] is not None:\n",
        "                zones[\"formal_dining_zone\"] = {\n",
        "                    \"region\": main_dining_region[0],\n",
        "                    \"objects\": list(set(dining_items)),\n",
        "                    \"description\": f\"Formal dining area with {', '.join(list(set(dining_items))[:3])}\"\n",
        "                }\n",
        "\n",
        "        # Identify decorative zone with enhanced detection\n",
        "        decor_items = []\n",
        "        decor_regions = {}\n",
        "\n",
        "        # Look for decorative elements (vases, wine glasses, unused dishes)\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [75, 40]:  # Vase, wine glass\n",
        "                region = obj[\"region\"]\n",
        "                if region not in decor_regions:\n",
        "                    decor_regions[region] = []\n",
        "                decor_regions[region].append(obj)\n",
        "                decor_items.append(obj[\"class_name\"])\n",
        "\n",
        "        if decor_items:\n",
        "            main_decor_region = max(decor_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "            if main_decor_region[0] is not None:\n",
        "                zones[\"decorative_zone\"] = {\n",
        "                    \"region\": main_decor_region[0],\n",
        "                    \"objects\": list(set(decor_items)),\n",
        "                    \"description\": f\"Decorative area with {', '.join(list(set(decor_items)))}\"\n",
        "                }\n",
        "\n",
        "        # Identify seating arrangement zone\n",
        "        chairs = [obj for obj in detected_objects if obj[\"class_id\"] == 56]  # chairs\n",
        "        if len(chairs) >= 2:\n",
        "            chair_regions = {}\n",
        "            for obj in chairs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in chair_regions:\n",
        "                    chair_regions[region] = []\n",
        "                chair_regions[region].append(obj)\n",
        "\n",
        "            if chair_regions:\n",
        "                main_seating_region = max(chair_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_seating_region[0] is not None:\n",
        "                    zones[\"dining_seating_zone\"] = {\n",
        "                        \"region\": main_seating_region[0],\n",
        "                        \"objects\": [\"chair\"] * len(main_seating_region[1]),\n",
        "                        \"description\": f\"Formal dining seating arrangement with {len(main_seating_region[1])} chairs\"\n",
        "                    }\n",
        "\n",
        "        # Identify serving area (if different from dining area)\n",
        "        serving_items = []\n",
        "        serving_regions = {}\n",
        "\n",
        "        # Serving areas might have bottles, bowls, containers\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [39, 45]:  # Bottle, bowl\n",
        "                # Check if it's in a different region from the main dining table\n",
        "                if \"formal_dining_zone\" in zones and obj[\"region\"] != zones[\"formal_dining_zone\"][\"region\"]:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in serving_regions:\n",
        "                        serving_regions[region] = []\n",
        "                    serving_regions[region].append(obj)\n",
        "                    serving_items.append(obj[\"class_name\"])\n",
        "\n",
        "        if serving_items:\n",
        "            main_serving_region = max(serving_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "            if main_serving_region[0] is not None:\n",
        "                zones[\"serving_zone\"] = {\n",
        "                    \"region\": main_serving_region[0],\n",
        "                    \"objects\": list(set(serving_items)),\n",
        "                    \"description\": f\"Serving or sideboard area with {', '.join(list(set(serving_items)))}\"\n",
        "                }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_financial_district_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for financial district scenes.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            Dict: Financial district functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Identify traffic zone\n",
        "        traffic_items = []\n",
        "        traffic_regions = {}\n",
        "\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7, 9]:  # Various vehicles and traffic lights\n",
        "                region = obj[\"region\"]\n",
        "                if region not in traffic_regions:\n",
        "                    traffic_regions[region] = []\n",
        "                traffic_regions[region].append(obj)\n",
        "                traffic_items.append(obj[\"class_name\"])\n",
        "\n",
        "        if traffic_items:\n",
        "            main_traffic_region = max(traffic_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "            if main_traffic_region[0] is not None:\n",
        "                zones[\"traffic_zone\"] = {\n",
        "                    \"region\": main_traffic_region[0],\n",
        "                    \"objects\": list(set(traffic_items)),\n",
        "                    \"description\": f\"Urban traffic area with {', '.join(list(set(traffic_items))[:3])}\"\n",
        "                }\n",
        "\n",
        "        # Building zones on the sides (inferred from scene context)\n",
        "        # Enhanced to check if there are actual regions that might contain buildings\n",
        "        # Check for regions without vehicles or pedestrians - likely building areas\n",
        "        left_side_regions = [\"top_left\", \"middle_left\", \"bottom_left\"]\n",
        "        right_side_regions = [\"top_right\", \"middle_right\", \"bottom_right\"]\n",
        "\n",
        "        # Check left side\n",
        "        left_building_evidence = True\n",
        "        for region in left_side_regions:\n",
        "            # If many vehicles or people in this region, less likely to be buildings\n",
        "            vehicle_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] in [1, 2, 3, 5, 7]\n",
        "                                for obj in detected_objects)\n",
        "            people_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] == 0\n",
        "                                for obj in detected_objects)\n",
        "\n",
        "            if vehicle_in_region or people_in_region:\n",
        "                left_building_evidence = False\n",
        "                break\n",
        "\n",
        "        # Check right side\n",
        "        right_building_evidence = True\n",
        "        for region in right_side_regions:\n",
        "            # If many vehicles or people in this region, less likely to be buildings\n",
        "            vehicle_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] in [1, 2, 3, 5, 7]\n",
        "                                for obj in detected_objects)\n",
        "            people_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] == 0\n",
        "                                for obj in detected_objects)\n",
        "\n",
        "            if vehicle_in_region or people_in_region:\n",
        "                right_building_evidence = False\n",
        "                break\n",
        "\n",
        "        # Add building zones if evidence supports them\n",
        "        if left_building_evidence:\n",
        "            zones[\"building_zone_left\"] = {\n",
        "                \"region\": \"middle_left\",\n",
        "                \"objects\": [\"building\"],  # Inferred\n",
        "                \"description\": \"Tall buildings line the left side of the street\"\n",
        "            }\n",
        "\n",
        "        if right_building_evidence:\n",
        "            zones[\"building_zone_right\"] = {\n",
        "                \"region\": \"middle_right\",\n",
        "                \"objects\": [\"building\"],  # Inferred\n",
        "                \"description\": \"Tall buildings line the right side of the street\"\n",
        "            }\n",
        "\n",
        "        # Identify pedestrian zone if people are present\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "        if people_objs:\n",
        "            people_regions = {}\n",
        "            for obj in people_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in people_regions:\n",
        "                    people_regions[region] = []\n",
        "                people_regions[region].append(obj)\n",
        "\n",
        "            if people_regions:\n",
        "                main_pedestrian_region = max(people_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        default=(None, []))\n",
        "\n",
        "                if main_pedestrian_region[0] is not None:\n",
        "                    zones[\"pedestrian_zone\"] = {\n",
        "                        \"region\": main_pedestrian_region[0],\n",
        "                        \"objects\": [\"person\"] * len(main_pedestrian_region[1]),\n",
        "                        \"description\": f\"Pedestrian area with {len(main_pedestrian_region[1])} people navigating the financial district\"\n",
        "                    }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_aerial_view_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for scenes viewed from an aerial perspective.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Specific scene type\n",
        "\n",
        "        Returns:\n",
        "            Dict: Aerial view functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # For aerial views, we focus on patterns and flows rather than specific zones\n",
        "\n",
        "        # Identify pedestrian patterns\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "        if people_objs:\n",
        "            # Convert positions to arrays for pattern analysis\n",
        "            positions = np.array([obj[\"normalized_center\"] for obj in people_objs])\n",
        "\n",
        "            if len(positions) >= 3:\n",
        "                # Calculate distribution metrics\n",
        "                x_coords = positions[:, 0]\n",
        "                y_coords = positions[:, 1]\n",
        "\n",
        "                x_mean = np.mean(x_coords)\n",
        "                y_mean = np.mean(y_coords)\n",
        "                x_std = np.std(x_coords)\n",
        "                y_std = np.std(y_coords)\n",
        "\n",
        "                # Determine if people are organized in a linear pattern\n",
        "                if x_std < 0.1 or y_std < 0.1:\n",
        "                    # Linear distribution along one axis\n",
        "                    pattern_direction = \"vertical\" if x_std < y_std else \"horizontal\"\n",
        "\n",
        "                    zones[\"pedestrian_pattern\"] = {\n",
        "                        \"region\": \"central\",\n",
        "                        \"objects\": [\"person\"] * len(people_objs),\n",
        "                        \"description\": f\"Aerial view shows a {pattern_direction} pedestrian movement pattern\"\n",
        "                    }\n",
        "                else:\n",
        "                    # More dispersed pattern\n",
        "                    zones[\"pedestrian_distribution\"] = {\n",
        "                        \"region\": \"wide\",\n",
        "                        \"objects\": [\"person\"] * len(people_objs),\n",
        "                        \"description\": f\"Aerial view shows pedestrians distributed across the area\"\n",
        "                    }\n",
        "\n",
        "        # Identify vehicle patterns for traffic analysis\n",
        "        vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7]]\n",
        "        if vehicle_objs:\n",
        "            # Convert positions to arrays for pattern analysis\n",
        "            positions = np.array([obj[\"normalized_center\"] for obj in vehicle_objs])\n",
        "\n",
        "            if len(positions) >= 2:\n",
        "                # Calculate distribution metrics\n",
        "                x_coords = positions[:, 0]\n",
        "                y_coords = positions[:, 1]\n",
        "\n",
        "                x_mean = np.mean(x_coords)\n",
        "                y_mean = np.mean(y_coords)\n",
        "                x_std = np.std(x_coords)\n",
        "                y_std = np.std(y_coords)\n",
        "\n",
        "                # Determine if vehicles are organized in lanes\n",
        "                if x_std < y_std * 0.5:\n",
        "                    # Vehicles aligned vertically - indicates north-south traffic\n",
        "                    zones[\"vertical_traffic_flow\"] = {\n",
        "                        \"region\": \"central_vertical\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"North-south traffic flow visible from aerial view\"\n",
        "                    }\n",
        "                elif y_std < x_std * 0.5:\n",
        "                    # Vehicles aligned horizontally - indicates east-west traffic\n",
        "                    zones[\"horizontal_traffic_flow\"] = {\n",
        "                        \"region\": \"central_horizontal\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"East-west traffic flow visible from aerial view\"\n",
        "                    }\n",
        "                else:\n",
        "                    # Vehicles in multiple directions - indicates intersection\n",
        "                    zones[\"intersection_traffic\"] = {\n",
        "                        \"region\": \"central\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"Multi-directional traffic at intersection visible from aerial view\"\n",
        "                    }\n",
        "\n",
        "        # For intersection specific aerial views, identify crossing patterns\n",
        "        if \"intersection\" in scene_type:\n",
        "            # Check for traffic signals\n",
        "            traffic_light_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 9]\n",
        "            if traffic_light_objs:\n",
        "                zones[\"traffic_control_pattern\"] = {\n",
        "                    \"region\": \"intersection\",\n",
        "                    \"objects\": [\"traffic light\"] * len(traffic_light_objs),\n",
        "                    \"description\": f\"Intersection traffic control with {len(traffic_light_objs)} signals visible from above\"\n",
        "                }\n",
        "\n",
        "            # Crosswalks are inferred from context in aerial views\n",
        "            zones[\"crossing_pattern\"] = {\n",
        "                \"region\": \"central\",\n",
        "                \"objects\": [\"inferred crosswalk\"],\n",
        "                \"description\": \"Crossing pattern visible from aerial perspective\"\n",
        "            }\n",
        "\n",
        "        # For plaza aerial views, identify gathering patterns\n",
        "        if \"plaza\" in scene_type:\n",
        "            # Plazas typically have central open area with people\n",
        "            if people_objs:\n",
        "                # Check if people are clustered in central region\n",
        "                central_people = [obj for obj in people_objs\n",
        "                                if \"middle\" in obj[\"region\"]]\n",
        "\n",
        "                if central_people:\n",
        "                    zones[\"central_gathering\"] = {\n",
        "                        \"region\": \"middle_center\",\n",
        "                        \"objects\": [\"person\"] * len(central_people),\n",
        "                        \"description\": f\"Central plaza gathering area with {len(central_people)} people viewed from above\"\n",
        "                    }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_outdoor_general_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify functional zones for general outdoor scenes.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Specific outdoor scene type\n",
        "\n",
        "        Returns:\n",
        "            Dict: Outdoor functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Identify pedestrian zones\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "        if people_objs:\n",
        "            people_regions = {}\n",
        "            for obj in people_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in people_regions:\n",
        "                    people_regions[region] = []\n",
        "                people_regions[region].append(obj)\n",
        "\n",
        "            if people_regions:\n",
        "                # Find main pedestrian areas\n",
        "                main_people_regions = sorted(people_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        reverse=True)[:2]  # Top 2 regions\n",
        "\n",
        "                for idx, (region, objs) in enumerate(main_people_regions):\n",
        "                    if len(objs) > 0:\n",
        "                        zones[f\"pedestrian_zone_{idx+1}\"] = {\n",
        "                            \"region\": region,\n",
        "                            \"objects\": [\"person\"] * len(objs),\n",
        "                            \"description\": f\"Pedestrian area with {len(objs)} {'people' if len(objs) > 1 else 'person'}\"\n",
        "                        }\n",
        "\n",
        "        # Identify vehicle zones for streets and parking lots\n",
        "        vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7]]\n",
        "        if vehicle_objs:\n",
        "            vehicle_regions = {}\n",
        "            for obj in vehicle_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in vehicle_regions:\n",
        "                    vehicle_regions[region] = []\n",
        "                vehicle_regions[region].append(obj)\n",
        "\n",
        "            if vehicle_regions:\n",
        "                main_vehicle_region = max(vehicle_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_vehicle_region[0] is not None:\n",
        "                    vehicle_types = [obj[\"class_name\"] for obj in main_vehicle_region[1]]\n",
        "                    zones[\"vehicle_zone\"] = {\n",
        "                        \"region\": main_vehicle_region[0],\n",
        "                        \"objects\": vehicle_types,\n",
        "                        \"description\": f\"Traffic area with {', '.join(list(set(vehicle_types))[:3])}\"\n",
        "                    }\n",
        "\n",
        "        # For park areas, identify recreational zones\n",
        "        if scene_type == \"park_area\":\n",
        "            # Look for recreational objects (sports balls, kites, etc.)\n",
        "            rec_items = []\n",
        "            rec_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [32, 33, 34, 35, 38]:  # sports ball, kite, baseball bat, glove, tennis racket\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in rec_regions:\n",
        "                        rec_regions[region] = []\n",
        "                    rec_regions[region].append(obj)\n",
        "                    rec_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if rec_items:\n",
        "                main_rec_region = max(rec_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "                if main_rec_region[0] is not None:\n",
        "                    zones[\"recreational_zone\"] = {\n",
        "                        \"region\": main_rec_region[0],\n",
        "                        \"objects\": list(set(rec_items)),\n",
        "                        \"description\": f\"Recreational area with {', '.join(list(set(rec_items)))}\"\n",
        "                    }\n",
        "\n",
        "        # For parking lots, identify parking zones\n",
        "        if scene_type == \"parking_lot\":\n",
        "            # Look for parked cars with consistent spacing\n",
        "            car_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 2]  # cars\n",
        "\n",
        "            if len(car_objs) >= 3:\n",
        "                # Check if cars are arranged in patterns (simplified)\n",
        "                car_positions = [obj[\"normalized_center\"] for obj in car_objs]\n",
        "\n",
        "                # Check for row patterns by analyzing vertical positions\n",
        "                y_coords = [pos[1] for pos in car_positions]\n",
        "                y_clusters = {}\n",
        "\n",
        "                # Simplified clustering - group cars by similar y-coordinates\n",
        "                for i, y in enumerate(y_coords):\n",
        "                    assigned = False\n",
        "                    for cluster_y in y_clusters.keys():\n",
        "                        if abs(y - cluster_y) < 0.1:  # Within 10% of image height\n",
        "                            y_clusters[cluster_y].append(i)\n",
        "                            assigned = True\n",
        "                            break\n",
        "\n",
        "                    if not assigned:\n",
        "                        y_clusters[y] = [i]\n",
        "\n",
        "                # If we have row patterns\n",
        "                if max(len(indices) for indices in y_clusters.values()) >= 2:\n",
        "                    zones[\"parking_row\"] = {\n",
        "                        \"region\": \"central\",\n",
        "                        \"objects\": [\"car\"] * len(car_objs),\n",
        "                        \"description\": f\"Organized parking area with vehicles arranged in rows\"\n",
        "                    }\n",
        "                else:\n",
        "                    zones[\"parking_area\"] = {\n",
        "                        \"region\": \"wide\",\n",
        "                        \"objects\": [\"car\"] * len(car_objs),\n",
        "                        \"description\": f\"Parking area with {len(car_objs)} vehicles\"\n",
        "                    }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _identify_default_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Identify general functional zones when no specific scene type is matched.\n",
        "\n",
        "        Args:\n",
        "            category_regions: Objects grouped by category and region\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            Dict: Default functional zones\n",
        "        \"\"\"\n",
        "        zones = {}\n",
        "\n",
        "        # Group objects by category and find main concentrations\n",
        "        for category, regions in category_regions.items():\n",
        "            if not regions:\n",
        "                continue\n",
        "\n",
        "            # Find region with most objects in this category\n",
        "            main_region = max(regions.items(),\n",
        "                        key=lambda x: len(x[1]),\n",
        "                        default=(None, []))\n",
        "\n",
        "            if main_region[0] is None or len(main_region[1]) < 2:\n",
        "                continue\n",
        "\n",
        "            # Create zone based on object category\n",
        "            zone_objects = [obj[\"class_name\"] for obj in main_region[1]]\n",
        "\n",
        "            # Skip if too few objects\n",
        "            if len(zone_objects) < 2:\n",
        "                continue\n",
        "\n",
        "            # Create appropriate zone name and description based on category\n",
        "            if category == \"furniture\":\n",
        "                zones[\"furniture_zone\"] = {\n",
        "                    \"region\": main_region[0],\n",
        "                    \"objects\": zone_objects,\n",
        "                    \"description\": f\"Area with furniture including {', '.join(zone_objects[:3])}\"\n",
        "                }\n",
        "            elif category == \"electronics\":\n",
        "                zones[\"electronics_zone\"] = {\n",
        "                    \"region\": main_region[0],\n",
        "                    \"objects\": zone_objects,\n",
        "                    \"description\": f\"Area with electronic devices including {', '.join(zone_objects[:3])}\"\n",
        "                }\n",
        "            elif category == \"kitchen_items\":\n",
        "                zones[\"dining_zone\"] = {\n",
        "                    \"region\": main_region[0],\n",
        "                    \"objects\": zone_objects,\n",
        "                    \"description\": f\"Dining or food area with {', '.join(zone_objects[:3])}\"\n",
        "                }\n",
        "            elif category == \"vehicles\":\n",
        "                zones[\"vehicle_zone\"] = {\n",
        "                    \"region\": main_region[0],\n",
        "                    \"objects\": zone_objects,\n",
        "                    \"description\": f\"Area with vehicles including {', '.join(zone_objects[:3])}\"\n",
        "                }\n",
        "            elif category == \"personal_items\":\n",
        "                zones[\"personal_items_zone\"] = {\n",
        "                    \"region\": main_region[0],\n",
        "                    \"objects\": zone_objects,\n",
        "                    \"description\": f\"Area with personal items including {', '.join(zone_objects[:3])}\"\n",
        "                }\n",
        "\n",
        "        # Check for people groups\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "        if len(people_objs) >= 2:\n",
        "            people_regions = {}\n",
        "            for obj in people_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in people_regions:\n",
        "                    people_regions[region] = []\n",
        "                people_regions[region].append(obj)\n",
        "\n",
        "            if people_regions:\n",
        "                main_people_region = max(people_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_people_region[0] is not None:\n",
        "                    zones[\"people_zone\"] = {\n",
        "                        \"region\": main_people_region[0],\n",
        "                        \"objects\": [\"person\"] * len(main_people_region[1]),\n",
        "                        \"description\": f\"Area with {len(main_people_region[1])} people\"\n",
        "                    }\n",
        "\n",
        "        return zones\n",
        "\n",
        "    def _find_main_region(self, region_objects_dict: Dict) -> str:\n",
        "        \"\"\"Find the main region with the most objects\"\"\"\n",
        "        if not region_objects_dict:\n",
        "            return \"unknown\"\n",
        "\n",
        "        return max(region_objects_dict.items(),\n",
        "                key=lambda x: len(x[1]),\n",
        "                default=(\"unknown\", []))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48kGS4FtFNYn"
      },
      "outputs": [],
      "source": [
        "# %%writefile places365_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import logging\n",
        "\n",
        "class Places365Model:\n",
        "    \"\"\"\n",
        "    Places365 scene classification model wrapper for scene understanding integration.\n",
        "    Provides scene classification and scene attribute prediction capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'resnet50_places365', device: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize Places365 model with configurable architecture and device.\n",
        "\n",
        "        Args:\n",
        "            model_name: Model architecture name (默認 resnet50)\n",
        "            device: Target device for inference (auto-detected if None)\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        # Device configuration with fallback logic\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.scene_classes = []\n",
        "        self.scene_attributes = []\n",
        "\n",
        "        # Model configuration mapping\n",
        "        self.model_configs = {\n",
        "            'resnet18_places365': {\n",
        "                'arch': 'resnet18',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar'\n",
        "            },\n",
        "            'resnet50_places365': {\n",
        "                'arch': 'resnet50',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar'\n",
        "            },\n",
        "            'densenet161_places365': {\n",
        "                'arch': 'densenet161',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/densenet161_places365.pth.tar'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self._load_model()\n",
        "        self._load_class_names()\n",
        "        self._setup_scene_mapping()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"載入與初始化 Places365 model\"\"\"\n",
        "        try:\n",
        "            if self.model_name not in self.model_configs:\n",
        "                raise ValueError(f\"Unsupported model name: {self.model_name}\")\n",
        "\n",
        "            config = self.model_configs[self.model_name]\n",
        "\n",
        "            # Import model architecture\n",
        "            if config['arch'].startswith('resnet'):\n",
        "                import torchvision.models as models\n",
        "                if config['arch'] == 'resnet18':\n",
        "                    self.model = models.resnet18(num_classes=config['num_classes'])\n",
        "                elif config['arch'] == 'resnet50':\n",
        "                    self.model = models.resnet50(num_classes=config['num_classes'])\n",
        "            elif config['arch'] == 'densenet161':\n",
        "                import torchvision.models as models\n",
        "                self.model = models.densenet161(num_classes=config['num_classes'])\n",
        "\n",
        "            # Load pretrained weights\n",
        "            checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                config['url'],\n",
        "                map_location=self.device,\n",
        "                progress=True\n",
        "            )\n",
        "\n",
        "            # Handle different checkpoint formats\n",
        "            if 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "                # Remove 'module.' prefix if present\n",
        "                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "\n",
        "            self.model.load_state_dict(state_dict)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            self.logger.info(f\"Places365 model {self.model_name} loaded successfully on {self.device}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading Places365 model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _load_class_names(self):\n",
        "        \"\"\"Load Places365 class names and scene attributes.\"\"\"\n",
        "        try:\n",
        "            # Load scene class names (365 categories)\n",
        "            import urllib.request\n",
        "\n",
        "            class_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
        "            class_file = urllib.request.urlopen(class_url)\n",
        "\n",
        "            self.scene_classes = []\n",
        "            for line in class_file:\n",
        "                class_name = line.decode('utf-8').strip().split(' ')[0][3:]  # Remove /x/ prefix\n",
        "                self.scene_classes.append(class_name)\n",
        "\n",
        "            # Load scene attributes (optional, for enhanced description)\n",
        "            attr_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
        "            try:\n",
        "                attr_file = urllib.request.urlopen(attr_url)\n",
        "                self.scene_attributes = []\n",
        "                for line in attr_file:\n",
        "                    attr_name = line.decode('utf-8').strip()\n",
        "                    self.scene_attributes.append(attr_name)\n",
        "            except:\n",
        "                self.logger.warning(\"Scene attributes not loaded, continuing with basic classification\")\n",
        "                self.scene_attributes = []\n",
        "\n",
        "            self.logger.info(f\"Loaded {len(self.scene_classes)} scene classes and {len(self.scene_attributes)} attributes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading class names: {str(e)}\")\n",
        "            # Fallback to basic class names if download fails\n",
        "            self.scene_classes = [f\"scene_class_{i}\" for i in range(365)]\n",
        "            self.scene_attributes = []\n",
        "\n",
        "    def _setup_scene_mapping(self):\n",
        "        \"\"\"Setup mapping from Places365 classes to common scene types.\"\"\"\n",
        "        # 建立Places365類別到通用場景類型的映射關係\n",
        "        self.scene_type_mapping = {\n",
        "            # Indoor scenes\n",
        "            'living_room': 'living_room',\n",
        "            'bedroom': 'bedroom',\n",
        "            'kitchen': 'kitchen',\n",
        "            'dining_room': 'dining_area',\n",
        "            'bathroom': 'bathroom',\n",
        "            'office': 'office_workspace',\n",
        "            'conference_room': 'office_workspace',\n",
        "            'classroom': 'educational_setting',\n",
        "            'library': 'library',\n",
        "            'restaurant': 'restaurant',\n",
        "            'cafe': 'cafe',\n",
        "            'bar': 'bar',\n",
        "            'hotel_room': 'hotel_room',\n",
        "            'hospital_room': 'medical_facility',\n",
        "            'gym': 'gym',\n",
        "            'supermarket': 'retail_store',\n",
        "            'clothing_store': 'retail_store',\n",
        "\n",
        "            # Outdoor urban scenes\n",
        "            'street': 'city_street',\n",
        "            'crosswalk': 'intersection',\n",
        "            'parking_lot': 'parking_lot',\n",
        "            'gas_station': 'gas_station',\n",
        "            'bus_station': 'bus_stop',\n",
        "            'train_station': 'train_station',\n",
        "            'airport_terminal': 'airport',\n",
        "            'subway_station': 'subway_station',\n",
        "            'bridge': 'bridge',\n",
        "            'highway': 'highway',\n",
        "            'downtown': 'commercial_district',\n",
        "            'shopping_mall': 'shopping_mall',\n",
        "\n",
        "            # Natural outdoor scenes\n",
        "            'park': 'park_area',\n",
        "            'beach': 'beach',\n",
        "            'forest': 'forest',\n",
        "            'mountain': 'mountain',\n",
        "            'lake': 'lake',\n",
        "            'river': 'river',\n",
        "            'ocean': 'ocean',\n",
        "            'desert': 'desert',\n",
        "            'field': 'field',\n",
        "            'garden': 'garden',\n",
        "\n",
        "            # Landmark and tourist areas\n",
        "            'castle': 'historical_monument',\n",
        "            'palace': 'historical_monument',\n",
        "            'temple': 'temple',\n",
        "            'church': 'church',\n",
        "            'mosque': 'mosque',\n",
        "            'museum': 'museum',\n",
        "            'art_gallery': 'art_gallery',\n",
        "            'tower': 'tourist_landmark',\n",
        "            'monument': 'historical_monument',\n",
        "\n",
        "            # Sports and entertainment\n",
        "            'stadium': 'stadium',\n",
        "            'basketball_court': 'sports_field',\n",
        "            'tennis_court': 'sports_field',\n",
        "            'swimming_pool': 'swimming_pool',\n",
        "            'playground': 'playground',\n",
        "            'amusement_park': 'amusement_park',\n",
        "            'theater': 'theater',\n",
        "            'concert_hall': 'concert_hall',\n",
        "\n",
        "            # Transportation\n",
        "            'airplane_cabin': 'airplane_cabin',\n",
        "            'train_interior': 'train_interior',\n",
        "            'car_interior': 'car_interior',\n",
        "\n",
        "            # Construction and industrial\n",
        "            'construction_site': 'construction_site',\n",
        "            'factory': 'factory',\n",
        "            'warehouse': 'warehouse'\n",
        "        }\n",
        "\n",
        "        # Indoor/outdoor classification helper\n",
        "        self.indoor_classes = {\n",
        "            'living_room', 'bedroom', 'kitchen', 'dining_room', 'bathroom', 'office',\n",
        "            'conference_room', 'classroom', 'library', 'restaurant', 'cafe', 'bar',\n",
        "            'hotel_room', 'hospital_room', 'gym', 'supermarket', 'clothing_store',\n",
        "            'airplane_cabin', 'train_interior', 'car_interior', 'theater', 'concert_hall',\n",
        "            'museum', 'art_gallery', 'shopping_mall'\n",
        "        }\n",
        "\n",
        "        self.outdoor_classes = {\n",
        "            'street', 'crosswalk', 'parking_lot', 'gas_station', 'bus_station',\n",
        "            'train_station', 'airport_terminal', 'bridge', 'highway', 'downtown',\n",
        "            'park', 'beach', 'forest', 'mountain', 'lake', 'river', 'ocean',\n",
        "            'desert', 'field', 'garden', 'stadium', 'basketball_court', 'tennis_court',\n",
        "            'swimming_pool', 'playground', 'amusement_park', 'construction_site',\n",
        "            'factory', 'warehouse', 'castle', 'palace', 'temple', 'church', 'mosque',\n",
        "            'tower', 'monument'\n",
        "        }\n",
        "\n",
        "    def preprocess(self, image_pil: Image.Image) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Preprocess PIL image for Places365 model inference.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Preprocessed image tensor\n",
        "        \"\"\"\n",
        "        # Places365 standard preprocessing\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Convert to RGB if needed\n",
        "        if image_pil.mode != 'RGB':\n",
        "            image_pil = image_pil.convert('RGB')\n",
        "\n",
        "        # Apply preprocessing\n",
        "        input_tensor = transform(image_pil).unsqueeze(0)\n",
        "        return input_tensor.to(self.device)\n",
        "\n",
        "    def predict(self, image_pil: Image.Image) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Predict scene classification and attributes for input image.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            Dict containing scene predictions and confidence scores\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Preprocess image\n",
        "            input_tensor = self.preprocess(image_pil)\n",
        "\n",
        "            # Model inference\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "            # 返回最有可能的項目\n",
        "            top_k = min(10, len(self.scene_classes))  # Configurable top-k\n",
        "            top_probs, top_indices = torch.topk(probabilities, top_k, dim=1)\n",
        "\n",
        "            # Extract results\n",
        "            top_probs = top_probs.cpu().numpy()[0]\n",
        "            top_indices = top_indices.cpu().numpy()[0]\n",
        "\n",
        "            # Build prediction results\n",
        "            predictions = []\n",
        "            for i in range(top_k):\n",
        "                class_idx = top_indices[i]\n",
        "                confidence = float(top_probs[i])\n",
        "                scene_class = self.scene_classes[class_idx]\n",
        "\n",
        "                predictions.append({\n",
        "                    'class_name': scene_class,\n",
        "                    'class_index': class_idx,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "            # Get primary prediction\n",
        "            primary_prediction = predictions[0]\n",
        "            primary_class = primary_prediction['class_name']\n",
        "\n",
        "            # 確認是 indoor/outdoor\n",
        "            is_indoor = self._classify_indoor_outdoor(primary_class)\n",
        "\n",
        "            # Map to common scene type\n",
        "            mapped_scene_type = self._map_places365_to_scene_types(primary_class)\n",
        "\n",
        "            # Determine scene attributes (basic inference based on class)\n",
        "            scene_attributes = self._infer_scene_attributes(primary_class)\n",
        "\n",
        "            result = {\n",
        "                'scene_label': primary_class,\n",
        "                'mapped_scene_type': mapped_scene_type,\n",
        "                'confidence': primary_prediction['confidence'],\n",
        "                'is_indoor': is_indoor,\n",
        "                'attributes': scene_attributes,\n",
        "                'top_predictions': predictions,\n",
        "                'all_probabilities': probabilities.cpu().numpy()[0].tolist()\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in Places365 prediction: {str(e)}\")\n",
        "            return {\n",
        "                'scene_label': 'unknown',\n",
        "                'mapped_scene_type': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'is_indoor': None,\n",
        "                'attributes': [],\n",
        "                'top_predictions': [],\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    def _classify_indoor_outdoor(self, scene_class: str) -> Optional[bool]:\n",
        "        \"\"\"\n",
        "        Classify if scene is indoor or outdoor based on Places365 class.\n",
        "\n",
        "        Args:\n",
        "            scene_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            bool or None: True for indoor, False for outdoor, None if uncertain\n",
        "        \"\"\"\n",
        "        if scene_class in self.indoor_classes:\n",
        "            return True\n",
        "        elif scene_class in self.outdoor_classes:\n",
        "            return False\n",
        "        else:\n",
        "            # For ambiguous classes, use heuristics\n",
        "            indoor_keywords = ['room', 'office', 'store', 'shop', 'hall', 'interior', 'indoor']\n",
        "            outdoor_keywords = ['street', 'road', 'park', 'field', 'beach', 'mountain', 'outdoor']\n",
        "\n",
        "            scene_lower = scene_class.lower()\n",
        "            if any(keyword in scene_lower for keyword in indoor_keywords):\n",
        "                return True\n",
        "            elif any(keyword in scene_lower for keyword in outdoor_keywords):\n",
        "                return False\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    def _map_places365_to_scene_types(self, places365_class: str) -> str:\n",
        "        \"\"\"\n",
        "        Map Places365 class to common scene type used by the system.\n",
        "\n",
        "        Args:\n",
        "            places365_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            str: Mapped scene type\n",
        "        \"\"\"\n",
        "        # Direct mapping lookup\n",
        "        if places365_class in self.scene_type_mapping:\n",
        "            return self.scene_type_mapping[places365_class]\n",
        "\n",
        "        # Fuzzy matching for similar classes\n",
        "        places365_lower = places365_class.lower()\n",
        "\n",
        "        # Indoor fuzzy matching\n",
        "        if any(keyword in places365_lower for keyword in ['living', 'bedroom', 'kitchen']):\n",
        "            return 'general_indoor_space'\n",
        "        elif any(keyword in places365_lower for keyword in ['office', 'conference', 'meeting']):\n",
        "            return 'office_workspace'\n",
        "        elif any(keyword in places365_lower for keyword in ['dining', 'restaurant', 'cafe']):\n",
        "            return 'dining_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['store', 'shop', 'market']):\n",
        "            return 'retail_store'\n",
        "        elif any(keyword in places365_lower for keyword in ['school', 'class', 'library']):\n",
        "            return 'educational_setting'\n",
        "\n",
        "        # Outdoor fuzzy matching\n",
        "        elif any(keyword in places365_lower for keyword in ['street', 'road', 'crosswalk']):\n",
        "            return 'city_street'\n",
        "        elif any(keyword in places365_lower for keyword in ['park', 'garden', 'plaza']):\n",
        "            return 'park_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['beach', 'ocean', 'lake']):\n",
        "            return 'beach'\n",
        "        elif any(keyword in places365_lower for keyword in ['mountain', 'forest', 'desert']):\n",
        "            return 'natural_outdoor_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['parking', 'garage']):\n",
        "            return 'parking_lot'\n",
        "        elif any(keyword in places365_lower for keyword in ['station', 'terminal', 'airport']):\n",
        "            return 'transportation_hub'\n",
        "\n",
        "        # Landmark fuzzy matching\n",
        "        elif any(keyword in places365_lower for keyword in ['castle', 'palace', 'monument', 'temple']):\n",
        "            return 'historical_monument'\n",
        "        elif any(keyword in places365_lower for keyword in ['tower', 'landmark']):\n",
        "            return 'tourist_landmark'\n",
        "        elif any(keyword in places365_lower for keyword in ['museum', 'gallery']):\n",
        "            return 'cultural_venue'\n",
        "\n",
        "        # Default fallback based on indoor/outdoor\n",
        "        is_indoor = self._classify_indoor_outdoor(places365_class)\n",
        "        if is_indoor is True:\n",
        "            return 'general_indoor_space'\n",
        "        elif is_indoor is False:\n",
        "            return 'generic_street_view'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "    def _infer_scene_attributes(self, scene_class: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Infer basic scene attributes from Places365 class.\n",
        "\n",
        "        Args:\n",
        "            scene_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Inferred scene attributes\n",
        "        \"\"\"\n",
        "        attributes = []\n",
        "        scene_lower = scene_class.lower()\n",
        "\n",
        "        # Lighting attributes\n",
        "        if any(keyword in scene_lower for keyword in ['outdoor', 'street', 'park', 'beach']):\n",
        "            attributes.append('natural_lighting')\n",
        "        elif any(keyword in scene_lower for keyword in ['indoor', 'room', 'office']):\n",
        "            attributes.append('artificial_lighting')\n",
        "\n",
        "        # Functional attributes\n",
        "        if any(keyword in scene_lower for keyword in ['commercial', 'store', 'shop', 'restaurant']):\n",
        "            attributes.append('commercial')\n",
        "        elif any(keyword in scene_lower for keyword in ['residential', 'home', 'living', 'bedroom']):\n",
        "            attributes.append('residential')\n",
        "        elif any(keyword in scene_lower for keyword in ['office', 'conference', 'meeting']):\n",
        "            attributes.append('workplace')\n",
        "        elif any(keyword in scene_lower for keyword in ['recreation', 'park', 'playground', 'stadium']):\n",
        "            attributes.append('recreational')\n",
        "        elif any(keyword in scene_lower for keyword in ['educational', 'school', 'library', 'classroom']):\n",
        "            attributes.append('educational')\n",
        "\n",
        "        # Spatial attributes\n",
        "        if any(keyword in scene_lower for keyword in ['open', 'field', 'plaza', 'stadium']):\n",
        "            attributes.append('open_space')\n",
        "        elif any(keyword in scene_lower for keyword in ['enclosed', 'room', 'interior']):\n",
        "            attributes.append('enclosed_space')\n",
        "\n",
        "        return attributes\n",
        "\n",
        "    def get_scene_probabilities(self, image_pil: Image.Image) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Get probability distribution over all scene classes.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            Dict mapping scene class names to probabilities\n",
        "        \"\"\"\n",
        "        try:\n",
        "            input_tensor = self.preprocess(image_pil)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "            probs = probabilities.cpu().numpy()[0]\n",
        "\n",
        "            return {\n",
        "                self.scene_classes[i]: float(probs[i])\n",
        "                for i in range(len(self.scene_classes))\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting scene probabilities: {str(e)}\")\n",
        "            return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atHycbc0-3_6"
      },
      "outputs": [],
      "source": [
        "# %%writefile enhance_scene_describer.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from scene_detail_templates import SCENE_DETAIL_TEMPLATES\n",
        "# from object_template_fillers import OBJECT_TEMPLATE_FILLERS\n",
        "# from lighting_conditions import LIGHTING_CONDITIONS\n",
        "# from viewpoint_templates import VIEWPOINT_TEMPLATES\n",
        "# from cultural_templates import CULTURAL_TEMPLATES\n",
        "# from confifence_templates import CONFIDENCE_TEMPLATES\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "\n",
        "class EnhancedSceneDescriber:\n",
        "    \"\"\"\n",
        "    Enhanced scene description generator with improved template handling,\n",
        "    viewpoint awareness, and cultural context recognition.\n",
        "    Provides detailed natural language descriptions of scenes based on\n",
        "    detection results and scene classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, templates_db: Optional[Dict] = None, scene_types: Optional[Dict] = None, spatial_analyzer_instance: Optional[Any] = None):\n",
        "        \"\"\"\n",
        "        Initialize the enhanced scene describer.\n",
        "\n",
        "        Args:\n",
        "            templates_db: Optional custom templates database\n",
        "            scene_types: Dictionary of scene type definitions\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__) # Use class name for logger\n",
        "        self.logger.setLevel(logging.INFO) # Or your desired logging level\n",
        "        # Optional: Add a handler if not configured globally\n",
        "        if not self.logger.hasHandlers():\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "\n",
        "        # Load or use provided scene types\n",
        "        self.scene_types = scene_types or self._load_default_scene_types()\n",
        "\n",
        "        # Load templates database\n",
        "        self.templates = templates_db or self._load_templates()\n",
        "\n",
        "        # Initialize viewpoint detection parameters\n",
        "        self._initialize_viewpoint_parameters()\n",
        "\n",
        "    def _load_default_scene_types(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Load default scene types.\n",
        "\n",
        "        Returns:\n",
        "            Dict: Scene type definitions\n",
        "        \"\"\"\n",
        "\n",
        "        return SCENE_TYPES\n",
        "\n",
        "    def _load_templates(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Load description templates from imported Python modules.\n",
        "\n",
        "        Returns:\n",
        "            Dict: Template collections for different description components\n",
        "        \"\"\"\n",
        "        templates = {}\n",
        "\n",
        "        # 載入事先準備的模板\n",
        "        templates[\"scene_detail_templates\"] = SCENE_DETAIL_TEMPLATES\n",
        "        templates[\"object_template_fillers\"] = OBJECT_TEMPLATE_FILLERS\n",
        "        templates[\"viewpoint_templates\"] = VIEWPOINT_TEMPLATES\n",
        "        templates[\"cultural_templates\"] = CULTURAL_TEMPLATES\n",
        "\n",
        "        # 從 LIGHTING_CONDITIONS 獲取照明模板\n",
        "        templates[\"lighting_templates\"] = {\n",
        "            key: data[\"general\"] for key, data in LIGHTING_CONDITIONS.get(\"time_descriptions\", {}).items()\n",
        "        }\n",
        "\n",
        "        # 設置默認的置信度模板\n",
        "        templates[\"confidence_templates\"] = {\n",
        "            \"high\": \"{description} {details}\",\n",
        "            \"medium\": \"This appears to be {description} {details}\",\n",
        "            \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "        }\n",
        "\n",
        "        # 初始化其他必要的模板（現在這個函數簡化了很多）\n",
        "        self._initialize_default_templates(templates)\n",
        "\n",
        "        return templates\n",
        "\n",
        "    def _initialize_default_templates(self, templates: Dict):\n",
        "        \"\"\"\n",
        "        檢查模板字典並填充任何缺失的默認模板。\n",
        "\n",
        "        在將模板移至專門的模組後，此方法主要作為安全機制，\n",
        "        確保即使導入失敗或某些模板未在外部定義，系統仍能正常運行。\n",
        "\n",
        "        Args:\n",
        "            templates: 要檢查和更新的模板字典\n",
        "        \"\"\"\n",
        "        # 檢查關鍵模板類型是否存在，如果不存在則添加默認值\n",
        "\n",
        "        # 置信度模板 - 用於控制描述的語氣\n",
        "        if \"confidence_templates\" not in templates:\n",
        "            templates[\"confidence_templates\"] = {\n",
        "                \"high\": \"{description} {details}\",\n",
        "                \"medium\": \"This appears to be {description} {details}\",\n",
        "                \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "            }\n",
        "\n",
        "        # 場景細節模板\n",
        "        if \"scene_detail_templates\" not in templates:\n",
        "            templates[\"scene_detail_templates\"] = {\n",
        "                \"default\": [\"A space with various objects.\"]\n",
        "            }\n",
        "\n",
        "        # 物體填充模板，用於生成物體描述\n",
        "        if \"object_template_fillers\" not in templates:\n",
        "            templates[\"object_template_fillers\"] = {\n",
        "                \"default\": [\"various items\"]\n",
        "            }\n",
        "\n",
        "        # 視角模板，雖然現在從專門模組導入，但可作為備份\n",
        "        if \"viewpoint_templates\" not in templates:\n",
        "            # 使用簡化版的默認視角模板\n",
        "            templates[\"viewpoint_templates\"] = {\n",
        "                \"eye_level\": {\n",
        "                    \"prefix\": \"From eye level, \",\n",
        "                    \"observation\": \"the scene is viewed straight on.\"\n",
        "                },\n",
        "                \"aerial\": {\n",
        "                    \"prefix\": \"From above, \",\n",
        "                    \"observation\": \"the scene is viewed from a bird's-eye perspective.\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "        # 文化模板\n",
        "        if \"cultural_templates\" not in templates:\n",
        "            templates[\"cultural_templates\"] = {\n",
        "                \"asian\": {\n",
        "                    \"elements\": [\"cultural elements\"],\n",
        "                    \"description\": \"The scene has Asian characteristics.\"\n",
        "                },\n",
        "                \"european\": {\n",
        "                    \"elements\": [\"architectural features\"],\n",
        "                    \"description\": \"The scene has European characteristics.\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "        # 照明模板 - 用於描述光照條件\n",
        "        if \"lighting_templates\" not in templates:\n",
        "            templates[\"lighting_templates\"] = {\n",
        "                \"day_clear\": \"The scene is captured during daylight.\",\n",
        "                \"night\": \"The scene is captured at night.\",\n",
        "                \"unknown\": \"The lighting conditions are not easily determined.\"\n",
        "            }\n",
        "\n",
        "\n",
        "    def _initialize_viewpoint_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters used for viewpoint detection.\n",
        "        \"\"\"\n",
        "        self.viewpoint_params = {\n",
        "            # Parameters for detecting aerial views\n",
        "            \"aerial_threshold\": 0.7,  # High object density viewed from top\n",
        "            \"aerial_size_variance_threshold\": 0.15,  # Low size variance in aerial views\n",
        "\n",
        "            # Parameters for detecting low angle views\n",
        "            \"low_angle_threshold\": 0.3,  # Bottom-heavy object distribution\n",
        "            \"vertical_size_ratio_threshold\": 1.8,  # Vertical objects appear taller\n",
        "\n",
        "            # Parameters for detecting elevated views\n",
        "            \"elevated_threshold\": 0.6,  # Objects mostly in middle/bottom\n",
        "            \"elevated_top_threshold\": 0.3  # Few objects at top of frame\n",
        "        }\n",
        "\n",
        "    def _generate_landmark_description(self,\n",
        "                                 scene_type: str,\n",
        "                                 detected_objects: List[Dict],\n",
        "                                 confidence: float,\n",
        "                                 lighting_info: Optional[Dict] = None,\n",
        "                                 functional_zones: Optional[Dict] = None,\n",
        "                                 landmark_objects: Optional[List[Dict]] = None) -> str:\n",
        "        \"\"\"\n",
        "        生成包含地標信息的場景描述\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            confidence: 場景分類置信度\n",
        "            lighting_info: 照明條件信息（可選）\n",
        "            functional_zones: 功能區域信息（可選）\n",
        "            landmark_objects: 識別為地標的物體列表（可選）\n",
        "\n",
        "        Returns:\n",
        "            str: 包含地標信息的自然語言場景描述\n",
        "        \"\"\"\n",
        "        # 如果沒有提供地標物體，則從檢測物體中篩選\n",
        "        if landmark_objects is None:\n",
        "            landmark_objects = [obj for obj in detected_objects if obj.get(\"is_landmark\", False)]\n",
        "\n",
        "        # 如果沒有地標，退回到標準描述\n",
        "        if not landmark_objects:\n",
        "            if scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                # 場景類型是地標但沒有具體地標物體\n",
        "                base_description = \"A scenic area that appears to be a tourist destination, though specific landmarks are not clearly identifiable.\"\n",
        "            else:\n",
        "                # 使用標準方法生成基本描述\n",
        "                return self._format_final_description(self._generate_scene_details(\n",
        "                    scene_type,\n",
        "                    detected_objects,\n",
        "                    lighting_info,\n",
        "                    self._detect_viewpoint(detected_objects)\n",
        "                ))\n",
        "        else:\n",
        "            # 獲取主要地標（信心度最高的）\n",
        "            primary_landmark = max(landmark_objects, key=lambda x: x.get(\"confidence\", 0))\n",
        "            landmark_name = primary_landmark.get(\"class_name\", \"landmark\")\n",
        "            landmark_location = primary_landmark.get(\"location\", \"\")\n",
        "\n",
        "            # 根據地標類型選擇適當的描述模板\n",
        "            if scene_type == \"natural_landmark\" or primary_landmark.get(\"landmark_type\") == \"natural\":\n",
        "                base_description = f\"A natural landmark scene featuring {landmark_name} in {landmark_location}.\"\n",
        "            elif scene_type == \"historical_monument\" or primary_landmark.get(\"landmark_type\") == \"monument\":\n",
        "                base_description = f\"A historical monument scene showcasing {landmark_name}, a significant landmark in {landmark_location}.\"\n",
        "            else:\n",
        "                base_description = f\"A tourist landmark scene centered around {landmark_name}, an iconic structure in {landmark_location}.\"\n",
        "\n",
        "        # 加地標的額外信息\n",
        "        landmark_details = []\n",
        "        for landmark in landmark_objects:\n",
        "            details = []\n",
        "\n",
        "            # 加建造年份\n",
        "            if \"year_built\" in landmark:\n",
        "                details.append(f\"built in {landmark['year_built']}\")\n",
        "\n",
        "            # 加建築風格\n",
        "            if \"architectural_style\" in landmark:\n",
        "                details.append(f\"featuring {landmark['architectural_style']} architectural style\")\n",
        "\n",
        "            # 加重要性\n",
        "            if \"significance\" in landmark:\n",
        "                details.append(landmark[\"significance\"])\n",
        "\n",
        "            # 如果有詳細信息，加到描述中\n",
        "            if details:\n",
        "                landmark_details.append(f\"{landmark['class_name']} ({', '.join(details)})\")\n",
        "\n",
        "        # 將詳細信息添加到基本描述中\n",
        "        if landmark_details:\n",
        "            description = base_description + \" \" + \"The scene features \" + \", \".join(landmark_details) + \".\"\n",
        "        else:\n",
        "            description = base_description\n",
        "\n",
        "        # 獲取視角\n",
        "        viewpoint = self._detect_viewpoint(detected_objects)\n",
        "\n",
        "        # 生成人員活動描述\n",
        "        people_count = len([obj for obj in detected_objects if obj[\"class_id\"] == 0])  # 人的類別ID通常為0\n",
        "\n",
        "        if people_count > 0:\n",
        "            if people_count == 1:\n",
        "                people_description = \"There is one person in the scene, likely a tourist or visitor.\"\n",
        "            elif people_count < 5:\n",
        "                people_description = f\"There are {people_count} people in the scene, possibly tourists visiting the landmark.\"\n",
        "            else:\n",
        "                people_description = f\"The scene includes a group of {people_count} people, indicating this is a popular tourist destination.\"\n",
        "\n",
        "            description = self._smart_append(description, people_description)\n",
        "\n",
        "        # 添加照明信息\n",
        "        if lighting_info and \"time_of_day\" in lighting_info:\n",
        "            lighting_type = lighting_info[\"time_of_day\"]\n",
        "            if lighting_type in self.templates.get(\"lighting_templates\", {}):\n",
        "                lighting_description = self.templates[\"lighting_templates\"][lighting_type]\n",
        "                description = self._smart_append(description, lighting_description)\n",
        "\n",
        "        # 添加視角描述\n",
        "        if viewpoint != \"eye_level\" and viewpoint in self.templates.get(\"viewpoint_templates\", {}):\n",
        "            viewpoint_template = self.templates[\"viewpoint_templates\"][viewpoint]\n",
        "\n",
        "            # 添加視角前綴\n",
        "            prefix = viewpoint_template.get('prefix', '')\n",
        "            if prefix and not description.startswith(prefix):\n",
        "                # 保持句子流暢性\n",
        "                if description and description[0].isupper():\n",
        "                    description = prefix + description[0].lower() + description[1:]\n",
        "                else:\n",
        "                    description = prefix + description\n",
        "\n",
        "            # 添加視角觀察描述\n",
        "            viewpoint_desc = viewpoint_template.get(\"observation\", \"\").format(\n",
        "                scene_elements=\"the landmark and surrounding area\"\n",
        "            )\n",
        "\n",
        "            if viewpoint_desc and viewpoint_desc not in description:\n",
        "                description = self._smart_append(description, viewpoint_desc)\n",
        "\n",
        "        # 添加功能區域描述\n",
        "        if functional_zones and len(functional_zones) > 0:\n",
        "            zones_desc = self._describe_functional_zones(functional_zones)\n",
        "            if zones_desc:\n",
        "                description = self._smart_append(description, zones_desc)\n",
        "\n",
        "        # 描述可能的活動\n",
        "        landmark_activities = []\n",
        "\n",
        "        # 根據地標類型生成通用活動\n",
        "        if scene_type == \"natural_landmark\" or any(obj.get(\"landmark_type\") == \"natural\" for obj in landmark_objects):\n",
        "            landmark_activities = [\n",
        "                \"nature photography\",\n",
        "                \"scenic viewing\",\n",
        "                \"hiking or walking\",\n",
        "                \"guided nature tours\",\n",
        "                \"outdoor appreciation\"\n",
        "            ]\n",
        "        elif scene_type == \"historical_monument\" or any(obj.get(\"landmark_type\") == \"monument\" for obj in landmark_objects):\n",
        "            landmark_activities = [\n",
        "                \"historical sightseeing\",\n",
        "                \"educational tours\",\n",
        "                \"cultural appreciation\",\n",
        "                \"photography of historical architecture\",\n",
        "                \"learning about historical significance\"\n",
        "            ]\n",
        "        else:\n",
        "            landmark_activities = [\n",
        "                \"sightseeing\",\n",
        "                \"taking photographs\",\n",
        "                \"guided tours\",\n",
        "                \"cultural tourism\",\n",
        "                \"souvenir shopping\"\n",
        "            ]\n",
        "\n",
        "        # 添加活動描述\n",
        "        if landmark_activities:\n",
        "            activities_text = \"Common activities at this location include \" + \", \".join(landmark_activities[:3]) + \".\"\n",
        "            description = self._smart_append(description, activities_text)\n",
        "\n",
        "        # 最後格式化描述\n",
        "        return self._format_final_description(description)\n",
        "\n",
        "    def filter_landmark_references(self, text, enable_landmark=True):\n",
        "        \"\"\"\n",
        "        動態過濾文本中的地標引用\n",
        "\n",
        "        Args:\n",
        "            text: 需要過濾的文本\n",
        "            enable_landmark: 是否啟用地標功能\n",
        "\n",
        "        Returns:\n",
        "            str: 過濾後的文本\n",
        "        \"\"\"\n",
        "        if enable_landmark or not text:\n",
        "            return text\n",
        "\n",
        "        try:\n",
        "            # 動態收集所有地標名稱和位置\n",
        "            landmark_names = []\n",
        "            locations = []\n",
        "\n",
        "            for landmark_id, info in ALL_LANDMARKS.items():\n",
        "                # 收集地標名稱及其別名\n",
        "                landmark_names.append(info[\"name\"])\n",
        "                landmark_names.extend(info.get(\"aliases\", []))\n",
        "\n",
        "                # 收集地理位置\n",
        "                if \"location\" in info:\n",
        "                    location = info[\"location\"]\n",
        "                    locations.append(location)\n",
        "\n",
        "                    # 處理分離的城市和國家名稱\n",
        "                    parts = location.split(\",\")\n",
        "                    if len(parts) >= 1:\n",
        "                        locations.append(parts[0].strip())\n",
        "                    if len(parts) >= 2:\n",
        "                        locations.append(parts[1].strip())\n",
        "\n",
        "            # 使用正則表達式動態替換所有地標名稱\n",
        "            import re\n",
        "            for name in landmark_names:\n",
        "                if name and len(name) > 2:  # 避免過短的名稱\n",
        "                    text = re.sub(r'\\b' + re.escape(name) + r'\\b', \"tall structure\", text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 動態替換所有位置引用\n",
        "            for location in locations:\n",
        "                if location and len(location) > 2:\n",
        "                    # 替換常見位置表述模式\n",
        "                    text = re.sub(r'in ' + re.escape(location), \"in the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'of ' + re.escape(location), \"of the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'\\b' + re.escape(location) + r'\\b', \"the urban area\", text, flags=re.IGNORECASE)\n",
        "\n",
        "        except ImportError:\n",
        "            # 如果無法導入，使用基本模式\n",
        "            pass\n",
        "\n",
        "        # 通用地標描述模式替換\n",
        "        landmark_patterns = [\n",
        "            (r'a (tourist|popular|famous) landmark', r'an urban structure'),\n",
        "            (r'an iconic structure in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure in the area'),\n",
        "            (r'a famous (monument|tower|landmark) in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure in the area'),\n",
        "            (r'(centered|built|located|positioned) around the ([A-Z][a-zA-Z\\s]+? (Tower|Monument|Landmark))', r'located in this area'),\n",
        "            (r'(sightseeing|guided tours|cultural tourism) (at|around|near) (this landmark|the [A-Z][a-zA-Z\\s]+)', r'\\1 in this area'),\n",
        "            (r'this (famous|iconic|historic|well-known) (landmark|monument|tower|structure)', r'this urban structure'),\n",
        "            (r'([A-Z][a-zA-Z\\s]+) Tower', r'tall structure'),\n",
        "            (r'a (tower|structure) in ([A-Z][a-zA-Z\\s,]+)', r'a \\1 in the area'),\n",
        "            (r'landmark scene', r'urban scene'),\n",
        "            (r'tourist destination', r'urban area'),\n",
        "            (r'tourist attraction', r'urban area')\n",
        "        ]\n",
        "\n",
        "        for pattern, replacement in landmark_patterns:\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "    def generate_description(self, scene_type: str, detected_objects: List[Dict], confidence: float,\n",
        "                    lighting_info: Dict, functional_zones: List[str], enable_landmark: bool = True,\n",
        "                    scene_scores: Optional[Dict] = None, spatial_analysis: Optional[Dict] = None,\n",
        "                    image_dimensions: Optional[Dict] = None, places365_info: Optional[Dict] = None,\n",
        "                    object_statistics: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate enhanced scene description based on detection results, scene type,\n",
        "        and additional contextual information.\n",
        "        This version ensures that the main scene_details (from the first call)\n",
        "        is properly integrated and not overwritten by a simplified second call.\n",
        "        \"\"\"\n",
        "        # Handle unknown scene type or very low confidence as an early exit\n",
        "        if scene_type == \"unknown\" or confidence < 0.4:\n",
        "            # _generate_generic_description should also ideally use image_dimensions if it does spatial reasoning\n",
        "            generic_desc = self._generate_generic_description(detected_objects, lighting_info)\n",
        "            return self._format_final_description(generic_desc)\n",
        "\n",
        "        # Filter out landmark objects if landmark detection is disabled for this run\n",
        "        current_detected_objects = detected_objects\n",
        "        if not enable_landmark:\n",
        "            current_detected_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "\n",
        "        # Log Places365 context if available\n",
        "        places365_context = \"\"\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.3:\n",
        "            scene_label = places365_info.get('scene_label', '')\n",
        "            attributes = places365_info.get('attributes', [])\n",
        "            is_indoor = places365_info.get('is_indoor', None)\n",
        "\n",
        "            if scene_label:\n",
        "                places365_context = f\"Scene context: {scene_label}\"\n",
        "                if attributes:\n",
        "                    places365_context += f\" with characteristics: {', '.join(attributes[:3])}\"\n",
        "                if is_indoor is not None:\n",
        "                    indoor_outdoor = \"indoor\" if is_indoor else \"outdoor\"\n",
        "                    places365_context += f\" ({indoor_outdoor} environment)\"\n",
        "\n",
        "            print(f\"Enhanced description incorporating Places365 context: {places365_context}\")\n",
        "\n",
        "        landmark_objects_in_scene = [obj for obj in current_detected_objects if obj.get(\"is_landmark\", False)]\n",
        "        has_landmark_in_scene = len(landmark_objects_in_scene) > 0\n",
        "\n",
        "        # If landmark processing is enabled and it's a landmark scene or landmarks are detected\n",
        "        if enable_landmark and (scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"] or has_landmark_in_scene):\n",
        "            landmark_desc = self._generate_landmark_description(\n",
        "                scene_type,\n",
        "                current_detected_objects, # Pass potentially filtered list\n",
        "                confidence,\n",
        "                lighting_info,\n",
        "                functional_zones,\n",
        "                landmark_objects_in_scene # Pass the explicitly filtered landmark objects\n",
        "            )\n",
        "            return self._format_final_description(landmark_desc)\n",
        "\n",
        "        # **[Start of main description construction for non-landmark or landmark-disabled everyday scenes]**\n",
        "\n",
        "        # Detect viewpoint based on current (potentially filtered) objects\n",
        "        viewpoint = self._detect_viewpoint(current_detected_objects)\n",
        "        current_scene_type = scene_type # Use a mutable variable for scene_type if it can change\n",
        "\n",
        "        # Process aerial viewpoint scene types (may re-assign current_scene_type)\n",
        "        if viewpoint == \"aerial\":\n",
        "            if \"intersection\" in current_scene_type.lower() or self._is_intersection(current_detected_objects): # Use lower for robustness\n",
        "                current_scene_type = \"aerial_view_intersection\"\n",
        "            elif any(keyword in current_scene_type.lower() for keyword in [\"commercial\", \"shopping\", \"retail\"]):\n",
        "                current_scene_type = \"aerial_view_commercial_area\"\n",
        "            elif any(keyword in current_scene_type.lower() for keyword in [\"plaza\", \"square\"]):\n",
        "                current_scene_type = \"aerial_view_plaza\"\n",
        "            else: # Default aerial if specific not matched\n",
        "                current_scene_type = \"aerial_view_general\" # Or use a specific default like aerial_view_intersection\n",
        "\n",
        "        # Detect cultural context (only for non-aerial viewpoints)\n",
        "        cultural_context = None\n",
        "        if viewpoint != \"aerial\":\n",
        "            cultural_context = self._detect_cultural_context(current_scene_type, current_detected_objects)\n",
        "\n",
        "        # Get base description for the (potentially updated) scene type\n",
        "        base_description = \"A scene\" # Default initialization\n",
        "        if viewpoint == \"aerial\":\n",
        "            # Check if current_scene_type (which might be an aerial type) has a base description\n",
        "            if current_scene_type in self.scene_types:\n",
        "                 base_description = self.scene_types[current_scene_type].get(\"description\", \"An aerial view showing the layout and movement patterns from above\")\n",
        "            else:\n",
        "                 base_description = \"An aerial view showing the layout and movement patterns from above\"\n",
        "        elif current_scene_type in self.scene_types:\n",
        "            base_description = self.scene_types[current_scene_type].get(\"description\", \"A scene\")\n",
        "\n",
        "        # spatial analysis, and image dimensions. This is where dynamic description or template filling happens.\n",
        "        core_scene_details = self._generate_scene_details(\n",
        "            current_scene_type, # Use the potentially updated scene_type\n",
        "            current_detected_objects,\n",
        "            lighting_info,\n",
        "            viewpoint,\n",
        "            spatial_analysis=spatial_analysis,    # Pass this through\n",
        "            image_dimensions=image_dimensions,     # Pass this through\n",
        "            places365_info=places365_info,        # Pass Places365 info\n",
        "            object_statistics=object_statistics   # Pass object statistics\n",
        "        )\n",
        "\n",
        "        # Start with the base description derived from SCENE_TYPES or a default.\n",
        "        description = base_description\n",
        "        if core_scene_details and core_scene_details.strip() != \"\": # Ensure core_scene_details is not empty\n",
        "            # If base_description is generic like \"A scene\", consider replacing it or appending smartly.\n",
        "            if base_description.lower() == \"a scene\" and len(core_scene_details) > len(base_description):\n",
        "                description = core_scene_details # Prioritize dynamic/template-filled details if base is too generic\n",
        "            else:\n",
        "                description = self._smart_append(description, core_scene_details)\n",
        "        elif not core_scene_details and not description: # If both are empty, use a generic fallback\n",
        "            description = self._generate_generic_description(current_detected_objects, lighting_info)\n",
        "\n",
        "\n",
        "        # Append secondary description from scene type template, if any\n",
        "        if current_scene_type in self.scene_types and \"secondary_description\" in self.scene_types[current_scene_type]:\n",
        "            secondary_desc = self.scene_types[current_scene_type][\"secondary_description\"]\n",
        "            if secondary_desc:\n",
        "                description = self._smart_append(description, secondary_desc)\n",
        "\n",
        "        # Append people count information\n",
        "        people_objs = [obj for obj in current_detected_objects if obj.get(\"class_id\") == 0]\n",
        "        if people_objs:\n",
        "            people_count = len(people_objs)\n",
        "\n",
        "            if people_count == 1: people_phrase = \"a single person\"\n",
        "            elif people_count > 1 and people_count <= 3: people_phrase = f\"{people_count} people\" # Accurate for small counts\n",
        "            elif people_count > 3 and people_count <=7: people_phrase = \"several people\"\n",
        "            else: people_phrase = \"multiple people\" # For larger counts, or use \"numerous\"\n",
        "\n",
        "            # Only add if not already well covered in core_scene_details or base_description\n",
        "            if \"person\" not in description.lower() and \"people\" not in description.lower() and \"pedestrian\" not in description.lower():\n",
        "                description = self._smart_append(description, f\"The scene includes {people_phrase}.\")\n",
        "\n",
        "        # Append cultural context\n",
        "        if cultural_context and viewpoint != \"aerial\": # Already checked viewpoint\n",
        "            cultural_elements = self._generate_cultural_elements(cultural_context)\n",
        "            if cultural_elements:\n",
        "                description = self._smart_append(description, cultural_elements)\n",
        "\n",
        "        # Append lighting information\n",
        "        lighting_description_text = \"\"\n",
        "        if lighting_info and \"time_of_day\" in lighting_info:\n",
        "            lighting_type = lighting_info[\"time_of_day\"]\n",
        "            lighting_desc_template = self.templates.get(\"lighting_templates\", {}).get(lighting_type)\n",
        "            if lighting_desc_template:\n",
        "                lighting_description_text = lighting_desc_template\n",
        "        if lighting_description_text and lighting_description_text.lower() not in description.lower():\n",
        "            description = self._smart_append(description, lighting_description_text)\n",
        "\n",
        "        # Append viewpoint information (if not eye-level)\n",
        "        if viewpoint != \"eye_level\" and viewpoint in self.templates.get(\"viewpoint_templates\", {}):\n",
        "            viewpoint_template = self.templates[\"viewpoint_templates\"][viewpoint]\n",
        "            prefix = viewpoint_template.get('prefix', '')\n",
        "            observation_template = viewpoint_template.get(\"observation\", \"\")\n",
        "\n",
        "            # Determine scene_elements for the observation template\n",
        "            scene_elements_for_vp = \"the overall layout and objects\" # Generic default\n",
        "            if viewpoint == \"aerial\":\n",
        "                scene_elements_for_vp = \"crossing patterns and general layout\"\n",
        "\n",
        "            viewpoint_observation_text = observation_template.format(scene_elements=scene_elements_for_vp)\n",
        "\n",
        "            # Combine prefix and observation carefully\n",
        "            full_viewpoint_text = \"\"\n",
        "            if prefix:\n",
        "                full_viewpoint_text = prefix.strip() + \" \"\n",
        "                if viewpoint_observation_text and viewpoint_observation_text[0].islower():\n",
        "                    full_viewpoint_text += viewpoint_observation_text\n",
        "                elif viewpoint_observation_text:\n",
        "                    full_viewpoint_text = prefix + viewpoint_observation_text[0].lower() + viewpoint_observation_text[1:] if description else prefix + viewpoint_observation_text\n",
        "\n",
        "            elif viewpoint_observation_text: # No prefix, but observation exists\n",
        "                 full_viewpoint_text = viewpoint_observation_text[0].upper() + viewpoint_observation_text[1:]\n",
        "\n",
        "\n",
        "            if full_viewpoint_text and full_viewpoint_text.lower() not in description.lower():\n",
        "                description = self._smart_append(description, full_viewpoint_text)\n",
        "\n",
        "\n",
        "        # Append functional zones information\n",
        "        if functional_zones and len(functional_zones) > 0:\n",
        "            zones_desc_text = self._describe_functional_zones(functional_zones)\n",
        "            if zones_desc_text:\n",
        "                description = self._smart_append(description, zones_desc_text)\n",
        "\n",
        "        final_formatted_description = self._format_final_description(description)\n",
        "\n",
        "        if not enable_landmark:\n",
        "            final_formatted_description = self.filter_landmark_references(final_formatted_description, enable_landmark=False)\n",
        "\n",
        "        # If after all processing, description is empty, fallback to a very generic one.\n",
        "        if not final_formatted_description.strip() or final_formatted_description.strip() == \".\":\n",
        "            self.logger.warning(f\"Description for scene_type '{current_scene_type}' became empty after processing. Falling back.\")\n",
        "            final_formatted_description = self._format_final_description(\n",
        "                self._generate_generic_description(current_detected_objects, lighting_info)\n",
        "            )\n",
        "\n",
        "        return final_formatted_description\n",
        "\n",
        "\n",
        "    def _smart_append(self, current_text: str, new_fragment: str) -> str:\n",
        "        \"\"\"\n",
        "        Intelligently append a new text fragment to the current text,\n",
        "        handling punctuation and capitalization correctly.\n",
        "\n",
        "        Args:\n",
        "            current_text: The existing text to append to\n",
        "            new_fragment: The new text fragment to append\n",
        "\n",
        "        Returns:\n",
        "            str: The combined text with proper formatting\n",
        "        \"\"\"\n",
        "        # Handle empty cases\n",
        "        if not new_fragment:\n",
        "            return current_text\n",
        "\n",
        "        if not current_text:\n",
        "            # Ensure first character is uppercase for the first fragment\n",
        "            return new_fragment[0].upper() + new_fragment[1:] if new_fragment else \"\"\n",
        "\n",
        "        # Clean up existing text\n",
        "        current_text = current_text.rstrip()\n",
        "\n",
        "        # Check for ending punctuation\n",
        "        ends_with_sentence = current_text.endswith(('.', '!', '?'))\n",
        "        ends_with_comma = current_text.endswith(',')\n",
        "\n",
        "        # Specifically handle the \"A xxx A yyy\" pattern that's causing issues\n",
        "        if (current_text.startswith(\"A \") or current_text.startswith(\"An \")) and \\\n",
        "        (new_fragment.startswith(\"A \") or new_fragment.startswith(\"An \")):\n",
        "            return current_text + \". \" + new_fragment\n",
        "\n",
        "        # 檢查新片段是否包含地標名稱（通常為專有名詞）\n",
        "        has_landmark_name = any(word[0].isupper() for word in new_fragment.split()\n",
        "                            if len(word) > 2 and not word.startswith((\"A \", \"An \", \"The \")))\n",
        "\n",
        "        # Decide how to join the texts\n",
        "        if ends_with_sentence:\n",
        "            # After a sentence, start with uppercase and add proper spacing\n",
        "            joined_text = current_text + \" \" + (new_fragment[0].upper() + new_fragment[1:])\n",
        "        elif ends_with_comma:\n",
        "            # After a comma, maintain flow with lowercase unless it's a proper noun or special case\n",
        "            if new_fragment.startswith(('I ', 'I\\'', 'A ', 'An ', 'The ')) or new_fragment[0].isupper() or has_landmark_name:\n",
        "                joined_text = current_text + \" \" + new_fragment\n",
        "            else:\n",
        "                joined_text = current_text + \" \" + new_fragment[0].lower() + new_fragment[1:]\n",
        "        elif \"scene is\" in new_fragment.lower() or \"scene includes\" in new_fragment.lower():\n",
        "            # When adding a new sentence about the scene, use a period\n",
        "            joined_text = current_text + \". \" + new_fragment\n",
        "        else:\n",
        "            # For other cases, decide based on the content\n",
        "            if self._is_related_phrases(current_text, new_fragment):\n",
        "                if new_fragment.startswith(('I ', 'I\\'', 'A ', 'An ', 'The ')) or new_fragment[0].isupper() or has_landmark_name:\n",
        "                    joined_text = current_text + \", \" + new_fragment\n",
        "                else:\n",
        "                    joined_text = current_text + \", \" + new_fragment[0].lower() + new_fragment[1:]\n",
        "            else:\n",
        "                # Use period for unrelated phrases\n",
        "                joined_text = current_text + \". \" + (new_fragment[0].upper() + new_fragment[1:])\n",
        "\n",
        "        return joined_text\n",
        "\n",
        "    def _is_related_phrases(self, text1: str, text2: str) -> bool:\n",
        "        \"\"\"\n",
        "        Determine if two phrases are related and should be connected with a comma\n",
        "        rather than separated with a period.\n",
        "\n",
        "        Args:\n",
        "            text1: The first text fragment\n",
        "            text2: The second text fragment to be appended\n",
        "\n",
        "        Returns:\n",
        "            bool: Whether the phrases appear to be related\n",
        "        \"\"\"\n",
        "        # Check if either phrase starts with \"A\" or \"An\" - these are likely separate descriptions\n",
        "        if (text1.startswith(\"A \") or text1.startswith(\"An \")) and \\\n",
        "        (text2.startswith(\"A \") or text2.startswith(\"An \")):\n",
        "            return False  # These are separate descriptions, not related phrases\n",
        "\n",
        "        # Check if the second phrase starts with a connecting word\n",
        "        connecting_words = [\"which\", \"where\", \"who\", \"whom\", \"whose\", \"with\", \"without\",\n",
        "                        \"this\", \"these\", \"that\", \"those\", \"and\", \"or\", \"but\"]\n",
        "\n",
        "        first_word = text2.split()[0].lower() if text2 else \"\"\n",
        "        if first_word in connecting_words:\n",
        "            return True\n",
        "\n",
        "        # Check if the first phrase ends with something that suggests continuity\n",
        "        ending_patterns = [\"such as\", \"including\", \"like\", \"especially\", \"particularly\",\n",
        "                        \"for example\", \"for instance\", \"namely\", \"specifically\"]\n",
        "\n",
        "        for pattern in ending_patterns:\n",
        "            if text1.lower().endswith(pattern):\n",
        "                return True\n",
        "\n",
        "        # Check if both phrases are about the scene\n",
        "        if \"scene\" in text1.lower() and \"scene\" in text2.lower():\n",
        "            return False  # Separate statements about the scene should be separate sentences\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _format_final_description(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Format the final description text to ensure correct punctuation,\n",
        "        capitalization, and spacing.\n",
        "        \"\"\"\n",
        "        if not text or not text.strip(): # Also check if text is just whitespace\n",
        "            return \"\"\n",
        "\n",
        "        # Trim leading/trailing whitespace first\n",
        "        text = text.strip()\n",
        "\n",
        "        # 1. Handle consecutive \"A/An\" segments (potentially split them into sentences)\n",
        "        text = re.sub(r'(A\\s+[^.!?]+?[\\w\\.])\\s+(A\\s+)', r'\\1. \\2', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'(An\\s+[^.!?]+?[\\w\\.])\\s+(An?\\s+)', r'\\1. \\2', text, flags=re.IGNORECASE)\n",
        "\n",
        "        # 2. Ensure first character of the entire text is uppercase\n",
        "        if text:\n",
        "            text = text[0].upper() + text[1:]\n",
        "\n",
        "        # 3. Normalize whitespace: multiple spaces to one\n",
        "        text = re.sub(r'\\s{2,}', ' ', text)\n",
        "\n",
        "        # 4. Capitalize after sentence-ending punctuation (. ! ?)\n",
        "        def capitalize_after_punctuation(match):\n",
        "            return match.group(1) + match.group(2).upper()\n",
        "        text = re.sub(r'([.!?]\\s+)([a-z])', capitalize_after_punctuation, text)\n",
        "\n",
        "        # 5. Handle capitalization after commas (your existing robust logic is good)\n",
        "        def fix_capitalization_after_comma(match):\n",
        "            leading_comma_space = match.group(1) # (,\\s+)\n",
        "            word_after_comma = match.group(2)    # ([A-Z][a-zA-Z]*)\n",
        "\n",
        "            proper_nouns_exceptions = [\"I\", \"I'm\", \"I've\", \"I'd\", \"I'll\",\n",
        "                                     \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",\n",
        "                                     \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",\n",
        "                                     \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "            if word_after_comma in proper_nouns_exceptions:\n",
        "                return match.group(0)\n",
        "            # If the word looks like a proper noun (e.g., multi-word capitalized, or a known location/brand)\n",
        "            # This heuristic can be tricky. For simplicity, if it's already capitalized and not a common word, keep it.\n",
        "            if len(word_after_comma) > 2 and word_after_comma[0].isupper() and word_after_comma.lower() not in [\"this\", \"that\", \"these\", \"those\", \"they\", \"their\", \"then\", \"thus\"]:\n",
        "                 return match.group(0) # Keep it if it looks like a proper noun already\n",
        "\n",
        "            return leading_comma_space + word_after_comma[0].lower() + word_after_comma[1:]\n",
        "        text = re.sub(r'(,\\s+)([A-Z][a-zA-Z\\'\\-]+)', fix_capitalization_after_comma, text) # Added hyphen and apostrophe to word\n",
        "\n",
        "        # 6. Correct spacing around punctuation\n",
        "        text = re.sub(r'\\s*([.,;:!?])\\s*', r'\\1 ', text) # Ensures one space AFTER punctuation, none before\n",
        "        text = text.replace(' .', '.').replace(' ,', ',') # Clean up potential space before period/comma from previous rule\n",
        "\n",
        "        # 7. Consolidate multiple sentence-ending punctuations (e.g., \"!!\", \"?.\", \".?\")\n",
        "        text = re.sub(r'[.!?]{2,}', '.', text) # Convert multiple to a single period\n",
        "        text = re.sub(r',+', ',', text) # Multiple commas to one\n",
        "\n",
        "        # 8. Ensure text ends with a single sentence-ending punctuation mark\n",
        "        text = text.strip() # Remove trailing whitespace before checking last char\n",
        "        if text and not text[-1] in '.!?':\n",
        "            text += '.'\n",
        "\n",
        "        # 9. Remove any leading punctuation or extra spaces that might have been introduced\n",
        "        text = re.sub(r'^[.,;:!?\\s]+', '', text)\n",
        "\n",
        "        # 10. Final check for first letter capitalization\n",
        "        if text:\n",
        "            text = text[0].upper() + text[1:]\n",
        "\n",
        "        # 11. Remove space before final punctuation mark if accidentally added by rule 7\n",
        "        text = re.sub(r'\\s+([.!?])$', r'\\1', text)\n",
        "\n",
        "        return text.strip() # Final strip\n",
        "\n",
        "    def _is_intersection(self, detected_objects: List[Dict]) -> bool:\n",
        "        \"\"\"\n",
        "        通過分析物體分佈來判斷場景是否為十字路口\n",
        "        \"\"\"\n",
        "        # 檢查行人分佈模式\n",
        "        pedestrians = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "\n",
        "        if len(pedestrians) >= 8:  # 需要足夠的行人來形成十字路口\n",
        "            # 抓取行人位置\n",
        "            positions = [obj.get(\"normalized_center\", (0, 0)) for obj in pedestrians]\n",
        "\n",
        "            # 分析 x 和 y 坐標分佈\n",
        "            x_coords = [pos[0] for pos in positions]\n",
        "            y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "            # 計算 x 和 y 坐標的變異數\n",
        "            x_variance = np.var(x_coords) if len(x_coords) > 1 else 0\n",
        "            y_variance = np.var(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "            # 計算範圍\n",
        "            x_range = max(x_coords) - min(x_coords)\n",
        "            y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "            # 如果 x 和 y 方向都有較大範圍且範圍相似，那就有可能是十字路口\n",
        "            if x_range > 0.5 and y_range > 0.5 and 0.7 < (x_range / y_range) < 1.3:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _generate_generic_description(self, detected_objects: List[Dict], lighting_info: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate a generic description when scene type is unknown or confidence is very low.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            lighting_info: Optional lighting condition information\n",
        "\n",
        "        Returns:\n",
        "            str: Generic description based on detected objects\n",
        "        \"\"\"\n",
        "        # Count object occurrences\n",
        "        obj_counts = {}\n",
        "        for obj in detected_objects:\n",
        "            class_name = obj[\"class_name\"]\n",
        "            if class_name not in obj_counts:\n",
        "                obj_counts[class_name] = 0\n",
        "            obj_counts[class_name] += 1\n",
        "\n",
        "        # Get top objects by count\n",
        "        top_objects = sorted(obj_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "        if not top_objects:\n",
        "            base_desc = \"No clearly identifiable objects are visible in this scene.\"\n",
        "        else:\n",
        "            # Format object list\n",
        "            objects_text = []\n",
        "            for name, count in top_objects:\n",
        "                if count > 1:\n",
        "                    objects_text.append(f\"{count} {name}s\")\n",
        "                else:\n",
        "                    objects_text.append(name)\n",
        "\n",
        "            if len(objects_text) == 1:\n",
        "                objects_list = objects_text[0]\n",
        "            elif len(objects_text) == 2:\n",
        "                objects_list = f\"{objects_text[0]} and {objects_text[1]}\"\n",
        "            else:\n",
        "                objects_list = \", \".join(objects_text[:-1]) + f\", and {objects_text[-1]}\"\n",
        "\n",
        "            base_desc = f\"This scene contains {objects_list}.\"\n",
        "\n",
        "        # Add lighting information if available\n",
        "        if lighting_info and \"time_of_day\" in lighting_info:\n",
        "            lighting_type = lighting_info[\"time_of_day\"]\n",
        "            if lighting_type in self.templates.get(\"lighting_templates\", {}):\n",
        "                lighting_desc = self.templates[\"lighting_templates\"][lighting_type]\n",
        "                base_desc += f\" {lighting_desc}\"\n",
        "\n",
        "        return base_desc\n",
        "\n",
        "    def _get_prominent_objects(self, detected_objects: List[Dict], min_prominence_score: float = 0.1, max_categories_to_return: int = 5, max_total_objects: int = 7) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Helper function to get the most prominent objects.\n",
        "        Prioritizes high-confidence, large objects, and ensures a diversity of object types.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects.\n",
        "            min_prominence_score: Minimum score for an object to be considered initially.\n",
        "            max_categories_to_return: Max number of different object categories to prioritize.\n",
        "            max_total_objects: Overall cap on the number of prominent objects returned.\n",
        "\n",
        "        Returns:\n",
        "            List of prominent detected objects.\n",
        "        \"\"\"\n",
        "        if not detected_objects:\n",
        "            return []\n",
        "\n",
        "        scored_objects = []\n",
        "        for obj in detected_objects:\n",
        "            area = obj.get(\"normalized_area\", 0.0) + 1e-6\n",
        "            confidence = obj.get(\"confidence\", 0.0)\n",
        "\n",
        "            # Base score: area and confidence are key\n",
        "            score = (area * 0.65) + (confidence * 0.35) # Slightly more weight to area\n",
        "\n",
        "            # Bonus for generally important object classes (in a generic way)\n",
        "            # This is a simple heuristic. More advanced would be context-dependent.\n",
        "            # For example, 'person' is often more salient.\n",
        "            # Avoid hardcoding specific class_ids here if possible, or use broad categories if available.\n",
        "            # For simplicity, we'll keep the landmark bonus for now.\n",
        "            if obj.get(\"class_name\") == \"person\": # Example: person is generally prominent\n",
        "                 score += 0.1\n",
        "            if obj.get(\"is_landmark\"): # Landmarks are always prominent\n",
        "                score += 0.5\n",
        "\n",
        "            if score >= min_prominence_score:\n",
        "                 scored_objects.append((obj, score))\n",
        "\n",
        "        if not scored_objects:\n",
        "            return []\n",
        "\n",
        "        # Sort by score in descending order\n",
        "        scored_objects.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Prioritize diversity of object categories first\n",
        "        prominent_by_category = {}\n",
        "        final_prominent_objects = []\n",
        "\n",
        "        for obj, score in scored_objects:\n",
        "            category = obj.get(\"class_name\", \"unknown\")\n",
        "            if category not in prominent_by_category:\n",
        "                if len(prominent_by_category) < max_categories_to_return:\n",
        "                    prominent_by_category[category] = obj\n",
        "                    final_prominent_objects.append(obj)\n",
        "\n",
        "            elif len(final_prominent_objects) < max_total_objects and obj not in final_prominent_objects:\n",
        "                 if score > 0.3:\n",
        "                    final_prominent_objects.append(obj)\n",
        "\n",
        "        # If still under max_total_objects, fill with highest scored remaining objects regardless of category\n",
        "        if len(final_prominent_objects) < max_total_objects:\n",
        "            for obj, score in scored_objects:\n",
        "                if len(final_prominent_objects) >= max_total_objects:\n",
        "                    break\n",
        "                if obj not in final_prominent_objects:\n",
        "                    final_prominent_objects.append(obj)\n",
        "\n",
        "        # Re-sort the final list by original prominence score to maintain order\n",
        "        final_prominent_objects_with_scores = []\n",
        "        for obj in final_prominent_objects:\n",
        "            for original_obj, original_score in scored_objects:\n",
        "                if obj is original_obj: # Check for object identity\n",
        "                    final_prominent_objects_with_scores.append((obj, original_score))\n",
        "                    break\n",
        "\n",
        "        final_prominent_objects_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return [obj for obj, score in final_prominent_objects_with_scores[:max_total_objects]]\n",
        "\n",
        "\n",
        "    def _format_object_list_for_description(self,\n",
        "                                            objects: List[Dict],\n",
        "                                            use_indefinite_article_for_one: bool = False,\n",
        "                                            count_threshold_for_generalization: int = -1, # Default to -1 for precise counts\n",
        "                                            max_types_to_list: int = 5\n",
        "                                           ) -> str:\n",
        "        \"\"\"\n",
        "        Formats a list of detected objects into a human-readable string with counts.\n",
        "        Args:\n",
        "            objects: List of object dictionaries, each expected to have 'class_name'.\n",
        "            use_indefinite_article_for_one: If True, uses \"a/an\" for single items. If False, uses \"one\".\n",
        "            count_threshold_for_generalization: If count exceeds this, use general terms. -1 means precise counts.\n",
        "            max_types_to_list: Maximum number of different object types to include in the list.\n",
        "        \"\"\"\n",
        "        if not objects:\n",
        "            return \"no specific objects clearly identified\"\n",
        "\n",
        "        counts: Dict[str, int] = {}\n",
        "        for obj in objects:\n",
        "            name = obj.get(\"class_name\", \"unknown object\")\n",
        "            if name == \"unknown object\" or not name: # Skip unknown or empty names\n",
        "                continue\n",
        "            counts[name] = counts.get(name, 0) + 1\n",
        "\n",
        "        if not counts:\n",
        "            return \"no specific objects clearly identified\"\n",
        "\n",
        "        descriptions = []\n",
        "        # Sort by count (desc) then name (asc) for consistent output order\n",
        "        # Limit the number of distinct object types being listed\n",
        "        sorted_counts = sorted(counts.items(), key=lambda item: (-item[1], item[0]))[:max_types_to_list]\n",
        "\n",
        "\n",
        "        for name, count in sorted_counts:\n",
        "            if count == 1:\n",
        "                if use_indefinite_article_for_one:\n",
        "                    if name[0].lower() in 'aeiou':\n",
        "                        descriptions.append(f\"an {name}\")\n",
        "                    else:\n",
        "                        descriptions.append(f\"a {name}\")\n",
        "                else:\n",
        "                    descriptions.append(f\"one {name}\") # Output \"one car\" instead of \"a car\"\n",
        "            else: # count > 1\n",
        "                plural_name = name\n",
        "                if name.endswith(\"y\") and not name.lower().endswith((\"ay\", \"ey\", \"iy\", \"oy\", \"uy\")):\n",
        "                    plural_name = name[:-1] + \"ies\"\n",
        "                elif name.endswith((\"s\", \"sh\", \"ch\", \"x\", \"z\")):\n",
        "                    plural_name = name + \"es\"\n",
        "                elif not name.endswith(\"s\"): # Avoid double 's' like \"buss\"\n",
        "                    plural_name = name + \"s\"\n",
        "\n",
        "                if count_threshold_for_generalization != -1 and count > count_threshold_for_generalization:\n",
        "                    if count <= count_threshold_for_generalization + 3:\n",
        "                        descriptions.append(f\"several {plural_name}\")\n",
        "                    else:\n",
        "                        descriptions.append(f\"many {plural_name}\")\n",
        "                else: # Use exact count (e.g., \"6 cars\")\n",
        "                    descriptions.append(f\"{count} {plural_name}\")\n",
        "\n",
        "        if not descriptions:\n",
        "            return \"no specific objects clearly identified\"\n",
        "\n",
        "        if len(descriptions) == 1:\n",
        "            return descriptions[0]\n",
        "        elif len(descriptions) == 2:\n",
        "            return f\"{descriptions[0]} and {descriptions[1]}\"\n",
        "        else:\n",
        "            # Oxford comma for lists of 3 or more.\n",
        "            return \", \".join(descriptions[:-1]) + f\", and {descriptions[-1]}\"\n",
        "\n",
        "    def _get_spatial_description(self, obj: Dict, image_width: Optional[int] = None, image_height: Optional[int] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generates a brief spatial description for an object.\n",
        "        (This is a new helper function)\n",
        "        \"\"\"\n",
        "        region = obj.get(\"region\")\n",
        "        if region:\n",
        "            # Convert region name to more descriptive terms\n",
        "            region_map = {\n",
        "                \"top_left\": \"in the top-left\", \"top_center\": \"at the top-center\", \"top_right\": \"in the top-right\",\n",
        "                \"middle_left\": \"on the middle-left side\", \"middle_center\": \"in the center\", \"middle_right\": \"on the middle-right side\",\n",
        "                \"bottom_left\": \"in the bottom-left\", \"bottom_center\": \"at the bottom-center\", \"bottom_right\": \"in the bottom-right\"\n",
        "            }\n",
        "            # More general terms if exact region is not critical\n",
        "            if \"top\" in region: general_v_pos = \"towards the top\"\n",
        "            elif \"bottom\" in region: general_v_pos = \"towards the bottom\"\n",
        "            else: general_v_pos = \"in the middle vertically\"\n",
        "\n",
        "            if \"left\" in region: general_h_pos = \"towards the left\"\n",
        "            elif \"right\" in region: general_h_pos = \"towards the right\"\n",
        "            else: general_h_pos = \"in the center horizontally\"\n",
        "\n",
        "            # Prioritize specific region if available, else use general\n",
        "            specific_desc = region_map.get(region, \"\")\n",
        "            if specific_desc:\n",
        "                return f\"{specific_desc} of the frame\"\n",
        "            else:\n",
        "                return f\"{general_v_pos} and {general_h_pos} of the frame\"\n",
        "\n",
        "        # Fallback if region info is not detailed enough or missing\n",
        "        # We can use normalized_center if available\n",
        "        norm_center = obj.get(\"normalized_center\")\n",
        "        if norm_center and image_width and image_height: # Check if image_width/height are provided\n",
        "            x_norm, y_norm = norm_center\n",
        "            h_pos = \"left\" if x_norm < 0.4 else \"right\" if x_norm > 0.6 else \"center\"\n",
        "            v_pos = \"top\" if y_norm < 0.4 else \"bottom\" if y_norm > 0.6 else \"middle\"\n",
        "\n",
        "            if h_pos == \"center\" and v_pos == \"middle\":\n",
        "                return \"near the center of the image\"\n",
        "            return f\"in the {v_pos}-{h_pos} area of the image\"\n",
        "\n",
        "        return \"in the scene\" # Generic fallback\n",
        "\n",
        "\n",
        "    def _generate_dynamic_everyday_description(self,\n",
        "                                          detected_objects: List[Dict],\n",
        "                                          lighting_info: Optional[Dict] = None,\n",
        "                                          viewpoint: str = \"eye_level\",\n",
        "                                          spatial_analysis: Optional[Dict] = None,\n",
        "                                          image_dimensions: Optional[Tuple[int, int]] = None,\n",
        "                                          places365_info: Optional[Dict] = None,\n",
        "                                          object_statistics: Optional[Dict] = None\n",
        "                                          ) -> str:\n",
        "        \"\"\"\n",
        "        Dynamically generates a description for everyday scenes based on ALL relevant detected_objects,\n",
        "        their counts, and context.\n",
        "        It aims to describe the overall scene first, then details of object groups including accurate counts.\n",
        "        \"\"\"\n",
        "        description_segments = []\n",
        "        image_width, image_height = image_dimensions if image_dimensions else (None, None)\n",
        "\n",
        "        if hasattr(self, 'logger'):\n",
        "            self.logger.info(f\"DynamicDesc: Start. Total Raw Objects: {len(detected_objects)}, View: {viewpoint}, Light: {lighting_info is not None}\")\n",
        "\n",
        "        # 1. Overall Ambiance (Lighting and Viewpoint)\n",
        "        ambiance_parts = []\n",
        "        if lighting_info:\n",
        "            time_of_day = lighting_info.get(\"time_of_day\", \"unknown lighting\")\n",
        "            is_indoor = lighting_info.get(\"is_indoor\")\n",
        "            ambiance_statement = \"This is\"\n",
        "            if is_indoor is True: ambiance_statement += \" an indoor scene\"\n",
        "            elif is_indoor is False: ambiance_statement += \" an outdoor scene\"\n",
        "            else: ambiance_statement += \" a scene\"\n",
        "            lighting_map = self.templates.get(\"lighting_templates\", {})\n",
        "            readable_lighting_base = lighting_map.get(time_of_day, f\"with {time_of_day.replace('_', ' ')} lighting conditions\")\n",
        "            readable_lighting = readable_lighting_base.lower().replace(\"the scene is captured\", \"\").replace(\"the scene has\", \"\").strip()\n",
        "            ambiance_statement += f\", likely {readable_lighting}.\"\n",
        "            ambiance_parts.append(ambiance_statement)\n",
        "\n",
        "        if viewpoint and viewpoint != \"eye_level\":\n",
        "            vp_templates = self.templates.get(\"viewpoint_templates\", {})\n",
        "            if viewpoint in vp_templates:\n",
        "                vp_prefix = vp_templates[viewpoint].get(\"prefix\", \"\").strip()\n",
        "                if vp_prefix:\n",
        "                    if not ambiance_parts:\n",
        "                        ambiance_parts.append(f\"{vp_prefix.capitalize()} the general layout of the scene is observed.\")\n",
        "                    else:\n",
        "                        ambiance_parts[-1] = ambiance_parts[-1].rstrip('.') + f\", viewed {vp_templates[viewpoint].get('short_desc', viewpoint)}.\"\n",
        "\n",
        "        if ambiance_parts:\n",
        "            description_segments.append(\" \".join(ambiance_parts))\n",
        "\n",
        "        # 2. Describe ALL detected objects, grouped by class, with accurate counts and locations\n",
        "        if not detected_objects:\n",
        "            # This part remains, but the conditions to reach here might change based on confident_objects check\n",
        "            if not description_segments:\n",
        "                 description_segments.append(\"A general scene is visible, but no specific objects were clearly identified.\")\n",
        "            else:\n",
        "                 description_segments.append(\"Within this setting, no specific objects were clearly identified.\")\n",
        "        else:\n",
        "            objects_by_class: Dict[str, List[Dict]] = {}\n",
        "\n",
        "            # keeping 0.25 as a placeholder\n",
        "            confidence_filter_threshold = getattr(self, 'confidence_threshold_for_description', 0.25)\n",
        "            confident_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= confidence_filter_threshold]\n",
        "\n",
        "            if not confident_objects:\n",
        "                 # This message is more appropriate if objects existed but none met confidence\n",
        "                 no_confident_obj_msg = \"While some elements might be present, no objects were identified with sufficient confidence for a detailed description.\"\n",
        "                 if not description_segments: description_segments.append(no_confident_obj_msg)\n",
        "                 else: description_segments.append(no_confident_obj_msg.lower().capitalize()) # Append as a new sentence\n",
        "            else:\n",
        "                if object_statistics:\n",
        "                    # 使用預計算的統計信息，並採用動態置信度策略\n",
        "                    for class_name, stats in object_statistics.items():\n",
        "                        count = stats.get(\"count\", 0)\n",
        "                        avg_confidence = stats.get(\"avg_confidence\", 0)\n",
        "\n",
        "                        # 動態調整置信度閾值：裝飾性物品使用較低閾值\n",
        "                        dynamic_threshold = confidence_filter_threshold\n",
        "                        if class_name in [\"potted plant\", \"vase\", \"clock\", \"book\"]:\n",
        "                            dynamic_threshold = max(0.15, confidence_filter_threshold * 0.6)\n",
        "                        elif count >= 3:  # 數量多的物品降低閾值\n",
        "                            dynamic_threshold = max(0.2, confidence_filter_threshold * 0.8)\n",
        "\n",
        "                        if count > 0 and avg_confidence >= dynamic_threshold:\n",
        "                            matching_objects = [obj for obj in confident_objects if obj.get(\"class_name\") == class_name]\n",
        "                            if not matching_objects:\n",
        "                                # 如果高信心度的物體中沒有，從原始列表中尋找\n",
        "                                matching_objects = [obj for obj in detected_objects\n",
        "                                                if obj.get(\"class_name\") == class_name and obj.get(\"confidence\", 0) >= dynamic_threshold]\n",
        "\n",
        "                            if matching_objects:\n",
        "                                actual_count = min(stats[\"count\"], len(matching_objects))\n",
        "                                objects_by_class[class_name] = matching_objects[:actual_count]\n",
        "                else:\n",
        "                    # 回退邏輯同樣使用動態閾值\n",
        "                    for obj in confident_objects:\n",
        "                        name = obj.get(\"class_name\", \"unknown object\")\n",
        "                        if name == \"unknown object\" or not name: continue\n",
        "                        if name not in objects_by_class:\n",
        "                            objects_by_class[name] = []\n",
        "                        objects_by_class[name].append(obj)\n",
        "\n",
        "                if not objects_by_class: # Should be rare if confident_objects was not empty and had valid names\n",
        "                    description_segments.append(\"No common objects were confidently identified for detailed description.\")\n",
        "                else:\n",
        "                    def sort_key_object_groups(item_tuple: Tuple[str, List[Dict]]):\n",
        "                        class_name_key, obj_group_list = item_tuple\n",
        "                        priority = 3  # 預設優先級\n",
        "                        count = len(obj_group_list)\n",
        "\n",
        "                        # 動態優先級：基於場景相關性和數量\n",
        "                        if class_name_key == \"person\":\n",
        "                            priority = 0\n",
        "                        elif class_name_key in [\"dining table\", \"chair\", \"sofa\", \"bed\"]:\n",
        "                            priority = 1  # 室內主要家具\n",
        "                        elif class_name_key in [\"car\", \"bus\", \"truck\", \"traffic light\"]:\n",
        "                            priority = 2  # 交通相關物體\n",
        "                        elif count >= 3:  # 數量多的物體提升優先級\n",
        "                            priority = max(1, priority - 1)\n",
        "                        elif class_name_key in [\"potted plant\", \"vase\", \"clock\", \"book\"] and count >= 2:\n",
        "                            priority = 2  # 裝飾性物品有一定數量時提升優先級\n",
        "\n",
        "                        avg_area = sum(o.get(\"normalized_area\", 0.0) for o in obj_group_list) / len(obj_group_list) if obj_group_list else 0\n",
        "\n",
        "                        # 增加數量權重：多個同類物體更重要\n",
        "                        quantity_bonus = min(count / 5.0, 1.0)  # 最多1.0的加成\n",
        "\n",
        "                        return (priority, -len(obj_group_list), -avg_area, -quantity_bonus)\n",
        "\n",
        "                    # 去除重複的邏輯\n",
        "                    deduplicated_objects_by_class = {}\n",
        "                    processed_positions = []\n",
        "\n",
        "                    for class_name, group_of_objects in objects_by_class.items():\n",
        "                        unique_objects = []\n",
        "\n",
        "                        for obj in group_of_objects:\n",
        "                            obj_position = obj.get(\"normalized_center\", [0.5, 0.5])\n",
        "                            is_duplicate = False\n",
        "\n",
        "                            # 檢查是否與已處理的物體位置重疊\n",
        "                            for processed_pos in processed_positions:\n",
        "                                position_distance = abs(obj_position[0] - processed_pos[0]) + abs(obj_position[1] - processed_pos[1])\n",
        "                                if position_distance < 0.15:  # 位置重疊閾值\n",
        "                                    is_duplicate = True\n",
        "                                    break\n",
        "\n",
        "                            if not is_duplicate:\n",
        "                                unique_objects.append(obj)\n",
        "                                processed_positions.append(obj_position)\n",
        "\n",
        "                        if unique_objects:\n",
        "                            deduplicated_objects_by_class[class_name] = unique_objects\n",
        "\n",
        "                    objects_by_class = deduplicated_objects_by_class\n",
        "\n",
        "                    sorted_object_groups = sorted(objects_by_class.items(), key=sort_key_object_groups)\n",
        "\n",
        "                    object_clauses = [] # Stores individual object group descriptions\n",
        "\n",
        "                    for class_name, group_of_objects in sorted_object_groups:\n",
        "                        count = len(group_of_objects)\n",
        "                        if count == 0: continue\n",
        "\n",
        "                        # 使用統計信息確保準確的數量描述\n",
        "                        if object_statistics and class_name in object_statistics:\n",
        "                            actual_count = object_statistics[class_name][\"count\"]\n",
        "                            # 根據實際統計數量生成描述\n",
        "                            if actual_count == 1:\n",
        "                                formatted_name_with_exact_count = f\"one {class_name}\"\n",
        "                            else:\n",
        "                                plural_form = f\"{class_name}s\" if not class_name.endswith('s') else class_name\n",
        "                                formatted_name_with_exact_count = f\"{actual_count} {plural_form}\"\n",
        "                        else:\n",
        "                            # 回退到原有的格式化邏輯\n",
        "                            formatted_name_with_exact_count = self._format_object_list_for_description(\n",
        "                                [group_of_objects[0]] * count,\n",
        "                                use_indefinite_article_for_one=False,\n",
        "                                count_threshold_for_generalization=-1\n",
        "                            )\n",
        "\n",
        "                        if formatted_name_with_exact_count == \"no specific objects clearly identified\" or not formatted_name_with_exact_count:\n",
        "                            continue\n",
        "\n",
        "                        # Determine collective location for the group\n",
        "                        location_description_suffix = \"\" # e.g., \"is in the center\" or \"are in the west area\"\n",
        "                        if count == 1:\n",
        "                            location_description_suffix = f\"is {self._get_spatial_description(group_of_objects[0], image_width, image_height)}\"\n",
        "                        else:\n",
        "                            distinct_regions = sorted(list(set(obj.get(\"region\", \"unknown_region\") for obj in group_of_objects)))\n",
        "                            known_regions = [r for r in distinct_regions if r != \"unknown_region\"]\n",
        "                            if not known_regions and \"unknown_region\" in distinct_regions:\n",
        "                                location_description_suffix = \"are visible in the scene\"\n",
        "                            elif len(known_regions) == 1:\n",
        "                                location_description_suffix = f\"are primarily in the {known_regions[0].replace('_', ' ')} area\"\n",
        "                            elif len(known_regions) == 2:\n",
        "                                location_description_suffix = f\"are mainly across the {known_regions[0].replace('_',' ')} and {known_regions[1].replace('_',' ')} areas\"\n",
        "                            elif len(known_regions) > 2:\n",
        "                                location_description_suffix = \"are distributed in various parts of the scene\"\n",
        "                            else:\n",
        "                                location_description_suffix = \"are visible in the scene\"\n",
        "\n",
        "                        # Capitalize the object description (e.g., \"Six cars\")\n",
        "                        formatted_name_capitalized = formatted_name_with_exact_count[0].upper() + formatted_name_with_exact_count[1:]\n",
        "                        object_clauses.append(f\"{formatted_name_capitalized} {location_description_suffix}\")\n",
        "\n",
        "                    if object_clauses:\n",
        "                        # Join object clauses into one or more sentences.\n",
        "                        if not description_segments: # If no ambiance, start with the first object clause.\n",
        "                            if object_clauses:\n",
        "                                first_clause = object_clauses.pop(0) # Take the first one out\n",
        "                                description_segments.append(first_clause + \".\")\n",
        "                        else: # Ambiance exists, prepend with \"The scene features...\" or similar\n",
        "                            if object_clauses:\n",
        "                                description_segments.append(\"The scene features:\") # Or \"Key elements include:\"\n",
        "\n",
        "                        # Add remaining object clauses as separate points or a continuous sentence\n",
        "                        # For now, let's join them into a single continuous sentence string to be added.\n",
        "                        if object_clauses: # If there are more clauses after the first (or after \"The scene features:\")\n",
        "                            joined_object_clauses = \". \".join(object_clauses)\n",
        "                            if joined_object_clauses and not joined_object_clauses.endswith(\".\"):\n",
        "                                joined_object_clauses += \".\"\n",
        "                            description_segments.append(joined_object_clauses)\n",
        "\n",
        "                    elif not description_segments : # No ambiance and no describable objects after filtering\n",
        "                        return \"The image depicts a scene, but specific objects could not be described with confidence or detail.\"\n",
        "\n",
        "        # --- Final assembly and formatting ---\n",
        "        # Join all collected segments. _smart_append might be better if parts are not full sentences.\n",
        "        # Since we aim for full sentences in segments, simple join then format.\n",
        "        raw_description = \"\"\n",
        "        for i, segment in enumerate(filter(None, description_segments)):\n",
        "            segment = segment.strip()\n",
        "            if not segment: continue\n",
        "\n",
        "            if not raw_description: # First non-empty segment\n",
        "                raw_description = segment\n",
        "            else:\n",
        "                if not raw_description.endswith(('.', '!', '?')):\n",
        "                    raw_description += \".\"\n",
        "                raw_description += \" \" + (segment[0].upper() + segment[1:] if len(segment) > 1 else segment.upper())\n",
        "\n",
        "        if raw_description and not raw_description.endswith(('.', '!', '?')):\n",
        "            raw_description += \".\"\n",
        "\n",
        "        final_description = self._format_final_description(raw_description) # Crucial for final polish\n",
        "\n",
        "        if not final_description or len(final_description.strip()) < 20:\n",
        "            # Fallback if description is too short or empty after processing\n",
        "            # Use a more informative fallback if confident_objects existed\n",
        "            if 'confident_objects' in locals() and confident_objects:\n",
        "                 return \"The scene contains several detected objects, but a detailed textual description could not be fully constructed.\"\n",
        "            else:\n",
        "                 return \"A general scene is depicted with no objects identified with high confidence.\"\n",
        "\n",
        "        return final_description\n",
        "\n",
        "\n",
        "    def _generate_scene_details(self,\n",
        "                          scene_type: str,\n",
        "                          detected_objects: List[Dict],\n",
        "                          lighting_info: Optional[Dict] = None,\n",
        "                          viewpoint: str = \"eye_level\",\n",
        "                          spatial_analysis: Optional[Dict] = None,\n",
        "                          image_dimensions: Optional[Tuple[int, int]] = None,\n",
        "                          places365_info: Optional[Dict] = None,\n",
        "                          object_statistics: Optional[Dict] = None\n",
        "                          ) -> str:\n",
        "        \"\"\"\n",
        "        Generate detailed description based on scene type and detected objects.\n",
        "        Enhanced to handle everyday scenes dynamically with accurate object counting.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type.\n",
        "            detected_objects: List of detected objects.\n",
        "            lighting_info: Optional lighting condition information.\n",
        "            viewpoint: Detected viewpoint (aerial, eye_level, etc.).\n",
        "            spatial_analysis: Optional results from SpatialAnalyzer.\n",
        "            image_dimensions: Optional tuple of (image_width, image_height).\n",
        "            places365_info: Optional Places365 scene classification results.\n",
        "            object_statistics: Optional detailed object statistics with counts and confidence.\n",
        "\n",
        "        Returns:\n",
        "            str: Detailed scene description.\n",
        "        \"\"\"\n",
        "        scene_details = \"\"\n",
        "        scene_templates = self.templates.get(\"scene_detail_templates\", {})\n",
        "\n",
        "        # List of scene types considered \"everyday\" or generic\n",
        "        everyday_scene_types = [\n",
        "            \"general_indoor_space\", \"generic_street_view\",\n",
        "            \"desk_area_workspace\", \"outdoor_gathering_spot\",\n",
        "            \"kitchen_counter_or_utility_area\", \"unknown\"\n",
        "        ]\n",
        "\n",
        "        # Extract Places365 attributes for enhanced description\n",
        "        places365_attributes = []\n",
        "        scene_specific_details = \"\"\n",
        "\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.4:\n",
        "            attributes = places365_info.get('attributes', [])\n",
        "            scene_label = places365_info.get('scene_label', '')\n",
        "\n",
        "            # Filter relevant attributes for description enhancement\n",
        "            relevant_attributes = [attr for attr in attributes if attr in [\n",
        "                'natural_lighting', 'artificial_lighting', 'commercial', 'residential',\n",
        "                'workplace', 'recreational', 'educational', 'open_space', 'enclosed_space'\n",
        "            ]]\n",
        "            places365_attributes = relevant_attributes[:2]\n",
        "\n",
        "            # Generate scene-specific contextual details using object statistics\n",
        "            if object_statistics:\n",
        "                if 'commercial' in attributes and object_statistics.get('person', {}).get('count', 0) > 0:\n",
        "                    person_count = object_statistics['person']['count']\n",
        "                    if person_count == 1:\n",
        "                        scene_specific_details = \"This appears to be an active commercial environment with a customer present.\"\n",
        "                    else:\n",
        "                        scene_specific_details = f\"This appears to be an active commercial environment with {person_count} people present.\"\n",
        "                elif 'residential' in attributes and scene_type in ['living_room', 'bedroom', 'kitchen']:\n",
        "                    scene_specific_details = \"The setting suggests a comfortable residential living space.\"\n",
        "                elif 'workplace' in attributes and any(object_statistics.get(obj, {}).get('count', 0) > 0\n",
        "                                                    for obj in ['laptop', 'keyboard', 'monitor']):\n",
        "                    scene_specific_details = \"The environment indicates an active workspace or office setting.\"\n",
        "            else:\n",
        "                # Fallback to original logic if object_statistics not available\n",
        "                if 'commercial' in attributes and any(obj['class_name'] in ['person', 'chair', 'table'] for obj in detected_objects):\n",
        "                    scene_specific_details = \"This appears to be an active commercial environment with customer activity.\"\n",
        "                elif 'residential' in attributes and scene_type in ['living_room', 'bedroom', 'kitchen']:\n",
        "                    scene_specific_details = \"The setting suggests a comfortable residential living space.\"\n",
        "                elif 'workplace' in attributes and any(obj['class_name'] in ['laptop', 'keyboard', 'monitor'] for obj in detected_objects):\n",
        "                    scene_specific_details = \"The environment indicates an active workspace or office setting.\"\n",
        "\n",
        "        # Determine scene description approach\n",
        "        is_confident_specific_scene = scene_type not in everyday_scene_types and scene_type in scene_templates\n",
        "        treat_as_everyday = scene_type in everyday_scene_types\n",
        "\n",
        "        if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "            if scene_type not in [\"kitchen\", \"bedroom\", \"living_room\", \"office_workspace\", \"dining_area\", \"professional_kitchen\"]:\n",
        "                treat_as_everyday = True\n",
        "\n",
        "        if treat_as_everyday or not is_confident_specific_scene:\n",
        "            # Generate dynamic description for everyday scenes with object statistics\n",
        "            self.logger.info(f\"Generating dynamic description for scene_type: {scene_type}\")\n",
        "            scene_details = self._generate_dynamic_everyday_description(\n",
        "                detected_objects,\n",
        "                lighting_info,\n",
        "                viewpoint,\n",
        "                spatial_analysis,\n",
        "                image_dimensions,\n",
        "                places365_info,\n",
        "                object_statistics  # Pass object statistics to dynamic description\n",
        "            )\n",
        "        elif scene_type in scene_templates:\n",
        "            # Use template-based description with enhanced object information\n",
        "            self.logger.info(f\"Using template for scene_type: {scene_type}\")\n",
        "            viewpoint_key = f\"{scene_type}_{viewpoint}\"\n",
        "            templates_list = scene_templates.get(viewpoint_key, scene_templates.get(scene_type, []))\n",
        "\n",
        "            if templates_list:\n",
        "                detail_template = random.choice(templates_list)\n",
        "                scene_details = self._fill_detail_template(\n",
        "                    detail_template,\n",
        "                    detected_objects,\n",
        "                    scene_type,\n",
        "                    places365_info,\n",
        "                    object_statistics  # Pass object statistics to template filling\n",
        "                )\n",
        "            else:\n",
        "                scene_details = self._generate_dynamic_everyday_description(\n",
        "                    detected_objects, lighting_info, viewpoint, spatial_analysis,\n",
        "                    image_dimensions, places365_info, object_statistics\n",
        "                )\n",
        "        else:\n",
        "            # Fallback to dynamic description with object statistics\n",
        "            self.logger.info(f\"No specific template for {scene_type}, generating dynamic description.\")\n",
        "            scene_details = self._generate_dynamic_everyday_description(\n",
        "                detected_objects, lighting_info, viewpoint, spatial_analysis,\n",
        "                image_dimensions, places365_info, object_statistics\n",
        "            )\n",
        "\n",
        "        # Filter out landmark references if landmark detection is disabled\n",
        "        if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "            scene_details = self.filter_landmark_references(scene_details, enable_landmark=False)\n",
        "\n",
        "        return scene_details if scene_details else \"A scene with some visual elements.\"\n",
        "\n",
        "    def _fill_detail_template(self, template: str, detected_objects: List[Dict], scene_type: str, places365_info: Optional[Dict] = None, object_statistics: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        Fill a template with specific details based on detected objects.\n",
        "\n",
        "        Args:\n",
        "            template: Template string with placeholders\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Identified scene type\n",
        "\n",
        "        Returns:\n",
        "            str: Filled template\n",
        "        \"\"\"\n",
        "        # Find placeholders in the template using simple {placeholder} syntax\n",
        "        import re\n",
        "        placeholders = re.findall(r'\\{([^}]+)\\}', template)\n",
        "\n",
        "        filled_template = template\n",
        "\n",
        "        # Get object template fillers\n",
        "        fillers = self.templates.get(\"object_template_fillers\", {})\n",
        "\n",
        "        # 基於物品的統計資訊形成更準確的模板填充內容\n",
        "        statistics_based_replacements = {}\n",
        "        if object_statistics:\n",
        "            # 根據統計信息生成具體的物體描述\n",
        "            for class_name, stats in object_statistics.items():\n",
        "                count = stats.get(\"count\", 0)\n",
        "                if count > 0:\n",
        "                    # 為常見物體類別生成基於統計的描述\n",
        "                    if class_name == \"potted plant\":\n",
        "                        if count == 1:\n",
        "                            statistics_based_replacements[\"plant_elements\"] = \"a potted plant\"\n",
        "                        elif count <= 3:\n",
        "                            statistics_based_replacements[\"plant_elements\"] = f\"{count} potted plants\"\n",
        "                        else:\n",
        "                            statistics_based_replacements[\"plant_elements\"] = f\"multiple potted plants ({count} total)\"\n",
        "\n",
        "                    elif class_name == \"chair\":\n",
        "                        if count == 1:\n",
        "                            statistics_based_replacements[\"seating\"] = \"a chair\"\n",
        "                        elif count <= 4:\n",
        "                            statistics_based_replacements[\"seating\"] = f\"{count} chairs\"\n",
        "                        else:\n",
        "                            statistics_based_replacements[\"seating\"] = f\"numerous chairs ({count} total)\"\n",
        "\n",
        "                    elif class_name == \"person\":\n",
        "                        if count == 1:\n",
        "                            statistics_based_replacements[\"people_and_vehicles\"] = \"a person\"\n",
        "                            statistics_based_replacements[\"pedestrian_flow\"] = \"an individual walking\"\n",
        "                        elif count <= 5:\n",
        "                            statistics_based_replacements[\"people_and_vehicles\"] = f\"{count} people\"\n",
        "                            statistics_based_replacements[\"pedestrian_flow\"] = f\"{count} people walking\"\n",
        "                        else:\n",
        "                            statistics_based_replacements[\"people_and_vehicles\"] = f\"many people ({count} individuals)\"\n",
        "                            statistics_based_replacements[\"pedestrian_flow\"] = f\"a crowd of {count} people\"\n",
        "\n",
        "        # 為所有可能的變數設置默認值\n",
        "        default_replacements = {\n",
        "            # 室內相關\n",
        "            \"furniture\": \"various furniture pieces\",\n",
        "            \"seating\": \"comfortable seating\",\n",
        "            \"electronics\": \"entertainment devices\",\n",
        "            \"bed_type\": \"a bed\",\n",
        "            \"bed_location\": \"room\",\n",
        "            \"bed_description\": \"sleeping arrangements\",\n",
        "            \"extras\": \"personal items\",\n",
        "            \"table_setup\": \"a dining table and chairs\",\n",
        "            \"table_description\": \"a dining surface\",\n",
        "            \"dining_items\": \"dining furniture and tableware\",\n",
        "            \"appliances\": \"kitchen appliances\",\n",
        "            \"kitchen_items\": \"cooking utensils and dishware\",\n",
        "            \"cooking_equipment\": \"cooking equipment\",\n",
        "            \"office_equipment\": \"work-related furniture and devices\",\n",
        "            \"desk_setup\": \"a desk and chair\",\n",
        "            \"computer_equipment\": \"electronic devices\",\n",
        "\n",
        "            # 室外/城市相關\n",
        "            \"traffic_description\": \"vehicles and pedestrians\",\n",
        "            \"people_and_vehicles\": \"people and various vehicles\",\n",
        "            \"street_elements\": \"urban infrastructure\",\n",
        "            \"park_features\": \"benches and greenery\",\n",
        "            \"outdoor_elements\": \"natural features\",\n",
        "            \"park_description\": \"outdoor amenities\",\n",
        "            \"store_elements\": \"merchandise displays\",\n",
        "            \"shopping_activity\": \"customers browse and shop\",\n",
        "            \"store_items\": \"products for sale\",\n",
        "\n",
        "            # 高級餐廳相關\n",
        "            \"design_elements\": \"elegant decor\",\n",
        "            \"lighting\": \"stylish lighting fixtures\",\n",
        "\n",
        "            # 亞洲商業街相關\n",
        "            \"storefront_features\": \"compact shops\",\n",
        "            \"pedestrian_flow\": \"people walking\",\n",
        "            \"asian_elements\": \"distinctive cultural elements\",\n",
        "            \"cultural_elements\": \"traditional design features\",\n",
        "            \"signage\": \"colorful signs\",\n",
        "            \"street_activities\": \"busy urban activity\",\n",
        "\n",
        "            # 金融區相關\n",
        "            \"buildings\": \"tall buildings\",\n",
        "            \"traffic_elements\": \"vehicles\",\n",
        "            \"skyscrapers\": \"high-rise buildings\",\n",
        "            \"road_features\": \"wide streets\",\n",
        "            \"architectural_elements\": \"modern architecture\",\n",
        "            \"city_landmarks\": \"prominent structures\",\n",
        "\n",
        "            # 十字路口相關\n",
        "            \"crossing_pattern\": \"marked pedestrian crossings\",\n",
        "            \"pedestrian_behavior\": \"careful walking\",\n",
        "            \"pedestrian_density\": \"groups of pedestrians\",\n",
        "            \"traffic_pattern\": \"regulated traffic flow\",\n",
        "\n",
        "            # 交通樞紐相關\n",
        "            \"transit_vehicles\": \"public transportation vehicles\",\n",
        "            \"passenger_activity\": \"commuter movement\",\n",
        "            \"transportation_modes\": \"various transit options\",\n",
        "            \"passenger_needs\": \"waiting areas\",\n",
        "            \"transit_infrastructure\": \"transit facilities\",\n",
        "            \"passenger_movement\": \"commuter flow\",\n",
        "\n",
        "            # 購物區相關\n",
        "            \"retail_elements\": \"shops and displays\",\n",
        "            \"store_types\": \"various retail establishments\",\n",
        "            \"walkway_features\": \"pedestrian pathways\",\n",
        "            \"commercial_signage\": \"store signs\",\n",
        "            \"consumer_behavior\": \"shopping activities\",\n",
        "\n",
        "            # 空中視角相關\n",
        "            \"commercial_layout\": \"organized retail areas\",\n",
        "            \"pedestrian_pattern\": \"people movement patterns\",\n",
        "            \"gathering_features\": \"public gathering spaces\",\n",
        "            \"movement_pattern\": \"crowd flow patterns\",\n",
        "            \"urban_elements\": \"city infrastructure\",\n",
        "            \"public_activity\": \"social interaction\",\n",
        "\n",
        "            # 文化特定元素\n",
        "            \"stall_elements\": \"vendor booths\",\n",
        "            \"lighting_features\": \"decorative lights\",\n",
        "            \"food_elements\": \"food offerings\",\n",
        "            \"vendor_stalls\": \"market stalls\",\n",
        "            \"nighttime_activity\": \"evening commerce\",\n",
        "            \"cultural_lighting\": \"traditional lighting\",\n",
        "            \"night_market_sounds\": \"lively market sounds\",\n",
        "            \"evening_crowd_behavior\": \"nighttime social activity\",\n",
        "            \"architectural_elements\": \"cultural buildings\",\n",
        "            \"religious_structures\": \"sacred buildings\",\n",
        "            \"decorative_features\": \"ornamental designs\",\n",
        "            \"cultural_practices\": \"traditional activities\",\n",
        "            \"temple_architecture\": \"religious structures\",\n",
        "            \"sensory_elements\": \"atmospheric elements\",\n",
        "            \"visitor_activities\": \"cultural experiences\",\n",
        "            \"ritual_activities\": \"ceremonial practices\",\n",
        "            \"cultural_symbols\": \"meaningful symbols\",\n",
        "            \"architectural_style\": \"historical buildings\",\n",
        "            \"historic_elements\": \"traditional architecture\",\n",
        "            \"urban_design\": \"city planning elements\",\n",
        "            \"social_behaviors\": \"public interactions\",\n",
        "            \"european_features\": \"European architectural details\",\n",
        "            \"tourist_activities\": \"visitor activities\",\n",
        "            \"local_customs\": \"regional practices\",\n",
        "\n",
        "            # 時間特定元素\n",
        "            \"lighting_effects\": \"artificial lighting\",\n",
        "            \"shadow_patterns\": \"light and shadow\",\n",
        "            \"urban_features\": \"city elements\",\n",
        "            \"illuminated_elements\": \"lit structures\",\n",
        "            \"evening_activities\": \"nighttime activities\",\n",
        "            \"light_sources\": \"lighting points\",\n",
        "            \"lit_areas\": \"illuminated spaces\",\n",
        "            \"shadowed_zones\": \"darker areas\",\n",
        "            \"illuminated_signage\": \"bright signs\",\n",
        "            \"colorful_lighting\": \"multicolored lights\",\n",
        "            \"neon_elements\": \"neon signs\",\n",
        "            \"night_crowd_behavior\": \"evening social patterns\",\n",
        "            \"light_displays\": \"lighting installations\",\n",
        "            \"building_features\": \"architectural elements\",\n",
        "            \"nightlife_activities\": \"evening entertainment\",\n",
        "            \"lighting_modifier\": \"bright\",\n",
        "\n",
        "            # 混合環境元素\n",
        "            \"transitional_elements\": \"connecting features\",\n",
        "            \"indoor_features\": \"interior elements\",\n",
        "            \"outdoor_setting\": \"exterior spaces\",\n",
        "            \"interior_amenities\": \"inside comforts\",\n",
        "            \"exterior_features\": \"outside elements\",\n",
        "            \"inside_elements\": \"interior design\",\n",
        "            \"outside_spaces\": \"outdoor areas\",\n",
        "            \"dual_environment_benefits\": \"combined settings\",\n",
        "            \"passenger_activities\": \"waiting behaviors\",\n",
        "            \"transportation_types\": \"transit vehicles\",\n",
        "            \"sheltered_elements\": \"covered areas\",\n",
        "            \"exposed_areas\": \"open sections\",\n",
        "            \"waiting_behaviors\": \"passenger activities\",\n",
        "            \"indoor_facilities\": \"inside services\",\n",
        "            \"platform_features\": \"transit platform elements\",\n",
        "            \"transit_routines\": \"transportation procedures\",\n",
        "\n",
        "            # 專門場所元素\n",
        "            \"seating_arrangement\": \"spectator seating\",\n",
        "            \"playing_surface\": \"athletic field\",\n",
        "            \"sporting_activities\": \"sports events\",\n",
        "            \"spectator_facilities\": \"viewer accommodations\",\n",
        "            \"competition_space\": \"sports arena\",\n",
        "            \"sports_events\": \"athletic competitions\",\n",
        "            \"viewing_areas\": \"audience sections\",\n",
        "            \"field_elements\": \"field markings and equipment\",\n",
        "            \"game_activities\": \"competitive play\",\n",
        "            \"construction_equipment\": \"building machinery\",\n",
        "            \"building_materials\": \"construction supplies\",\n",
        "            \"construction_activities\": \"building work\",\n",
        "            \"work_elements\": \"construction tools\",\n",
        "            \"structural_components\": \"building structures\",\n",
        "            \"site_equipment\": \"construction gear\",\n",
        "            \"raw_materials\": \"building supplies\",\n",
        "            \"construction_process\": \"building phases\",\n",
        "            \"medical_elements\": \"healthcare equipment\",\n",
        "            \"clinical_activities\": \"medical procedures\",\n",
        "            \"facility_design\": \"healthcare layout\",\n",
        "            \"healthcare_features\": \"medical facilities\",\n",
        "            \"patient_interactions\": \"care activities\",\n",
        "            \"equipment_types\": \"medical devices\",\n",
        "            \"care_procedures\": \"health services\",\n",
        "            \"treatment_spaces\": \"clinical areas\",\n",
        "            \"educational_furniture\": \"learning furniture\",\n",
        "            \"learning_activities\": \"educational practices\",\n",
        "            \"instructional_design\": \"teaching layout\",\n",
        "            \"classroom_elements\": \"school equipment\",\n",
        "            \"teaching_methods\": \"educational approaches\",\n",
        "            \"student_engagement\": \"learning participation\",\n",
        "            \"learning_spaces\": \"educational areas\",\n",
        "            \"educational_tools\": \"teaching resources\",\n",
        "            \"knowledge_transfer\": \"learning exchanges\"\n",
        "        }\n",
        "\n",
        "        # 將統計的資訊形成的替換內容合併到默認替換中\n",
        "        default_replacements.update(statistics_based_replacements)\n",
        "\n",
        "        # Add Places365-specific template variables\n",
        "        places365_scene_context = \"\"\n",
        "        places365_atmosphere = \"\"\n",
        "\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.35:\n",
        "            scene_label = places365_info.get('scene_label', '').replace('_', ' ')\n",
        "            attributes = places365_info.get('attributes', [])\n",
        "\n",
        "            if scene_label and scene_label != scene_type:\n",
        "                places365_scene_context = f\"characteristic of a {scene_label}\"\n",
        "\n",
        "            if 'natural_lighting' in attributes:\n",
        "                places365_atmosphere = \"with natural illumination\"\n",
        "            elif 'artificial_lighting' in attributes:\n",
        "                places365_atmosphere = \"under artificial lighting\"\n",
        "\n",
        "        # Update default_replacements with Places365 context\n",
        "        if places365_scene_context:\n",
        "            default_replacements[\"places365_context\"] = places365_scene_context\n",
        "        else:\n",
        "            default_replacements[\"places365_context\"] = \"\"\n",
        "\n",
        "        if places365_atmosphere:\n",
        "            default_replacements[\"places365_atmosphere\"] = places365_atmosphere\n",
        "        else:\n",
        "            default_replacements[\"places365_atmosphere\"] = \"\"\n",
        "\n",
        "        # For each placeholder, try to fill with appropriate content\n",
        "        for placeholder in placeholders:\n",
        "            if placeholder in fillers:\n",
        "                # Get random filler for this placeholder\n",
        "                options = fillers[placeholder]\n",
        "                if options:\n",
        "                    # Select 1-3 items from the options list\n",
        "                    num_items = min(len(options), random.randint(1, 3))\n",
        "                    selected_items = random.sample(options, num_items)\n",
        "\n",
        "                    # Create a formatted list\n",
        "                    if len(selected_items) == 1:\n",
        "                        replacement = selected_items[0]\n",
        "                    elif len(selected_items) == 2:\n",
        "                        replacement = f\"{selected_items[0]} and {selected_items[1]}\"\n",
        "                    else:\n",
        "                        replacement = \", \".join(selected_items[:-1]) + f\", and {selected_items[-1]}\"\n",
        "\n",
        "                    # Replace the placeholder\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", replacement)\n",
        "            else:\n",
        "                # Try to fill with scene-specific logic\n",
        "                replacement = self._generate_placeholder_content(placeholder, detected_objects, scene_type)\n",
        "                if replacement:\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", replacement)\n",
        "                elif placeholder in default_replacements:\n",
        "                    # Use default replacement if available\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", default_replacements[placeholder])\n",
        "                else:\n",
        "                    # Last resort default\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", \"various items\")\n",
        "\n",
        "        return filled_template\n",
        "\n",
        "    def _generate_placeholder_content(self, placeholder: str, detected_objects: List[Dict], scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate content for a template placeholder based on scene-specific logic.\n",
        "\n",
        "        Args:\n",
        "            placeholder: Template placeholder\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Identified scene type\n",
        "\n",
        "        Returns:\n",
        "            str: Content for the placeholder\n",
        "        \"\"\"\n",
        "        # Handle different types of placeholders with custom logic\n",
        "        if placeholder == \"furniture\":\n",
        "            # Extract furniture items\n",
        "            furniture_ids = [56, 57, 58, 59, 60, 61]  # Example furniture IDs\n",
        "            furniture_objects = [obj for obj in detected_objects if obj[\"class_id\"] in furniture_ids]\n",
        "\n",
        "            if furniture_objects:\n",
        "                furniture_names = [obj[\"class_name\"] for obj in furniture_objects[:3]]\n",
        "                return \", \".join(set(furniture_names))\n",
        "            return \"various furniture items\"\n",
        "\n",
        "        elif placeholder == \"electronics\":\n",
        "            # Extract electronic items\n",
        "            electronics_ids = [62, 63, 64, 65, 66, 67, 68, 69, 70]  # Example electronics IDs\n",
        "            electronics_objects = [obj for obj in detected_objects if obj[\"class_id\"] in electronics_ids]\n",
        "\n",
        "            if electronics_objects:\n",
        "                electronics_names = [obj[\"class_name\"] for obj in electronics_objects[:3]]\n",
        "                return \", \".join(set(electronics_names))\n",
        "            return \"electronic devices\"\n",
        "\n",
        "        elif placeholder == \"people_count\":\n",
        "            # Count people\n",
        "            people_count = len([obj for obj in detected_objects if obj[\"class_id\"] == 0])\n",
        "\n",
        "            if people_count == 0:\n",
        "                return \"no people\"\n",
        "            elif people_count == 1:\n",
        "                return \"one person\"\n",
        "            elif people_count < 5:\n",
        "                return f\"{people_count} people\"\n",
        "            else:\n",
        "                return \"several people\"\n",
        "\n",
        "        elif placeholder == \"seating\":\n",
        "            # Extract seating items\n",
        "            seating_ids = [56, 57]  # chair, sofa\n",
        "            seating_objects = [obj for obj in detected_objects if obj[\"class_id\"] in seating_ids]\n",
        "\n",
        "            if seating_objects:\n",
        "                seating_names = [obj[\"class_name\"] for obj in seating_objects[:2]]\n",
        "                return \", \".join(set(seating_names))\n",
        "            return \"seating arrangements\"\n",
        "\n",
        "        # Default case - empty string\n",
        "        return \"\"\n",
        "\n",
        "    def _generate_basic_details(self, scene_type: str, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Generate basic details when templates aren't available.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            str: Basic scene details\n",
        "        \"\"\"\n",
        "        # Handle specific scene types with custom logic\n",
        "        if scene_type == \"living_room\":\n",
        "            tv_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 62]  # TV\n",
        "            sofa_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 57]  # Sofa\n",
        "\n",
        "            if tv_objs and sofa_objs:\n",
        "                tv_region = tv_objs[0][\"region\"]\n",
        "                sofa_region = sofa_objs[0][\"region\"]\n",
        "\n",
        "                arrangement = f\"The TV is in the {tv_region.replace('_', ' ')} of the image, \"\n",
        "                arrangement += f\"while the sofa is in the {sofa_region.replace('_', ' ')}. \"\n",
        "\n",
        "                return f\"{arrangement}This appears to be a space designed for relaxation and entertainment.\"\n",
        "\n",
        "        elif scene_type == \"bedroom\":\n",
        "            bed_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 59]  # Bed\n",
        "\n",
        "            if bed_objs:\n",
        "                bed_region = bed_objs[0][\"region\"]\n",
        "                extra_items = []\n",
        "\n",
        "                for obj in detected_objects:\n",
        "                    if obj[\"class_id\"] == 74:  # Clock\n",
        "                        extra_items.append(\"clock\")\n",
        "                    elif obj[\"class_id\"] == 73:  # Book\n",
        "                        extra_items.append(\"book\")\n",
        "\n",
        "                extras = \"\"\n",
        "                if extra_items:\n",
        "                    extras = f\" There is also a {' and a '.join(extra_items)} visible.\"\n",
        "\n",
        "                return f\"The bed is located in the {bed_region.replace('_', ' ')} of the image.{extras}\"\n",
        "\n",
        "        elif scene_type in [\"dining_area\", \"kitchen\"]:\n",
        "            # Count food and dining-related items\n",
        "            food_items = []\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [39, 41, 42, 43, 44, 45]:  # Kitchen items\n",
        "                    food_items.append(obj[\"class_name\"])\n",
        "\n",
        "            food_str = \"\"\n",
        "            if food_items:\n",
        "                unique_items = list(set(food_items))\n",
        "                if len(unique_items) <= 3:\n",
        "                    food_str = f\" with {', '.join(unique_items)}\"\n",
        "                else:\n",
        "                    food_str = f\" with {', '.join(unique_items[:3])} and other items\"\n",
        "\n",
        "            return f\"{food_str}.\"\n",
        "\n",
        "        elif scene_type == \"city_street\":\n",
        "            # Count people and vehicles\n",
        "            people_count = len([obj for obj in detected_objects if obj[\"class_id\"] == 0])\n",
        "            vehicle_count = len([obj for obj in detected_objects\n",
        "                               if obj[\"class_id\"] in [1, 2, 3, 5, 7]])  # Bicycle, car, motorbike, bus, truck\n",
        "\n",
        "            traffic_desc = \"\"\n",
        "            if people_count > 0 and vehicle_count > 0:\n",
        "                traffic_desc = f\" with {people_count} {'people' if people_count > 1 else 'person'} and \"\n",
        "                traffic_desc += f\"{vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "            elif people_count > 0:\n",
        "                traffic_desc = f\" with {people_count} {'people' if people_count > 1 else 'person'}\"\n",
        "            elif vehicle_count > 0:\n",
        "                traffic_desc = f\" with {vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "\n",
        "            return f\"{traffic_desc}.\"\n",
        "\n",
        "        # Handle more specialized scenes\n",
        "        elif scene_type == \"asian_commercial_street\":\n",
        "            # Look for key urban elements\n",
        "            people_count = len([obj for obj in detected_objects if obj[\"class_id\"] == 0])\n",
        "            vehicle_count = len([obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3]])\n",
        "\n",
        "            # Analyze pedestrian distribution\n",
        "            people_positions = []\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] == 0:  # Person\n",
        "                    people_positions.append(obj[\"normalized_center\"])\n",
        "\n",
        "            # Check if people are distributed along a line (indicating a walking path)\n",
        "            structured_path = False\n",
        "            if len(people_positions) >= 3:\n",
        "                # Simplified check - see if y-coordinates are similar for multiple people\n",
        "                y_coords = [pos[1] for pos in people_positions]\n",
        "                y_mean = sum(y_coords) / len(y_coords)\n",
        "                y_variance = sum((y - y_mean)**2 for y in y_coords) / len(y_coords)\n",
        "                if y_variance < 0.05:  # Low variance indicates linear arrangement\n",
        "                    structured_path = True\n",
        "\n",
        "            street_desc = \"A commercial street with \"\n",
        "            if people_count > 0:\n",
        "                street_desc += f\"{people_count} {'pedestrians' if people_count > 1 else 'pedestrian'}\"\n",
        "                if vehicle_count > 0:\n",
        "                    street_desc += f\" and {vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "            elif vehicle_count > 0:\n",
        "                street_desc += f\"{vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "            else:\n",
        "                street_desc += \"various commercial elements\"\n",
        "\n",
        "            if structured_path:\n",
        "                street_desc += \". The pedestrians appear to be following a defined walking path\"\n",
        "\n",
        "            # Add cultural elements\n",
        "            street_desc += \". The signage and architectural elements suggest an Asian urban setting.\"\n",
        "\n",
        "            return street_desc\n",
        "\n",
        "        # Default general description\n",
        "        return \"The scene contains various elements characteristic of this environment.\"\n",
        "\n",
        "    def _detect_viewpoint(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        改進視角檢測，特別加強對空中俯視視角的識別。\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的視角類型\n",
        "        \"\"\"\n",
        "        if not detected_objects:\n",
        "            return \"eye_level\"  # default\n",
        "\n",
        "        # extract space and size\n",
        "        top_region_count = 0\n",
        "        bottom_region_count = 0\n",
        "        total_objects = len(detected_objects)\n",
        "\n",
        "        # 追蹤大小分布以檢測空中視角\n",
        "        sizes = []\n",
        "\n",
        "        # 垂直大小比例用於低角度檢測\n",
        "        height_width_ratios = []\n",
        "\n",
        "        # 用於檢測規則圖案的變數\n",
        "        people_positions = []\n",
        "        crosswalk_pattern_detected = False\n",
        "\n",
        "        for obj in detected_objects:\n",
        "            # 計算頂部or底部區域中的物體\n",
        "            region = obj[\"region\"]\n",
        "            if \"top\" in region:\n",
        "                top_region_count += 1\n",
        "            elif \"bottom\" in region:\n",
        "                bottom_region_count += 1\n",
        "\n",
        "            # 計算標準化大小（Area）\n",
        "            if \"normalized_area\" in obj:\n",
        "                sizes.append(obj[\"normalized_area\"])\n",
        "\n",
        "            # 計算高度or寬度比例\n",
        "            if \"normalized_size\" in obj:\n",
        "                width, height = obj[\"normalized_size\"]\n",
        "                if width > 0:\n",
        "                    height_width_ratios.append(height / width)\n",
        "\n",
        "            # 收集人的位置\n",
        "            if obj[\"class_id\"] == 0:  # 人\n",
        "                if \"normalized_center\" in obj:\n",
        "                    people_positions.append(obj[\"normalized_center\"])\n",
        "\n",
        "        # 專門為斑馬線的十字路口添加檢測邏輯\n",
        "        # 檢查是否有明顯的垂直和水平行人分布\n",
        "        people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]  # 人\n",
        "\n",
        "        if len(people_objs) >= 8:  # 需要足夠多的人才能形成十字路口模式\n",
        "            # 檢查是否有斑馬線模式 - 新增功能\n",
        "            if len(people_positions) >= 4:\n",
        "                # 對位置進行聚類分析，尋找線性分布\n",
        "                x_coords = [pos[0] for pos in people_positions]\n",
        "                y_coords = [pos[1] for pos in people_positions]\n",
        "\n",
        "                # 計算 x 和 y 坐標的變異數和範圍\n",
        "                x_variance = np.var(x_coords) if len(x_coords) > 1 else 0\n",
        "                y_variance = np.var(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "                x_range = max(x_coords) - min(x_coords)\n",
        "                y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "                # 嘗試檢測十字形分布\n",
        "                # 如果 x 和 y 方向都有較大範圍，且範圍相似，就有可能是十字路口\n",
        "                if x_range > 0.5 and y_range > 0.5 and 0.7 < (x_range / y_range) < 1.3:\n",
        "\n",
        "                    # 計算到中心點的距離\n",
        "                    center_x = np.mean(x_coords)\n",
        "                    center_y = np.mean(y_coords)\n",
        "\n",
        "                    # 將點映射到十字架的軸上（水平和垂直）\n",
        "                    x_axis_distance = [abs(x - center_x) for x in x_coords]\n",
        "                    y_axis_distance = [abs(y - center_y) for y in y_coords]\n",
        "\n",
        "                    # 點應該接近軸線（水平或垂直）\n",
        "                    # 對於每個點，檢查它是否接近水平或垂直軸線\n",
        "                    close_to_axis_count = 0\n",
        "                    for i in range(len(x_coords)):\n",
        "                        if x_axis_distance[i] < 0.1 or y_axis_distance[i] < 0.1:\n",
        "                            close_to_axis_count += 1\n",
        "\n",
        "                    # 如果足夠多的點接近軸線，認為是十字路口\n",
        "                    if close_to_axis_count >= len(x_coords) * 0.6:\n",
        "                        crosswalk_pattern_detected = True\n",
        "\n",
        "                # 如果沒有檢測到十字形，嘗試檢測線性聚類分布\n",
        "                if not crosswalk_pattern_detected:\n",
        "                    # 檢查 x 和 y 方向的聚類\n",
        "                    x_clusters = self._detect_linear_clusters(x_coords)\n",
        "                    y_clusters = self._detect_linear_clusters(y_coords)\n",
        "\n",
        "                    # 如果在 x 和 y 方向上都有多個聚類，可能是交叉的斑馬線\n",
        "                    if len(x_clusters) >= 2 and len(y_clusters) >= 2:\n",
        "                        crosswalk_pattern_detected = True\n",
        "\n",
        "        # 檢測斑馬線模式 - 優先判斷\n",
        "        if crosswalk_pattern_detected:\n",
        "            return \"aerial\"\n",
        "\n",
        "        # 檢測行人分布情況\n",
        "        if len(people_objs) >= 10:\n",
        "            people_region_counts = {}\n",
        "            for obj in people_objs:\n",
        "                region = obj[\"region\"]\n",
        "                if region not in people_region_counts:\n",
        "                    people_region_counts[region] = 0\n",
        "                people_region_counts[region] += 1\n",
        "\n",
        "            # 計算不同區域中的行人數量\n",
        "            region_count = len([r for r, c in people_region_counts.items() if c >= 2])\n",
        "\n",
        "            # 如果行人分布在多個區域中，可能是空中視角\n",
        "            if region_count >= 4:\n",
        "                # 檢查行人分布的模式\n",
        "                # 特別是檢查不同區域中行人數量的差異\n",
        "                region_counts = list(people_region_counts.values())\n",
        "                region_counts_variance = np.var(region_counts) if len(region_counts) > 1 else 0\n",
        "                region_counts_mean = np.mean(region_counts) if region_counts else 0\n",
        "\n",
        "                # 如果行人分布較為均勻（變異係數小），可能是空中視角\n",
        "                if region_counts_mean > 0:\n",
        "                    variation_coefficient = region_counts_variance / region_counts_mean\n",
        "                    if variation_coefficient < 0.5:\n",
        "                        return \"aerial\"\n",
        "\n",
        "        # 計算指標\n",
        "        top_ratio = top_region_count / total_objects if total_objects > 0 else 0\n",
        "        bottom_ratio = bottom_region_count / total_objects if total_objects > 0 else 0\n",
        "\n",
        "        # 大小變異數（標準化）\n",
        "        size_variance = 0\n",
        "        if sizes:\n",
        "            mean_size = sum(sizes) / len(sizes)\n",
        "            size_variance = sum((s - mean_size) ** 2 for s in sizes) / len(sizes)\n",
        "            size_variance = size_variance / (mean_size ** 2)  # 標準化\n",
        "\n",
        "        # 平均高度/寬度比例\n",
        "        avg_height_width_ratio = sum(height_width_ratios) / len(height_width_ratios) if height_width_ratios else 1.0\n",
        "\n",
        "        # 空中視角：低大小差異，物體均勻分布，底部很少或沒有物體\n",
        "        if (size_variance < self.viewpoint_params[\"aerial_size_variance_threshold\"] and\n",
        "            bottom_ratio < 0.3 and top_ratio > self.viewpoint_params[\"aerial_threshold\"]):\n",
        "            return \"aerial\"\n",
        "\n",
        "        # 低角度視角：物體傾向於比寬高，頂部較多物體\n",
        "        elif (avg_height_width_ratio > self.viewpoint_params[\"vertical_size_ratio_threshold\"] and\n",
        "            top_ratio > self.viewpoint_params[\"low_angle_threshold\"]):\n",
        "            return \"low_angle\"\n",
        "\n",
        "        # 高視角：底部較多物體，頂部較少\n",
        "        elif (bottom_ratio > self.viewpoint_params[\"elevated_threshold\"] and\n",
        "            top_ratio < self.viewpoint_params[\"elevated_top_threshold\"]):\n",
        "            return \"elevated\"\n",
        "\n",
        "        # 默認：平視角\n",
        "        return \"eye_level\"\n",
        "\n",
        "    def _detect_linear_clusters(self, coords, threshold=0.05):\n",
        "        \"\"\"\n",
        "        檢測坐標中的線性聚類\n",
        "\n",
        "        Args:\n",
        "            coords: 一維坐標列表\n",
        "            threshold: 聚類閾值\n",
        "\n",
        "        Returns:\n",
        "            list: 聚類列表\n",
        "        \"\"\"\n",
        "        if not coords:\n",
        "            return []\n",
        "\n",
        "        # 排序坐標\n",
        "        sorted_coords = sorted(coords)\n",
        "\n",
        "        clusters = []\n",
        "        current_cluster = [sorted_coords[0]]\n",
        "\n",
        "        for i in range(1, len(sorted_coords)):\n",
        "            # 如果當前坐標與前一個接近，添加到當前聚類\n",
        "            if sorted_coords[i] - sorted_coords[i-1] < threshold:\n",
        "                current_cluster.append(sorted_coords[i])\n",
        "            else:\n",
        "                # 否則開始新的聚類\n",
        "                if len(current_cluster) >= 2:  # 至少需要2個點形成聚類\n",
        "                    clusters.append(current_cluster)\n",
        "                current_cluster = [sorted_coords[i]]\n",
        "\n",
        "        # 添加最後一個cluster\n",
        "        if len(current_cluster) >= 2:\n",
        "            clusters.append(current_cluster)\n",
        "\n",
        "        return clusters\n",
        "\n",
        "    def _detect_cultural_context(self, scene_type: str, detected_objects: List[Dict]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Detect the likely cultural context of the scene.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type\n",
        "            detected_objects: List of detected objects\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: Detected cultural context (asian, european, etc.) or None\n",
        "        \"\"\"\n",
        "        # Scene types with explicit cultural contexts\n",
        "        cultural_scene_mapping = {\n",
        "            \"asian_commercial_street\": \"asian\",\n",
        "            \"asian_night_market\": \"asian\",\n",
        "            \"asian_temple_area\": \"asian\",\n",
        "            \"european_plaza\": \"european\"\n",
        "        }\n",
        "\n",
        "        # Check if scene type directly indicates cultural context\n",
        "        if scene_type in cultural_scene_mapping:\n",
        "            return cultural_scene_mapping[scene_type]\n",
        "\n",
        "        # No specific cultural context detected\n",
        "        return None\n",
        "\n",
        "    def _generate_cultural_elements(self, cultural_context: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate description of cultural elements for the detected context.\n",
        "\n",
        "        Args:\n",
        "            cultural_context: Detected cultural context\n",
        "\n",
        "        Returns:\n",
        "            str: Description of cultural elements\n",
        "        \"\"\"\n",
        "        # Get template for this cultural context\n",
        "        cultural_templates = self.templates.get(\"cultural_templates\", {})\n",
        "\n",
        "        if cultural_context in cultural_templates:\n",
        "            template = cultural_templates[cultural_context]\n",
        "            elements = template.get(\"elements\", [])\n",
        "\n",
        "            if elements:\n",
        "                # Select 1-2 random elements\n",
        "                num_elements = min(len(elements), random.randint(1, 2))\n",
        "                selected_elements = random.sample(elements, num_elements)\n",
        "\n",
        "                # Format elements list\n",
        "                elements_text = \" and \".join(selected_elements) if num_elements == 2 else selected_elements[0]\n",
        "\n",
        "                # Fill template\n",
        "                return template.get(\"description\", \"\").format(elements=elements_text)\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def _optimize_object_description(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        優化物品描述，避免重複列舉相同物品\n",
        "        \"\"\"\n",
        "        import re\n",
        "\n",
        "        # 處理床鋪重複描述\n",
        "        if \"bed in the room\" in description:\n",
        "            description = description.replace(\"a bed in the room\", \"a bed\")\n",
        "\n",
        "        # 處理重複的物品列表\n",
        "        object_lists = re.findall(r'with ([^\\.]+?)(?:\\.|\\band\\b)', description)\n",
        "\n",
        "        for obj_list in object_lists:\n",
        "            # 計算每個物品出現次數\n",
        "            items = re.findall(r'([a-zA-Z\\s]+)(?:,|\\band\\b|$)', obj_list)\n",
        "            item_counts = {}\n",
        "\n",
        "            for item in items:\n",
        "                item = item.strip()\n",
        "                if item and item not in [\"and\", \"with\"]:\n",
        "                    if item not in item_counts:\n",
        "                        item_counts[item] = 0\n",
        "                    item_counts[item] += 1\n",
        "\n",
        "            # 生成優化後的物品列表\n",
        "            if item_counts:\n",
        "                new_items = []\n",
        "                for item, count in item_counts.items():\n",
        "                    if count > 1:\n",
        "                        new_items.append(f\"{count} {item}s\")\n",
        "                    else:\n",
        "                        new_items.append(item)\n",
        "\n",
        "                # 格式化新列表\n",
        "                if len(new_items) == 1:\n",
        "                    new_list = new_items[0]\n",
        "                elif len(new_items) == 2:\n",
        "                    new_list = f\"{new_items[0]} and {new_items[1]}\"\n",
        "                else:\n",
        "                    new_list = \", \".join(new_items[:-1]) + f\", and {new_items[-1]}\"\n",
        "\n",
        "                # 替換原始列表\n",
        "                description = description.replace(obj_list, new_list)\n",
        "\n",
        "        return description\n",
        "\n",
        "    def _describe_functional_zones(self, functional_zones: Dict) -> str:\n",
        "        \"\"\"\n",
        "        生成場景功能區域的描述，優化處理行人區域、人數統計和物品重複問題。\n",
        "\n",
        "        Args:\n",
        "            functional_zones: 識別出的功能區域字典\n",
        "\n",
        "        Returns:\n",
        "            str: 功能區域描述\n",
        "        \"\"\"\n",
        "        if not functional_zones:\n",
        "            return \"\"\n",
        "\n",
        "        # 處理不同類型的 functional_zones 參數\n",
        "        if isinstance(functional_zones, list):\n",
        "            # 如果是列表，轉換為字典格式\n",
        "            zones_dict = {}\n",
        "            for i, zone in enumerate(functional_zones):\n",
        "                if isinstance(zone, dict) and 'name' in zone:\n",
        "                    zone_name = zone['name']\n",
        "                else:\n",
        "                    zone_name = f\"zone_{i}\"\n",
        "                zones_dict[zone_name] = zone if isinstance(zone, dict) else {\"description\": str(zone)}\n",
        "            functional_zones = zones_dict\n",
        "        elif not isinstance(functional_zones, dict):\n",
        "            return \"\"\n",
        "\n",
        "        # 計算場景中的總人數\n",
        "        total_people_count = 0\n",
        "        people_by_zone = {}\n",
        "\n",
        "        # 計算每個區域的人數並累計總人數\n",
        "        for zone_name, zone_info in functional_zones.items():\n",
        "            if \"objects\" in zone_info:\n",
        "                zone_people_count = zone_info[\"objects\"].count(\"person\")\n",
        "                people_by_zone[zone_name] = zone_people_count\n",
        "                total_people_count += zone_people_count\n",
        "\n",
        "        # 分類區域為行人區域和其他區域\n",
        "        pedestrian_zones = []\n",
        "        other_zones = []\n",
        "\n",
        "        for zone_name, zone_info in functional_zones.items():\n",
        "            # 檢查是否是行人相關區域\n",
        "            if any(keyword in zone_name.lower() for keyword in [\"pedestrian\", \"crossing\", \"people\"]):\n",
        "                pedestrian_zones.append((zone_name, zone_info))\n",
        "            else:\n",
        "                other_zones.append((zone_name, zone_info))\n",
        "\n",
        "        # 獲取最重要的行人區域和其他區域\n",
        "        main_pedestrian_zones = sorted(pedestrian_zones,\n",
        "                                    key=lambda z: people_by_zone.get(z[0], 0),\n",
        "                                    reverse=True)[:1]  # 最多1個主要行人區域\n",
        "\n",
        "        top_other_zones = sorted(other_zones,\n",
        "                            key=lambda z: len(z[1].get(\"objects\", [])),\n",
        "                            reverse=True)[:2]  # 最多2個其他區域\n",
        "\n",
        "        # 合併區域\n",
        "        top_zones = main_pedestrian_zones + top_other_zones\n",
        "\n",
        "        if not top_zones:\n",
        "            return \"\"\n",
        "\n",
        "        # 生成匯總描述\n",
        "        summary = \"\"\n",
        "        max_mentioned_people = 0  # track已經提到的最大人數\n",
        "\n",
        "        # 如果總人數顯著且還沒在主描述中提到，添加總人數描述\n",
        "        if total_people_count > 5:\n",
        "            summary = f\"The scene contains a significant number of pedestrians ({total_people_count} people). \"\n",
        "            max_mentioned_people = total_people_count  # update已提到的最大人數\n",
        "\n",
        "        # 處理每個區域的描述，確保人數信息的一致性\n",
        "        processed_zones = []\n",
        "\n",
        "        for zone_name, zone_info in top_zones:\n",
        "            zone_desc = zone_info.get(\"description\", \"a functional zone\")\n",
        "            zone_people_count = people_by_zone.get(zone_name, 0)\n",
        "\n",
        "            # 檢查描述中是否包含人數資訊\n",
        "            contains_people_info = \"with\" in zone_desc and (\"person\" in zone_desc.lower() or \"people\" in zone_desc.lower())\n",
        "\n",
        "            # 如果描述包含人數信息，且人數較小（小於已提到的最大人數），則修改描述\n",
        "            if contains_people_info and zone_people_count < max_mentioned_people:\n",
        "                parts = zone_desc.split(\"with\")\n",
        "                if len(parts) > 1:\n",
        "                    # 移除人數部分\n",
        "                    zone_desc = parts[0].strip() + \" area\"\n",
        "\n",
        "            processed_zones.append((zone_name, {\"description\": zone_desc}))\n",
        "\n",
        "        # 根據處理後的區域數量生成最終描述\n",
        "        final_desc = \"\"\n",
        "\n",
        "        if len(processed_zones) == 1:\n",
        "            _, zone_info = processed_zones[0]\n",
        "            zone_desc = zone_info[\"description\"]\n",
        "            final_desc = summary + f\"The scene includes {zone_desc}.\"\n",
        "        elif len(processed_zones) == 2:\n",
        "            _, zone1_info = processed_zones[0]\n",
        "            _, zone2_info = processed_zones[1]\n",
        "            zone1_desc = zone1_info[\"description\"]\n",
        "            zone2_desc = zone2_info[\"description\"]\n",
        "            final_desc = summary + f\"The scene is divided into two main areas: {zone1_desc} and {zone2_desc}.\"\n",
        "        else:\n",
        "            zones_desc = [\"The scene contains multiple functional areas including\"]\n",
        "            zone_descriptions = [z[1][\"description\"] for z in processed_zones]\n",
        "\n",
        "            # 格式化最終的多區域描述\n",
        "            if len(zone_descriptions) == 3:\n",
        "                formatted_desc = f\"{zone_descriptions[0]}, {zone_descriptions[1]}, and {zone_descriptions[2]}\"\n",
        "            else:\n",
        "                formatted_desc = \", \".join(zone_descriptions[:-1]) + f\", and {zone_descriptions[-1]}\"\n",
        "\n",
        "            final_desc = summary + f\"{zones_desc[0]} {formatted_desc}.\"\n",
        "\n",
        "        return self._optimize_object_description(final_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slarD41pZ9WB"
      },
      "outputs": [],
      "source": [
        "# %%writefile lighting_analyzer.py\n",
        "import numpy as np\n",
        "import cv2\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "class LightingAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes lighting conditions of an image, providing enhanced indoor/outdoor\n",
        "    determination and light type classification, with a focus on lighting analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[Dict[str, Any]] = None):\n",
        "        \"\"\"\n",
        "        Initializes the LightingAnalyzer.\n",
        "\n",
        "        Args:\n",
        "            config: Optional configuration dictionary for custom analysis parameters.\n",
        "        \"\"\"\n",
        "        self.config = config or self._get_default_config()\n",
        "\n",
        "    def analyze(self, image, places365_info: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        Analyzes the lighting conditions of an image.\n",
        "        Main entry point for analysis, computes basic features, determines\n",
        "        indoor/outdoor, and identifies lighting conditions.\n",
        "\n",
        "        Args:\n",
        "            image: Input image (numpy array or PIL Image).\n",
        "\n",
        "        Returns:\n",
        "            Dict: Dictionary containing lighting analysis results.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert image format\n",
        "            if not isinstance(image, np.ndarray):\n",
        "                image_np = np.array(image) # Convert PIL Image to numpy array\n",
        "            else:\n",
        "                image_np = image.copy()\n",
        "\n",
        "            # Ensure image is in BGR for OpenCV if it's from PIL (RGB)\n",
        "            if image_np.shape[2] == 3 and not isinstance(image, np.ndarray): #  PIL images are typically RGB\n",
        "                 image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "            elif image_np.shape[2] == 3 and image.shape[2] == 3: # Already a numpy array, assume BGR from cv2.imread\n",
        "                 image_bgr = image_np\n",
        "            elif image_np.shape[2] == 4: # RGBA\n",
        "                 image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGBA2BGR)\n",
        "            else: # Grayscale or other\n",
        "                 # If grayscale, convert to BGR for consistency, though feature extraction will mostly use grayscale/HSV\n",
        "                 if len(image_np.shape) == 2:\n",
        "                     image_bgr = cv2.cvtColor(image_np, cv2.COLOR_GRAY2BGR)\n",
        "                 else: # Fallback for other unexpected formats\n",
        "                     print(f\"Warning: Unexpected image format with shape {image_np.shape}. Attempting to proceed.\")\n",
        "                     image_bgr = image_np\n",
        "\n",
        "\n",
        "            # Ensure RGB format for internal processing (some functions expect RGB)\n",
        "            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            features = self._compute_basic_features(image_rgb) # features 字典現在也包含由 P365 間接影響的預計算值\n",
        "\n",
        "            # 將 places365_info 傳遞給室內/室外判斷\n",
        "            indoor_result = self._analyze_indoor_outdoor(features, places365_info=places365_info)\n",
        "            is_indoor = indoor_result[\"is_indoor\"]\n",
        "            indoor_probability = indoor_result[\"indoor_probability\"]\n",
        "\n",
        "            # 將 places365_info 和已修正的 is_indoor 傳遞給光線類型判斷\n",
        "            lighting_conditions = self._determine_lighting_conditions(features, is_indoor, places365_info=places365_info)\n",
        "\n",
        "            # Consolidate results\n",
        "            result = {\n",
        "                \"time_of_day\": lighting_conditions[\"time_of_day\"],\n",
        "                \"confidence\": float(lighting_conditions[\"confidence\"]),\n",
        "                \"is_indoor\": is_indoor,\n",
        "                \"indoor_probability\": float(indoor_probability),\n",
        "                \"brightness\": {\n",
        "                    \"average\": float(features[\"avg_brightness\"]),\n",
        "                    \"std_dev\": float(features[\"brightness_std\"]),\n",
        "                    \"dark_ratio\": float(features[\"dark_pixel_ratio\"]),\n",
        "                    \"bright_ratio\": float(features.get(\"bright_pixel_ratio\", 0)) # Added\n",
        "                },\n",
        "                \"color_info\": {\n",
        "                    \"blue_ratio\": float(features[\"blue_ratio\"]),\n",
        "                    \"sky_like_blue_ratio\": float(features.get(\"sky_like_blue_ratio\",0)), # More specific sky blue\n",
        "                    \"yellow_orange_ratio\": float(features[\"yellow_orange_ratio\"]),\n",
        "                    \"gray_ratio\": float(features[\"gray_ratio\"]),\n",
        "                    \"avg_saturation\": float(features[\"avg_saturation\"]),\n",
        "                    \"sky_region_brightness_ratio\": float(features.get(\"sky_region_brightness_ratio\", 1.0)), # Renamed and clarified\n",
        "                    \"sky_region_saturation\": float(features.get(\"sky_region_saturation\", 0)),\n",
        "                    \"sky_region_blue_dominance\": float(features.get(\"sky_region_blue_dominance\", 0)),\n",
        "                    \"color_atmosphere\": features[\"color_atmosphere\"],\n",
        "                    \"warm_ratio\": float(features[\"warm_ratio\"]),\n",
        "                    \"cool_ratio\": float(features[\"cool_ratio\"]),\n",
        "                },\n",
        "                \"texture_info\": { # New category for texture/gradient features\n",
        "                    \"gradient_ratio_vertical_horizontal\": float(features.get(\"gradient_ratio_vertical_horizontal\", 0)), # Renamed\n",
        "                    \"top_region_texture_complexity\": float(features.get(\"top_region_texture_complexity\", 0)),\n",
        "                    \"shadow_clarity_score\": float(features.get(\"shadow_clarity_score\",0.5)), # Default to neutral\n",
        "                },\n",
        "                \"structure_info\": { # New category for structural features\n",
        "                     \"ceiling_likelihood\": float(features.get(\"ceiling_likelihood\",0)),\n",
        "                     \"boundary_clarity\": float(features.get(\"boundary_clarity\",0)),\n",
        "                     \"openness_top_edge\": float(features.get(\"openness_top_edge\", 0.5)), # Default to neutral\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Add diagnostic information\n",
        "            if self.config.get(\"include_diagnostics\", False): # Use .get for safety\n",
        "                result[\"diagnostics\"] = {\n",
        "                    \"feature_contributions\": indoor_result.get(\"feature_contributions\", {}),\n",
        "                    \"lighting_diagnostics\": lighting_conditions.get(\"diagnostics\", {})\n",
        "                }\n",
        "\n",
        "            if self.config.get(\"include_diagnostics\", False):\n",
        "                # indoor_result[\"diagnostics\"] 現在會包含 P365 的影響\n",
        "                result[\"diagnostics\"][\"feature_contributions\"] = indoor_result.get(\"feature_contributions\", {})\n",
        "                result[\"diagnostics\"][\"lighting_diagnostics\"] = lighting_conditions.get(\"diagnostics\", {})\n",
        "                result[\"diagnostics\"][\"indoor_outdoor_diagnostics\"] = indoor_result.get(\"diagnostics\", {})\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in lighting analysis: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\n",
        "                \"time_of_day\": \"unknown\",\n",
        "                \"confidence\": 0,\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "    def _compute_basic_features(self, image_rgb: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Computes basic lighting features from an RGB image.\n",
        "        This version includes enhancements for sky, ceiling, and boundary detection.\n",
        "        \"\"\"\n",
        "        # Get image dimensions\n",
        "        height, width = image_rgb.shape[:2]\n",
        "        if height == 0 or width == 0:\n",
        "            print(\"Error: Image has zero height or width.\")\n",
        "            # Return a dictionary of zeros or default values for all expected features\n",
        "            return {feature: 0.0 for feature in [ # Ensure all keys expected by other methods are present\n",
        "                \"avg_brightness\", \"brightness_std\", \"dark_pixel_ratio\", \"bright_pixel_ratio\",\n",
        "                \"blue_ratio\", \"sky_like_blue_ratio\", \"yellow_orange_ratio\", \"gray_ratio\",\n",
        "                \"avg_saturation\", \"sky_region_brightness_ratio\", \"sky_region_saturation\", \"sky_region_blue_dominance\",\n",
        "                \"color_atmosphere\", \"warm_ratio\", \"cool_ratio\", \"gradient_ratio_vertical_horizontal\",\n",
        "                \"top_region_texture_complexity\", \"shadow_clarity_score\", \"ceiling_likelihood\",\n",
        "                \"boundary_clarity\", \"openness_top_edge\", \"ceiling_uniformity\", \"horizontal_line_ratio\", # Old keys kept for compatibility if still used\n",
        "                \"indoor_light_score\", \"circular_light_count\", \"light_distribution_uniformity\",\n",
        "                \"boundary_edge_score\", \"top_region_std\", \"edges_density\", \"street_line_score\",\n",
        "                \"sky_brightness\", \"vertical_strength\", \"horizontal_strength\", \"brightness_uniformity\", \"bright_spot_count\"\n",
        "            ]}\n",
        "\n",
        "\n",
        "        # Adaptive scaling factor based on image size for performance\n",
        "        base_scale = 4\n",
        "        # Protect against zero division if height or width is tiny\n",
        "        scale_factor = base_scale + min(8, max(0, int((height * width) / (1000 * 1000)) if height * width > 0 else 0))\n",
        "        scale_factor = max(1, scale_factor) # Ensure scale_factor is at least 1\n",
        "\n",
        "        # Create a smaller version of the image for faster processing of some features\n",
        "        small_rgb = cv2.resize(image_rgb, (width // scale_factor, height // scale_factor), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # Convert to HSV and Grayscale once\n",
        "        hsv_img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
        "        gray_img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
        "        small_gray = cv2.cvtColor(small_rgb, cv2.COLOR_RGB2GRAY) # Grayscale of the small image\n",
        "\n",
        "        # Separate HSV channels\n",
        "        h_channel, s_channel, v_channel = cv2.split(hsv_img)\n",
        "\n",
        "        # --- Brightness Features ---\n",
        "        avg_brightness = np.mean(v_channel)\n",
        "        brightness_std = np.std(v_channel)\n",
        "        dark_pixel_ratio = np.sum(v_channel < self.config.get(\"dark_pixel_threshold\", 50)) / (height * width) # 使用配置閾值\n",
        "        bright_pixel_ratio = np.sum(v_channel > self.config.get(\"bright_pixel_threshold\", 220)) / (height * width) # 新增：亮部像素比例\n",
        "\n",
        "        # --- Color Features ---\n",
        "        # Yellow-Orange Ratio\n",
        "        yellow_orange_mask = ((h_channel >= 15) & (h_channel <= 45)) # Adjusted range slightly\n",
        "        yellow_orange_ratio = np.sum(yellow_orange_mask) / (height * width)\n",
        "\n",
        "        # General Blue Ratio\n",
        "        blue_mask = ((h_channel >= 90) & (h_channel <= 140)) # Slightly wider blue range\n",
        "        blue_ratio = np.sum(blue_mask) / (height * width)\n",
        "\n",
        "        # More specific \"Sky-Like Blue\" Ratio - for clearer skies\n",
        "        # 中文備註：更精確地定義「天空藍」，排除室內常見的深藍或青色。\n",
        "        sky_like_blue_hue_min = self.config.get(\"sky_blue_hue_min\", 100)\n",
        "        sky_like_blue_hue_max = self.config.get(\"sky_blue_hue_max\", 130) # Typical sky blue Hues in HSV\n",
        "        sky_like_blue_sat_min = self.config.get(\"sky_blue_sat_min\", 60)   # Sky is usually somewhat saturated\n",
        "        sky_like_blue_val_min = self.config.get(\"sky_blue_val_min\", 120)  # Sky is usually bright\n",
        "        sky_like_blue_mask = ((h_channel >= sky_like_blue_hue_min) & (h_channel <= sky_like_blue_hue_max) &\n",
        "                              (s_channel > sky_like_blue_sat_min) & (v_channel > sky_like_blue_val_min))\n",
        "        sky_like_blue_ratio = np.sum(sky_like_blue_mask) / (height * width)\n",
        "\n",
        "        # Gray Ratio (low saturation, mid-high brightness)\n",
        "        gray_sat_max = self.config.get(\"gray_sat_max\", 50)\n",
        "        gray_val_min = self.config.get(\"gray_val_min\", 80) # Adjusted to avoid very dark grays\n",
        "        gray_val_max = self.config.get(\"gray_val_max\", 200) # Avoid pure white being too gray\n",
        "        gray_mask = (s_channel < gray_sat_max) & (v_channel > gray_val_min) & (v_channel < gray_val_max)\n",
        "        gray_ratio = np.sum(gray_mask) / (height * width)\n",
        "\n",
        "        avg_saturation = np.mean(s_channel)\n",
        "\n",
        "        # --- Sky Region Analysis (Top 1/3 of image) ---\n",
        "        # 中文備註：專門分析圖像頂部區域，這是判斷天空的關鍵。\n",
        "        top_third_height = height // 3\n",
        "        sky_region_v = v_channel[:top_third_height, :]\n",
        "        sky_region_s = s_channel[:top_third_height, :]\n",
        "        sky_region_h = h_channel[:top_third_height, :]\n",
        "\n",
        "        sky_region_avg_brightness = np.mean(sky_region_v) if sky_region_v.size > 0 else 0\n",
        "        sky_region_brightness_ratio = sky_region_avg_brightness / max(avg_brightness, 1e-5) # Ratio to overall brightness\n",
        "        sky_region_saturation = np.mean(sky_region_s) if sky_region_s.size > 0 else 0\n",
        "\n",
        "        # Blue dominance in sky region\n",
        "        sky_region_blue_pixels = np.sum(\n",
        "            (sky_region_h >= sky_like_blue_hue_min) & (sky_region_h <= sky_like_blue_hue_max) &\n",
        "            (sky_region_s > sky_like_blue_sat_min) & (sky_region_v > sky_like_blue_val_min)\n",
        "        )\n",
        "        sky_region_blue_dominance = sky_region_blue_pixels / max(1, sky_region_v.size)\n",
        "\n",
        "\n",
        "        # --- Color Atmosphere ---\n",
        "        warm_hue_ranges = self.config.get(\"warm_hue_ranges\", [(0, 50), (330, 360)]) # Red, Orange, Yellow, some Magentas\n",
        "        cool_hue_ranges = self.config.get(\"cool_hue_ranges\", [(90, 270)]) # Cyan, Blue, Purple, Green\n",
        "\n",
        "        warm_mask = np.zeros_like(h_channel, dtype=bool)\n",
        "        for h_min, h_max in warm_hue_ranges:\n",
        "            warm_mask |= ((h_channel >= h_min) & (h_channel <= h_max))\n",
        "        warm_ratio = np.sum(warm_mask & (s_channel > 30)) / (height * width) # Consider saturation for warmth\n",
        "\n",
        "        cool_mask = np.zeros_like(h_channel, dtype=bool)\n",
        "        for h_min, h_max in cool_hue_ranges:\n",
        "            cool_mask |= ((h_channel >= h_min) & (h_channel <= h_max))\n",
        "        cool_ratio = np.sum(cool_mask & (s_channel > 30)) / (height * width) # Consider saturation for coolness\n",
        "\n",
        "        if warm_ratio > cool_ratio and warm_ratio > 0.3: # Increased threshold\n",
        "            color_atmosphere = \"warm\"\n",
        "        elif cool_ratio > warm_ratio and cool_ratio > 0.3: # Increased threshold\n",
        "            color_atmosphere = \"cool\"\n",
        "        else:\n",
        "            color_atmosphere = \"neutral\"\n",
        "\n",
        "        # --- Gradient and Texture Features (on small image for speed) ---\n",
        "        # 中文備註：在縮小的灰階圖像上計算梯度，以提高效率。\n",
        "        gx = cv2.Sobel(small_gray, cv2.CV_32F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(small_gray, cv2.CV_32F, 0, 1, ksize=3)\n",
        "\n",
        "        avg_abs_gx = np.mean(np.abs(gx))\n",
        "        avg_abs_gy = np.mean(np.abs(gy))\n",
        "        # Renamed for clarity: ratio of vertical to horizontal gradients\n",
        "        gradient_ratio_vertical_horizontal = avg_abs_gy / max(avg_abs_gx, 1e-5)\n",
        "\n",
        "\n",
        "        # Texture complexity of the top region (potential ceiling or sky)\n",
        "        # 中文備註：分析頂部區域的紋理複雜度，天空通常紋理簡單，天花板可能複雜。\n",
        "        small_top_third_height = small_gray.shape[0] // 3\n",
        "        small_sky_region_gray = small_gray[:small_top_third_height, :]\n",
        "        if small_sky_region_gray.size > 0:\n",
        "            laplacian_var_sky = cv2.Laplacian(small_sky_region_gray, cv2.CV_64F).var()\n",
        "            # Normalize, though this might need scene-adaptive normalization or defined bins\n",
        "            top_region_texture_complexity = min(1.0, laplacian_var_sky / 1000.0) # Example normalization\n",
        "        else:\n",
        "            top_region_texture_complexity = 0.5 # Neutral if no top region\n",
        "\n",
        "        # 先簡單的估計陰影清晰度。清晰陰影通常表示強烈又單一的光源（像是太陽）。\n",
        "        # High brightness std dev might indicate strong highlights and shadows.\n",
        "        # Low dark_pixel_ratio with high brightness_std could imply sharp shadows.\n",
        "        if brightness_std > 60 and dark_pixel_ratio < 0.15 and avg_brightness > 100:\n",
        "            shadow_clarity_score = 0.7 # Potential for clear shadows (more outdoor-like)\n",
        "        elif brightness_std < 30 and dark_pixel_ratio > 0.1:\n",
        "            shadow_clarity_score = 0.3 # Potential for diffuse shadows (more indoor/cloudy-like)\n",
        "        else:\n",
        "            shadow_clarity_score = 0.5 # Neutral\n",
        "\n",
        "        # Structural Features (Ceiling, Boundary, Openness)\n",
        "        # 判斷天花板的可能性。\n",
        "        ceiling_likelihood = 0.0\n",
        "        # 條件1: 頂部區域紋理簡單且亮度適中 (表明可能是平坦的天花板)\n",
        "        if top_region_texture_complexity < self.config.get(\"ceiling_texture_thresh\", 0.4) and \\\n",
        "        self.config.get(\"ceiling_brightness_min\", 60) < sky_region_avg_brightness < self.config.get(\"ceiling_brightness_max\", 230): # 放寬亮度上限\n",
        "            ceiling_likelihood += 0.45 # 稍微提高基礎分\n",
        "\n",
        "        # 條件2: 頂部區域存在水平線條 (可能是天花板邊緣或結構)\n",
        "        top_horizontal_lines_strength = np.mean(np.abs(gx[:small_gray.shape[0]//3, :]))\n",
        "        if top_horizontal_lines_strength > avg_abs_gx * self.config.get(\"ceiling_horizontal_line_factor\", 1.15): # 稍微降低因子\n",
        "            ceiling_likelihood += 0.35 # 稍微提高貢獻\n",
        "\n",
        "        # 條件3: 中央區域比周圍亮 (可能是吊燈，暗示天花板) - 針對室內光源\n",
        "        # 這個條件對於 room_02.jpg 可能比較重要，因為它有一個中央吊燈\n",
        "        center_y_sm, center_x_sm = small_gray.shape[0]//2, small_gray.shape[1]//2\n",
        "        # 定義一個更小的中心區域來檢測吊燈類型的亮點\n",
        "        lamp_check_radius_y = small_gray.shape[0] // 8\n",
        "        lamp_check_radius_x = small_gray.shape[1] // 8\n",
        "        center_bright_spot_region = small_gray[max(0, center_y_sm - lamp_check_radius_y) : min(small_gray.shape[0], center_y_sm + lamp_check_radius_y),\n",
        "                                            max(0, center_x_sm - lamp_check_radius_x) : min(small_gray.shape[1], center_x_sm + lamp_check_radius_x)]\n",
        "\n",
        "        if center_bright_spot_region.size > 0 and np.mean(center_bright_spot_region) > avg_brightness * self.config.get(\"ceiling_center_bright_factor\", 1.25): # 提高中心亮度要求\n",
        "            ceiling_likelihood += 0.30 # 顯著提高吊燈對天花板的貢獻\n",
        "\n",
        "        # 條件4: 如果頂部區域藍色成分不高，且不是特別亮（排除天空），則增加天花板可能性\n",
        "        # 這個條件有助於區分多雲天空和室內天花板\n",
        "        if sky_region_blue_dominance < self.config.get(\"ceiling_max_sky_blue_thresh\", 0.08) and \\\n",
        "        sky_region_brightness_ratio < self.config.get(\"ceiling_max_sky_brightness_ratio\", 1.15): # 頂部不能太亮\n",
        "            ceiling_likelihood += 0.15\n",
        "\n",
        "        # 懲罰項: 如果有強烈天空信號，大幅降低天花板可能性\n",
        "        if sky_region_blue_dominance > self.config.get(\"sky_blue_dominance_strong_thresh\", 0.25) and \\\n",
        "        sky_region_brightness_ratio > self.config.get(\"sky_brightness_strong_thresh\", 1.25):\n",
        "            ceiling_likelihood *= self.config.get(\"ceiling_sky_override_factor\", 0.1) # 大幅降低\n",
        "\n",
        "        ceiling_likelihood = min(1.0, ceiling_likelihood)\n",
        "\n",
        "\n",
        "        # 邊界感的，通常室內邊界較強\n",
        "        # Using Sobel on edges of the small_gray image\n",
        "        edge_width_sm = max(1, small_gray.shape[1] // 10) # 10% for edge\n",
        "        edge_height_sm = max(1, small_gray.shape[0] // 10)\n",
        "\n",
        "        left_edge_grad_x = np.mean(np.abs(gx[:, :edge_width_sm])) if small_gray.shape[1] > edge_width_sm else 0\n",
        "        right_edge_grad_x = np.mean(np.abs(gx[:, -edge_width_sm:])) if small_gray.shape[1] > edge_width_sm else 0\n",
        "        top_edge_grad_y = np.mean(np.abs(gy[:edge_height_sm, :])) if small_gray.shape[0] > edge_height_sm else 0\n",
        "\n",
        "        # Normalize these gradients (e.g. against average gradient)\n",
        "        boundary_clarity = (left_edge_grad_x + right_edge_grad_x + top_edge_grad_y) / (3 * max(avg_abs_gx, avg_abs_gy, 1e-5))\n",
        "        boundary_clarity = min(1.0, boundary_clarity / 1.5) # Normalize, 1.5 is a heuristic factor\n",
        "\n",
        "\n",
        "        # 判斷頂部邊緣是否開放（例如天空），室外的特徵比較明顯\n",
        "        # Low vertical gradient at the very top edge suggests openness (sky)\n",
        "        top_edge_strip_gy = np.mean(np.abs(gy[:max(1,small_gray.shape[0]//20), :])) # Very top 5%\n",
        "        openness_top_edge = 1.0 - min(1.0, top_edge_strip_gy / max(avg_abs_gy, 1e-5) / 0.5 ) # Normalize, 0.5 factor, less grad = more open\n",
        "\n",
        "        top_region = v_channel[:height//4, :] # Full res top region\n",
        "        top_region_std_fullres = np.std(top_region) if top_region.size > 0 else 0\n",
        "        ceiling_uniformity_old = 1.0 - min(1, top_region_std_fullres / max(np.mean(top_region) if top_region.size >0 else 1e-5, 1e-5))\n",
        "\n",
        "        top_gradients_old = np.abs(cv2.Sobel(gray_img[:height//4, :], cv2.CV_32F, 0, 1, ksize=3)) # Full res top gradients for gy\n",
        "        horizontal_lines_strength_old = np.mean(top_gradients_old) if top_gradients_old.size > 0 else 0\n",
        "        horizontal_line_ratio_old = min(1, horizontal_lines_strength_old / 40) # Original normalization\n",
        "\n",
        "        # Light source detection (simplified, as in original)\n",
        "        sampled_v = v_channel[::scale_factor*2, ::scale_factor*2] # Already calculated\n",
        "        light_threshold = min(self.config.get(\"light_source_abs_thresh\", 220), avg_brightness + 2*brightness_std)\n",
        "        is_bright_spots = sampled_v > light_threshold\n",
        "        bright_spot_count_old = np.sum(is_bright_spots)\n",
        "        circular_light_score_old = 0\n",
        "        indoor_light_score_old = 0.0 # Default to float\n",
        "        light_distribution_uniformity_old = 0.5\n",
        "        if 1 < bright_spot_count_old < 20:\n",
        "            bright_y, bright_x = np.where(is_bright_spots)\n",
        "            if len(bright_y) > 1:\n",
        "                mean_x, mean_y = np.mean(bright_x), np.mean(bright_y)\n",
        "                dist_from_center = np.sqrt((bright_x - mean_x)**2 + (bright_y - mean_y)**2)\n",
        "                if np.std(dist_from_center) < np.mean(dist_from_center): # Concentrated\n",
        "                    circular_light_score_old = min(3, len(bright_y) // 2)\n",
        "                    light_distribution_uniformity_old = 0.7\n",
        "                if np.mean(bright_y) < sampled_v.shape[0] / 2: # Lights in upper half\n",
        "                    indoor_light_score_old = 0.6\n",
        "                else:\n",
        "                    indoor_light_score_old = 0.3\n",
        "\n",
        "\n",
        "        # Boundary edge score\n",
        "        # Using small_gray for consistency with other gradient features\n",
        "        left_edge_sm = small_gray[:, :small_gray.shape[1]//6]\n",
        "        right_edge_sm = small_gray[:, 5*small_gray.shape[1]//6:]\n",
        "        top_edge_sm = small_gray[:small_gray.shape[0]//6, :]\n",
        "\n",
        "        left_gradient_old = np.mean(np.abs(cv2.Sobel(left_edge_sm, cv2.CV_32F, 1, 0, ksize=3))) if left_edge_sm.size >0 else 0\n",
        "        right_gradient_old = np.mean(np.abs(cv2.Sobel(right_edge_sm, cv2.CV_32F, 1, 0, ksize=3))) if right_edge_sm.size >0 else 0\n",
        "        top_gradient_old = np.mean(np.abs(cv2.Sobel(top_edge_sm, cv2.CV_32F, 0, 1, ksize=3))) if top_edge_sm.size >0 else 0\n",
        "        boundary_edge_score_old = (min(1, left_gradient_old/50) + min(1, right_gradient_old/50) + min(1, top_gradient_old/50)) / 3\n",
        "\n",
        "        edges_density_old = min(1, (avg_abs_gx + avg_abs_gy) / 100) # Using already computed avg_abs_gx, avg_abs_gy\n",
        "\n",
        "        # Street line score (original)\n",
        "        street_line_score_old = 0\n",
        "        bottom_half_sm = small_gray[small_gray.shape[0]//2:, :]\n",
        "        if bottom_half_sm.size > 0:\n",
        "            bottom_vert_gradient = cv2.Sobel(bottom_half_sm, cv2.CV_32F, 0, 1, ksize=3)\n",
        "            strong_vert_lines = np.abs(bottom_vert_gradient) > 50\n",
        "            if np.sum(strong_vert_lines) > (bottom_half_sm.size * 0.05):\n",
        "                street_line_score_old = 0.7\n",
        "\n",
        "\n",
        "        features = {\n",
        "            # Brightness\n",
        "            \"avg_brightness\": avg_brightness,\n",
        "            \"brightness_std\": brightness_std,\n",
        "            \"dark_pixel_ratio\": dark_pixel_ratio,\n",
        "            \"bright_pixel_ratio\": bright_pixel_ratio,\n",
        "\n",
        "            # Color\n",
        "            \"blue_ratio\": blue_ratio,\n",
        "            \"sky_like_blue_ratio\": sky_like_blue_ratio,\n",
        "            \"yellow_orange_ratio\": yellow_orange_ratio,\n",
        "            \"gray_ratio\": gray_ratio,\n",
        "            \"avg_saturation\": avg_saturation,\n",
        "            \"color_atmosphere\": color_atmosphere,\n",
        "            \"warm_ratio\": warm_ratio,\n",
        "            \"cool_ratio\": cool_ratio,\n",
        "\n",
        "            # Sky Region Specific\n",
        "            \"sky_region_brightness_ratio\": sky_region_brightness_ratio,\n",
        "            \"sky_region_saturation\": sky_region_saturation,\n",
        "            \"sky_region_blue_dominance\": sky_region_blue_dominance,\n",
        "\n",
        "            # Texture / Gradient\n",
        "            \"gradient_ratio_vertical_horizontal\": gradient_ratio_vertical_horizontal,\n",
        "            \"top_region_texture_complexity\": top_region_texture_complexity,\n",
        "            \"shadow_clarity_score\": shadow_clarity_score,\n",
        "\n",
        "            # Structure\n",
        "            \"ceiling_likelihood\": ceiling_likelihood,\n",
        "            \"boundary_clarity\": boundary_clarity,\n",
        "            \"openness_top_edge\": openness_top_edge,\n",
        "\n",
        "            # color distribution\n",
        "            \"sky_blue_ratio\": sky_like_blue_ratio,\n",
        "            \"sky_brightness\": sky_region_avg_brightness,\n",
        "            \"gradient_ratio\": gradient_ratio_vertical_horizontal,\n",
        "            \"brightness_uniformity\": 1 - min(1, brightness_std / max(avg_brightness, 1e-5)),\n",
        "            \"vertical_strength\": avg_abs_gy,\n",
        "            \"horizontal_strength\": avg_abs_gx,\n",
        "            \"ceiling_uniformity\": ceiling_uniformity_old,\n",
        "            \"horizontal_line_ratio\": horizontal_line_ratio_old,\n",
        "            \"bright_spot_count\": bright_spot_count_old,\n",
        "            \"indoor_light_score\": indoor_light_score_old,\n",
        "            \"circular_light_count\": circular_light_score_old,\n",
        "            \"light_distribution_uniformity\": light_distribution_uniformity_old,\n",
        "            \"boundary_edge_score\": boundary_edge_score_old,\n",
        "            \"top_region_std\": top_region_std_fullres,\n",
        "            \"edges_density\": edges_density_old,\n",
        "            \"street_line_score\": street_line_score_old,\n",
        "        }\n",
        "        return features\n",
        "\n",
        "\n",
        "    def _analyze_indoor_outdoor(self, features: Dict[str, Any], places365_info: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyzes features and Places365 info to determine if the scene is indoor or outdoor.\n",
        "        Places365 info is used to strongly influence the decision if its confidence is high.\n",
        "        \"\"\"\n",
        "        # Use a copy of weights if they might be modified, otherwise direct access is fine\n",
        "        weights = self.config.get(\"indoor_outdoor_weights\", {})\n",
        "        visual_indoor_score = 0.0  # Score based purely on visual features\n",
        "        feature_contributions = {}\n",
        "        diagnostics = {}\n",
        "\n",
        "        # Internal Thresholds and Definitions for this function\n",
        "        P365_HIGH_CONF_THRESHOLD = 0.65  # Confidence threshold for P365 to strongly influence/override\n",
        "        P365_MODERATE_CONF_THRESHOLD = 0.4 # Confidence threshold for P365 to moderately influence\n",
        "\n",
        "        # Simplified internal lists for definitely indoor/outdoor based on P365 mapped_scene_type\n",
        "        DEFINITELY_OUTDOOR_KEYWORDS_P365 = [\n",
        "            \"street\", \"road\", \"highway\", \"park\", \"beach\", \"mountain\", \"forest\", \"field\",\n",
        "            \"outdoor\", \"sky\", \"coast\", \"courtyard\", \"square\", \"plaza\", \"bridge\",\n",
        "            \"parking_lot\", \"playground\", \"stadium\", \"construction_site\", \"river\", \"ocean\", \"desert\", \"garden\", \"trail\"\n",
        "        ]\n",
        "        DEFINITELY_INDOOR_KEYWORDS_P365 = [\n",
        "            \"bedroom\", \"office\", \"kitchen\", \"library\", \"classroom\", \"conference_room\", \"living_room\",\n",
        "            \"bathroom\", \"hospital\", \"hotel_room\", \"cabin\", \"interior\", \"museum\", \"gallery\",\n",
        "            \"mall\", \"market_indoor\", \"basement\", \"corridor\", \"lobby\", \"restaurant_indoor\", \"bar_indoor\", \"shop_indoor\", \"gym_indoor\"\n",
        "        ]\n",
        "\n",
        "        # Extract key info from places365_info\n",
        "        p365_mapped_scene = \"unknown\"\n",
        "        p365_is_indoor_from_classification = None\n",
        "        p365_attributes = []\n",
        "        p365_confidence = 0.0\n",
        "\n",
        "        if places365_info:\n",
        "            p365_mapped_scene = places365_info.get('mapped_scene_type', 'unknown').lower()\n",
        "            p365_attributes = [attr.lower() for attr in places365_info.get('attributes', [])]\n",
        "            p365_confidence = places365_info.get('confidence', 0.0)\n",
        "            p365_is_indoor_from_classification = places365_info.get('is_indoor_from_classification', None)\n",
        "\n",
        "            diagnostics[\"p365_context_received\"] = (\n",
        "                f\"P365 Scene: {p365_mapped_scene}, P365 SceneConf: {p365_confidence:.2f}, \"\n",
        "                f\"P365 DirectIndoor: {p365_is_indoor_from_classification}, P365 Attrs: {p365_attributes}\"\n",
        "            )\n",
        "\n",
        "        # Step 1: Calculate visual_indoor_score based on its own features\n",
        "        sky_evidence_score_visual = 0.0\n",
        "        strong_sky_signal_visual = False\n",
        "        sky_blue_dominance_val = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_region_brightness_ratio_val = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        top_texture_complexity_val = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        openness_top_edge_val = features.get(\"openness_top_edge\", 0.5)\n",
        "\n",
        "        # Condition 1: Visual Strong blue sky signal\n",
        "        if sky_blue_dominance_val > self.config.get(\"sky_blue_dominance_strong_thresh\", 0.35):\n",
        "            sky_evidence_score_visual -= weights.get(\"sky_blue_dominance_w\", 3.5) * sky_blue_dominance_val\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = f\"Visual: Strong sky-like blue ({sky_blue_dominance_val:.2f})\"\n",
        "            strong_sky_signal_visual = True\n",
        "\n",
        "        elif sky_region_brightness_ratio_val > self.config.get(\"sky_brightness_ratio_strong_thresh\", 1.35) and \\\n",
        "            top_texture_complexity_val < self.config.get(\"sky_texture_complexity_clear_thresh\", 0.25):\n",
        "            outdoor_push = weights.get(\"sky_brightness_ratio_w\", 3.0) * (sky_region_brightness_ratio_val - 1.0)\n",
        "            sky_evidence_score_visual -= outdoor_push\n",
        "            sky_evidence_score_visual -= weights.get(\"sky_texture_w\", 2.0)\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = f\"Visual: Top brighter (ratio:{sky_region_brightness_ratio_val:.2f}) & low texture.\"\n",
        "            strong_sky_signal_visual = True\n",
        "\n",
        "        elif openness_top_edge_val > self.config.get(\"openness_top_strong_thresh\", 0.80):\n",
        "            sky_evidence_score_visual -= weights.get(\"openness_top_w\", 2.8) * openness_top_edge_val\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = f\"Visual: Very high top edge openness ({openness_top_edge_val:.2f}).\"\n",
        "            strong_sky_signal_visual = True\n",
        "\n",
        "        elif not strong_sky_signal_visual and \\\n",
        "            top_texture_complexity_val < self.config.get(\"sky_texture_complexity_cloudy_thresh\", 0.20) and \\\n",
        "            sky_region_brightness_ratio_val > self.config.get(\"sky_brightness_ratio_cloudy_thresh\", 0.95):\n",
        "            sky_evidence_score_visual -= weights.get(\"sky_texture_w\", 2.0) * (1.0 - top_texture_complexity_val) * 0.5\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = f\"Visual: Weak sky signal (low texture, brightish top: {top_texture_complexity_val:.2f}), less weight.\"\n",
        "\n",
        "        if abs(sky_evidence_score_visual) > 0.01:\n",
        "            visual_indoor_score += sky_evidence_score_visual\n",
        "            feature_contributions[\"sky_openness_features_visual\"] = round(sky_evidence_score_visual, 2)\n",
        "            if strong_sky_signal_visual:\n",
        "                diagnostics[\"strong_sky_signal_visual_detected\"] = True\n",
        "\n",
        "        # Indoor Indicators (Visual): Ceiling, Enclosure\n",
        "        enclosure_evidence_score_visual = 0.0\n",
        "        ceiling_likelihood_val = features.get(\"ceiling_likelihood\", 0.0)\n",
        "        boundary_clarity_val = features.get(\"boundary_clarity\", 0.0)\n",
        "\n",
        "        # Get base weights for modification\n",
        "        effective_ceiling_weight = weights.get(\"ceiling_likelihood_w\", 1.5)\n",
        "        effective_boundary_weight = weights.get(\"boundary_clarity_w\", 1.2)\n",
        "\n",
        "        if ceiling_likelihood_val > self.config.get(\"ceiling_likelihood_thresh\", 0.38):\n",
        "            current_ceiling_score = effective_ceiling_weight * ceiling_likelihood_val\n",
        "            if strong_sky_signal_visual:\n",
        "                current_ceiling_score *= self.config.get(\"sky_override_factor_ceiling\", 0.1)\n",
        "            enclosure_evidence_score_visual += current_ceiling_score\n",
        "            diagnostics[\"indoor_reason_ceiling_visual\"] = f\"Visual Ceiling: {ceiling_likelihood_val:.2f}, ScoreCont: {current_ceiling_score:.2f}\"\n",
        "\n",
        "        if boundary_clarity_val > self.config.get(\"boundary_clarity_thresh\", 0.38):\n",
        "            current_boundary_score = effective_boundary_weight * boundary_clarity_val\n",
        "            if strong_sky_signal_visual:\n",
        "                current_boundary_score *= self.config.get(\"sky_override_factor_boundary\", 0.2)\n",
        "            enclosure_evidence_score_visual += current_boundary_score\n",
        "            diagnostics[\"indoor_reason_boundary_visual\"] = f\"Visual Boundary: {boundary_clarity_val:.2f}, ScoreCont: {current_boundary_score:.2f}\"\n",
        "\n",
        "        if not strong_sky_signal_visual and top_texture_complexity_val > 0.7 and \\\n",
        "        openness_top_edge_val < 0.3 and ceiling_likelihood_val < 0.35:\n",
        "            diagnostics[\"complex_urban_top_visual\"] = True\n",
        "            if boundary_clarity_val > 0.5:\n",
        "                enclosure_evidence_score_visual *= 0.5\n",
        "                diagnostics[\"reduced_enclosure_for_urban_top_visual\"] = True\n",
        "\n",
        "        if abs(enclosure_evidence_score_visual) > 0.01:\n",
        "            visual_indoor_score += enclosure_evidence_score_visual\n",
        "            feature_contributions[\"enclosure_features\"] = round(enclosure_evidence_score_visual, 2)\n",
        "\n",
        "        # Brightness Uniformity (Visual)\n",
        "        brightness_uniformity_val = 1.0 - min(1.0, features.get(\"brightness_std\", 50.0) / max(features.get(\"avg_brightness\", 100.0), 1e-5))\n",
        "        uniformity_contribution_visual = 0.0\n",
        "        if brightness_uniformity_val > self.config.get(\"brightness_uniformity_thresh_indoor\", 0.6):\n",
        "            uniformity_contribution_visual = weights.get(\"brightness_uniformity_w\", 0.6) * brightness_uniformity_val\n",
        "            if strong_sky_signal_visual: uniformity_contribution_visual *= self.config.get(\"sky_override_factor_uniformity\", 0.15)\n",
        "        elif brightness_uniformity_val < self.config.get(\"brightness_uniformity_thresh_outdoor\", 0.40):\n",
        "            if features.get(\"shadow_clarity_score\", 0.5) > 0.65:\n",
        "                uniformity_contribution_visual = -weights.get(\"brightness_non_uniformity_outdoor_w\", 1.0) * (1.0 - brightness_uniformity_val)\n",
        "            elif not strong_sky_signal_visual:\n",
        "                uniformity_contribution_visual = weights.get(\"brightness_non_uniformity_indoor_penalty_w\", 0.1) * (1.0 - brightness_uniformity_val)\n",
        "        if abs(uniformity_contribution_visual) > 0.01:\n",
        "            visual_indoor_score += uniformity_contribution_visual\n",
        "            feature_contributions[\"brightness_uniformity_contribution\"] = round(uniformity_contribution_visual, 2)\n",
        "\n",
        "        # Light Sources (Visual)\n",
        "        indoor_light_score_val = features.get(\"indoor_light_score\", 0.0)\n",
        "        circular_light_count_val = features.get(\"circular_light_count\", 0)\n",
        "        bright_spot_count_val = features.get(\"bright_spot_count\", 0)\n",
        "        avg_brightness_val = features.get(\"avg_brightness\", 100.0)\n",
        "        light_source_contribution_visual = 0.0\n",
        "\n",
        "        if circular_light_count_val >= 1 and not strong_sky_signal_visual:\n",
        "            light_source_contribution_visual += weights.get(\"circular_lights_w\", 1.2) * circular_light_count_val\n",
        "        elif indoor_light_score_val > 0.55 and not strong_sky_signal_visual:\n",
        "            light_source_contribution_visual += weights.get(\"indoor_light_score_w\", 0.8) * indoor_light_score_val\n",
        "        elif bright_spot_count_val > self.config.get(\"many_bright_spots_thresh\", 6) and \\\n",
        "            avg_brightness_val < self.config.get(\"dim_scene_for_spots_thresh\", 115) and \\\n",
        "            not strong_sky_signal_visual:\n",
        "            light_source_contribution_visual += weights.get(\"many_bright_spots_indoor_w\", 0.3) * min(bright_spot_count_val / 10.0, 1.5)\n",
        "\n",
        "        grad_ratio_val = features.get(\"gradient_ratio_vertical_horizontal\", 1.0)\n",
        "        is_likely_street_structure_visual = (0.7 < grad_ratio_val < 1.5) and features.get(\"edges_density\", 0.0) > 0.15\n",
        "\n",
        "        if is_likely_street_structure_visual and bright_spot_count_val > 3 and not strong_sky_signal_visual:\n",
        "            light_source_contribution_visual *= 0.2\n",
        "            diagnostics[\"street_lights_heuristic_visual\"] = True\n",
        "        elif strong_sky_signal_visual:\n",
        "            light_source_contribution_visual *= self.config.get(\"sky_override_factor_lights\", 0.05)\n",
        "\n",
        "        if abs(light_source_contribution_visual) > 0.01:\n",
        "            visual_indoor_score += light_source_contribution_visual\n",
        "            feature_contributions[\"light_source_features\"] = round(light_source_contribution_visual, 2)\n",
        "\n",
        "        # Color Atmosphere (Visual)\n",
        "        color_atmosphere_contribution_visual = 0.0\n",
        "        if features.get(\"color_atmosphere\") == \"warm\" and \\\n",
        "        avg_brightness_val < self.config.get(\"warm_indoor_max_brightness_thresh\", 135):\n",
        "            if not strong_sky_signal_visual and \\\n",
        "            not diagnostics.get(\"complex_urban_top_visual\", False) and \\\n",
        "            not (is_likely_street_structure_visual and avg_brightness_val > 80) and \\\n",
        "            features.get(\"avg_saturation\", 100.0) < 160:\n",
        "                if light_source_contribution_visual > 0.05:\n",
        "                    color_atmosphere_contribution_visual = weights.get(\"warm_atmosphere_indoor_w\", 0.15)\n",
        "        visual_indoor_score += color_atmosphere_contribution_visual\n",
        "        if abs(color_atmosphere_contribution_visual) > 0.01:\n",
        "            feature_contributions[\"warm_atmosphere_indoor_visual_contrib\"] = round(color_atmosphere_contribution_visual, 2) # New key\n",
        "\n",
        "        # Home Environment Pattern (Visual)\n",
        "        home_env_score_contribution_visual = 0.0\n",
        "        if not strong_sky_signal_visual:\n",
        "            bedroom_indicators = 0\n",
        "            if features.get(\"brightness_uniformity\",0.0) > 0.65 and features.get(\"boundary_clarity\",0.0) > 0.40 : bedroom_indicators+=1.1\n",
        "            if features.get(\"ceiling_likelihood\",0.0) > 0.35 and (bright_spot_count_val > 0 or circular_light_count_val > 0) : bedroom_indicators+=1.1\n",
        "            if features.get(\"warm_ratio\", 0.0) > 0.55 and features.get(\"brightness_uniformity\",0.0) > 0.65 : bedroom_indicators+=1.0\n",
        "            if features.get(\"brightness_uniformity\",0.0) > 0.70 and features.get(\"avg_saturation\",100.0) < 60 : bedroom_indicators+=0.7\n",
        "\n",
        "            if bedroom_indicators >= self.config.get(\"home_pattern_thresh_strong\", 2.0) :\n",
        "                home_env_score_contribution_visual = weights.get(\"home_env_strong_w\", 1.5)\n",
        "            elif bedroom_indicators >= self.config.get(\"home_pattern_thresh_moderate\", 1.0):\n",
        "                home_env_score_contribution_visual = weights.get(\"home_env_moderate_w\", 0.7)\n",
        "            if bedroom_indicators > 0:\n",
        "                diagnostics[\"home_environment_pattern_visual_indicators\"] = round(bedroom_indicators,1)\n",
        "        else:\n",
        "            diagnostics[\"skipped_home_env_visual_due_to_sky\"] = True\n",
        "\n",
        "        if abs(home_env_score_contribution_visual) > 0.01:\n",
        "            visual_indoor_score += home_env_score_contribution_visual\n",
        "            feature_contributions[\"home_environment_pattern_visual\"] = round(home_env_score_contribution_visual, 2)\n",
        "\n",
        "        # Aerial View of Streets (Visual Heuristic)\n",
        "        if features.get(\"sky_region_brightness_ratio\", 1.0) < self.config.get(\"aerial_top_dark_ratio_thresh\", 0.9) and \\\n",
        "        top_texture_complexity_val > self.config.get(\"aerial_top_complex_thresh\", 0.60) and \\\n",
        "        avg_brightness_val > self.config.get(\"aerial_min_avg_brightness_thresh\", 65) and \\\n",
        "        not strong_sky_signal_visual:\n",
        "            aerial_street_outdoor_push_visual = -weights.get(\"aerial_street_w\", 2.5)\n",
        "            visual_indoor_score += aerial_street_outdoor_push_visual\n",
        "            feature_contributions[\"aerial_street_pattern_visual\"] = round(aerial_street_outdoor_push_visual, 2)\n",
        "            diagnostics[\"aerial_street_pattern_visual_detected\"] = True\n",
        "            if \"enclosure_features\" in feature_contributions and feature_contributions[\"enclosure_features\"] > 0: # Check if positive\n",
        "                reduction_factor = self.config.get(\"aerial_enclosure_reduction_factor\", 0.75)\n",
        "                # Only reduce the positive part of enclosure_evidence_score_visual\n",
        "                positive_enclosure_score = max(0, enclosure_evidence_score_visual)\n",
        "                reduction_amount = positive_enclosure_score * reduction_factor\n",
        "                visual_indoor_score -= reduction_amount\n",
        "                feature_contributions[\"enclosure_features_reduced_by_aerial\"] = round(-reduction_amount, 2)\n",
        "                # Update the main enclosure_features contribution\n",
        "                feature_contributions[\"enclosure_features\"] = round(enclosure_evidence_score_visual - reduction_amount, 2)\n",
        "\n",
        "        diagnostics[\"visual_indoor_score_subtotal\"] = round(visual_indoor_score, 3)\n",
        "\n",
        "        # Step 2: Incorporate Places365 Influence\n",
        "        final_indoor_score = visual_indoor_score # Start with the visual score\n",
        "        p365_influence_score = 0.0 # Score component specifically from P365\n",
        "\n",
        "        # 處理所有Places365資訊\n",
        "        if places365_info:\n",
        "            # Define internal (non-config) weights for P365 influence to keep it self-contained\n",
        "            P365_DIRECT_INDOOR_WEIGHT = 3.5  # Strong influence for P365's direct classification\n",
        "            P365_DIRECT_OUTDOOR_WEIGHT = 4.0 # Slightly stronger for outdoor to counter visual enclosure bias\n",
        "            P365_SCENE_CONTEXT_INDOOR_WEIGHT = 2.0\n",
        "            P365_SCENE_CONTEXT_OUTDOOR_WEIGHT = 2.5\n",
        "            P365_ATTRIBUTE_INDOOR_WEIGHT = 1.0\n",
        "            P365_ATTRIBUTE_OUTDOOR_WEIGHT = 1.5\n",
        "\n",
        "            # 場景關鍵字定義，包含十字路口相關詞彙\n",
        "            DEFINITELY_OUTDOOR_KEYWORDS_P365 = [\n",
        "                \"street\", \"road\", \"highway\", \"park\", \"beach\", \"mountain\", \"forest\", \"field\",\n",
        "                \"outdoor\", \"sky\", \"coast\", \"courtyard\", \"square\", \"plaza\", \"bridge\",\n",
        "                \"parking_lot\", \"playground\", \"stadium\", \"construction_site\", \"river\", \"ocean\",\n",
        "                \"desert\", \"garden\", \"trail\", \"intersection\", \"crosswalk\", \"sidewalk\", \"pathway\",\n",
        "                \"avenue\", \"boulevard\", \"downtown\", \"city_center\", \"market_outdoor\"\n",
        "            ]\n",
        "\n",
        "            DEFINITELY_INDOOR_KEYWORDS_P365 = [\n",
        "                \"bedroom\", \"office\", \"kitchen\", \"library\", \"classroom\", \"conference_room\", \"living_room\",\n",
        "                \"bathroom\", \"hospital\", \"hotel_room\", \"cabin\", \"interior\", \"museum\", \"gallery\",\n",
        "                \"mall\", \"market_indoor\", \"basement\", \"corridor\", \"lobby\", \"restaurant_indoor\",\n",
        "                \"bar_indoor\", \"shop_indoor\", \"gym_indoor\"\n",
        "            ]\n",
        "\n",
        "            # A. Influence from P365's direct indoor/outdoor classification (is_indoor_from_classification)\n",
        "            if p365_is_indoor_from_classification is not None and \\\n",
        "            p365_confidence >= P365_MODERATE_CONF_THRESHOLD:\n",
        "\n",
        "                current_p365_direct_contrib = 0.0\n",
        "                if p365_is_indoor_from_classification is True:\n",
        "                    current_p365_direct_contrib = P365_DIRECT_INDOOR_WEIGHT * p365_confidence\n",
        "                    diagnostics[\"p365_influence_source\"] = f\"P365_DirectIndoor(True,Conf:{p365_confidence:.2f},Scene:{p365_mapped_scene})\"\n",
        "                else: # P365 says outdoor\n",
        "                    current_p365_direct_contrib = -P365_DIRECT_OUTDOOR_WEIGHT * p365_confidence\n",
        "                    diagnostics[\"p365_influence_source\"] = f\"P365_DirectIndoor(False,Conf:{p365_confidence:.2f},Scene:{p365_mapped_scene})\"\n",
        "\n",
        "                # Modulate P365's indoor push if strong VISUAL sky signal exists from LA\n",
        "                if strong_sky_signal_visual and current_p365_direct_contrib > 0:\n",
        "                    sky_override_factor = self.config.get(\"sky_override_factor_p365_indoor_decision\", 0.3)\n",
        "                    current_p365_direct_contrib *= sky_override_factor\n",
        "                    diagnostics[\"p365_indoor_push_reduced_by_visual_sky\"] = f\"Reduced to {current_p365_direct_contrib:.2f}\"\n",
        "\n",
        "                p365_influence_score += current_p365_direct_contrib\n",
        "\n",
        "            # B. Influence from P365's mapped scene type context (修改：適用於所有信心度情況)\n",
        "            elif p365_confidence >= P365_MODERATE_CONF_THRESHOLD:\n",
        "                current_p365_context_contrib = 0.0\n",
        "                is_def_indoor = any(kw in p365_mapped_scene for kw in DEFINITELY_INDOOR_KEYWORDS_P365)\n",
        "                is_def_outdoor = any(kw in p365_mapped_scene for kw in DEFINITELY_OUTDOOR_KEYWORDS_P365)\n",
        "\n",
        "                if is_def_indoor and not is_def_outdoor: # Clearly an indoor scene type from P365\n",
        "                    current_p365_context_contrib = P365_SCENE_CONTEXT_INDOOR_WEIGHT * p365_confidence\n",
        "                    diagnostics[\"p365_influence_source\"] = f\"P365_SceneContext(Indoor: {p365_mapped_scene}, Conf:{p365_confidence:.2f})\"\n",
        "                elif is_def_outdoor and not is_def_indoor: # Clearly an outdoor scene type from P365\n",
        "                    current_p365_context_contrib = -P365_SCENE_CONTEXT_OUTDOOR_WEIGHT * p365_confidence\n",
        "                    diagnostics[\"p365_influence_source\"] = f\"P365_SceneContext(Outdoor: {p365_mapped_scene}, Conf:{p365_confidence:.2f})\"\n",
        "\n",
        "                if strong_sky_signal_visual and current_p365_context_contrib > 0:\n",
        "                    sky_override_factor = self.config.get(\"sky_override_factor_p365_indoor_decision\", 0.3)\n",
        "                    current_p365_context_contrib *= sky_override_factor\n",
        "                    diagnostics[\"p365_context_indoor_push_reduced_by_visual_sky\"] = f\"Reduced to {current_p365_context_contrib:.2f}\"\n",
        "\n",
        "                p365_influence_score += current_p365_context_contrib\n",
        "\n",
        "            # C. Influence from P365 attributes\n",
        "            if p365_attributes and p365_confidence > self.config.get(\"places365_attribute_confidence_thresh\", 0.5):\n",
        "                attr_contrib = 0.0\n",
        "                if \"indoor\" in p365_attributes and \"outdoor\" not in p365_attributes: # Prioritize \"indoor\" if both somehow appear\n",
        "                    attr_contrib += P365_ATTRIBUTE_INDOOR_WEIGHT * (p365_confidence * 0.5) # Attributes usually less direct\n",
        "                    diagnostics[\"p365_attr_influence\"] = f\"+{attr_contrib:.2f} (indoor attr)\"\n",
        "                elif \"outdoor\" in p365_attributes and \"indoor\" not in p365_attributes:\n",
        "                    attr_contrib -= P365_ATTRIBUTE_OUTDOOR_WEIGHT * (p365_confidence * 0.5)\n",
        "                    diagnostics[\"p365_attr_influence\"] = f\"{attr_contrib:.2f} (outdoor attr)\"\n",
        "\n",
        "                if strong_sky_signal_visual and attr_contrib > 0:\n",
        "                    attr_contrib *= self.config.get(\"sky_override_factor_p365_indoor_decision\", 0.3) # Reduce if LA sees sky\n",
        "\n",
        "                p365_influence_score += attr_contrib\n",
        "\n",
        "            # 針對高信心度戶外場景的額外處理\n",
        "            if p365_confidence >= 0.85 and any(kw in p365_mapped_scene for kw in [\"intersection\", \"crosswalk\", \"street\", \"road\"]):\n",
        "                # 當Places365強烈指示戶外街道場景時，額外增加戶外影響分數\n",
        "                additional_outdoor_push = -3.0 * p365_confidence\n",
        "                p365_influence_score += additional_outdoor_push\n",
        "                diagnostics[\"p365_street_scene_boost\"] = f\"Additional outdoor push: {additional_outdoor_push:.2f} for street scene: {p365_mapped_scene}\"\n",
        "                print(f\"DEBUG: High confidence street scene detected - {p365_mapped_scene} with confidence {p365_confidence:.3f}\")\n",
        "\n",
        "            if abs(p365_influence_score) > 0.01:\n",
        "                feature_contributions[\"places365_influence_score\"] = round(p365_influence_score, 2)\n",
        "\n",
        "        final_indoor_score = visual_indoor_score + p365_influence_score\n",
        "\n",
        "        diagnostics[\"final_indoor_score_value\"] = round(final_indoor_score, 3)\n",
        "        diagnostics[\"final_score_breakdown\"] = f\"VisualScore: {visual_indoor_score:.2f}, P365Influence: {p365_influence_score:.2f}\"\n",
        "\n",
        "        # Step 3: Final probability and decision\n",
        "        sigmoid_scale = self.config.get(\"indoor_score_sigmoid_scale\", 0.30)\n",
        "        indoor_probability = 1 / (1 + np.exp(-final_indoor_score * sigmoid_scale))\n",
        "        decision_threshold = self.config.get(\"indoor_decision_threshold\", 0.5)\n",
        "        is_indoor = indoor_probability > decision_threshold\n",
        "\n",
        "        # Places365 高信心度強制覆蓋（在 sigmoid 計算之後才執行）\n",
        "        print(f\"DEBUG_OVERRIDE: Pre-override -> is_indoor: {is_indoor} (type: {type(is_indoor)}), p365_conf: {p365_confidence}, p365_raw_is_indoor: {places365_info.get('is_indoor', 'N/A') if places365_info else 'N/A'}\")\n",
        "\n",
        "        # Places365 Model 信心大於0.5時候直接覆蓋結果\n",
        "        if places365_info and p365_confidence >= 0.5:\n",
        "            p365_is_indoor_decision = places365_info.get('is_indoor', None) # 這應該是 Python bool (True, False) 或 None\n",
        "\n",
        "            print(f\"DEBUG_OVERRIDE: Override condition p365_conf >= 0.8 MET. p365_is_indoor_decision: {p365_is_indoor_decision} (type: {type(p365_is_indoor_decision)})\")\n",
        "\n",
        "            # 使用 '==' 進行比較以增加對 NumPy bool 型別的兼容性\n",
        "            # 並且明確檢查 p365_is_indoor_decision 不是 None\n",
        "            if p365_is_indoor_decision == False and p365_is_indoor_decision is not None:\n",
        "                print(f\"DEBUG_OVERRIDE: Path for p365_is_indoor_decision == False taken. Original is_indoor: {is_indoor}\")\n",
        "                original_decision_str = f\"Indoor:{is_indoor}, Prob:{indoor_probability:.3f}, Score:{final_indoor_score:.2f}\"\n",
        "\n",
        "                is_indoor = False\n",
        "                indoor_probability = 0.02  # 強制設定為極低的室內機率，基本上就是變成室外\n",
        "                final_indoor_score = -8.0    # 強制設定為極低的室內分數\n",
        "                feature_contributions[\"places365_influence_score\"] = final_indoor_score # 更新貢獻分數\n",
        "\n",
        "                diagnostics[\"p365_force_override_applied\"] = f\"P365 FORCED OUTDOOR (is_indoor: {p365_is_indoor_decision}, Conf: {p365_confidence:.3f})\"\n",
        "                diagnostics[\"p365_override_original_decision\"] = original_decision_str\n",
        "                print(f\"INFO: Places365 FORCED OUTDOOR override applied. New is_indoor: {is_indoor}\")\n",
        "\n",
        "            elif p365_is_indoor_decision == True and p365_is_indoor_decision is not None:\n",
        "                print(f\"DEBUG_OVERRIDE: Path for p365_is_indoor_decision == True taken. Original is_indoor: {is_indoor}\")\n",
        "                original_decision_str = f\"Indoor:{is_indoor}, Prob:{indoor_probability:.3f}, Score:{final_indoor_score:.2f}\"\n",
        "\n",
        "                is_indoor = True\n",
        "                indoor_probability = 0.98  # 強制設定為極高的室內機率，基本上就是變成室內\n",
        "                final_indoor_score = 8.0     # 強制設定為極高的室內分數\n",
        "                feature_contributions[\"places365_influence_score\"] = final_indoor_score # 更新貢獻分數\n",
        "\n",
        "                diagnostics[\"p365_force_override_applied\"] = f\"P365 FORCED INDOOR (is_indoor: {p365_is_indoor_decision}, Conf: {p365_confidence:.3f})\"\n",
        "                diagnostics[\"p365_override_original_decision\"] = original_decision_str\n",
        "                print(f\"INFO: Places365 FORCED INDOOR override applied. New is_indoor: {is_indoor}\")\n",
        "            else:\n",
        "                print(f\"DEBUG_OVERRIDE: No P365 True/False override. p365_is_indoor_decision was: {p365_is_indoor_decision}\")\n",
        "\n",
        "        # 確保 diagnostics 反映的是覆蓋後的 is_indoor 值\n",
        "        diagnostics[\"final_indoor_probability_calculated\"] = round(indoor_probability, 3) # 使用可能已被覆蓋的 indoor_probability\n",
        "        diagnostics[\"final_is_indoor_decision\"] = bool(is_indoor) # 避免 np.True_\n",
        "\n",
        "        print(f\"DEBUG_OVERRIDE: Returning from _analyze_indoor_outdoor -> is_indoor: {is_indoor} (type: {type(is_indoor)}), final_indoor_score: {final_indoor_score}, indoor_probability: {indoor_probability}\")\n",
        "\n",
        "        for key in [\"sky_openness_features\", \"enclosure_features\", \"brightness_uniformity_contribution\", \"light_source_features\"]:\n",
        "            if key not in feature_contributions:\n",
        "                feature_contributions[key] = 0.0 # Default to 0 if not specifically calculated by visual or P365 parts\n",
        "\n",
        "        return {\n",
        "            \"is_indoor\": is_indoor,\n",
        "            \"indoor_probability\": indoor_probability,\n",
        "            \"indoor_score_raw\": final_indoor_score,\n",
        "            \"feature_contributions\": feature_contributions, # Contains visual contributions and P365 influence\n",
        "            \"diagnostics\": diagnostics\n",
        "        }\n",
        "\n",
        "    def _determine_lighting_conditions(self, features: Dict[str, Any], is_indoor: bool, places365_info: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Determines specific lighting conditions based on features, the (Places365-influenced) is_indoor status,\n",
        "        and Places365 scene context.\n",
        "        \"\"\"\n",
        "        time_of_day = \"unknown\"\n",
        "        confidence = 0.5  # Base confidence for visual feature analysis\n",
        "        diagnostics = {}\n",
        "\n",
        "        # Internal Thresholds and Definitions for this function\n",
        "        P365_ATTRIBUTE_CONF_THRESHOLD = 0.60 # Min P365 scene confidence to trust its attributes for lighting\n",
        "        P365_SCENE_MODERATE_CONF_THRESHOLD = 0.45 # Min P365 scene confidence for its type to influence lighting\n",
        "        P365_SCENE_HIGH_CONF_THRESHOLD = 0.70 # Min P365 scene confidence for strong influence\n",
        "\n",
        "        # Keywords for P365 mapped scene types (lowercase)\n",
        "        P365_OUTDOOR_SCENE_KEYWORDS = [\n",
        "            \"street\", \"road\", \"highway\", \"park\", \"beach\", \"mountain\", \"forest\", \"field\",\n",
        "            \"outdoor\", \"sky\", \"coast\", \"courtyard\", \"square\", \"plaza\", \"bridge\",\n",
        "            \"parking\", \"playground\", \"stadium\", \"construction\", \"river\", \"ocean\", \"desert\", \"garden\", \"trail\",\n",
        "            \"natural_landmark\", \"airport_outdoor\", \"train_station_outdoor\", \"bus_station_outdoor\",  \"intersection\", \"crosswalk\", \"sidewalk\", \"pathway\"\n",
        "        ]\n",
        "        P365_INDOOR_RESTAURANT_KEYWORDS = [\"restaurant\", \"bar\", \"cafe\", \"dining_room\", \"pub\", \"bistro\", \"eatery\"]\n",
        "\n",
        "        # Extract key info from places365_info - Initialize all variables first\n",
        "        p365_mapped_scene = \"unknown\"\n",
        "        p365_attributes = []\n",
        "        p365_confidence = 0.0\n",
        "\n",
        "        if places365_info:\n",
        "            p365_mapped_scene = places365_info.get('mapped_scene_type', 'unknown').lower()\n",
        "            p365_attributes = [attr.lower() for attr in places365_info.get('attributes', [])]\n",
        "            p365_confidence = places365_info.get('confidence', 0.0)\n",
        "            diagnostics[\"p365_context_for_lighting\"] = (\n",
        "                f\"P365 Scene: {p365_mapped_scene}, Attrs: {p365_attributes}, Conf: {p365_confidence:.2f}\"\n",
        "            )\n",
        "\n",
        "        # Extract visual features (using .get with defaults for safety)\n",
        "        avg_brightness = features.get(\"avg_brightness\", 128.0)\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "        gray_ratio = features.get(\"gray_ratio\", 0.0)\n",
        "        sky_like_blue_in_sky_region = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_region_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        sky_region_is_brighter = sky_region_brightness_ratio > 1.05\n",
        "        top_texture_complexity_val = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "        circular_lights = features.get(\"circular_light_count\", 0)\n",
        "        is_likely_home_environment = features.get(\"home_environment_pattern\", 0.0) > self.config.get(\"home_pattern_thresh_moderate\", 1.0) * 0.7\n",
        "        light_dist_uniformity = features.get(\"light_distribution_uniformity\", 0.5)\n",
        "\n",
        "        # Config thresholds\n",
        "        config_thresholds = self.config\n",
        "\n",
        "        # Priority 1: Use Places365 Attributes if highly confident and consistent with `is_indoor`\n",
        "        determined_by_p365_attr = False\n",
        "        if p365_attributes and p365_confidence > P365_ATTRIBUTE_CONF_THRESHOLD:\n",
        "            if not is_indoor: # Apply outdoor attributes only if current `is_indoor` decision is False\n",
        "                if \"sunny\" in p365_attributes or \"clear sky\" in p365_attributes:\n",
        "                    time_of_day = \"day_clear\"\n",
        "                    confidence = 0.85 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.25\n",
        "                    diagnostics[\"reason\"] = \"P365 attribute: sunny/clear sky (Outdoor).\"\n",
        "                    determined_by_p365_attr = True\n",
        "\n",
        "                elif (\"nighttime\" in p365_attributes or \"night\" in p365_attributes):\n",
        "                    # Further refine based on lights if P365 confirms it's a typically lit outdoor night scene\n",
        "                    if (\"artificial lighting\" in p365_attributes or \"man-made lighting\" in p365_attributes or \\\n",
        "                    any(kw in p365_mapped_scene for kw in [\"street\", \"city\", \"road\", \"urban\", \"downtown\"])):\n",
        "                        time_of_day = \"night_with_lights\"\n",
        "                        confidence = 0.82 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.20\n",
        "                        diagnostics[\"reason\"] = \"P365 attribute: nighttime with artificial/street lights (Outdoor).\"\n",
        "\n",
        "                    else: # General dark night\n",
        "                        time_of_day = \"night_dark\"\n",
        "                        confidence = 0.78 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.20\n",
        "                        diagnostics[\"reason\"] = \"P365 attribute: nighttime, dark (Outdoor).\"\n",
        "                    determined_by_p365_attr = True\n",
        "\n",
        "                elif \"cloudy\" in p365_attributes or \"overcast\" in p365_attributes:\n",
        "                    time_of_day = \"day_cloudy_overcast\"\n",
        "                    confidence = 0.80 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.25\n",
        "                    diagnostics[\"reason\"] = \"P365 attribute: cloudy/overcast (Outdoor).\"\n",
        "                    determined_by_p365_attr = True\n",
        "\n",
        "            elif is_indoor: # Apply indoor attributes only if current `is_indoor` decision is True\n",
        "                if \"artificial lighting\" in p365_attributes or \"man-made lighting\" in p365_attributes:\n",
        "                    base_indoor_conf = 0.70 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.20\n",
        "                    if avg_brightness > config_thresholds.get(\"indoor_bright_thresh\", 130):\n",
        "                        time_of_day = \"indoor_bright_artificial\"\n",
        "                        confidence = base_indoor_conf + 0.10\n",
        "\n",
        "                    elif avg_brightness > config_thresholds.get(\"indoor_moderate_thresh\", 95):\n",
        "                        time_of_day = \"indoor_moderate_artificial\"\n",
        "                        confidence = base_indoor_conf\n",
        "\n",
        "                    else:\n",
        "                        time_of_day = \"indoor_dim_artificial\" # More specific than _general\n",
        "                        confidence = base_indoor_conf - 0.05\n",
        "                    diagnostics[\"reason\"] = f\"P365 attribute: artificial lighting (Indoor), brightness based category: {time_of_day}.\"\n",
        "                    determined_by_p365_attr = True\n",
        "\n",
        "                elif \"natural lighting\" in p365_attributes and \\\n",
        "                    (is_likely_home_environment or any(kw in p365_mapped_scene for kw in [\"living_room\", \"bedroom\", \"sunroom\"])):\n",
        "                    time_of_day = \"indoor_residential_natural\"\n",
        "                    confidence = 0.80 + (p365_confidence - P365_ATTRIBUTE_CONF_THRESHOLD) * 0.20\n",
        "                    diagnostics[\"reason\"] = \"P365 attribute: natural lighting in residential/applicable indoor scene.\"\n",
        "                    determined_by_p365_attr = True\n",
        "\n",
        "        # Step 2: If P365 attributes didn't make a high-confidence decision\n",
        "        # proceed with visual feature analysis, but now refined by P365 scene context.\n",
        "        if not determined_by_p365_attr or confidence < 0.75: # If P365 attributes didn't strongly decide\n",
        "\n",
        "            # Store the initial P365-attribute based tod and conf if they existed\n",
        "            initial_tod_by_attr = time_of_day if determined_by_p365_attr else \"unknown\"\n",
        "            initial_conf_by_attr = confidence if determined_by_p365_attr else 0.5\n",
        "\n",
        "            # Reset for visual analysis, but keep P365 context in diagnostics\n",
        "            time_of_day = \"unknown\"\n",
        "            confidence = 0.5 # Base for visual\n",
        "            current_visual_reason = \"\" # For diagnostics from visual features\n",
        "\n",
        "            if is_indoor: # `is_indoor` is already P365-influenced from _analyze_indoor_outdoor\n",
        "                natural_light_hints = 0\n",
        "                if sky_like_blue_in_sky_region > 0.05 and sky_region_is_brighter: natural_light_hints += 1.0\n",
        "                if features.get(\"brightness_uniformity\", 0.0) > 0.65 and features.get(\"brightness_std\", 100.0) < 70: natural_light_hints += 1.0\n",
        "                if features.get(\"warm_ratio\", 0.0) > 0.15 and avg_brightness > 110: natural_light_hints += 0.5\n",
        "\n",
        "                is_designer_lit_flag = (circular_lights > 0 or bright_spots_overall > 2) and \\\n",
        "                                features.get(\"brightness_uniformity\", 0.0) > 0.6 and \\\n",
        "                                features.get(\"warm_ratio\", 0.0) > 0.2 and \\\n",
        "                                avg_brightness > 90\n",
        "\n",
        "                if avg_brightness > config_thresholds.get(\"indoor_bright_thresh\", 130):\n",
        "                    if natural_light_hints >= 1.5 and (is_likely_home_environment or any(kw in p365_mapped_scene for kw in [\"home\", \"residential\", \"living\", \"bedroom\"])):\n",
        "                        time_of_day = \"indoor_residential_natural\"\n",
        "                        confidence = 0.82\n",
        "                        current_visual_reason = \"Visual: Bright residential, natural window light hints.\"\n",
        "                    elif is_designer_lit_flag and (is_likely_home_environment or any(kw in p365_mapped_scene for kw in [\"home\", \"designer\", \"modern_interior\"])):\n",
        "                        time_of_day = \"indoor_designer_residential\"\n",
        "                        confidence = 0.85\n",
        "                        current_visual_reason = \"Visual: Bright, designer-lit residential.\"\n",
        "                    elif sky_like_blue_in_sky_region > 0.03 and sky_region_is_brighter:\n",
        "                        time_of_day = \"indoor_bright_natural_mix\"\n",
        "                        confidence = 0.78\n",
        "                        current_visual_reason = \"Visual: Bright indoor, mixed natural/artificial (window).\"\n",
        "                    else:\n",
        "                        time_of_day = \"indoor_bright_artificial\"\n",
        "                        confidence = 0.75\n",
        "                        current_visual_reason = \"Visual: High brightness, artificial indoor.\"\n",
        "                elif avg_brightness > config_thresholds.get(\"indoor_moderate_thresh\", 95):\n",
        "                    if is_designer_lit_flag and (is_likely_home_environment or any(kw in p365_mapped_scene for kw in [\"home\", \"designer\"])):\n",
        "                        time_of_day = \"indoor_designer_residential\"\n",
        "                        confidence = 0.78\n",
        "                        current_visual_reason = \"Visual: Moderately bright, designer-lit residential.\"\n",
        "                    elif features.get(\"warm_ratio\", 0.0) > 0.35 and yellow_orange_ratio > 0.1:\n",
        "\n",
        "                        if any(kw in p365_mapped_scene for kw in P365_INDOOR_RESTAURANT_KEYWORDS) and \\\n",
        "                        p365_confidence > P365_SCENE_MODERATE_CONF_THRESHOLD :\n",
        "                            time_of_day = \"indoor_restaurant_bar\"\n",
        "                            confidence = 0.80 + p365_confidence * 0.15 # Boost with P365 context\n",
        "                            current_visual_reason = \"Visual: Moderate warm tones. P365 context confirms restaurant/bar.\"\n",
        "                        elif any(kw in p365_mapped_scene for kw in P365_OUTDOOR_SCENE_KEYWORDS) and \\\n",
        "                            p365_confidence > P365_SCENE_MODERATE_CONF_THRESHOLD :\n",
        "                            # This shouldn't happen if `is_indoor` was correctly set to False by P365 in `_analyze_indoor_outdoor`\n",
        "                            # But as a fallback, if is_indoor=True but P365 scene context says strongly outdoor\n",
        "                            time_of_day = \"indoor_moderate_artificial\" # Fallback to general indoor\n",
        "                            confidence = 0.55 # Lower confidence due to strong conflict\n",
        "                            current_visual_reason = \"Visual: Moderate warm. CONFLICT: LA says indoor but P365 scene is outdoor. Defaulting to general indoor artificial.\"\n",
        "                            diagnostics[\"conflict_is_indoor_vs_p365_scene_for_restaurant_bar\"] = True\n",
        "                        else: # P365 context is neutral, or not strongly conflicting restaurant/bar\n",
        "                            time_of_day = \"indoor_restaurant_bar\"\n",
        "                            confidence = 0.70 # Standard confidence without strong P365 confirmation\n",
        "                            current_visual_reason = \"Visual: Moderate warm tones, typical of restaurant/bar. P365 context neutral or weak.\"\n",
        "                    else:\n",
        "                        time_of_day = \"indoor_moderate_artificial\"\n",
        "                        confidence = 0.70\n",
        "                        current_visual_reason = \"Visual: Moderate brightness, standard artificial indoor.\"\n",
        "                else:  # Dimmer indoor\n",
        "                    if features.get(\"warm_ratio\", 0.0) > 0.45 and yellow_orange_ratio > 0.15:\n",
        "                        time_of_day = \"indoor_dim_warm\"\n",
        "                        confidence = 0.75\n",
        "                        current_visual_reason = \"Visual: Dim indoor with very warm tones.\"\n",
        "                    else:\n",
        "                        time_of_day = \"indoor_dim_general\"\n",
        "                        confidence = 0.70\n",
        "                        current_visual_reason = \"Visual: Low brightness indoor.\"\n",
        "\n",
        "                # Refined commercial check (indoor)\n",
        "                if \"residential\" not in time_of_day and \"restaurant\" not in time_of_day and \"bar\" not in time_of_day and \\\n",
        "                not (any(kw in p365_mapped_scene for kw in P365_INDOOR_RESTAURANT_KEYWORDS)): # Avoid reclassifying if P365 already said restaurant/bar\n",
        "                    if avg_brightness > config_thresholds.get(\"commercial_min_brightness_thresh\", 105) and \\\n",
        "                        bright_spots_overall > config_thresholds.get(\"commercial_min_spots_thresh\", 3) and \\\n",
        "                        (light_dist_uniformity > 0.5 or features.get(\"ceiling_likelihood\",0) > 0.4):\n",
        "                        if not (any(kw in p365_mapped_scene for kw in [\"home\", \"residential\"])): # Don't call commercial if P365 suggests home\n",
        "                            time_of_day = \"indoor_commercial\"\n",
        "                            confidence = 0.70 + min(0.2, bright_spots_overall * 0.02)\n",
        "                            current_visual_reason = \"Visual: Multiple/structured light sources in non-residential/restaurant setting.\"\n",
        "\n",
        "                diagnostics[\"visual_analysis_reason\"] = current_visual_reason\n",
        "\n",
        "            else:  # Outdoor (is_indoor is False, influenced by P365 in the previous step)\n",
        "                current_visual_reason = \"\"\n",
        "\n",
        "                if (any(kw in p365_mapped_scene for kw in P365_OUTDOOR_SCENE_KEYWORDS) and any(kw in p365_mapped_scene for kw in [\"street\", \"city\", \"road\", \"urban\", \"downtown\", \"intersection\"])) and \\\n",
        "                p365_confidence > P365_SCENE_MODERATE_CONF_THRESHOLD and \\\n",
        "                features.get(\"color_atmosphere\") == \"warm\" and \\\n",
        "                avg_brightness < config_thresholds.get(\"outdoor_dusk_dawn_thresh_brightness\", 135): # Not bright daytime\n",
        "\n",
        "                    if avg_brightness < config_thresholds.get(\"outdoor_night_thresh_brightness\", 85) and \\\n",
        "                    bright_spots_overall > config_thresholds.get(\"outdoor_night_lights_thresh\", 2):\n",
        "                        time_of_day = \"night_with_lights\"\n",
        "                        confidence = 0.88 + p365_confidence * 0.1 # High confidence\n",
        "                        current_visual_reason = f\"P365 outdoor scene '{p365_mapped_scene}' + visual low-warm light with spots -> night_with_lights.\"\n",
        "                    elif avg_brightness >= config_thresholds.get(\"outdoor_night_thresh_brightness\", 85) : # Dusk/Dawn range\n",
        "                        time_of_day = \"sunset_sunrise\"\n",
        "                        confidence = 0.88 + p365_confidence * 0.1 # High confidence\n",
        "                        current_visual_reason = f\"P365 outdoor scene '{p365_mapped_scene}' + visual moderate-warm light -> sunset/sunrise.\"\n",
        "                    else: # Too dark for sunset, but not enough spots for \"night_with_lights\" based on pure visual\n",
        "                        time_of_day = \"night_dark\" # Fallback if P365 indicates night but visual light spots are few\n",
        "                        confidence = 0.75 + p365_confidence * 0.1\n",
        "                        current_visual_reason = f\"P365 outdoor scene '{p365_mapped_scene}' + visual very low light -> night_dark.\"\n",
        "\n",
        "                # Fallback to your original visual logic if P365 street context isn't strong enough for above\n",
        "                elif avg_brightness < config_thresholds.get(\"outdoor_night_thresh_brightness\", 85):\n",
        "                    if bright_spots_overall > config_thresholds.get(\"outdoor_night_lights_thresh\", 2):\n",
        "                        time_of_day = \"night_with_lights\"\n",
        "                        confidence = 0.82 + min(0.13, features.get(\"dark_pixel_ratio\", 0.0) / 2.5)\n",
        "                        current_visual_reason = \"Visual: Low brightness with light sources (street/car lights).\"\n",
        "                    else:\n",
        "                        time_of_day = \"night_dark\"\n",
        "                        confidence = 0.78 + min(0.17, features.get(\"dark_pixel_ratio\", 0.0) / 1.8)\n",
        "                        current_visual_reason = \"Visual: Very low brightness outdoor, deep night.\"\n",
        "\n",
        "                elif avg_brightness < config_thresholds.get(\"outdoor_dusk_dawn_thresh_brightness\", 135) and \\\n",
        "                    yellow_orange_ratio > config_thresholds.get(\"outdoor_dusk_dawn_color_thresh\", 0.10) and \\\n",
        "                    features.get(\"color_atmosphere\") == \"warm\" and \\\n",
        "                    sky_region_brightness_ratio < 1.5 :\n",
        "                    time_of_day = \"sunset_sunrise\"\n",
        "                    confidence = 0.75 + min(0.20, yellow_orange_ratio / 1.5)\n",
        "                    current_visual_reason = \"Visual: Moderate brightness, warm tones -> sunset/sunrise.\"\n",
        "                    if any(kw in p365_mapped_scene for kw in [\"beach\", \"mountain\", \"lake\", \"ocean\", \"desert\", \"field\", \"natural_landmark\", \"sky\"]) and \\\n",
        "                    p365_confidence > P365_SCENE_MODERATE_CONF_THRESHOLD:\n",
        "                        confidence = min(0.95, confidence + 0.15)\n",
        "                        current_visual_reason += f\" P365 natural scene '{p365_mapped_scene}' supports.\"\n",
        "\n",
        "                elif avg_brightness > config_thresholds.get(\"outdoor_day_bright_thresh\", 140) and \\\n",
        "                    (sky_like_blue_in_sky_region > config_thresholds.get(\"outdoor_day_blue_thresh\", 0.05) or \\\n",
        "                    (sky_region_is_brighter and top_texture_complexity_val < 0.4) ):\n",
        "                    time_of_day = \"day_clear\"\n",
        "                    confidence = 0.80 + min(0.15, sky_like_blue_in_sky_region * 2 + (sky_like_blue_in_sky_region*1.5 if sky_region_is_brighter else 0) ) # Corrected feature name\n",
        "                    current_visual_reason = \"Visual: High brightness with blue/sky tones or bright smooth top.\"\n",
        "\n",
        "                elif avg_brightness > config_thresholds.get(\"outdoor_day_cloudy_thresh\", 120):\n",
        "                    if sky_region_is_brighter and top_texture_complexity_val < 0.45 and features.get(\"avg_saturation\", 100) < 70:\n",
        "                        time_of_day = \"day_cloudy_overcast\"\n",
        "                        confidence = 0.75 + min(0.20, gray_ratio / 1.5 + (features.get(\"brightness_uniformity\",0.0)-0.5)/1.5)\n",
        "                        current_visual_reason = \"Visual: Good brightness, uniform bright top, lower saturation -> overcast.\"\n",
        "                    elif gray_ratio > config_thresholds.get(\"outdoor_day_gray_thresh\", 0.18):\n",
        "                        time_of_day = \"day_cloudy_gray\"\n",
        "                        confidence = 0.72 + min(0.23, gray_ratio / 1.8)\n",
        "                        current_visual_reason = \"Visual: Good brightness with higher gray tones.\"\n",
        "                    else:\n",
        "                        time_of_day = \"day_bright_general\"\n",
        "                        confidence = 0.68\n",
        "                        current_visual_reason = \"Visual: Bright outdoor, specific type less clear.\"\n",
        "                else:  # Fallback for outdoor\n",
        "                    if features.get(\"color_atmosphere\") == \"warm\" and yellow_orange_ratio > 0.08:\n",
        "                        time_of_day = \"sunset_sunrise_low_confidence\"\n",
        "                        confidence = 0.62\n",
        "                    elif sky_like_blue_in_sky_region > 0.02 or features.get(\"sky_region_blue_dominance\",0) > 0.03 :\n",
        "                        time_of_day = \"day_hazy_or_partly_cloudy\"\n",
        "                        confidence = 0.62\n",
        "                    else:\n",
        "                        time_of_day = \"outdoor_unknown_daylight\"\n",
        "                        confidence = 0.58\n",
        "                    current_visual_reason = \"Visual: Outdoor, specific conditions less clear; broader visual cues.\"\n",
        "\n",
        "                # Visual check for stadium/floodlit (only if is_indoor is false)\n",
        "                if avg_brightness > 150 and \\\n",
        "                features.get(\"brightness_uniformity\",0.0) > 0.70 and \\\n",
        "                bright_spots_overall > config_thresholds.get(\"stadium_min_spots_thresh\", 6):\n",
        "                        time_of_day = \"stadium_or_floodlit_area\"\n",
        "                        confidence = 0.78\n",
        "                        current_visual_reason = \"Visual: Very bright, uniform lighting with multiple sources, suggests floodlights (Outdoor).\"\n",
        "\n",
        "                diagnostics[\"visual_analysis_reason\"] = current_visual_reason\n",
        "\n",
        "            # If P365 attributes made a decision, and visual analysis refined it or provided a different one,\n",
        "            # we need to decide which one to trust or how to blend.\n",
        "            # If P365 attributes were strong (determined_by_p365_attr=True and initial_p365_confidence >=0.8), we stick with it.\n",
        "            # Otherwise, the visual analysis (now also P365 scene-context-aware) takes over.\n",
        "            if determined_by_p365_attr and initial_conf_by_attr >= 0.80 and initial_tod_by_attr != \"unknown\":\n",
        "                # time_of_day and confidence are already set from P365 attributes.\n",
        "                diagnostics[\"final_decision_source\"] = \"High-confidence P365 attribute.\"\n",
        "            else:\n",
        "                # If P365 attribute was not decisive, or visual analysis provided a different and\n",
        "                # potentially more nuanced result (especially if P365 scene context was used in visual path),\n",
        "                diagnostics[\"final_decision_source\"] = \"Visual features (potentially P365-context-refined).\"\n",
        "                if initial_tod_by_attr != \"unknown\" and initial_tod_by_attr != time_of_day:\n",
        "                    diagnostics[\"p365_attr_overridden_by_visual\"] = f\"P365 Attr ToD {initial_tod_by_attr} (Conf {initial_conf_by_attr:.2f}) was less certain or overridden by visual logic result {time_of_day} (Conf {confidence:.2f}).\"\n",
        "\n",
        "        # Neon/Sodium Vapor Night (can apply to either indoor if bar-like, or outdoor street)\n",
        "        # This refinement can apply *after* the main decision.\n",
        "        is_current_night_or_dim_warm = \"night\" in time_of_day or time_of_day == \"indoor_dim_warm\"\n",
        "\n",
        "        # Define these thresholds here if not in self.config or use self.config.get()\n",
        "        neon_yellow_orange_thresh = self.config.get(\"neon_yellow_orange_thresh\", 0.12)\n",
        "        neon_bright_spots_thresh = self.config.get(\"neon_bright_spots_thresh\", 4)\n",
        "        neon_avg_saturation_thresh = self.config.get(\"neon_avg_saturation_thresh\", 60)\n",
        "\n",
        "        if is_current_night_or_dim_warm and \\\n",
        "        yellow_orange_ratio > neon_yellow_orange_thresh and \\\n",
        "        bright_spots_overall > neon_bright_spots_thresh and \\\n",
        "        features.get(\"color_atmosphere\") == \"warm\" and \\\n",
        "        features.get(\"avg_saturation\",0) > neon_avg_saturation_thresh:\n",
        "\n",
        "            old_time_of_day_for_neon_check = time_of_day\n",
        "            old_confidence_for_neon_check = confidence\n",
        "\n",
        "            # Check P365 context for \"neon\" related scenes\n",
        "            is_p365_neon_context = any(kw in p365_mapped_scene for kw in [\"neon\", \"nightclub\", \"bar_neon\"]) or \\\n",
        "                                \"neon\" in p365_attributes\n",
        "\n",
        "            if is_indoor:\n",
        "                if is_p365_neon_context or any(kw in p365_mapped_scene for kw in P365_INDOOR_RESTAURANT_KEYWORDS): # e.g. bar with neon\n",
        "                    time_of_day = \"indoor_neon_lit\"\n",
        "                    confidence = max(confidence, 0.80) # Boost confidence if P365 supports\n",
        "                else: # Generic indoor dim warm with neon characteristics\n",
        "                    time_of_day = \"indoor_dim_warm_neon_accent\" # A more nuanced category\n",
        "                    confidence = max(confidence, 0.77)\n",
        "            else: # outdoor street neon\n",
        "                if is_p365_neon_context or any(kw in p365_mapped_scene for kw in [\"street_night\", \"city_night\", \"downtown_night\"]):\n",
        "                    time_of_day = \"neon_or_sodium_vapor_night\"\n",
        "                    confidence = max(confidence, 0.82) # Boost confidence\n",
        "                else: # Generic outdoor night with neon characteristics\n",
        "                    time_of_day = \"night_with_neon_lights\" # A more nuanced category\n",
        "                    confidence = max(confidence, 0.79)\n",
        "\n",
        "            diagnostics[\"special_lighting_detected\"] = (\n",
        "                f\"Refined from {old_time_of_day_for_neon_check} (Conf:{old_confidence_for_neon_check:.2f}) \"\n",
        "                f\"to {time_of_day} (Conf:{confidence:.2f}) due to neon/sodium vapor light characteristics. \"\n",
        "                f\"P365 Context: {p365_mapped_scene if is_p365_neon_context else 'N/A'}.\"\n",
        "            )\n",
        "\n",
        "        # Final confidence clamp\n",
        "        confidence = min(0.95, max(0.50, confidence))\n",
        "        diagnostics[\"final_lighting_time_of_day\"] = time_of_day\n",
        "        diagnostics[\"final_lighting_confidence\"] = round(confidence,3)\n",
        "\n",
        "        return {\n",
        "            \"time_of_day\": time_of_day,\n",
        "            \"confidence\": confidence,\n",
        "            \"diagnostics\": diagnostics\n",
        "        }\n",
        "\n",
        "    def _get_default_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns default configuration parameters, with adjustments for better balance.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            # Thresholds for feature calculation (from _compute_basic_features)\n",
        "            \"dark_pixel_threshold\": 50,\n",
        "            \"bright_pixel_threshold\": 220,\n",
        "            \"sky_blue_hue_min\": 95,\n",
        "            \"sky_blue_hue_max\": 135,\n",
        "            \"sky_blue_sat_min\": 40,\n",
        "            \"sky_blue_val_min\": 90,\n",
        "            \"gray_sat_max\": 70,\n",
        "            \"gray_val_min\": 60,\n",
        "            \"gray_val_max\": 220,\n",
        "            \"light_source_abs_thresh\": 220, # For old bright_spot_count compatibility if used\n",
        "\n",
        "            \"warm_hue_ranges\": [(0, 50), (330, 360)],\n",
        "            \"cool_hue_ranges\": [(90, 270)],\n",
        "\n",
        "            # Thresholds for _analyze_indoor_outdoor logic\n",
        "            \"sky_blue_dominance_thresh\": 0.18,\n",
        "            \"sky_brightness_ratio_thresh\": 1.25,\n",
        "            \"openness_top_thresh\": 0.68,\n",
        "            \"sky_texture_complexity_thresh\": 0.35,\n",
        "            \"ceiling_likelihood_thresh\": 0.4,\n",
        "            \"boundary_clarity_thresh\": 0.38,\n",
        "            \"brightness_uniformity_thresh_indoor\": 0.6,\n",
        "            \"brightness_uniformity_thresh_outdoor\": 0.40,\n",
        "            \"many_bright_spots_thresh\": 6,\n",
        "            \"dim_scene_for_spots_thresh\": 115,\n",
        "            \"home_pattern_thresh_strong\": 2.0,\n",
        "            \"home_pattern_thresh_moderate\": 1.0,\n",
        "            \"warm_indoor_max_brightness_thresh\": 135,\n",
        "            \"aerial_top_dark_ratio_thresh\": 0.9,\n",
        "            \"aerial_top_complex_thresh\": 0.60,\n",
        "            \"aerial_min_avg_brightness_thresh\": 65,\n",
        "\n",
        "            # Factors to reduce indoor cues if strong sky signal\n",
        "            \"sky_override_factor_ceiling\": 0.1,\n",
        "            \"sky_override_factor_boundary\": 0.2,\n",
        "            \"sky_override_factor_uniformity\": 0.15,\n",
        "            \"sky_override_factor_lights\": 0.05,\n",
        "\n",
        "            # Factor to reduce enclosure score if aerial street pattern detected\n",
        "            \"aerial_enclosure_reduction_factor\": 0.75,\n",
        "\n",
        "            # Weights for _analyze_indoor_outdoor scoring (positive = indoor, negative = outdoor)\n",
        "            \"indoor_outdoor_weights\": {\n",
        "                # Sky/Openness (Negative values push towards outdoor)\n",
        "                \"sky_blue_dominance_w\": 3.5,\n",
        "                \"sky_brightness_ratio_w\": 3,\n",
        "                \"openness_top_w\": 2.8,\n",
        "                \"sky_texture_w\": 2,\n",
        "\n",
        "                # Ceiling/Enclosure (Positive values push towards indoor)\n",
        "                \"ceiling_likelihood_w\": 1.5,\n",
        "                \"boundary_clarity_w\": 1.2,\n",
        "\n",
        "                # Brightness\n",
        "                \"brightness_uniformity_w\": 0.6,\n",
        "                \"brightness_non_uniformity_outdoor_w\": 1.0,\n",
        "                \"brightness_non_uniformity_indoor_penalty_w\": 0.1,\n",
        "\n",
        "                # Light Sources\n",
        "                \"circular_lights_w\": 1.2,\n",
        "                \"indoor_light_score_w\": 0.8,\n",
        "                \"many_bright_spots_indoor_w\": 0.3,\n",
        "\n",
        "                # Color Atmosphere\n",
        "                \"warm_atmosphere_indoor_w\": 0.15,\n",
        "\n",
        "                # Home Environment Pattern (structural cues for indoor)\n",
        "                \"home_env_strong_w\": 1.5,\n",
        "                \"home_env_moderate_w\": 0.7,\n",
        "\n",
        "                # Aerial street pattern (negative pushes to outdoor)\n",
        "                \"aerial_street_w\": 2.5,\n",
        "\n",
        "                \"places365_outdoor_scene_w\": 4.0, # Places365 明確判斷為室外場景時的強烈負（室外）權重\n",
        "                \"places365_indoor_scene_w\": 3.0,  # Places365 明確判斷為室內場景時的正面（室內）權重\n",
        "                \"places365_attribute_w\": 1.5,\n",
        "\n",
        "                \"blue_ratio\": 0.0, \"gradient_ratio\": 0.0, \"bright_spots\": 0.0,\n",
        "                \"color_tone\": 0.0, \"sky_brightness\": 0.0, \"ceiling_features\": 0.0,\n",
        "                \"light_features\": 0.0, \"boundary_features\": 0.0,\n",
        "                \"street_features\": 0.0, \"building_features\": 0.0,\n",
        "            },\n",
        "            \"indoor_score_sigmoid_scale\": 0.3,\n",
        "            \"indoor_decision_threshold\": 0.5,\n",
        "\n",
        "            # Places365 相關閾值\n",
        "            \"places365_high_confidence_thresh\": 0.75, # Places365 判斷結果被視為高信心度的閾值\n",
        "            \"places365_moderate_confidence_thresh\": 0.5, # Places365 中等信心度閾值\n",
        "            \"places365_attribute_confidence_thresh\": 0.6, # Places365 屬性判斷的置信度閾值\n",
        "\n",
        "            \"p365_outdoor_reduces_enclosure_factor\": 0.3, # 如果P365認為是室外，圍合特徵的影響降低到30%\n",
        "            \"p365_indoor_boosts_ceiling_factor\": 1.5,\n",
        "\n",
        "            # Thresholds for _determine_lighting_conditions (outdoor)\n",
        "            \"outdoor_night_thresh_brightness\": 80,\n",
        "            \"outdoor_night_lights_thresh\": 2,\n",
        "            \"outdoor_dusk_dawn_thresh_brightness\": 130,\n",
        "            \"outdoor_dusk_dawn_color_thresh\": 0.10,\n",
        "            \"outdoor_day_bright_thresh\": 140,\n",
        "            \"outdoor_day_blue_thresh\": 0.05,\n",
        "            \"outdoor_day_cloudy_thresh\": 120,\n",
        "            \"outdoor_day_gray_thresh\": 0.18,\n",
        "\n",
        "            \"include_diagnostics\": True,\n",
        "\n",
        "            \"ceiling_likelihood_thresh_indoor\": 0.38,\n",
        "            \"sky_blue_dominance_strong_thresh\": 0.35,\n",
        "            \"sky_brightness_ratio_strong_thresh\": 1.35,\n",
        "            \"sky_texture_complexity_clear_thresh\": 0.25,\n",
        "            \"openness_top_strong_thresh\": 0.80,\n",
        "            \"sky_texture_complexity_cloudy_thresh\": 0.20,\n",
        "            \"sky_brightness_ratio_cloudy_thresh\": 0.95,\n",
        "\n",
        "            \"ceiling_texture_thresh\": 0.4,\n",
        "            \"ceiling_brightness_min\": 60,\n",
        "            \"ceiling_brightness_max\": 230,\n",
        "            \"ceiling_horizontal_line_factor\": 1.15,\n",
        "            \"ceiling_center_bright_factor\": 1.25,\n",
        "            \"ceiling_max_sky_blue_thresh\": 0.08,\n",
        "            \"ceiling_max_sky_brightness_ratio\": 1.15,\n",
        "            \"ceiling_sky_override_factor\": 0.1,\n",
        "\n",
        "            \"stadium_min_spots_thresh\": 6\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClX1q_9rW_TY"
      },
      "outputs": [],
      "source": [
        "# %%writefile scene_description.py\n",
        "import os\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from scene_detail_templates import SCENE_DETAIL_TEMPLATES\n",
        "# from object_template_fillers import OBJECT_TEMPLATE_FILLERS\n",
        "# from activity_templates import ACTIVITY_TEMPLATES\n",
        "# from safety_templates import SAFETY_TEMPLATES\n",
        "# from confifence_templates import CONFIDENCE_TEMPLATES\n",
        "\n",
        "class SceneDescriptor:\n",
        "    \"\"\"\n",
        "    Generates natural language descriptions of scenes.\n",
        "    Handles scene descriptions, activity inference, and safety concerns identification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scene_types=None, object_categories=None):\n",
        "        \"\"\"\n",
        "        Initialize the scene descriptor\n",
        "\n",
        "        Args:\n",
        "            scene_types: Dictionary of scene type definitions\n",
        "        \"\"\"\n",
        "        self.scene_types = scene_types or {}\n",
        "        self.SCENE_TYPES = scene_types or {}\n",
        "\n",
        "        if object_categories:\n",
        "            self.OBJECT_CATEGORIES = object_categories\n",
        "        else:\n",
        "            # 從 JSON 加載或使用默認值\n",
        "            self.OBJECT_CATEGORIES = self._load_json_data(\"object_categories\") or {\n",
        "                \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "                \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "                \"kitchen_items\": [39, 40, 41, 42, 43, 44, 45],\n",
        "                \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "                \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "                \"personal_items\": [24, 25, 26, 27, 28, 73, 78, 79]\n",
        "            }\n",
        "\n",
        "        # 加載所有模板數據\n",
        "        self._load_templates()\n",
        "\n",
        "    def _load_templates(self):\n",
        "        \"\"\"Load all template data from script or fallback to imported defaults\"\"\"\n",
        "        self.confidence_templates = CONFIDENCE_TEMPLATES\n",
        "        self.scene_detail_templates = SCENE_DETAIL_TEMPLATES\n",
        "        self.object_template_fillers = OBJECT_TEMPLATE_FILLERS\n",
        "        self.safety_templates = SAFETY_TEMPLATES\n",
        "        self.activity_templates = ACTIVITY_TEMPLATES\n",
        "\n",
        "\n",
        "    def _initialize_fallback_templates(self):\n",
        "        \"\"\"Initialize fallback templates when no external data is available\"\"\"\n",
        "        # 只在無法從文件或導入加載時使用\n",
        "        self.confidence_templates = {\n",
        "            \"high\": \"{description} {details}\",\n",
        "            \"medium\": \"This appears to be {description} {details}\",\n",
        "            \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "        }\n",
        "\n",
        "        # 只提供最基本的模板作為後備\n",
        "        self.scene_detail_templates = {\n",
        "            \"default\": [\"A space with various objects.\"]\n",
        "        }\n",
        "\n",
        "        self.object_template_fillers = {\n",
        "            \"default\": [\"various items\"]\n",
        "        }\n",
        "\n",
        "        self.safety_templates = {\n",
        "            \"general\": \"Pay attention to {safety_element}.\"\n",
        "        }\n",
        "\n",
        "        self.activity_templates = {\n",
        "            \"default\": [\"General activity\"]\n",
        "        }\n",
        "\n",
        "    def _get_alternative_scenes(self, scene_scores: Dict[str, float],\n",
        "                            threshold: float, top_k: int = 2) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get alternative scene interpretations with their scores.\n",
        "\n",
        "        Args:\n",
        "            scene_scores: Dictionary of scene type scores\n",
        "            threshold: Minimum confidence threshold\n",
        "            top_k: Number of alternatives to return\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries with alternative scenes\n",
        "        \"\"\"\n",
        "        # Sort scenes by score in descending order\n",
        "        sorted_scenes = sorted(scene_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Skip the first one (best match) and take the next top_k\n",
        "        alternatives = []\n",
        "        for scene_type, score in sorted_scenes[1:1+top_k]:\n",
        "            if score >= threshold:\n",
        "                alternatives.append({\n",
        "                    \"type\": scene_type,\n",
        "                    \"name\": self.SCENE_TYPES.get(scene_type, {}).get(\"name\", \"Unknown\"),\n",
        "                    \"confidence\": score\n",
        "                })\n",
        "\n",
        "        return alternatives\n",
        "\n",
        "\n",
        "    def _infer_possible_activities(self, scene_type: str, detected_objects: List[Dict], enable_landmark: bool = True, scene_scores: Optional[Dict] = None) -> List[str]:\n",
        "        \"\"\"\n",
        "        Infer possible activities based on scene type and detected objects.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type\n",
        "            detected_objects: List of detected objects\n",
        "            enable_landmark: Whether landmark detection is enabled\n",
        "            scene_scores: Optional dictionary of scene type scores\n",
        "\n",
        "        Returns:\n",
        "            List of possible activities\n",
        "        \"\"\"\n",
        "        activities = []\n",
        "\n",
        "        # Dynamically replace landmark scene types when landmark detection is disabled\n",
        "        if not enable_landmark and scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "            alternative_scene_type = self._get_alternative_scene_type(scene_type, detected_objects, scene_scores)\n",
        "            print(f\"Replacing landmark scene type '{scene_type}' with '{alternative_scene_type}' for activity inference\")\n",
        "            scene_type = alternative_scene_type\n",
        "\n",
        "        # Process aerial view scenes\n",
        "        if scene_type.startswith(\"aerial_view_\"):\n",
        "            if scene_type == \"aerial_view_intersection\":\n",
        "                # Use predefined intersection activities\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_intersection\", []))\n",
        "\n",
        "                # Add pedestrian and vehicle specific activities\n",
        "                pedestrians = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "                vehicles = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 5, 7]]  # Car, bus, truck\n",
        "\n",
        "                if pedestrians and vehicles:\n",
        "                    activities.append(\"Waiting for an opportunity to cross the street\")\n",
        "                    activities.append(\"Obeying traffic signals\")\n",
        "\n",
        "            elif scene_type == \"aerial_view_commercial_area\":\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_commercial_area\", []))\n",
        "\n",
        "            elif scene_type == \"aerial_view_plaza\":\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_plaza\", []))\n",
        "\n",
        "            else:\n",
        "                # Handle other undefined aerial view scenes\n",
        "                aerial_activities = [\n",
        "                    \"Street crossing\",\n",
        "                    \"Waiting for signals\",\n",
        "                    \"Following traffic rules\",\n",
        "                    \"Pedestrian movement\"\n",
        "                ]\n",
        "                activities.extend(aerial_activities)\n",
        "\n",
        "        # Add scene-specific activities from templates\n",
        "        if scene_type in self.activity_templates:\n",
        "            activities.extend(self.activity_templates[scene_type])\n",
        "        elif \"default\" in self.activity_templates:\n",
        "            activities.extend(self.activity_templates[\"default\"])\n",
        "\n",
        "        # Filter out landmark-related activities when landmark detection is disabled\n",
        "        if not enable_landmark:\n",
        "            filtered_activities = []\n",
        "            landmark_keywords = [\"sightseeing\", \"landmark\", \"tourist\", \"monument\", \"historical\",\n",
        "                                \"guided tour\", \"photography\", \"cultural tourism\", \"heritage\"]\n",
        "\n",
        "            for activity in activities:\n",
        "                if not any(keyword in activity.lower() for keyword in landmark_keywords):\n",
        "                    filtered_activities.append(activity)\n",
        "\n",
        "            activities = filtered_activities\n",
        "\n",
        "        # If we filtered out all activities, add some generic ones based on scene type\n",
        "        if not activities:\n",
        "            generic_activities = {\n",
        "                \"city_street\": [\"Walking\", \"Commuting\", \"Shopping\"],\n",
        "                \"intersection\": [\"Crossing the street\", \"Waiting for traffic signals\"],\n",
        "                \"commercial_district\": [\"Shopping\", \"Walking\", \"Dining\"],\n",
        "                \"pedestrian_area\": [\"Walking\", \"Socializing\", \"Shopping\"],\n",
        "                \"park_area\": [\"Relaxing\", \"Walking\", \"Exercise\"],\n",
        "                \"outdoor_natural_area\": [\"Walking\", \"Nature observation\", \"Relaxation\"],\n",
        "                \"urban_architecture\": [\"Walking\", \"Urban exploration\", \"Photography\"]\n",
        "            }\n",
        "\n",
        "            activities.extend(generic_activities.get(scene_type, [\"Walking\", \"Observing surroundings\"]))\n",
        "\n",
        "        # Add activities based on detected objects\n",
        "        detected_class_ids = [obj[\"class_id\"] for obj in detected_objects]\n",
        "\n",
        "        # Add activities based on specific object combinations\n",
        "        if 62 in detected_class_ids and 57 in detected_class_ids:  # TV and sofa\n",
        "            activities.append(\"Watching shows or movies\")\n",
        "\n",
        "        if 63 in detected_class_ids:  # laptop\n",
        "            activities.append(\"Using a computer/laptop\")\n",
        "\n",
        "        if 67 in detected_class_ids:  # cell phone\n",
        "            activities.append(\"Using a mobile phone\")\n",
        "\n",
        "        if 73 in detected_class_ids:  # book\n",
        "            activities.append(\"Reading\")\n",
        "\n",
        "        if any(food_id in detected_class_ids for food_id in [46, 47, 48, 49, 50, 51, 52, 53, 54, 55]):\n",
        "            activities.append(\"Eating or preparing food\")\n",
        "\n",
        "        # Person-specific activities\n",
        "        if 0 in detected_class_ids:  # Person\n",
        "            if any(vehicle in detected_class_ids for vehicle in [1, 2, 3, 5, 7]):  # Vehicles\n",
        "                activities.append(\"Commuting or traveling\")\n",
        "\n",
        "            if 16 in detected_class_ids:  # Dog\n",
        "                activities.append(\"Walking a dog\")\n",
        "\n",
        "            if 24 in detected_class_ids or 26 in detected_class_ids:  # Backpack or handbag\n",
        "                activities.append(\"Carrying personal items\")\n",
        "\n",
        "            # Add more person count-dependent activities\n",
        "            person_count = detected_class_ids.count(0)\n",
        "            if person_count > 3:\n",
        "                activities.append(\"Group gathering\")\n",
        "            elif person_count > 1:\n",
        "                activities.append(\"Social interaction\")\n",
        "\n",
        "        # Add additional activities based on significant objects\n",
        "        if 43 in detected_class_ids:  # cup\n",
        "            activities.append(\"Drinking beverages\")\n",
        "\n",
        "        if 32 in detected_class_ids:  # sports ball\n",
        "            activities.append(\"Playing sports\")\n",
        "\n",
        "        if 25 in detected_class_ids:  # umbrella\n",
        "            activities.append(\"Sheltering from weather\")\n",
        "\n",
        "        # Add location-specific activities based on environment objects\n",
        "        if any(furniture in detected_class_ids for furniture in [56, 57, 58, 59, 60]):  # furniture items\n",
        "            activities.append(\"Using indoor facilities\")\n",
        "\n",
        "        if any(outdoor_item in detected_class_ids for outdoor_item in [13, 14, 15]):  # bench, outdoor items\n",
        "            activities.append(\"Enjoying outdoor spaces\")\n",
        "\n",
        "        # Remove duplicates and ensure reasonable number of activities\n",
        "        unique_activities = list(set(activities))\n",
        "\n",
        "        # Limit to reasonable number (maximum 8 activities)\n",
        "        if len(unique_activities) > 8:\n",
        "            # Prioritize more specific activities over general ones\n",
        "            general_activities = [\"Walking\", \"Observing surroundings\", \"Commuting\", \"Using indoor facilities\"]\n",
        "            specific_activities = [a for a in unique_activities if a not in general_activities]\n",
        "\n",
        "            # Take all specific activities first, then fill with general ones if needed\n",
        "            if len(specific_activities) <= 8:\n",
        "                result = specific_activities + general_activities[:8-len(specific_activities)]\n",
        "            else:\n",
        "                result = specific_activities[:8]\n",
        "        else:\n",
        "            result = unique_activities\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _identify_safety_concerns(self, detected_objects: List[Dict], scene_type: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Identify potential safety concerns based on objects and scene type.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Identified scene type\n",
        "\n",
        "        Returns:\n",
        "            List of potential safety concerns\n",
        "        \"\"\"\n",
        "        concerns = []\n",
        "        detected_class_ids = [obj[\"class_id\"] for obj in detected_objects]\n",
        "\n",
        "        # General safety concerns\n",
        "        if 42 in detected_class_ids or 43 in detected_class_ids:  # Fork or knife\n",
        "            concerns.append(\"Sharp utensils present\")\n",
        "\n",
        "        if 76 in detected_class_ids:  # Scissors\n",
        "            concerns.append(\"Cutting tools present\")\n",
        "\n",
        "        # Traffic-related concerns\n",
        "        if scene_type in [\"city_street\", \"parking_lot\"]:\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                if any(vehicle in detected_class_ids for vehicle in [2, 3, 5, 7, 8]):  # Vehicles\n",
        "                    concerns.append(\"Pedestrians near vehicles\")\n",
        "\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Monitor traffic signals\")\n",
        "\n",
        "        # Identify crowded scenes\n",
        "        person_count = detected_class_ids.count(0)\n",
        "        if person_count > 5:\n",
        "            concerns.append(f\"Crowded area with multiple people ({person_count})\")\n",
        "\n",
        "        # Scene-specific concerns\n",
        "        if scene_type == \"kitchen\":\n",
        "            if 68 in detected_class_ids or 69 in detected_class_ids:  # Microwave or oven\n",
        "                concerns.append(\"Hot cooking equipment\")\n",
        "\n",
        "        # Potentially unstable objects\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [39, 40, 41, 45]:  # Bottle, wine glass, cup, bowl\n",
        "                if obj[\"region\"] in [\"top_left\", \"top_center\", \"top_right\"] and obj[\"normalized_area\"] > 0.05:\n",
        "                    concerns.append(f\"Elevated {obj['class_name']} might be unstable\")\n",
        "\n",
        "        # Upscale dining safety concerns\n",
        "        if scene_type == \"upscale_dining\":\n",
        "            # Check for fragile items\n",
        "            if 40 in detected_class_ids:  # Wine glass\n",
        "                concerns.append(\"Fragile glassware present\")\n",
        "\n",
        "            # Check for lit candles (can't directly detect but can infer from context)\n",
        "            # Look for small bright spots that might be candles\n",
        "            if any(obj[\"class_id\"] == 41 for obj in detected_objects):  # Cup (which might include candle holders)\n",
        "                # We can't reliably detect candles, but if the scene appears to be formal dining,\n",
        "                # we can suggest this as a possibility\n",
        "                concerns.append(\"Possible lit candles or decorative items requiring care\")\n",
        "\n",
        "            # Check for overcrowded table\n",
        "            table_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 60]  # Dining table\n",
        "            if table_objs:\n",
        "                table_region = table_objs[0][\"region\"]\n",
        "                items_on_table = 0\n",
        "\n",
        "                for obj in detected_objects:\n",
        "                    if obj[\"class_id\"] in [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]:\n",
        "                        if obj[\"region\"] == table_region:\n",
        "                            items_on_table += 1\n",
        "\n",
        "                if items_on_table > 8:\n",
        "                    concerns.append(\"Dining table has multiple items which should be handled with care\")\n",
        "\n",
        "        # Asian commercial street safety concerns\n",
        "        elif scene_type == \"asian_commercial_street\":\n",
        "            # Check for crowded walkways\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 3:\n",
        "                    # Calculate person density (simplified)\n",
        "                    person_positions = []\n",
        "                    for obj in detected_objects:\n",
        "                        if obj[\"class_id\"] == 0:\n",
        "                            person_positions.append(obj[\"normalized_center\"])\n",
        "\n",
        "                    if len(person_positions) >= 2:\n",
        "                        # Calculate average distance between people\n",
        "                        total_distance = 0\n",
        "                        count = 0\n",
        "                        for i in range(len(person_positions)):\n",
        "                            for j in range(i+1, len(person_positions)):\n",
        "                                p1 = person_positions[i]\n",
        "                                p2 = person_positions[j]\n",
        "                                distance = ((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)**0.5\n",
        "                                total_distance += distance\n",
        "                                count += 1\n",
        "\n",
        "                        if count > 0:\n",
        "                            avg_distance = total_distance / count\n",
        "                            if avg_distance < 0.1:  # Close proximity\n",
        "                                concerns.append(\"Crowded walkway with limited personal space\")\n",
        "\n",
        "            # Check for motorcycles/bicycles near pedestrians\n",
        "            if (1 in detected_class_ids or 3 in detected_class_ids) and 0 in detected_class_ids:  # Bicycle/motorcycle and person\n",
        "                concerns.append(\"Two-wheeled vehicles in pedestrian areas\")\n",
        "\n",
        "            # Check for potential trip hazards\n",
        "            if scene_type == \"asian_commercial_street\" and \"bottom\" in \" \".join([obj[\"region\"] for obj in detected_objects if obj[\"class_id\"] == 0]):\n",
        "                # If people are in bottom regions, they might be walking on uneven surfaces\n",
        "                concerns.append(\"Potential uneven walking surfaces in commercial area\")\n",
        "\n",
        "        # Financial district safety concerns\n",
        "        elif scene_type == \"financial_district\":\n",
        "            # Check for heavy traffic conditions\n",
        "            vehicle_count = sum(1 for obj_id in detected_class_ids if obj_id in [2, 5, 7])  # Car, bus, truck\n",
        "            if vehicle_count > 5:\n",
        "                concerns.append(\"Heavy vehicle traffic in urban area\")\n",
        "\n",
        "            # Check for pedestrians crossing busy streets\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                vehicle_nearby = any(vehicle in detected_class_ids for vehicle in [2, 3, 5, 7])\n",
        "\n",
        "                if person_count > 0 and vehicle_nearby:\n",
        "                    concerns.append(\"Pedestrians navigating busy urban traffic\")\n",
        "\n",
        "            # Check for traffic signals\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Observe traffic signals when navigating this area\")\n",
        "            else:\n",
        "                # If no traffic lights detected but it's a busy area, it's worth noting\n",
        "                if vehicle_count > 3:\n",
        "                    concerns.append(\"Busy traffic area potentially without visible traffic signals in view\")\n",
        "\n",
        "            # Time of day considerations\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 5, 7]]\n",
        "            if vehicle_objs and any(\"lighting_conditions\" in obj for obj in detected_objects):\n",
        "                # If vehicles are present and it might be evening/night\n",
        "                concerns.append(\"Reduced visibility conditions during evening commute\")\n",
        "\n",
        "        # Urban intersection safety concerns\n",
        "        elif scene_type == \"urban_intersection\":\n",
        "            # Check for pedestrians in crosswalks\n",
        "            pedestrian_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 3, 5, 7]]\n",
        "\n",
        "            if pedestrian_objs:\n",
        "                # Calculate distribution of pedestrians to see if they're crossing\n",
        "                pedestrian_positions = [obj[\"normalized_center\"] for obj in pedestrian_objs]\n",
        "\n",
        "                # Simplified check for pedestrians in crossing pattern\n",
        "                if len(pedestrian_positions) >= 3:\n",
        "                    # Check if pedestrians are distributed across different regions\n",
        "                    pedestrian_regions = set(obj[\"region\"] for obj in pedestrian_objs)\n",
        "                    if len(pedestrian_regions) >= 2:\n",
        "                        concerns.append(\"Multiple pedestrians crossing the intersection\")\n",
        "\n",
        "            # Check for traffic signal observation\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Observe traffic signals when crossing\")\n",
        "\n",
        "            # Check for busy intersection\n",
        "            if len(vehicle_objs) > 3:\n",
        "                concerns.append(\"Busy intersection with multiple vehicles\")\n",
        "\n",
        "            # Check for pedestrians potentially jay-walking\n",
        "            if pedestrian_objs and not 9 in detected_class_ids:  # People but no traffic lights\n",
        "                concerns.append(\"Pedestrians should use designated crosswalks\")\n",
        "\n",
        "            # Visibility concerns based on lighting\n",
        "            # This would be better with actual lighting data\n",
        "            pedestrian_count = len(pedestrian_objs)\n",
        "            if pedestrian_count > 5:\n",
        "                concerns.append(\"High pedestrian density at crossing points\")\n",
        "\n",
        "        # Transit hub safety concerns\n",
        "        elif scene_type == \"transit_hub\":\n",
        "            # These would be for transit areas like train stations or bus terminals\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 8:\n",
        "                    concerns.append(\"Crowded transit area requiring careful navigation\")\n",
        "\n",
        "            # Check for luggage/bags that could be trip hazards\n",
        "            if 24 in detected_class_ids or 28 in detected_class_ids:  # Backpack or suitcase\n",
        "                concerns.append(\"Luggage and personal items may create obstacles\")\n",
        "\n",
        "            # Public transportation vehicles\n",
        "            if any(vehicle in detected_class_ids for vehicle in [5, 6, 7]):  # Bus, train, truck\n",
        "                concerns.append(\"Stay clear of arriving and departing transit vehicles\")\n",
        "\n",
        "        # Shopping district safety concerns\n",
        "        elif scene_type == \"shopping_district\":\n",
        "            # Check for crowded shopping areas\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 5:\n",
        "                    concerns.append(\"Crowded shopping area with multiple people\")\n",
        "\n",
        "            # Check for shopping bags and personal items\n",
        "            if 24 in detected_class_ids or 26 in detected_class_ids:  # Backpack or handbag\n",
        "                concerns.append(\"Mind personal belongings in busy retail environment\")\n",
        "\n",
        "            # Check for store entrances/exits which might have automatic doors\n",
        "            # We can't directly detect this, but can infer from context\n",
        "            if scene_type == \"shopping_district\" and 0 in detected_class_ids:\n",
        "                concerns.append(\"Be aware of store entrances and exits with potential automatic doors\")\n",
        "\n",
        "        return concerns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOZv19OLEu6c"
      },
      "outputs": [],
      "source": [
        "# %%writefile clip_prompts.py\n",
        "\n",
        "# 場景類型提示\n",
        "SCENE_TYPE_PROMPTS = {\n",
        "    # 基本室內場景\n",
        "    \"living_room\": \"A photo of a living room with furniture and entertainment systems.\",\n",
        "    \"bedroom\": \"A photo of a bedroom with a bed and personal items.\",\n",
        "    \"dining_area\": \"A photo of a dining area with a table and chairs for meals.\",\n",
        "    \"kitchen\": \"A photo of a kitchen with cooking appliances and food preparation areas.\",\n",
        "    \"office_workspace\": \"A photo of an office workspace with desk, computer and work equipment.\",\n",
        "    \"meeting_room\": \"A photo of a meeting room with a conference table and multiple chairs.\",\n",
        "\n",
        "    # 基本室外/城市場景\n",
        "    \"city_street\": \"A photo of a city street with traffic, pedestrians and urban buildings.\",\n",
        "    \"parking_lot\": \"A photo of a parking lot with multiple parked vehicles.\",\n",
        "    \"park_area\": \"A photo of a park or recreational area with greenery and outdoor facilities.\",\n",
        "    \"retail_store\": \"A photo of a retail store with merchandise displays and shopping areas.\",\n",
        "    \"supermarket\": \"A photo of a supermarket with food items, aisles and shopping carts.\",\n",
        "\n",
        "    # 特殊室內場景\n",
        "    \"upscale_dining\": \"A photo of an upscale dining area with elegant furniture and refined decor.\",\n",
        "    \"conference_room\": \"A photo of a professional conference room with presentation equipment and seating.\",\n",
        "    \"classroom\": \"A photo of a classroom with desks, chairs and educational equipment.\",\n",
        "    \"library\": \"A photo of a library with bookshelves, reading areas and study spaces.\",\n",
        "\n",
        "    # 亞洲特色場景\n",
        "    \"asian_commercial_street\": \"A photo of an Asian commercial street with dense signage, shops and pedestrians.\",\n",
        "    \"asian_night_market\": \"A photo of an Asian night market with food stalls, crowds and colorful lights.\",\n",
        "    \"asian_temple_area\": \"A photo of an Asian temple with traditional architecture and cultural elements.\",\n",
        "\n",
        "    # 交通相關場景\n",
        "    \"financial_district\": \"A photo of a financial district with tall office buildings and business activity.\",\n",
        "    \"urban_intersection\": \"A photo of an urban intersection with crosswalks, traffic lights and pedestrians crossing.\",\n",
        "    \"transit_hub\": \"A photo of a transportation hub with multiple modes of public transit and passengers.\",\n",
        "    \"bus_stop\": \"A photo of a bus stop with people waiting and buses arriving or departing.\",\n",
        "    \"bus_station\": \"A photo of a bus terminal with multiple buses and traveler facilities.\",\n",
        "    \"train_station\": \"A photo of a train station with platforms, trains and passenger activity.\",\n",
        "    \"airport\": \"A photo of an airport with planes, terminals and traveler activity.\",\n",
        "\n",
        "    # 商業場景\n",
        "    \"shopping_district\": \"A photo of a shopping district with multiple retail stores and consumer activity.\",\n",
        "    \"cafe\": \"A photo of a cafe with coffee service, seating and casual dining.\",\n",
        "    \"restaurant\": \"A photo of a restaurant with dining tables, food service and eating areas.\",\n",
        "\n",
        "    # 空中視角場景\n",
        "    \"aerial_view_intersection\": \"An aerial view of an intersection showing crosswalks and traffic patterns from above.\",\n",
        "    \"aerial_view_commercial_area\": \"An aerial view of a commercial area showing shopping districts from above.\",\n",
        "    \"aerial_view_plaza\": \"An aerial view of a public plaza or square showing patterns of people movement from above.\",\n",
        "\n",
        "    # 娛樂場景\n",
        "    \"zoo\": \"A photo of a zoo with animal enclosures, exhibits and visitors.\",\n",
        "    \"playground\": \"A photo of a playground with recreational equipment and children playing.\",\n",
        "    \"sports_field\": \"A photo of a sports field with playing surfaces and athletic equipment.\",\n",
        "    \"sports_stadium\": \"A photo of a sports stadium with spectator seating and athletic facilities.\",\n",
        "\n",
        "    # 水相關場景\n",
        "    \"harbor\": \"A photo of a harbor with boats, docks and waterfront activity.\",\n",
        "    \"beach_water_recreation\": \"A photo of a beach area with water activities, sand and recreational equipment like surfboards.\",\n",
        "\n",
        "    # 文化時間特定場景\n",
        "    \"nighttime_street\": \"A photo of a street at night with artificial lighting and evening activity.\",\n",
        "    \"nighttime_commercial_district\": \"A photo of a commercial district at night with illuminated signs and evening shopping.\",\n",
        "    \"european_plaza\": \"A photo of a European-style plaza with historic architecture and public gathering spaces.\",\n",
        "\n",
        "    # 混合環境場景\n",
        "    \"indoor_outdoor_cafe\": \"A photo of a cafe with both indoor seating and outdoor patio areas.\",\n",
        "    \"transit_station_platform\": \"A photo of a transit station platform with waiting areas and arriving vehicles.\",\n",
        "\n",
        "    # 工作場景\n",
        "    \"construction_site\": \"A photo of a construction site with building materials, equipment and workers.\",\n",
        "    \"medical_facility\": \"A photo of a medical facility with healthcare equipment and professional staff.\",\n",
        "    \"educational_setting\": \"A photo of an educational setting with learning spaces and academic resources.\",\n",
        "    \"professional_kitchen\": \"A photo of a professional commercial kitchen with industrial cooking equipment and food preparation stations.\"\n",
        "}\n",
        "\n",
        "# 文化特定場景提示\n",
        "CULTURAL_SCENE_PROMPTS = {\n",
        "    \"asian_commercial_street\": [\n",
        "        \"A busy Asian shopping street with neon signs and dense storefronts.\",\n",
        "        \"A commercial street in Asia with multi-level signage and narrow walkways.\",\n",
        "        \"A street scene in Taiwan or Hong Kong with vertical signage and compact shops.\",\n",
        "        \"A crowded commercial alley in an Asian city with signs in Chinese characters.\",\n",
        "        \"A narrow shopping street in Asia with small shops on both sides.\",\n",
        "        \"An outdoor shopping district in an East Asian city with electronic billboards.\",\n",
        "        \"A bustling commercial street in Taiwan with food vendors and retail shops.\",\n",
        "        \"A pedestrian shopping area with Korean or Chinese signs and storefronts.\",\n",
        "        \"A daytime shopping street in an Asian urban center with vertical development.\"\n",
        "    ],\n",
        "    \"asian_night_market\": [\n",
        "        \"A vibrant night market in Asia with food stalls and large crowds.\",\n",
        "        \"An evening street market in Taiwan with street food vendors and bright lights.\",\n",
        "        \"A busy night bazaar in Asia with illuminated stalls and local food.\",\n",
        "        \"A crowded night street food market in an Asian city with vendor carts.\",\n",
        "        \"An Asian night market with steam from cooking food and hanging lanterns.\",\n",
        "        \"A nocturnal food street in East Asia with vendor canopies and neon lights.\",\n",
        "        \"A bustling evening market with rows of food stalls and plastic stools.\",\n",
        "        \"A lively Asian street food scene at night with cooking stations and crowds.\"\n",
        "    ],\n",
        "    \"asian_temple_area\": [\n",
        "        \"A traditional Asian temple with ornate roof details and religious symbols.\",\n",
        "        \"A Buddhist temple complex in East Asia with multiple pavilions and prayer areas.\",\n",
        "        \"A sacred site in Asia with incense burners and ceremonial elements.\",\n",
        "        \"A temple courtyard with stone statues and traditional Asian architecture.\",\n",
        "        \"A spiritual center in East Asia with pagoda-style structures and visitors.\",\n",
        "        \"An ancient temple site with Asian architectural elements and cultural symbols.\",\n",
        "        \"A religious compound with characteristic Asian roof curves and decorative features.\"\n",
        "    ],\n",
        "    \"european_plaza\": [\n",
        "        \"A historic European city square with classical architecture and cafes.\",\n",
        "        \"An old-world plaza in Europe with cobblestone paving and historic buildings.\",\n",
        "        \"A public square in a European city with fountains and surrounding architecture.\",\n",
        "        \"A central plaza in Europe with outdoor seating areas and historic monuments.\",\n",
        "        \"A traditional European town square with surrounding shops and restaurants.\",\n",
        "        \"A historic gathering space in Europe with distinctive architecture and pedestrians.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 對比類別提示\n",
        "COMPARATIVE_PROMPTS = {\n",
        "    \"indoor_vs_outdoor\": [\n",
        "        \"An indoor shopping mall corridor with controlled lighting and storefronts.\",\n",
        "        \"An outdoor commercial street with natural lighting and urban storefronts.\",\n",
        "        \"An enclosed shopping gallery with artificial lighting and climate control.\",\n",
        "        \"An open-air market street with natural light and weather exposure.\"\n",
        "    ],\n",
        "    \"professional_vs_home\": [\n",
        "        \"A professional commercial kitchen with stainless steel equipment and workstations.\",\n",
        "        \"A home kitchen with residential appliances and family cooking space.\",\n",
        "        \"A restaurant kitchen with multiple cooking stations and chef activity.\",\n",
        "        \"A family kitchen with standard household equipment and personal touches.\"\n",
        "    ],\n",
        "    \"sports_venue_vs_park\": [\n",
        "        \"A professional sports stadium with designated playing areas and audience seating.\",\n",
        "        \"A public park with casual recreation space and community greenery.\",\n",
        "        \"An athletic venue with specialized sports equipment and competitive playing surfaces.\",\n",
        "        \"An outdoor community space with general purpose areas and natural elements.\"\n",
        "    ],\n",
        "    \"asian_vs_western_commercial\": [\n",
        "        \"An Asian shopping street with vertical signage and compact multi-level shops.\",\n",
        "        \"A Western commercial street with horizontal storefronts and wider sidewalks.\",\n",
        "        \"An East Asian retail area with dense signage in Asian scripts and narrow walkways.\"\n",
        "        \"A Western shopping district with uniform building heights and Latin alphabetic signs.\"\n",
        "    ],\n",
        "    \"daytime_vs_nighttime\": [\n",
        "        \"A daytime urban scene with natural sunlight illuminating streets and buildings.\",\n",
        "        \"A nighttime city scene with artificial lighting from stores, signs and streetlights.\",\n",
        "        \"A commercial district during daylight hours with natural shadows and visibility.\",\n",
        "        \"An evening urban setting with illuminated storefronts and light patterns on streets.\"\n",
        "    ],\n",
        "    \"aerial_vs_street_level\": [\n",
        "        \"An aerial view showing urban patterns and layouts from above.\",\n",
        "        \"A street-level view showing pedestrian perspective and immediate surroundings.\",\n",
        "        \"A bird's-eye view of city organization and movement patterns from high above.\",\n",
        "        \"An eye-level perspective showing direct human interaction with urban elements.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 環境條件文本提示\n",
        "LIGHTING_CONDITION_PROMPTS = {\n",
        "    \"day_clear\": \"A photo taken during daytime with clear skies and direct sunlight.\",\n",
        "    \"day_cloudy\": \"A photo taken during daytime with overcast conditions and diffused light.\",\n",
        "    \"sunset/sunrise\": \"A photo taken during sunset or sunrise with warm golden lighting and long shadows.\",\n",
        "    \"night\": \"A photo taken at night with minimal natural light and artificial illumination.\",\n",
        "    \"indoor_bright\": \"An indoor photo with bright, even artificial lighting throughout the space.\",\n",
        "    \"indoor_moderate\": \"An indoor photo with moderate lighting creating a balanced indoor atmosphere.\",\n",
        "    \"indoor_dim\": \"An indoor photo with low lighting levels creating a subdued environment.\",\n",
        "    \"neon_night\": \"A night scene with colorful neon lighting creating vibrant illumination patterns.\",\n",
        "    \"indoor_commercial\": \"An indoor retail environment with directed display lighting highlighting products.\",\n",
        "    \"indoor_restaurant\": \"An indoor dining space with ambient mood lighting for atmosphere.\",\n",
        "    \"stadium_lighting\": \"A sports venue with powerful floodlights creating intense, even illumination.\",\n",
        "    \"mixed_lighting\": \"A scene with combined natural and artificial light sources creating transition zones.\",\n",
        "    \"beach_daylight\": \"A photo taken at a beach with bright natural sunlight and reflections from water.\",\n",
        "    \"sports_arena_lighting\": \"A photo of a sports venue illuminated by powerful overhead lighting systems.\",\n",
        "    \"kitchen_task_lighting\": \"A photo of a kitchen with focused lighting concentrated on work surfaces.\"\n",
        "}\n",
        "\n",
        "# 針對新場景類型的特殊提示\n",
        "SPECIALIZED_SCENE_PROMPTS = {\n",
        "    \"beach_water_recreation\": [\n",
        "        \"A coastal beach scene with people surfing and sunbathing on sandy shores.\",\n",
        "        \"Active water sports participants at a beach with surfboards and swimming areas.\",\n",
        "        \"A sunny beach destination with recreational water equipment and beachgoers.\",\n",
        "        \"A shoreline recreation area with surf gear and coastal activities.\",\n",
        "        \"An oceanfront scene with people engaging in water sports and beach leisure.\",\n",
        "        \"A popular beach spot with swimming areas and surfing zones.\",\n",
        "        \"A coastal recreation setting with beach umbrellas and water activities.\"\n",
        "    ],\n",
        "    \"sports_venue\": [\n",
        "        \"An indoor sports arena with professional equipment and competition spaces.\",\n",
        "        \"A sports stadium with marked playing areas and spectator seating arrangement.\",\n",
        "        \"A specialized athletic venue with competition equipment and performance areas.\",\n",
        "        \"A professional sports facility with game-related apparatus and audience zones.\",\n",
        "        \"An organized sports center with competitive play areas and athletic equipment.\",\n",
        "        \"A competition venue with sport-specific markings and professional setup.\",\n",
        "        \"A formal athletic facility with standardized equipment and playing surfaces.\"\n",
        "    ],\n",
        "    \"professional_kitchen\": [\n",
        "        \"A commercial restaurant kitchen with multiple cooking stations and food prep areas.\",\n",
        "        \"A professional culinary workspace with industrial appliances and chef activity.\",\n",
        "        \"A busy restaurant back-of-house with stainless steel equipment and meal preparation.\",\n",
        "        \"A commercial food service kitchen with chef workstations and specialized zones.\",\n",
        "        \"An industrial kitchen facility with specialized cooking equipment and prep surfaces.\",\n",
        "        \"A high-volume food production kitchen with professional-grade appliances.\",\n",
        "        \"A restaurant kitchen with distinct cooking areas and culinary workflow design.\"\n",
        "    ],\n",
        "    \"urban_intersection\": [\n",
        "        \"A city intersection with crosswalks and traffic signals controlling movement.\",\n",
        "        \"A busy urban crossroad with pedestrian crossings and vehicle traffic.\",\n",
        "        \"A regulated street intersection with crosswalk markings and waiting pedestrians.\",\n",
        "        \"A metropolitan junction with traffic lights and pedestrian crossing zones.\",\n",
        "        \"A city street crossing with safety features for pedestrians and traffic flow.\",\n",
        "        \"A controlled urban intersection with movement patterns for vehicles and people.\",\n",
        "        \"A city center crossroad with traffic management features and pedestrian areas.\"\n",
        "    ],\n",
        "    \"financial_district\": [\n",
        "        \"A downtown business area with tall office buildings and commercial activity.\",\n",
        "        \"An urban financial center with skyscrapers and professional environment.\",\n",
        "        \"A city's business district with corporate headquarters and office towers.\",\n",
        "        \"A metropolitan financial zone with high-rise buildings and business traffic.\",\n",
        "        \"A corporate district in a city center with professional architecture.\",\n",
        "        \"An urban area dominated by office buildings and business establishments.\",\n",
        "        \"A city's economic center with banking institutions and corporate offices.\"\n",
        "    ],\n",
        "    \"aerial_view_intersection\": [\n",
        "        \"A bird's-eye view of a city intersection showing crossing patterns from above.\",\n",
        "        \"An overhead perspective of an urban crossroad showing traffic organization.\",\n",
        "        \"A top-down view of a street intersection revealing pedestrian crosswalks.\",\n",
        "        \"An aerial shot of a city junction showing the layout of roads and crossings.\",\n",
        "        \"A high-angle view of an intersection showing traffic and pedestrian flow patterns.\",\n",
        "        \"A drone perspective of urban crossing design viewed from directly above.\",\n",
        "        \"A vertical view of a street intersection showing crossing infrastructure.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "VIEWPOINT_PROMPTS = {\n",
        "    \"eye_level\": \"A photo taken from normal human eye level showing a direct frontal perspective.\",\n",
        "    \"aerial\": \"A photo taken from high above looking directly down at the scene below.\",\n",
        "    \"elevated\": \"A photo taken from a higher than normal position looking down at an angle.\",\n",
        "    \"low_angle\": \"A photo taken from a low position looking upward at the scene.\",\n",
        "    \"bird_eye\": \"A photo taken from very high above showing a complete overhead perspective.\",\n",
        "    \"street_level\": \"A photo taken from the perspective of someone standing on the street.\",\n",
        "    \"interior\": \"A photo taken from inside a building showing the internal environment.\",\n",
        "    \"vehicular\": \"A photo taken from inside or mounted on a moving vehicle.\"\n",
        "}\n",
        "\n",
        "OBJECT_COMBINATION_PROMPTS = {\n",
        "    \"dining_setting\": \"A scene with tables, chairs, plates, and eating utensils arranged for meals.\",\n",
        "    \"office_setup\": \"A scene with desks, chairs, computers, and office supplies for work.\",\n",
        "    \"living_space\": \"A scene with sofas, coffee tables, TVs, and comfortable seating arrangements.\",\n",
        "    \"transportation_hub\": \"A scene with vehicles, waiting areas, passengers, and transit information.\",\n",
        "    \"retail_environment\": \"A scene with merchandise displays, shoppers, and store fixtures.\",\n",
        "    \"crosswalk_scene\": \"A scene with street markings, pedestrians crossing, and traffic signals.\",\n",
        "    \"cooking_area\": \"A scene with stoves, prep surfaces, cooking utensils, and food items.\",\n",
        "    \"recreational_space\": \"A scene with sports equipment, play areas, and activity participants.\"\n",
        "}\n",
        "\n",
        "ACTIVITY_PROMPTS = {\n",
        "    \"shopping\": \"People looking at merchandise, carrying shopping bags, and browsing stores.\",\n",
        "    \"dining\": \"People eating food, sitting at tables, and using dining utensils.\",\n",
        "    \"commuting\": \"People waiting for transportation, boarding vehicles, and traveling.\",\n",
        "    \"working\": \"People using computers, attending meetings, and engaged in professional tasks.\",\n",
        "    \"exercising\": \"People engaged in physical activities, using sports equipment, and training.\",\n",
        "    \"cooking\": \"People preparing food, using kitchen equipment, and creating meals.\",\n",
        "    \"crossing_street\": \"People walking across designated crosswalks and navigating intersections.\",\n",
        "    \"recreational_activity\": \"People engaged in leisure activities, games, and social recreation.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LTmls2hz4bu"
      },
      "outputs": [],
      "source": [
        "# %%writefile clip_analyzer.py\n",
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple, Any, Optional, Union\n",
        "\n",
        "# from clip_prompts import (\n",
        "#     SCENE_TYPE_PROMPTS,\n",
        "#     CULTURAL_SCENE_PROMPTS,\n",
        "#     COMPARATIVE_PROMPTS,\n",
        "#     LIGHTING_CONDITION_PROMPTS,\n",
        "#     SPECIALIZED_SCENE_PROMPTS,\n",
        "#     VIEWPOINT_PROMPTS,\n",
        "#     OBJECT_COMBINATION_PROMPTS,\n",
        "#     ACTIVITY_PROMPTS\n",
        "# )\n",
        "\n",
        "class CLIPAnalyzer:\n",
        "    \"\"\"\n",
        "    Use Clip to intergrate scene understanding function\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"ViT-L/14\", device: str = None):\n",
        "        \"\"\"\n",
        "        初始化 CLIP 分析器。\n",
        "\n",
        "        Args:\n",
        "            model_name: CLIP Model name, 默認 \"ViT-L/14\"\n",
        "            device: Use GPU if it can use\n",
        "        \"\"\"\n",
        "        # 自動選擇設備\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        print(f\"Loading CLIP model {model_name} on {self.device}...\")\n",
        "        try:\n",
        "            self.model, self.preprocess = clip.load(model_name, device=self.device)\n",
        "            print(f\"CLIP model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CLIP model: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.scene_type_prompts = SCENE_TYPE_PROMPTS\n",
        "        self.cultural_scene_prompts = CULTURAL_SCENE_PROMPTS\n",
        "        self.comparative_prompts = COMPARATIVE_PROMPTS\n",
        "        self.lighting_condition_prompts = LIGHTING_CONDITION_PROMPTS\n",
        "        self.specialized_scene_prompts = SPECIALIZED_SCENE_PROMPTS\n",
        "        self.viewpoint_prompts = VIEWPOINT_PROMPTS\n",
        "        self.object_combination_prompts = OBJECT_COMBINATION_PROMPTS\n",
        "        self.activity_prompts = ACTIVITY_PROMPTS\n",
        "\n",
        "        # turn to CLIP format\n",
        "        self._prepare_text_prompts()\n",
        "\n",
        "    def _prepare_text_prompts(self):\n",
        "        \"\"\"準備所有文本提示的 CLIP 特徵並存儲到 self.text_features_cache 中\"\"\"\n",
        "        self.text_features_cache = {}\n",
        "\n",
        "        # 處理基礎場景類型 (SCENE_TYPE_PROMPTS)\n",
        "        if hasattr(self, 'scene_type_prompts') and self.scene_type_prompts:\n",
        "            scene_texts = [prompt for scene_type, prompt in self.scene_type_prompts.items()]\n",
        "            if scene_texts:\n",
        "                self.text_features_cache[\"scene_type_keys\"] = list(self.scene_type_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"scene_type_tokens\"] = clip.tokenize(scene_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing scene_type_prompts: {e}\")\n",
        "                    self.text_features_cache[\"scene_type_tokens\"] = None # 標記錯誤或空\n",
        "            else:\n",
        "                self.text_features_cache[\"scene_type_keys\"] = []\n",
        "                self.text_features_cache[\"scene_type_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"scene_type_keys\"] = []\n",
        "            self.text_features_cache[\"scene_type_tokens\"] = None\n",
        "\n",
        "        # 處理文化場景 (CULTURAL_SCENE_PROMPTS)\n",
        "        # cultural_tokens_dict 存儲的是 tokenized prompts\n",
        "        cultural_tokens_dict_val = {}\n",
        "        if hasattr(self, 'cultural_scene_prompts') and self.cultural_scene_prompts:\n",
        "            for scene_type, prompts in self.cultural_scene_prompts.items():\n",
        "                if prompts and isinstance(prompts, list) and all(isinstance(p, str) for p in prompts):\n",
        "                    try:\n",
        "                        cultural_tokens_dict_val[scene_type] = clip.tokenize(prompts).to(self.device)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Error tokenizing cultural_scene_prompts for {scene_type}: {e}\")\n",
        "                        cultural_tokens_dict_val[scene_type] = None # 標記錯誤或空\n",
        "                else:\n",
        "                    cultural_tokens_dict_val[scene_type] = None # prompts 不合規\n",
        "        self.text_features_cache[\"cultural_tokens_dict\"] = cultural_tokens_dict_val\n",
        "\n",
        "        # 處理光照條件 (LIGHTING_CONDITION_PROMPTS)\n",
        "        if hasattr(self, 'lighting_condition_prompts') and self.lighting_condition_prompts:\n",
        "            lighting_texts = [prompt for cond, prompt in self.lighting_condition_prompts.items()]\n",
        "            if lighting_texts:\n",
        "                self.text_features_cache[\"lighting_condition_keys\"] = list(self.lighting_condition_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"lighting_tokens\"] = clip.tokenize(lighting_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing lighting_condition_prompts: {e}\")\n",
        "                    self.text_features_cache[\"lighting_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"lighting_condition_keys\"] = []\n",
        "                self.text_features_cache[\"lighting_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"lighting_condition_keys\"] = []\n",
        "            self.text_features_cache[\"lighting_tokens\"] = None\n",
        "\n",
        "        # 處理特殊場景 (SPECIALIZED_SCENE_PROMPTS)\n",
        "        specialized_tokens_dict_val = {}\n",
        "        if hasattr(self, 'specialized_scene_prompts') and self.specialized_scene_prompts:\n",
        "            for scene_type, prompts in self.specialized_scene_prompts.items():\n",
        "                if prompts and isinstance(prompts, list) and all(isinstance(p, str) for p in prompts):\n",
        "                    try:\n",
        "                        specialized_tokens_dict_val[scene_type] = clip.tokenize(prompts).to(self.device)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Error tokenizing specialized_scene_prompts for {scene_type}: {e}\")\n",
        "                        specialized_tokens_dict_val[scene_type] = None\n",
        "                else:\n",
        "                    specialized_tokens_dict_val[scene_type] = None\n",
        "        self.text_features_cache[\"specialized_tokens_dict\"] = specialized_tokens_dict_val\n",
        "\n",
        "        # 處理視角 (VIEWPOINT_PROMPTS)\n",
        "        if hasattr(self, 'viewpoint_prompts') and self.viewpoint_prompts:\n",
        "            viewpoint_texts = [prompt for viewpoint, prompt in self.viewpoint_prompts.items()]\n",
        "            if viewpoint_texts:\n",
        "                self.text_features_cache[\"viewpoint_keys\"] = list(self.viewpoint_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"viewpoint_tokens\"] = clip.tokenize(viewpoint_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing viewpoint_prompts: {e}\")\n",
        "                    self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"viewpoint_keys\"] = []\n",
        "                self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"viewpoint_keys\"] = []\n",
        "            self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "\n",
        "        # 處理物件組合 (OBJECT_COMBINATION_PROMPTS)\n",
        "        if hasattr(self, 'object_combination_prompts') and self.object_combination_prompts:\n",
        "            object_combination_texts = [prompt for combo, prompt in self.object_combination_prompts.items()]\n",
        "            if object_combination_texts:\n",
        "                self.text_features_cache[\"object_combination_keys\"] = list(self.object_combination_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"object_combination_tokens\"] = clip.tokenize(object_combination_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing object_combination_prompts: {e}\")\n",
        "                    self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"object_combination_keys\"] = []\n",
        "                self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"object_combination_keys\"] = []\n",
        "            self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "\n",
        "        # 處理活動 (ACTIVITY_PROMPTS)\n",
        "        if hasattr(self, 'activity_prompts') and self.activity_prompts:\n",
        "            activity_texts = [prompt for activity, prompt in self.activity_prompts.items()]\n",
        "            if activity_texts:\n",
        "                self.text_features_cache[\"activity_keys\"] = list(self.activity_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"activity_tokens\"] = clip.tokenize(activity_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing activity_prompts: {e}\")\n",
        "                    self.text_features_cache[\"activity_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"activity_keys\"] = []\n",
        "                self.text_features_cache[\"activity_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"activity_keys\"] = []\n",
        "            self.text_features_cache[\"activity_tokens\"] = None\n",
        "\n",
        "        self.scene_type_tokens = self.text_features_cache[\"scene_type_tokens\"]\n",
        "        self.lighting_tokens = self.text_features_cache[\"lighting_tokens\"]\n",
        "        self.viewpoint_tokens = self.text_features_cache[\"viewpoint_tokens\"]\n",
        "        self.object_combination_tokens = self.text_features_cache[\"object_combination_tokens\"]\n",
        "        self.activity_tokens = self.text_features_cache[\"activity_tokens\"]\n",
        "        self.cultural_tokens_dict = self.text_features_cache[\"cultural_tokens_dict\"]\n",
        "        self.specialized_tokens_dict = self.text_features_cache[\"specialized_tokens_dict\"]\n",
        "\n",
        "        print(\"CLIP text_features_cache prepared.\")\n",
        "\n",
        "    def analyze_image(self, image, include_cultural_analysis=True, exclude_categories=None, enable_landmark=True, places365_guidance=None):\n",
        "        \"\"\"\n",
        "        分析圖像，預測場景類型和光照條件。\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像 (PIL Image 或 numpy array)\n",
        "            include_cultural_analysis: 是否包含文化場景的詳細分析\n",
        "            exclude_categories: 要排除的類別列表\n",
        "            enable_landmark: 是否啟用地標檢測功能\n",
        "            places365_guidance: Places365 提供的場景指導信息 (可選)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含場景類型預測和光照條件的分析結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.enable_landmark = enable_landmark # 更新實例的 enable_landmark 狀態\n",
        "            # 確保圖像是 PIL 格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 預處理圖像\n",
        "            image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "            # 獲取圖像特徵\n",
        "            with torch.no_grad():\n",
        "                image_features = self.model.encode_image(image_input)\n",
        "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            places365_focus_areas = []\n",
        "            places365_scene_context = \"\" # 用於存儲 Places365 提供的場景描述\n",
        "\n",
        "            if places365_guidance and isinstance(places365_guidance, dict) and places365_guidance.get('confidence', 0) > 0.4:\n",
        "                mapped_scene = places365_guidance.get('mapped_scene_type', '')\n",
        "                scene_label = places365_guidance.get('scene_label', '')\n",
        "                # is_indoor = places365_guidance.get('is_indoor', None) # 未使用，可註釋\n",
        "                attributes = places365_guidance.get('attributes', [])\n",
        "\n",
        "                places365_scene_context = f\"Scene identified by Places365 as {scene_label}\" # 更新上下文描述\n",
        "\n",
        "                # Adjust CLIP analysis focus based on Places365 scene type\n",
        "                if mapped_scene in ['kitchen', 'dining_area', 'restaurant']:\n",
        "                    places365_focus_areas.extend(['food preparation', 'dining setup', 'kitchen appliances'])\n",
        "                elif mapped_scene in ['office_workspace', 'educational_setting', 'library', 'conference_room']:\n",
        "                    places365_focus_areas.extend(['work environment', 'professional setting', 'learning space', 'study area'])\n",
        "                elif mapped_scene in ['retail_store', 'shopping_mall', 'market', 'supermarket']: # 擴展匹配\n",
        "                    places365_focus_areas.extend(['commercial space', 'shopping environment', 'retail display', 'goods for sale'])\n",
        "                elif mapped_scene in ['park_area', 'beach', 'natural_outdoor_area', 'playground', 'sports_field']: # 擴展匹配\n",
        "                    places365_focus_areas.extend(['outdoor recreation', 'natural environment', 'leisure activity', 'open space'])\n",
        "\n",
        "                # 根據屬性添加更通用的 focus areas\n",
        "                if isinstance(attributes, list): # 確保 attributes 是列表\n",
        "                    if 'commercial' in attributes:\n",
        "                        places365_focus_areas.append('business activity')\n",
        "                    if 'recreational' in attributes:\n",
        "                        places365_focus_areas.append('entertainment or leisure')\n",
        "                    if 'residential' in attributes:\n",
        "                        places365_focus_areas.append('living space')\n",
        "\n",
        "                # 去重\n",
        "                places365_focus_areas = list(set(places365_focus_areas))\n",
        "\n",
        "                if places365_focus_areas: # 只有在確實有 focus areas 時才打印\n",
        "                    print(f\"CLIP analysis guided by Places365: {places365_scene_context}, focus areas: {places365_focus_areas}\")\n",
        "\n",
        "            # 分析場景類型，傳遞 enable_landmark 參數和 Places365 指導\n",
        "            scene_scores = self._analyze_scene_type(image_features,\n",
        "                                                  enable_landmark=self.enable_landmark, # 使用更新後的實例屬性\n",
        "                                                  places365_focus=places365_focus_areas)\n",
        "\n",
        "            # 如果禁用地標功能，確保排除地標相關類別\n",
        "            current_exclude_categories = list(exclude_categories) if exclude_categories is not None else []\n",
        "            if not self.enable_landmark: # 使用更新後的實例屬性\n",
        "                landmark_related_terms = [\"landmark\", \"monument\", \"tower\", \"tourist\", \"attraction\", \"historical\", \"famous\", \"iconic\"]\n",
        "                for term in landmark_related_terms:\n",
        "                    if term not in current_exclude_categories:\n",
        "                        current_exclude_categories.append(term)\n",
        "\n",
        "            if current_exclude_categories:\n",
        "                filtered_scores = {}\n",
        "                for scene, score in scene_scores.items():\n",
        "                    # 檢查 scene 的鍵名（通常是英文）是否包含任何排除詞彙\n",
        "                    if not any(cat.lower() in scene.lower() for cat in current_exclude_categories):\n",
        "                        filtered_scores[scene] = score\n",
        "\n",
        "                if filtered_scores:\n",
        "                    total_score = sum(filtered_scores.values())\n",
        "                    if total_score > 1e-5: # 避免除以零或非常小的數\n",
        "                        scene_scores = {k: v / total_score for k, v in filtered_scores.items()}\n",
        "                    else: # 如果總分趨近於0，則保持原樣或設為0\n",
        "                        scene_scores = {k: 0.0 for k in filtered_scores.keys()} # 或者 scene_scores = filtered_scores\n",
        "                else: # 如果過濾後沒有場景了\n",
        "                    scene_scores = {k: (0.0 if any(cat.lower() in k.lower() for cat in current_exclude_categories) else v) for k,v in scene_scores.items()}\n",
        "                    if not any(s > 1e-5 for s in scene_scores.values()): # 如果還是全0\n",
        "                         scene_scores = {\"unknown\": 1.0} # 給一個默認值避免空字典\n",
        "\n",
        "            lighting_scores = self._analyze_lighting_condition(image_features)\n",
        "            cultural_analysis = {}\n",
        "            if include_cultural_analysis and self.enable_landmark: # 使用更新後的實例屬性\n",
        "                for scene_type_cultural_key in self.text_features_cache.get(\"cultural_tokens_dict\", {}).keys():\n",
        "                     # 確保 scene_type_cultural_key 是 SCENE_TYPE_PROMPTS 中的鍵，或者有一個映射關係\n",
        "                    if scene_type_cultural_key in scene_scores and scene_scores[scene_type_cultural_key] > 0.2:\n",
        "                        cultural_analysis[scene_type_cultural_key] = self._analyze_cultural_scene(\n",
        "                            image_features, scene_type_cultural_key\n",
        "                        )\n",
        "\n",
        "            specialized_analysis = {}\n",
        "            for scene_type_specialized_key in self.text_features_cache.get(\"specialized_tokens_dict\", {}).keys():\n",
        "                if scene_type_specialized_key in scene_scores and scene_scores[scene_type_specialized_key] > 0.2:\n",
        "                    specialized_analysis[scene_type_specialized_key] = self._analyze_specialized_scene(\n",
        "                        image_features, scene_type_specialized_key\n",
        "                    )\n",
        "\n",
        "            viewpoint_scores = self._analyze_viewpoint(image_features)\n",
        "            object_combination_scores = self._analyze_object_combinations(image_features)\n",
        "            activity_scores = self._analyze_activities(image_features)\n",
        "\n",
        "            if scene_scores: # 確保 scene_scores 不是空的\n",
        "                top_scene = max(scene_scores.items(), key=lambda x: x[1])\n",
        "                 # 如果禁用地標，再次確認 top_scene 不是地標相關\n",
        "                if not self.enable_landmark and any(cat.lower() in top_scene[0].lower() for cat in current_exclude_categories):\n",
        "                    non_excluded_scores = {k:v for k,v in scene_scores.items() if not any(cat.lower() in k.lower() for cat in current_exclude_categories)}\n",
        "                    if non_excluded_scores:\n",
        "                        top_scene = max(non_excluded_scores.items(), key=lambda x: x[1])\n",
        "                    else:\n",
        "                        top_scene = (\"unknown\", 0.0) # 或其他合適的默認值\n",
        "            else:\n",
        "                top_scene = (\"unknown\", 0.0)\n",
        "\n",
        "\n",
        "            result = {\n",
        "                \"scene_scores\": scene_scores,\n",
        "                \"top_scene\": top_scene,\n",
        "                \"lighting_condition\": max(lighting_scores.items(), key=lambda x: x[1]) if lighting_scores else (\"unknown\", 0.0),\n",
        "                \"embedding\": image_features.cpu().numpy().tolist()[0], # 簡化\n",
        "                \"viewpoint\": max(viewpoint_scores.items(), key=lambda x: x[1]) if viewpoint_scores else (\"unknown\", 0.0),\n",
        "                \"object_combinations\": sorted(object_combination_scores.items(), key=lambda x: x[1], reverse=True)[:3] if object_combination_scores else [],\n",
        "                \"activities\": sorted(activity_scores.items(), key=lambda x: x[1], reverse=True)[:3] if activity_scores else []\n",
        "            }\n",
        "\n",
        "            if places365_guidance and isinstance(places365_guidance, dict) and places365_focus_areas: # 檢查 places365_focus_areas 是否被填充\n",
        "                result[\"places365_guidance\"] = {\n",
        "                    \"scene_context\": places365_scene_context,\n",
        "                    \"focus_areas\": places365_focus_areas, # 現在這個會包含基於 guidance 的內容\n",
        "                    \"guided_analysis\": True,\n",
        "                    \"original_places365_scene\": places365_guidance.get('scene_label', 'N/A'),\n",
        "                    \"original_places365_confidence\": places365_guidance.get('confidence', 0.0)\n",
        "                }\n",
        "\n",
        "            if cultural_analysis and self.enable_landmark:\n",
        "                result[\"cultural_analysis\"] = cultural_analysis\n",
        "\n",
        "            if specialized_analysis:\n",
        "                result[\"specialized_analysis\"] = specialized_analysis\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing image with CLIP: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\"error\": str(e), \"scene_scores\": {}, \"top_scene\": (\"error\", 0.0)}\n",
        "\n",
        "    def _analyze_scene_type(self, image_features: torch.Tensor, enable_landmark: bool = True, places365_focus: List[str] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        分析圖像特徵與各場景類型的相似度，並可選擇性地排除地標相關場景\n",
        "\n",
        "        Args:\n",
        "            image_features: 經過 CLIP 編碼的圖像特徵\n",
        "            enable_landmark: 是否啟用地標識別功能\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 各場景類型的相似度分數字典\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算場景類型文本特徵\n",
        "            text_features = self.model.encode_text(self.scene_type_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # Apply Places365 guidance if available\n",
        "            if places365_focus and len(places365_focus) > 0:\n",
        "                # Create enhanced prompts that incorporate Places365 guidance\n",
        "                enhanced_prompts = []\n",
        "                for scene_type in self.scene_type_prompts.keys():\n",
        "                    base_prompt = self.scene_type_prompts[scene_type]\n",
        "\n",
        "                    # Check if this scene type should be emphasized based on Places365 guidance\n",
        "                    scene_lower = scene_type.lower()\n",
        "                    should_enhance = False\n",
        "\n",
        "                    for focus_area in places365_focus:\n",
        "                        if any(keyword in scene_lower for keyword in focus_area.split()):\n",
        "                            should_enhance = True\n",
        "                            enhanced_prompts.append(f\"{base_prompt} with {focus_area}\")\n",
        "                            break\n",
        "\n",
        "                    if not should_enhance:\n",
        "                        enhanced_prompts.append(base_prompt)\n",
        "\n",
        "                # Re-tokenize and encode enhanced prompts\n",
        "                enhanced_tokens = clip.tokenize(enhanced_prompts).to(self.device)\n",
        "                text_features = self.model.encode_text(enhanced_tokens)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立場景分數字典\n",
        "            scene_scores = {}\n",
        "            for i, scene_type in enumerate(self.scene_type_prompts.keys()):\n",
        "                # 如果未啟用地標功能，則跳過地標相關場景類型\n",
        "                if not enable_landmark and scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                    scene_scores[scene_type] = 0.0  # 將地標場景分數設為零\n",
        "                else:\n",
        "                    base_score = float(similarity[i])\n",
        "\n",
        "                    # Apply Places365 guidance boost if applicable\n",
        "                    if places365_focus:\n",
        "                        scene_lower = scene_type.lower()\n",
        "                        boost_factor = 1.0\n",
        "\n",
        "                        for focus_area in places365_focus:\n",
        "                            if any(keyword in scene_lower for keyword in focus_area.split()):\n",
        "                                boost_factor = 1.15  # 15% boost for matching scenes\n",
        "                                break\n",
        "\n",
        "                        scene_scores[scene_type] = base_score * boost_factor\n",
        "                    else:\n",
        "                        scene_scores[scene_type] = base_score\n",
        "\n",
        "            # 如果禁用地標功能，確保重新歸一化剩餘場景分數\n",
        "            if not enable_landmark:\n",
        "                # 獲取所有非零分數\n",
        "                non_zero_scores = {k: v for k, v in scene_scores.items() if v > 0}\n",
        "                if non_zero_scores:\n",
        "                    # 計算總和並歸一化\n",
        "                    total_score = sum(non_zero_scores.values())\n",
        "                    if total_score > 0:\n",
        "                        for scene_type in non_zero_scores:\n",
        "                            scene_scores[scene_type] = non_zero_scores[scene_type] / total_score\n",
        "\n",
        "            return scene_scores\n",
        "\n",
        "    def _analyze_lighting_condition(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像的光照條件\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算光照條件文本特徵\n",
        "            text_features = self.model.encode_text(self.lighting_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立光照條件分數字典\n",
        "            lighting_scores = {}\n",
        "            for i, lighting_type in enumerate(self.lighting_condition_prompts.keys()):\n",
        "                lighting_scores[lighting_type] = float(similarity[i])\n",
        "\n",
        "            return lighting_scores\n",
        "\n",
        "    def _analyze_cultural_scene(self, image_features: torch.Tensor, scene_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"針對特定文化場景進行深入分析\"\"\"\n",
        "        if scene_type not in self.cultural_tokens_dict:\n",
        "            return {\"error\": f\"No cultural analysis available for {scene_type}\"}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 獲取特定文化場景的文本特徵\n",
        "            cultural_tokens = self.cultural_tokens_dict[scene_type]\n",
        "            text_features = self.model.encode_text(cultural_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 找到最匹配的文化描述\n",
        "            prompts = self.cultural_scene_prompts[scene_type]\n",
        "            scores = [(prompts[i], float(similarity[i])) for i in range(len(prompts))]\n",
        "            scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            return {\n",
        "                \"best_description\": scores[0][0],\n",
        "                \"confidence\": scores[0][1],\n",
        "                \"all_matches\": scores\n",
        "            }\n",
        "\n",
        "    def _analyze_specialized_scene(self, image_features: torch.Tensor, scene_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"針對特定專門場景進行深入分析\"\"\"\n",
        "        if scene_type not in self.specialized_tokens_dict:\n",
        "            return {\"error\": f\"No specialized analysis available for {scene_type}\"}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 獲取特定專門場景的文本特徵\n",
        "            specialized_tokens = self.specialized_tokens_dict[scene_type]\n",
        "            text_features = self.model.encode_text(specialized_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 找到最匹配的專門描述\n",
        "            prompts = self.specialized_scene_prompts[scene_type]\n",
        "            scores = [(prompts[i], float(similarity[i])) for i in range(len(prompts))]\n",
        "            scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            return {\n",
        "                \"best_description\": scores[0][0],\n",
        "                \"confidence\": scores[0][1],\n",
        "                \"all_matches\": scores\n",
        "            }\n",
        "\n",
        "    def _analyze_viewpoint(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像的拍攝視角\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算視角文本特徵\n",
        "            text_features = self.model.encode_text(self.viewpoint_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立視角分數字典\n",
        "            viewpoint_scores = {}\n",
        "            for i, viewpoint in enumerate(self.viewpoint_prompts.keys()):\n",
        "                viewpoint_scores[viewpoint] = float(similarity[i])\n",
        "\n",
        "            return viewpoint_scores\n",
        "\n",
        "    def _analyze_object_combinations(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像中的物體組合\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算物體組合文本特徵\n",
        "            text_features = self.model.encode_text(self.object_combination_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立物體組合分數字典\n",
        "            combination_scores = {}\n",
        "            for i, combination in enumerate(self.object_combination_prompts.keys()):\n",
        "                combination_scores[combination] = float(similarity[i])\n",
        "\n",
        "            return combination_scores\n",
        "\n",
        "    def _analyze_activities(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像中的活動\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算活動文本特徵\n",
        "            text_features = self.model.encode_text(self.activity_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立活動分數字典\n",
        "            activity_scores = {}\n",
        "            for i, activity in enumerate(self.activity_prompts.keys()):\n",
        "                activity_scores[activity] = float(similarity[i])\n",
        "\n",
        "            return activity_scores\n",
        "\n",
        "    def get_image_embedding(self, image) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        獲取圖像的 CLIP 嵌入表示\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy array\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: 圖像的 CLIP 特徵向量\n",
        "        \"\"\"\n",
        "        # 確保圖像是 PIL 格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 預處理並編碼\n",
        "        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_input)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # 轉換為 numpy 並返回\n",
        "        return image_features.cpu().numpy()[0] if self.device == \"cuda\" else image_features.numpy()[0]\n",
        "\n",
        "    def text_to_embedding(self, text: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        將文本轉換為 CLIP 嵌入表示\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: 文本的 CLIP 特徵向量\n",
        "        \"\"\"\n",
        "        text_token = clip.tokenize([text]).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_features = self.model.encode_text(text_token)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        return text_features.cpu().numpy()[0] if self.device == \"cuda\" else text_features.numpy()[0]\n",
        "\n",
        "    def calculate_similarity(self, image, text_queries: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        計算圖像與多個文本查詢的相似度\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy array\n",
        "            text_queries: 文本查詢列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 每個查詢的相似度分數\n",
        "        \"\"\"\n",
        "        # 獲取圖像嵌入\n",
        "        if isinstance(image, np.ndarray) and len(image.shape) == 1:\n",
        "            # 已經是嵌入向量\n",
        "            image_features = torch.tensor(image).unsqueeze(0).to(self.device)\n",
        "        else:\n",
        "            # 是圖像，需要提取嵌入\n",
        "            image_features = torch.tensor(self.get_image_embedding(image)).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # calulate similarity\n",
        "        text_tokens = clip.tokenize(text_queries).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_features = self.model.encode_text(text_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "        # display results\n",
        "        result = {}\n",
        "        for i, query in enumerate(text_queries):\n",
        "            result[query] = float(similarity[i])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_clip_instance(self):\n",
        "        \"\"\"\n",
        "        獲取初始化好的CLIP模型實例，便於其他模組重用\n",
        "\n",
        "        Returns:\n",
        "            tuple: (模型實例, 預處理函數, 設備名稱)\n",
        "        \"\"\"\n",
        "        return self.model, self.preprocess, self.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pQfOjOABhs4"
      },
      "outputs": [],
      "source": [
        "# %%writefile landmark_data.py\n",
        "\n",
        "\"\"\"\n",
        "Landmark database for zero-shot classification using CLIP\n",
        "\"\"\"\n",
        "\n",
        "LANDMARK_DATA = {\n",
        "    # 亞洲地標\n",
        "    \"asia\": {\n",
        "        \"taipei_101\": {\n",
        "            \"name\": \"Taipei 101\",\n",
        "            \"aliases\": [\"Taipei 101 Tower\", \"Taipei Financial Center\", \"台北101大樓\", \"Taipei World Financial Center\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic green bamboo-shaped Taipei 101 skyscraper against city skyline\",\n",
        "                \"Taipei 101 tower with its distinctive stacked pagoda design and vibrant green glass facade\",\n",
        "                \"world-famous Taipei 101 skyscraper with its segmented exterior resembling a bamboo stalk and prominent observation deck\",\n",
        "                \"close-up of Taipei 101's architectural details showing the ruyi-inspired motifs and bamboo-inspired segments\",\n",
        "                \"aerial view of Taipei 101 standing tall as a landmark in Taipei's urban landscape\",\n",
        "                \"Taipei 101 illuminated at night with a spectrum of colorful light displays, often themed for holidays\",\n",
        "                \"Taipei 101 seen from street level, emphasizing its immense height and unique green-tinted curtain wall\",\n",
        "                \"the 508-meter tall Taipei 101 tower, an engineering marvel with its unique tiered design and spire\",\n",
        "                \"Taipei 101's distinctive green glass exterior reflecting the sky, with visible bamboo segment patterns\",\n",
        "                \"famous Taipei skyscraper, its characteristic pagoda-like stacked sections symbolizing growth and prosperity\",\n",
        "                \"Taipei 101 featuring its massive tuned mass damper, visible through architectural openings, designed to counteract wind and seismic activity\",\n",
        "                \"modern Asian skyscraper Taipei 101, showcasing a fusion of contemporary architecture and traditional Asian symbolism\",\n",
        "                \"Taipei's iconic 101-story skyscraper with its tapered pinnacle reaching towards the sky, often against a backdrop of mountains or blue sky\",\n",
        "                \"Taipei 101 viewed from Elephant Mountain, offering a classic panoramic shot of the tower and city\",\n",
        "                \"close view of Taipei 101's signature green glass exterior with its intricate geometric patterns and reflective surface\",\n",
        "                \"Taipei 101 with its distinct floor segments that resemble ancient Chinese ingots or a blossoming bamboo\",\n",
        "                \"Taiwan's tallest building, Taipei 101, with its square base, tapered form, and prominent antenna\",\n",
        "                \"the tall, slender green Taipei 101 skyscraper, a prominent feature in the city's skyline, day or night\",\n",
        "                \"Taipei 101 with its unique green segmented tower design, a masterpiece of modern engineering and cultural symbolism, against a clear blue sky\",\n",
        "                \"distinctive green glass Taipei 101 tower, a symbol of Taiwan's modernity, dominating the city view\",\n",
        "                \"Taipei 101's iconic green tiered skyscraper structure with its high-speed elevators and 360-degree observation deck\"\n",
        "            ]\n",
        "        },\n",
        "        \"taroko_gorge\": {\n",
        "            \"name\": \"Taroko Gorge\",\n",
        "            \"aliases\": [\"Taroko National Park\", \"太魯閣國家公園\"],\n",
        "            \"location\": \"Hualien, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Taroko Gorge in Taiwan, showcasing its deep marble canyons and the Liwu River\",\n",
        "                \"sheer marble cliffs of Taroko Gorge, with tunnels carved through the rock like the Tunnel of Nine Turns\",\n",
        "                \"Taroko Gorge national park landscape with turquoise river, lush vegetation, and towering rock walls\",\n",
        "                \"Swallow Grotto (Yanzikou) trail in Taroko Gorge, with views of the river and cliff formations\",\n",
        "                \"the Cihmu Bridge, a distinctive red suspension bridge within Taroko Gorge\"\n",
        "            ]\n",
        "        },\n",
        "        \"sun_moon_lake\": {\n",
        "            \"name\": \"Sun Moon Lake\",\n",
        "            \"aliases\": [\"日月潭\", \"Lake Candidius\"],\n",
        "            \"location\": \"Nantou, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Sun Moon Lake in Taiwan, showing its calm, clear waters and surrounding mountains\",\n",
        "                \"the serene Sun Moon Lake with Lalu Island, its sacred ancestral ground, dividing the lake into sun and moon shapes\",\n",
        "                \"Sun Moon Lake surrounded by mist-covered mountains, with traditional temples like Wenwu Temple or Ci En Pagoda visible\",\n",
        "                \"boats and ferries on Sun Moon Lake, with cyclists on lakeside paths\",\n",
        "                \"aerial view of Sun Moon Lake highlighting its unique shape and the lush greenery of the region\"\n",
        "            ]\n",
        "        },\n",
        "        \"jiufen_old_street\": {\n",
        "            \"name\": \"Jiufen Old Street\",\n",
        "            \"aliases\": [\"九份老街\", \"Chiufen\"],\n",
        "            \"location\": \"New Taipei City, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"narrow, winding alleys of Jiufen Old Street, lined with glowing red lanterns, traditional teahouses, and local food stalls\",\n",
        "                \"atmospheric Jiufen Old Street at dusk or night, with countless red lanterns illuminating the historic hillside town and views of the coast\",\n",
        "                \"historic gold mining town architecture in Jiufen, with wooden buildings and steep staircases, reminiscent of scenes from 'Spirited Away'\",\n",
        "                \"A-Mei Tea House in Jiufen, a famous landmark with its traditional facade and lantern decorations\",\n",
        "                \"street food and bustling crowds in the vibrant Jiufen Old Street market\"\n",
        "            ]\n",
        "        },\n",
        "        \"kenting_national_park\": {\n",
        "            \"name\": \"Kenting National Park\",\n",
        "            \"aliases\": [\"墾丁國家公園\"],\n",
        "            \"location\": \"Pingtung, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"tropical beaches with white sand and clear blue water in Kenting National Park, southern Taiwan\",\n",
        "                \"Eluanbi Lighthouse, the iconic white lighthouse at Taiwan's southernmost point, within Kenting National Park\",\n",
        "                \"diverse coastal landscapes of Kenting, including coral reefs, rock formations like Sail Rock (Chuanfanshi), and lush forests\",\n",
        "                \"vibrant marine life and water activities like snorkeling or surfing in Kenting National Park\",\n",
        "                \"Longpan Park in Kenting, featuring dramatic grassy cliffs and coastline views\"\n",
        "            ]\n",
        "        },\n",
        "        \"national_palace_museum_tw\": { # Added _tw to differentiate from Beijing's\n",
        "            \"name\": \"National Palace Museum (Taipei)\",\n",
        "            \"aliases\": [\"國立故宮博物院\", \"Taipei Palace Museum\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"the grand exterior of the National Palace Museum in Taipei, a traditional Chinese palace-style building housing a vast collection of imperial artifacts\",\n",
        "                \"iconic exhibits like the Jadeite Cabbage, Meat-shaped Stone, and Mao Gong Ding at the National Palace Museum in Taipei\",\n",
        "                \"classical Chinese palace architecture of the National Palace Museum building in Taipei, with green tiled roofs and moon gates\",\n",
        "                \"interior halls of the National Palace Museum displaying ancient Chinese ceramics, bronzes, and calligraphy\",\n",
        "                \"gardens surrounding the National Palace Museum in Taipei, such as Zhishan Garden\"\n",
        "            ]\n",
        "        },\n",
        "        \"alishan_national_scenic_area\": {\n",
        "            \"name\": \"Alishan National Scenic Area\",\n",
        "            \"aliases\": [\"阿里山國家風景區\", \"Mount Ali\"],\n",
        "            \"location\": \"Chiayi, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"sea of clouds phenomenon at Alishan National Scenic Area, viewed from high mountain peaks at sunrise or sunset\",\n",
        "                \"Alishan Forest Railway trains, with their distinctive red carriages, winding through misty forests of ancient cypress and cedar trees\",\n",
        "                \"sunrise views over Yushan (Jade Mountain), Taiwan's highest peak, from Alishan's Chushan or Ogasawara Mountain observation points\",\n",
        "                \"tea plantations on the rolling hills of Alishan, known for its high-mountain oolong tea\",\n",
        "                \"hiking trails through Alishan's giant tree groves and serene forests, like the Sister Ponds\"\n",
        "            ]\n",
        "        },\n",
        "        \"shilin_night_market\": {\n",
        "            \"name\": \"Shilin Night Market\",\n",
        "            \"aliases\": [\"士林夜市\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"bustling and vibrant atmosphere of Shilin Night Market in Taipei, one of Taiwan's largest and most famous night markets, packed with people\",\n",
        "                \"a wide variety of Taiwanese street food stalls offering delicacies like oyster omelets, stinky tofu, and giant fried chicken cutlets at Shilin Night Market\",\n",
        "                \"crowds of people exploring the maze-like alleys of Shilin Night Market, filled with food vendors, game stalls, and small shops\",\n",
        "                \"brightly lit signs and food aromas filling the air at the lively Shilin Night Market\",\n",
        "                \"underground food court area of Shilin Night Market offering a diverse range of local dishes\"\n",
        "            ]\n",
        "        },\n",
        "        \"tokyo_tower\": {\n",
        "            \"name\": \"Tokyo Tower\",\n",
        "            \"aliases\": [\"東京タワー\", \"Tokyo Tower Landmark\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Tokyo Tower in Japan, its distinctive red and white lattice structure inspired by the Eiffel Tower\",\n",
        "                \"Tokyo Tower with its vibrant orange and white paint scheme, standing out against the Tokyo skyline\",\n",
        "                \"the iconic Tokyo Tower illuminated at night, often with seasonal or special light displays\",\n",
        "                \"view from Tokyo Tower's observation deck overlooking the sprawling metropolis of Tokyo\",\n",
        "                \"Tokyo Tower as a symbol of post-war Japan's rebirth and a prominent communications tower\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_fuji\": {\n",
        "            \"name\": \"Mount Fuji\",\n",
        "            \"aliases\": [\"富士山\", \"Fujisan\"],\n",
        "            \"location\": \"Honshu, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mount Fuji in Japan, its perfectly symmetrical snow-capped conical volcanic peak\",\n",
        "                \"the snow-capped peak of Mount Fuji, often with a clear blue sky or surrounded by clouds\",\n",
        "                \"Mount Fuji with cherry blossoms (sakura) in the foreground during spring, or reflected in one of the Fuji Five Lakes (Fujigoko)\",\n",
        "                \"iconic view of Mount Fuji from the Chureito Pagoda\",\n",
        "                \"Mount Fuji, Japan's highest mountain and an active stratovolcano, a symbol of Japan\"\n",
        "            ]\n",
        "        },\n",
        "        \"kinkaku_ji\": {\n",
        "            \"name\": \"Kinkaku-ji\",\n",
        "            \"aliases\": [\"Golden Pavilion\", \"金閣寺\", \"Rokuon-ji\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Kinkaku-ji temple (Golden Pavilion) in Kyoto, its top two floors completely covered in gold leaf\",\n",
        "                \"the Golden Pavilion Kinkaku-ji reflected perfectly in the Mirror Pond (Kyōko-chi) surrounding it\",\n",
        "                \"Kinkaku-ji, a Zen Buddhist temple in Kyoto, set within a beautiful Japanese stroll garden\",\n",
        "                \"the three-tiered structure of Kinkaku-ji, each floor representing a different architectural style\",\n",
        "                \"Kinkaku-ji in autumn with colorful foliage, or in winter dusted with snow\"\n",
        "            ]\n",
        "        },\n",
        "        \"fushimi_inari_shrine\": {\n",
        "            \"name\": \"Fushimi Inari Shrine\",\n",
        "            \"aliases\": [\"伏見稲荷大社\", \"Thousand Torii Gates\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Fushimi Inari Shrine in Kyoto, famous for its thousands of vibrant red/orange torii gates\",\n",
        "                \"thousands of vermilion torii gates forming tunnels along a network of trails at Fushimi Inari Taisha\",\n",
        "                \"pathways lined with densely packed red torii gates winding up a mountainside at Fushimi Inari Shrine\",\n",
        "                \"fox statues (kitsune), messengers of Inari, found throughout Fushimi Inari Shrine\",\n",
        "                \"the main shrine buildings of Fushimi Inari at the base of the mountain, with more torii gates leading upwards\"\n",
        "            ]\n",
        "        },\n",
        "        \"shibuya_crossing\": {\n",
        "            \"name\": \"Shibuya Crossing\",\n",
        "            \"aliases\": [\"Shibuya Scramble Crossing\", \"澀谷十字路口\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"massive pedestrian scramble at Shibuya Crossing, Tokyo, with crowds of people crossing from all directions, surrounded by neon signs and large video screens\",\n",
        "                \"bird's-eye view of the crowded Shibuya intersection with its iconic starburst pedestrian walkways and Hachiko statue nearby\",\n",
        "                \"throngs of people crossing the multi-directional Shibuya intersection surrounded by modern buildings, department stores, and vibrant advertisements\",\n",
        "                \"Shibuya Crossing at night with dazzling, vibrant lights from billboards and a continuous sea of people\",\n",
        "                \"the energetic and iconic Shibuya Crossing, a symbol of modern Tokyo and urban life\"\n",
        "            ]\n",
        "        },\n",
        "        \"tokyo_skytree\": {\n",
        "            \"name\": \"Tokyo Skytree\",\n",
        "            \"aliases\": [\"東京晴空塔\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the slender, futuristic Tokyo Skytree, a broadcasting and observation tower in Sumida, Tokyo, with its lattice steel structure\",\n",
        "                \"Tokyo Skytree illuminated in its signature pale blue (Iki) or purple (Miyabi) lights against the night sky\",\n",
        "                \"modern lattice structure of the Tokyo Skytree, the world's tallest freestanding tower, dominating the city's skyline\",\n",
        "                \"panoramic view from Tokyo Skytree's Tembo Deck or Tembo Galleria overlooking the sprawling city of Tokyo and beyond\",\n",
        "                \"Tokyo Skytree with the Sumida River and surrounding urban landscape\"\n",
        "            ]\n",
        "        },\n",
        "        \"senso_ji_temple\": {\n",
        "            \"name\": \"Senso-ji Temple\",\n",
        "            \"aliases\": [\"淺草寺\", \"Asakusa Kannon Temple\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the vibrant red Senso-ji Temple in Asakusa, Tokyo, with its iconic Kaminarimon (Thunder Gate) featuring a massive red paper lantern\",\n",
        "                \"traditional Japanese temple architecture of Senso-ji, Tokyo's oldest temple, including its five-story pagoda and main hall\",\n",
        "                \"incense smoke billowing from a large cauldron and worshippers at Senso-ji Temple\",\n",
        "                \"Nakamise-dori, the bustling market street leading to Senso-ji Temple, lined with traditional souvenir stalls and food vendors\",\n",
        "                \"the Hozomon Gate with its giant waraji (straw sandals) at Senso-ji Temple\"\n",
        "            ]\n",
        "        },\n",
        "        \"osaka_castle\": {\n",
        "            \"name\": \"Osaka Castle\",\n",
        "            \"aliases\": [\"大阪城\", \"Osaka-jo\"],\n",
        "            \"location\": \"Osaka, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic Osaka Castle with its distinctive white walls, green tiled roofs, golden embellishments, and surrounding moat and massive stone walls\",\n",
        "                \"Osaka Castle Park with the imposing castle keep (tenshukaku) in the background, especially beautiful during cherry blossom season or autumn foliage\",\n",
        "                \"historic Japanese castle, Osaka Castle, reconstructed with modern interiors, showcasing its historical significance\",\n",
        "                \"Osaka Castle illuminated at night, reflecting in its expansive moat, creating a stunning visual\",\n",
        "                \"view of Osaka Castle from Nishinomaru Garden, offering a picturesque perspective\"\n",
        "            ]\n",
        "        },\n",
        "        \"dotonbori\": {\n",
        "            \"name\": \"Dotonbori\",\n",
        "            \"aliases\": [\"道頓堀\"],\n",
        "            \"location\": \"Osaka, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the vibrant and eclectic Dotonbori entertainment district in Osaka, famous for its extravagant, oversized 3D signage like the Glico Running Man and Kani Doraku crab\",\n",
        "                \"canal view of Dotonbori at night with a dazzling array of neon lights from billboards and signs reflecting on the Dotonbori River\",\n",
        "                \"colorful and brightly lit billboards, including the iconic Glico Running Man, lining the Dotonbori canal, a symbol of Osaka's energy\",\n",
        "                \"bustling atmosphere of Dotonbori with street food stalls offering takoyaki and okonomiyaki, and throngs of people\",\n",
        "                \"the Ebisu Bridge over the Dotonbori canal, a popular meeting spot and photo location\"\n",
        "            ]\n",
        "        },\n",
        "        \"arashiyama_bamboo_grove\": {\n",
        "            \"name\": \"Arashiyama Bamboo Grove\",\n",
        "            \"aliases\": [\"嵐山竹林\", \"Sagano Bamboo Forest\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"towering stalks of green bamboo creating a dense, immersive canopy over a pathway in Arashiyama Bamboo Grove, Kyoto\",\n",
        "                \"sunlight filtering magically through the leaves of the tall, closely packed bamboo forest in Arashiyama\",\n",
        "                \"serene and tranquil walking path through the iconic Arashiyama Bamboo Grove, with the distinctive sound of rustling bamboo leaves\",\n",
        "                \"people in traditional kimono or yukata walking through the Arashiyama Bamboo Grove\",\n",
        "                \"the unique, otherworldly atmosphere of the Arashiyama Bamboo Grove, a natural wonder\"\n",
        "            ]\n",
        "        },\n",
        "        \"itsukushima_shrine\": {\n",
        "            \"name\": \"Itsukushima Shrine\",\n",
        "            \"aliases\": [\"嚴島神社\", \"Miyajima Shrine\"],\n",
        "            \"location\": \"Miyajima Island, Hiroshima, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic vermilion 'floating' torii gate of Itsukushima Shrine in Miyajima, appearing to float on the water during high tide\",\n",
        "                \"Itsukushima Shrine complex, a UNESCO World Heritage site, built on stilts over the sea, with its distinctive red-lacquered corridors and halls\",\n",
        "                \"sacred wild deer roaming freely around Miyajima Island with the Itsukushima Shrine and its torii gate in the background\",\n",
        "                \"Itsukushima Shrine and its torii gate illuminated at night, creating a mystical scene\",\n",
        "                \"view of Itsukushima Shrine from Mount Misen or from a ferry approaching Miyajima Island\"\n",
        "            ]\n",
        "        },\n",
        "        \"gyeongbokgung_palace\": {\n",
        "            \"name\": \"Gyeongbokgung Palace\",\n",
        "            \"aliases\": [\"경복궁\", \"Gyeongbok Palace\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Gyeongbokgung Palace in Seoul, the largest and most stunning of Seoul's five grand Joseon Dynasty palaces\",\n",
        "                \"the main royal palace of the Joseon dynasty, Gyeongbokgung, with its grand Gwanghwamun Gate and Heungnyemun Gate\",\n",
        "                \"traditional Korean architecture at Gyeongbokgung Palace, featuring intricate Dancheong (colorful painted patterns) on wooden structures and elegant curved roofs\",\n",
        "                \"the impressive Geunjeongjeon Hall (Imperial Throne Hall) and the picturesque Gyeonghoeru Pavilion (Royal Banquet Hall) on a pond at Gyeongbokgung Palace\",\n",
        "                \"Changing of the Royal Guard ceremony (Sumunjang Gyedaeui) taking place at Gyeongbokgung Palace\"\n",
        "            ]\n",
        "        },\n",
        "        \"n_seoul_tower\": {\n",
        "            \"name\": \"N Seoul Tower\",\n",
        "            \"aliases\": [\"N서울타워\", \"YTN Seoul Tower\", \"Namsan Tower\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of N Seoul Tower perched atop Namsan Mountain, offering panoramic views of Seoul\",\n",
        "                \"N Seoul Tower illuminated with vibrant LED lights at night, changing colors and patterns, visible from across the city\",\n",
        "                \"the iconic N Seoul Tower in South Korea, a popular landmark with its observation deck and 'love locks' fences\",\n",
        "                \"view from the N Seoul Tower looking down on the sprawling cityscape of Seoul, day or night\",\n",
        "                \"cable car ascending Namsan Mountain towards the N Seoul Tower\"\n",
        "            ]\n",
        "        },\n",
        "        \"bukchon_hanok_village\": {\n",
        "            \"name\": \"Bukchon Hanok Village\",\n",
        "            \"aliases\": [\"북촌한옥마을\", \"Traditional Korean Village\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Bukchon Hanok Village in Seoul, a preserved traditional Korean village with hundreds of hanok (traditional Korean houses)\",\n",
        "                \"traditional Korean houses (hanok) in Bukchon Village, featuring distinctive tiled roofs, wooden beams, and courtyards, nestled on a hillside\",\n",
        "                \"narrow, winding alleyways and cobblestone streets of Bukchon Hanok Village, offering glimpses into historic Seoul\",\n",
        "                \"view of modern Seoul skyline contrasting with the traditional rooftops of Bukchon Hanok Village\",\n",
        "                \"people wearing Hanbok (traditional Korean attire) walking through Bukchon Hanok Village\"\n",
        "            ]\n",
        "        },\n",
        "        \"myeongdong_shopping_street\": {\n",
        "            \"name\": \"Myeongdong Shopping Street\",\n",
        "            \"aliases\": [\"명동 쇼핑거리\", \"Myeong-dong\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"bustling Myeongdong shopping street in Seoul, a paradise for cosmetics, fashion, and K-pop merchandise, packed with shoppers and vibrant storefronts\",\n",
        "                \"crowds of shoppers navigating the pedestrian-friendly streets of Myeongdong, with bright neon signs and music from stores creating a lively atmosphere, especially at night\",\n",
        "                \"vibrant street food scene in Myeongdong, Seoul, with numerous stalls offering popular Korean snacks like tteokbokki, gyeranppang, and tornado potatoes\",\n",
        "                \"Myeongdong Cathedral, a historic Gothic-style church, standing amidst the bustling modern shopping district\",\n",
        "                \"large department stores and international brands alongside local boutiques in Myeongdong\"\n",
        "            ]\n",
        "        },\n",
        "        \"dmz_korea\": {\n",
        "            \"name\": \"DMZ (Korean Demilitarized Zone)\",\n",
        "            \"aliases\": [\"韓國非軍事區\", \"Panmunjom\", \"JSA\"],\n",
        "            \"location\": \"Gyeonggi-do, South Korea / North Korea\",\n",
        "            \"prompts\": [\n",
        "                \"the heavily fortified Korean Demilitarized Zone (DMZ) separating North and South Korea, with barbed wire fences and guard posts\",\n",
        "                \"Joint Security Area (JSA) or Panmunjom at the DMZ, with soldiers from North and South Korea facing each other across the Military Demarcation Line\",\n",
        "                \"the iconic blue conference buildings straddling the border within the JSA at the DMZ\",\n",
        "                \"tense and somber atmosphere of the DMZ, a symbol of the Korean War and the divided peninsula\",\n",
        "                \"observation posts like Dora Observatory overlooking North Korean territory from the DMZ\"\n",
        "            ]\n",
        "        },\n",
        "        \"busan_gamcheon_culture_village\": {\n",
        "            \"name\": \"Busan Gamcheon Culture Village\",\n",
        "            \"aliases\": [\"부산 감천문화마을\", \"Machu Picchu of Busan\", \"Taegukdo Village\"],\n",
        "            \"location\": \"Busan, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"colorful houses built in terraced fashion on a steep hillside in Gamcheon Culture Village, Busan, often called the 'Machu Picchu of Busan'\",\n",
        "                \"narrow, winding alleyways adorned with vibrant street art, colorful murals, and art installations in Gamcheon Culture Village\",\n",
        "                \"panoramic view of the brightly painted houses of Gamcheon Culture Village cascading down to the sea, creating a unique urban landscape\",\n",
        "                \"sculptures like 'The Little Prince and the Desert Fox' overlooking the village in Gamcheon Culture Village\",\n",
        "                \"artistic and quirky atmosphere of Gamcheon Culture Village, a regenerated slum transformed into an art hub\"\n",
        "            ]\n",
        "        },\n",
        "        \"jeju_island\": {\n",
        "            \"name\": \"Jeju Island\",\n",
        "            \"aliases\": [\"제주도\", \"Jejudo\"],\n",
        "            \"location\": \"Jeju Province, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"volcanic landscape of Jeju Island, South Korea, a UNESCO World Heritage site, featuring black basalt rock formations (like Jusangjeolli Cliff) and lush greenery\",\n",
        "                \"Seongsan Ilchulbong (Sunrise Peak), a dramatic tuff cone crater rising from the sea on the eastern coast of Jeju Island\",\n",
        "                \"beautiful sandy beaches like Hyeopjae Beach, waterfalls such as Cheonjeyeon Falls, and lava tubes like Manjanggul Cave on Jeju Island\",\n",
        "                \"Hallasan National Park, home to South Korea's highest mountain, Hallasan, a dormant shield volcano, on Jeju Island\",\n",
        "                \"Dol Hareubang (stone grandfathers), iconic black lava stone statues found throughout Jeju Island\"\n",
        "            ]\n",
        "        },\n",
        "        \"changdeokgung_palace_secret_garden\": {\n",
        "            \"name\": \"Changdeokgung Palace & Secret Garden\",\n",
        "            \"aliases\": [\"창덕궁과 후원\", \"Donggwol (East Palace)\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"the beautiful Changdeokgung Palace, a UNESCO World Heritage site in Seoul, known for its harmonious design that blends with the natural landscape\",\n",
        "                \"traditional Korean palace architecture of Changdeokgung, including the Injeongjeon (main throne hall) and Donhwamun (main gate)\",\n",
        "                \"the serene and picturesque Secret Garden (Huwon) of Changdeokgung Palace, a vast rear garden with pavilions, ponds, and ancient trees, requiring a guided tour\",\n",
        "                \"Buyongjeong Pavilion and Buyongji Pond in the Secret Garden of Changdeokgung Palace\",\n",
        "                \"Changdeokgung Palace as one of the best-preserved Joseon Dynasty palaces\"\n",
        "            ]\n",
        "        },\n",
        "        \"great_wall\": {\n",
        "            \"name\": \"Great Wall of China\",\n",
        "            \"aliases\": [\"长城\", \"The Great Wall\", \"萬里長城\"],\n",
        "            \"location\": \"China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Great Wall of China, the massive ancient fortification winding across rugged mountains and diverse terrains\",\n",
        "                \"the Great Wall stretching for thousands of miles, with watchtowers and battlements, a testament to ancient Chinese engineering\",\n",
        "                \"sections of the Great Wall like Badaling or Mutianyu, showing its impressive scale and historical significance\",\n",
        "                \"the Great Wall of China snaking along steep mountain ridges, often covered in snow or surrounded by lush greenery\",\n",
        "                \"iconic man-made structure, the Great Wall, visible from afar, symbolizing China's strength and history\"\n",
        "            ]\n",
        "        },\n",
        "        \"forbidden_city\": {\n",
        "            \"name\": \"Forbidden City\",\n",
        "            \"aliases\": [\"紫禁城\", \"Palace Museum\", \"故宫博物院\"],\n",
        "            \"location\": \"Beijing, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Forbidden City in Beijing, the vast imperial palace complex with its iconic red walls and yellow-tiled roofs\",\n",
        "                \"the imperial palace complex of the Forbidden City, former home to Chinese emperors, showcasing classical Chinese palatial architecture\",\n",
        "                \"courtyards, halls, and gates of the Forbidden City, such as the Hall of Supreme Harmony, arranged along a central axis\",\n",
        "                \"intricate details and symbolic ornamentation of the Forbidden City's buildings, reflecting imperial power and Chinese cosmology\",\n",
        "                \"the Meridian Gate (Wumen), the main entrance to the Forbidden City, or the Corner Towers with their complex roof structures\"\n",
        "            ]\n",
        "        },\n",
        "        \"terracotta_army\": {\n",
        "            \"name\": \"Terracotta Army\",\n",
        "            \"aliases\": [\"兵马俑\", \"Terracotta Warriors and Horses\"],\n",
        "            \"location\": \"Xi'an, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Terracotta Army in Xi'an, rows of life-sized terracotta warriors, archers, and chariots in vast pits\",\n",
        "                \"thousands of life-sized terracotta warriors and horses, each with unique facial expressions and armor, part of Qin Shi Huang's mausoleum\",\n",
        "                \"archaeological site of the Terracotta Army, a UNESCO World Heritage site, showcasing the incredible artistry and scale of ancient Chinese burial practices\",\n",
        "                \"close-up of the detailed faces and uniforms of the Terracotta Warriors\",\n",
        "                \"excavation pits containing the Terracotta Army, demonstrating the ongoing discovery and preservation efforts\"\n",
        "            ]\n",
        "        },\n",
        "        \"the_bund\": {\n",
        "            \"name\": \"The Bund\",\n",
        "            \"aliases\": [\"外滩\", \"Waitan\"],\n",
        "            \"location\": \"Shanghai, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of The Bund waterfront in Shanghai, with its impressive collection of historic colonial-era buildings in various architectural styles\",\n",
        "                \"skyline of The Bund featuring iconic early 20th-century buildings, contrasting with the modern skyscrapers of Pudong across the Huangpu River\",\n",
        "                \"The Bund overlooking the Huangpu River, with boats and ferries, and the Oriental Pearl Tower and Shanghai Tower visible on the Pudong side\",\n",
        "                \"pedestrian promenade along The Bund, a popular spot for tourists and locals to view Shanghai's historic and modern skylines\",\n",
        "                \"The Bund at night, with both the historic buildings and the Pudong skyline brilliantly illuminated\"\n",
        "            ]\n",
        "        },\n",
        "        \"li_river_guilin\": {\n",
        "            \"name\": \"Li River, Guilin\",\n",
        "            \"aliases\": [\"漓江\", \"Guilin Karst Landscape\"],\n",
        "            \"location\": \"Guilin, Guangxi, China\",\n",
        "            \"prompts\": [\n",
        "                \"surreal karst mountain landscape along the Li River in Guilin, China, with picturesque limestone peaks rising dramatically from the flat terrain\",\n",
        "                \"bamboo rafts and cruise boats navigating the scenic Li River, surrounded by mist-shrouded, unusually shaped karst formations\",\n",
        "                \"iconic view of the Li River, often depicted in traditional Chinese landscape paintings, particularly the scene on the 20 Yuan banknote (Yellow Cloth Shoal)\",\n",
        "                \"cormorant fishermen on bamboo rafts on the Li River\",\n",
        "                \"lush green vegetation covering the steep karst hills along the banks of the winding Li River\"\n",
        "            ]\n",
        "        },\n",
        "        \"potala_palace\": {\n",
        "            \"name\": \"Potala Palace\",\n",
        "            \"aliases\": [\"布達拉宮\"],\n",
        "            \"location\": \"Lhasa, Tibet, China\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic Potala Palace, former winter residence of the Dalai Lama, dramatically situated on Red Hill (Marpo Ri) in Lhasa, Tibet\",\n",
        "                \"distinctive white (White Palace) and red (Red Palace) architecture of the Potala Palace against a clear blue sky and surrounding mountains\",\n",
        "                \"the imposing Potala Palace, a UNESCO World Heritage site, a symbol of Tibetan Buddhism and a marvel of Tibetan architecture with its many chapels and statues\",\n",
        "                \"Potala Palace with prayer flags fluttering in the foreground\",\n",
        "                \"view of Potala Palace from afar, showcasing its grand scale and dominant position over Lhasa\"\n",
        "            ]\n",
        "        },\n",
        "        \"zhangjiajie_national_forest_park\": {\n",
        "            \"name\": \"Zhangjiajie National Forest Park\",\n",
        "            \"aliases\": [\"張家界國家森林公園\", \"Avatar Mountains\"],\n",
        "            \"location\": \"Hunan, China\",\n",
        "            \"prompts\": [\n",
        "                \"tall, pillar-like quartz-sandstone formations, often shrouded in mist, in Zhangjiajie National Forest Park, inspiration for the 'Avatar Hallelujah Mountains'\",\n",
        "                \"the 'Avatar Hallelujah Mountains' (formerly Southern Sky Column) in Zhangjiajie, known for their gravity-defying appearance and lush vegetation\",\n",
        "                \"glass bridges like the Zhangjiajie Grand Canyon Glass Bridge, and cable cars offering stunning, vertigo-inducing views of the unique landscape of Zhangjiajie\",\n",
        "                \"Bailong Elevator (Hundred Dragons Elevator), a massive glass elevator built onto the side of a cliff in Zhangjiajie\",\n",
        "                \"dense forests and deep ravines characterize the otherworldly scenery of Zhangjiajie National Forest Park\"\n",
        "            ]\n",
        "        },\n",
        "        \"west_lake_hangzhou\": {\n",
        "            \"name\": \"West Lake, Hangzhou\",\n",
        "            \"aliases\": [\"西湖\"],\n",
        "            \"location\": \"Hangzhou, China\",\n",
        "            \"prompts\": [\n",
        "                \"the serene and beautiful West Lake in Hangzhou, China, a UNESCO World Heritage site, famous for its scenic beauty, pagodas, islands, and causeways\",\n",
        "                \"iconic landmarks of West Lake such as the Broken Bridge (Duan Qiao), Leifeng Pagoda, Su Causeway, and Bai Causeway\",\n",
        "                \"traditional Chinese pavilions, arched bridges, and gardens surrounding West Lake, often depicted in Chinese art and poetry\",\n",
        "                \"boats gently gliding on West Lake, with willow trees lining its shores and lotus flowers blooming in summer\",\n",
        "                \"Three Ponds Mirroring the Moon, one of the most famous sights of West Lake\"\n",
        "            ]\n",
        "        },\n",
        "        \"summer_palace_beijing\": {\n",
        "            \"name\": \"Summer Palace, Beijing\",\n",
        "            \"aliases\": [\"頤和園\", \"Yiheyuan\"],\n",
        "            \"location\": \"Beijing, China\",\n",
        "            \"prompts\": [\n",
        "                \"the vast imperial garden of the Summer Palace in Beijing, a UNESCO World Heritage site, featuring Kunming Lake and Longevity Hill\",\n",
        "                \"ornate palaces, temples, bridges, and pavilions within the Summer Palace, such as the Marble Boat, the Long Corridor (Chang Lang), and the Tower of Buddhist Incense (Foxiang Ge)\",\n",
        "                \"traditional Chinese landscape garden design of the Summer Palace, showcasing harmony between man-made structures and nature\",\n",
        "                \"Kunming Lake in the Summer Palace, with the Seventeen-Arch Bridge leading to Nanhu Island\",\n",
        "                \"Longevity Hill at the Summer Palace, crowned by impressive imperial buildings\"\n",
        "            ]\n",
        "        },\n",
        "        \"petronas_towers\": {\n",
        "            \"name\": \"Petronas Twin Towers\",\n",
        "            \"aliases\": [\"KLCC Twin Towers\", \"Menara Petronas\", \"Petronas Towers\"],\n",
        "            \"location\": \"Kuala Lumpur, Malaysia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Petronas Twin Towers in Kuala Lumpur, the world's tallest twin skyscrapers with their distinctive postmodern Islamic architectural motifs\",\n",
        "                \"the iconic Petronas Towers connected by a double-decker skybridge on the 41st and 42nd floors\",\n",
        "                \"Petronas Twin Towers brilliantly illuminated at night, a striking landmark in Kuala Lumpur's skyline\",\n",
        "                \"the multi-faceted, tapering design of the Petronas Twin Towers, inspired by Islamic geometric patterns\",\n",
        "                \"view of the Petronas Twin Towers from KLCC Park, with its fountains and gardens\"\n",
        "            ]\n",
        "        },\n",
        "        \"marina_bay_sands\": {\n",
        "            \"name\": \"Marina Bay Sands\",\n",
        "            \"aliases\": [\"MBS\", \"Singapore Skypark\"],\n",
        "            \"location\": \"Singapore\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Marina Bay Sands in Singapore, the iconic integrated resort featuring three soaring hotel towers topped by a massive cantilevered SkyPark\",\n",
        "                \"the Marina Bay Sands resort with its distinctive three towers and the ship-like Sands SkyPark housing an infinity pool, observation deck, and gardens\",\n",
        "                \"Marina Bay Sands overlooking the Singapore skyline and Marina Bay, often seen with the ArtScience Museum in the foreground\",\n",
        "                \"the impressive architecture of Marina Bay Sands, a symbol of modern Singapore, illuminated at night\",\n",
        "                \"Spectra light and water show in front of Marina Bay Sands\"\n",
        "            ]\n",
        "        },\n",
        "        \"gardens_by_the_bay\": {\n",
        "            \"name\": \"Gardens by the Bay\",\n",
        "            \"aliases\": [\"Singapore Gardens\", \"Supertree Grove\"],\n",
        "            \"location\": \"Singapore\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Gardens by the Bay in Singapore, a futuristic nature park known for its iconic Supertree Grove\",\n",
        "                \"the towering Supertree Grove at Gardens by the Bay, tree-like vertical gardens that light up spectacularly during the Garden Rhapsody show at night\",\n",
        "                \"Flower Dome and Cloud Forest, two massive cooled conservatories at Gardens by the Bay, housing diverse plant life from around the world\",\n",
        "                \"the OCBC Skyway, an aerial walkway offering panoramic views of the Supertrees and surrounding gardens\",\n",
        "                \"lush landscapes and innovative horticultural displays within Gardens by the Bay\"\n",
        "            ]\n",
        "        },\n",
        "        \"taj_mahal\": {\n",
        "            \"name\": \"Taj Mahal\",\n",
        "            \"aliases\": [\"Crown of Palaces\", \"Mumtaz Mahal\"],\n",
        "            \"location\": \"Agra, India\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Taj Mahal in Agra, the iconic ivory-white marble mausoleum renowned for its beauty and symmetry\",\n",
        "                \"the ivory-white marble mausoleum of the Taj Mahal, a UNESCO World Heritage site, built by Mughal emperor Shah Jahan\",\n",
        "                \"Taj Mahal reflected perfectly in its long सामने (frontal) water feature (reflecting pool), flanked by symmetrical gardens\",\n",
        "                \"the intricate marble inlay work (pietra dura) and calligraphy on the facade of the Taj Mahal\",\n",
        "                \"the central dome and four minarets of the Taj Mahal, a masterpiece of Mughal architecture\"\n",
        "            ]\n",
        "        },\n",
        "        \"angkor_wat\": {\n",
        "            \"name\": \"Angkor Wat\",\n",
        "            \"aliases\": [\"吳哥窟\", \"City of Temples\"],\n",
        "            \"location\": \"Siem Reap, Cambodia\",\n",
        "            \"prompts\": [\n",
        "                \"the magnificent temple complex of Angkor Wat in Cambodia, a UNESCO World Heritage site, with its iconic five lotus-bud shaped towers reflecting in a surrounding moat\",\n",
        "                \"intricate bas-reliefs and stone carvings depicting Hindu epics like the Ramayana and Mahabharata, and apsaras (celestial dancers) at Angkor Wat\",\n",
        "                \"sunrise over Angkor Wat, casting a golden glow on its ancient stone structures, the world's largest religious monument\",\n",
        "                \"the grand scale and symmetrical design of Angkor Wat, an architectural marvel of the Khmer Empire\",\n",
        "                \"causeway leading to the main entrance of Angkor Wat, often with monks in saffron robes\"\n",
        "            ]\n",
        "        },\n",
        "        \"ha_long_bay\": {\n",
        "            \"name\": \"Ha Long Bay\",\n",
        "            \"aliases\": [\"下龍灣\", \"Vịnh Hạ Long\"],\n",
        "            \"location\": \"Quảng Ninh Province, Vietnam\",\n",
        "            \"prompts\": [\n",
        "                \"thousands of towering limestone karsts and islets rising dramatically from the emerald green waters of Ha Long Bay, Vietnam, a UNESCO World Heritage site\",\n",
        "                \"traditional Vietnamese junk boats sailing majestically through the stunning seascape of Ha Long Bay\",\n",
        "                \"caves and grottoes, such as Thien Cung Cave or Dau Go Cave, hidden within the limestone islands of Ha Long Bay\",\n",
        "                \"floating fishing villages and pearl farms nestled among the karsts in Ha Long Bay\",\n",
        "                \"misty and ethereal atmosphere of Ha Long Bay, especially at dawn or dusk\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_everest\": {\n",
        "            \"name\": \"Mount Everest\",\n",
        "            \"aliases\": [\"聖母峰\", \"Sagarmatha\", \"Chomolungma\"],\n",
        "            \"location\": \"Mahalangur Himal, Nepal/China border\",\n",
        "            \"prompts\": [\n",
        "                \"the snow-covered, pyramid-shaped peak of Mount Everest, the world's highest mountain, towering above the Himalayan range\",\n",
        "                \"climbers and expeditions at Mount Everest Base Camp, with prayer flags and views of the Khumbu Icefall\",\n",
        "                \"majestic and formidable landscape of Mount Everest and surrounding Himalayan peaks like Lhotse and Nuptse, often with wispy clouds\",\n",
        "                \"the challenging south face or north face routes leading to the summit of Mount Everest\",\n",
        "                \"breathtaking aerial view of Mount Everest, highlighting its immense scale and icy terrain\"\n",
        "            ]\n",
        "        },\n",
        "        \"bagan\": {\n",
        "            \"name\": \"Bagan\",\n",
        "            \"aliases\": [\"蒲甘\", \"Pagan\"],\n",
        "            \"location\": \"Mandalay Region, Myanmar\",\n",
        "            \"prompts\": [\n",
        "                \"thousands of ancient Buddhist temples, pagodas, and stupas, mostly in reddish-brown brick, spread across the plains of Bagan, Myanmar, a UNESCO World Heritage site\",\n",
        "                \"hot air balloons drifting gracefully over the temple-studded landscape of Bagan at sunrise or sunset, creating a magical scene\",\n",
        "                \"archaeological zone of Bagan with its diverse stupas (like Shwezigon Pagoda) and temples (like Ananda Temple) dating back to the 9th-13th centuries\",\n",
        "                \"sunlight illuminating the ancient temples of Bagan, with intricate carvings and Buddha statues inside\",\n",
        "                \"view from a high temple in Bagan, offering a panoramic vista of countless religious structures\"\n",
        "            ]\n",
        "        },\n",
        "        \"grand_palace_wat_phra_kaew\": {\n",
        "            \"name\": \"The Grand Palace & Wat Phra Kaew\",\n",
        "            \"aliases\": [\"曼谷大皇宮與玉佛寺\", \"Royal Palace Bangkok\"],\n",
        "            \"location\": \"Bangkok, Thailand\",\n",
        "            \"prompts\": [\n",
        "                \"ornate and glittering architecture of the Grand Palace in Bangkok, former residence of the Kings of Siam, with its intricate details and golden spires\",\n",
        "                \"Wat Phra Kaew (Temple of the Emerald Buddha) within the Grand Palace complex, housing the highly revered Emerald Buddha statue carved from a single jade stone\",\n",
        "                \"intricate details, golden chedis (stupas), colorful mosaics made of glass and porcelain, and mythical guardian statues (yakshas) of Thai traditional architecture at the Grand Palace\",\n",
        "                \"the dazzling exteriors of the royal halls and temples within the Grand Palace grounds\",\n",
        "                \"crowds of visitors and worshippers at the magnificent Grand Palace and Wat Phra Kaew\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 歐洲地標\n",
        "    \"europe\": {\n",
        "        \"eiffel_tower\": {\n",
        "            \"name\": \"Eiffel Tower\",\n",
        "            \"aliases\": [\"Tour Eiffel\", \"The Iron Lady\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Eiffel Tower in Paris, the iconic wrought-iron lattice tower on the Champ de Mars\",\n",
        "                \"the iconic Eiffel Tower structure, its intricate ironwork and graceful curves against the Paris skyline\",\n",
        "                \"Eiffel Tower illuminated at night with its sparkling light show, a beacon in the City of Lights\",\n",
        "                \"view from the top of the Eiffel Tower overlooking Paris, including the Seine River and landmarks like the Arc de Triomphe\",\n",
        "                \"Eiffel Tower seen from the Trocadéro, providing a classic photographic angle\"\n",
        "            ]\n",
        "        },\n",
        "        \"louvre_museum\": {\n",
        "            \"name\": \"Louvre Museum\",\n",
        "            \"aliases\": [\"Musée du Louvre\", \"The Louvre Pyramid\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Louvre Museum in Paris, with its iconic glass pyramid designed by I. M. Pei contrasting with the historic Louvre Palace\",\n",
        "                \"the Louvre Pyramid at the entrance of the museum, reflecting the sky and surrounding palace wings\",\n",
        "                \"exterior of the historic Louvre Palace, a former royal palace, now one of the world's largest art museums\",\n",
        "                \"crowds of visitors entering the Louvre Museum through the pyramid or its underground entrance\",\n",
        "                \"the Louvre Museum at night, with the pyramid and palace illuminated\"\n",
        "            ]\n",
        "        },\n",
        "        \"mont_saint_michel\": {\n",
        "            \"name\": \"Mont Saint-Michel\",\n",
        "            \"aliases\": [\"Saint Michael's Mount (France)\", \"Abbaye du Mont-Saint-Michel\"],\n",
        "            \"location\": \"Normandy, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mont Saint-Michel in France, the stunning tidal island commune topped by a medieval Benedictine abbey\",\n",
        "                \"the tidal island and abbey of Mont Saint-Michel rising dramatically from the bay, surrounded by water at high tide or sand flats at low tide\",\n",
        "                \"Mont Saint-Michel at high tide, appearing as a fairytale castle floating on the water\",\n",
        "                \"the Gothic architecture of the Abbey of Mont Saint-Michel, with its towering spire and fortified walls\",\n",
        "                \"narrow winding streets and historic buildings leading up to the abbey on Mont Saint-Michel\"\n",
        "            ]\n",
        "        },\n",
        "        \"arc_de_triomphe\": {\n",
        "            \"name\": \"Arc de Triomphe\",\n",
        "            \"aliases\": [\"Triumphal Arch of the Star\", \"Arc de Triomphe de l'Étoile\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Arc de Triomphe in Paris, the monumental triumphal arch at the center of Place Charles de Gaulle (Place de l'Étoile)\",\n",
        "                \"the iconic Arc de Triomphe at the western end of the Champs-Élysées, adorned with intricate sculptures depicting Napoleonic victories\",\n",
        "                \"view from the top of the Arc de Triomphe, looking down the twelve radiating avenues, including the Champs-Élysées towards the Louvre\",\n",
        "                \"the Eternal Flame burning beneath the Arc de Triomphe at the Tomb of the Unknown Soldier\",\n",
        "                \"Arc de Triomphe illuminated at night, a symbol of French national pride\"\n",
        "            ]\n",
        "        },\n",
        "        \"big_ben\": {\n",
        "            \"name\": \"Big Ben (Elizabeth Tower)\", # Clarified name\n",
        "            \"aliases\": [\"Elizabeth Tower\", \"Westminster Clock Tower\", \"Clock Tower, Palace of Westminster\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Big Ben (Elizabeth Tower) clock tower with the Houses of Parliament (Palace of Westminster) in London, on the bank of the River Thames\",\n",
        "                \"the iconic Gothic Revival clock tower Big Ben with its four massive, illuminated clock faces in London\",\n",
        "                \"Big Ben tower with its distinctive golden clock face, intricate stonework, and cast-iron spire, a symbol of London and the UK\",\n",
        "                \"the famous Westminster clock tower Big Ben in Gothic revival style, meticulously restored with its original blue clock hands\",\n",
        "                \"close-up of Big Ben's clock face showing the Roman numerals and detailed craftsmanship\"\n",
        "            ]\n",
        "        },\n",
        "        \"stonehenge\": {\n",
        "            \"name\": \"Stonehenge\",\n",
        "            \"aliases\": [\"Prehistoric Monument\", \"Ring of Stones\"],\n",
        "            \"location\": \"Wiltshire, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Stonehenge in the UK, the mysterious prehistoric monument of massive standing stones arranged in a circular formation\",\n",
        "                \"the prehistoric stone circle of Stonehenge, a UNESCO World Heritage site, with its sarsens and bluestones\",\n",
        "                \"Stonehenge at sunset or sunrise, with dramatic lighting casting long shadows over the ancient stones\",\n",
        "                \"the unique trilithons (two upright stones topped by a lintel) of Stonehenge\",\n",
        "                \"the enigmatic landscape surrounding Stonehenge on Salisbury Plain\"\n",
        "            ]\n",
        "        },\n",
        "        \"tower_of_london\": {\n",
        "            \"name\": \"Tower of London\",\n",
        "            \"aliases\": [\"His Majesty's Royal Palace and Fortress of the Tower of London\", \"The Tower\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Tower of London, the historic medieval castle on the north bank of the River Thames\",\n",
        "                \"the imposing White Tower, the central keep of the Tower of London, with its Norman architecture\",\n",
        "                \"Crown Jewels of the United Kingdom on display within the Tower of London\",\n",
        "                \"Yeoman Warders ('Beefeaters') in their traditional Tudor uniforms at the Tower of London\",\n",
        "                \"Traitors' Gate at the Tower of London, a famous water gate leading from the Thames\"\n",
        "            ]\n",
        "        },\n",
        "        \"buckingham_palace\": {\n",
        "            \"name\": \"Buckingham Palace\",\n",
        "            \"aliases\": [\"British Royal Residence\", \"The Palace\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Buckingham Palace in London, the official residence and administrative headquarters of the monarch of the United Kingdom\",\n",
        "                \"the iconic facade of Buckingham Palace with the Queen's Guard (King's Guard) in their red tunics and bearskin hats\",\n",
        "                \"Changing of the Guard ceremony taking place in the forecourt of Buckingham Palace, a popular tourist attraction\",\n",
        "                \"the Victoria Memorial statue in front of Buckingham Palace\",\n",
        "                \"Buckingham Palace with the Royal Standard flag flying, indicating the monarch is in residence\"\n",
        "            ]\n",
        "        },\n",
        "        \"colosseum\": {\n",
        "            \"name\": \"Colosseum\",\n",
        "            \"aliases\": [\"Roman Colosseum\", \"Flavian Amphitheatre\", \"Colosseo\"],\n",
        "            \"location\": \"Rome, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Colosseum in Rome, the massive ancient Roman amphitheater, an icon of Imperial Rome\",\n",
        "                \"the ancient Roman Colosseum structure, with its elliptical shape, tiered seating, and arched exterior, partly in ruins\",\n",
        "                \"historic Colosseum amphitheater in Italy, where gladiatorial contests and public spectacles were held\",\n",
        "                \"the interior of the Colosseum, showing the hypogeum (underground structures) and remaining seating areas\",\n",
        "                \"the Colosseum illuminated at night, a powerful symbol of Roman history\"\n",
        "            ]\n",
        "        },\n",
        "        \"leaning_tower_of_pisa\": {\n",
        "            \"name\": \"Leaning Tower of Pisa\",\n",
        "            \"aliases\": [\"Torre pendente di Pisa\", \"Tower of Pisa\"],\n",
        "            \"location\": \"Pisa, Tuscany, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Leaning Tower of Pisa in Italy, the iconic white marble freestanding bell tower (campanile) of Pisa Cathedral, famous for its significant unintended tilt\",\n",
        "                \"the world-famous leaning cylindrical campanile of Pisa Cathedral, built of white marble with Romanesque architecture and multiple tiers of arched colonnades, noticeably tilted to one side\",\n",
        "                \"tourists taking humorous forced perspective photos with the Leaning Tower of Pisa\",\n",
        "                \"the Leaning Tower of Pisa located in the Piazza dei Miracoli (Square of Miracles), alongside the Duomo (cathedral) and Baptistery\",\n",
        "                \"the white marble cylindrical structure of the Leaning Tower of Pisa with its distinctive arched galleries, showing its dramatic lean\",\n",
        "                \"the iconic leaning cylindrical bell tower with six tiers of open galleries with arches and columns, against a blue sky, in Pisa, Italy\",\n",
        "                \"a global tourist landmark: Italy's Leaning Tower of Pisa, a tilted white marble tower with intricate Romanesque arcades\",\n",
        "                \"side view emphasizing the dramatic four-degree angle of the Leaning Tower's tilt, showcasing its unique structural imbalance\",\n",
        "                \"ornate white marble cylindrical tower with multiple levels of columns, visibly leaning to one side, a masterpiece of medieval engineering\",\n",
        "                \"the famous tilted bell tower of Pisa with its many columned galleries viewed from below, highlighting its precarious stance\",\n",
        "                \"detailed close-up of the Leaning Tower of Pisa's distinctive multi-tiered arched colonnades and ornate architectural details in white marble\",\n",
        "                \"the freestanding belltower of Pisa Cathedral set on the green grass of Piazza dei Miracoli, with its visible foundation on the low side where it sinks into the ground\",\n",
        "                \"a photo of the white marble Leaning Tower of Pisa, known for its nearly four-degree lean, a UNESCO World Heritage Site in Tuscany\"\n",
        "            ]\n",
        "        },\n",
        "        \"trevi_fountain\": {\n",
        "            \"name\": \"Trevi Fountain\",\n",
        "            \"aliases\": [\"Fontana di Trevi\"],\n",
        "            \"location\": \"Rome, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Trevi Fountain in Rome, the largest Baroque fountain in the city and one of the most famous fountains in the world\",\n",
        "                \"the spectacular Baroque Trevi Fountain with its grand sculptures, including Oceanus, tritons, and horses, set against the Palazzo Poli\",\n",
        "                \"people throwing coins over their shoulders into the Trevi Fountain, a tradition said to ensure a return to Rome\",\n",
        "                \"the Trevi Fountain illuminated at night, showcasing its dramatic statues and cascading water\",\n",
        "                \"the vibrant turquoise water of the Trevi Fountain contrasting with its white travertine stone\"\n",
        "            ]\n",
        "        },\n",
        "        \"st_peters_basilica\": {\n",
        "            \"name\": \"St. Peter's Basilica\",\n",
        "            \"aliases\": [\"Basilica di San Pietro\", \"Vatican Basilica\"],\n",
        "            \"location\": \"Vatican City\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of St. Peter's Basilica in Vatican City, the immense Renaissance church, one of the largest and most renowned churches in the world\",\n",
        "                \"the magnificent dome of St. Peter's Basilica, designed by Michelangelo, dominating the skyline of Rome and Vatican City\",\n",
        "                \"St. Peter's Square (Piazza San Pietro), designed by Bernini, with its grand colonnades, obelisk, and fountains, leading to the basilica\",\n",
        "                \"the lavish interior of St. Peter's Basilica, featuring masterpieces like Michelangelo's Pietà and Bernini's Baldachin\",\n",
        "                \"St. Peter's Basilica viewed from Via della Conciliazione or from the top of its dome\"\n",
        "            ]\n",
        "        },\n",
        "        \"sagrada_familia\": {\n",
        "            \"name\": \"Sagrada Familia\",\n",
        "            \"aliases\": [\"Basílica de la Sagrada Família\", \"Gaudi's Church\"],\n",
        "            \"location\": \"Barcelona, Spain\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Sagrada Familia in Barcelona, Antoni Gaudí's unfinished masterpiece of Catalan Modernism, a Roman Catholic minor basilica\",\n",
        "                \"the unique and highly ornate architecture of Gaudí's Sagrada Familia, with its towering spires, intricate facades (Nativity, Passion, Glory), and organic forms\",\n",
        "                \"construction cranes still present on the perpetually evolving Sagrada Familia\",\n",
        "                \"the stunning interior of Sagrada Familia, with its tree-like columns and vibrant stained-glass windows creating a forest of light\",\n",
        "                \"close-up details of the sculptural elements and symbolic decorations on the facades of Sagrada Familia\"\n",
        "            ]\n",
        "        },\n",
        "        \"alhambra\": {\n",
        "            \"name\": \"Alhambra\",\n",
        "            \"aliases\": [\"Alhambra Palace\", \"The Red Fortress\", \"Alhambra of Granada\"],\n",
        "            \"location\": \"Granada, Spain\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Alhambra palace and fortress complex in Granada, Spain, a stunning example of Moorish architecture\",\n",
        "                \"exquisite Moorish architecture of the Alhambra, featuring intricate stucco work, geometric tile patterns (azulejos), and delicate courtyards like the Court of the Lions\",\n",
        "                \"courtyards, palaces (Nasrid Palaces), and gardens (Generalife) of the Alhambra, showcasing Islamic art and design\",\n",
        "                \"the Alhambra perched on a hill overlooking the city of Granada, with the Sierra Nevada mountains in the background\",\n",
        "                \"the red-hued walls of the Alcazaba fortress within the Alhambra complex\"\n",
        "            ]\n",
        "        },\n",
        "        \"brandenburg_gate\": {\n",
        "            \"name\": \"Brandenburg Gate\",\n",
        "            \"aliases\": [\"Brandenburger Tor\", \"Berlin Gate\"],\n",
        "            \"location\": \"Berlin, Germany\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Brandenburg Gate in Berlin, the iconic neoclassical triumphal arch, a symbol of German reunification and peace\",\n",
        "                \"the neoclassical Brandenburg Gate monument, with its Doric columns and the Quadriga (a chariot drawn by four horses) скульптура наверху\",\n",
        "                \"Brandenburg Gate illuminated at night, standing at the end of Unter den Linden boulevard\",\n",
        "                \"historical significance of the Brandenburg Gate, once a symbol of division during the Cold War\",\n",
        "                \"Pariser Platz in front of the Brandenburg Gate, a lively public square\"\n",
        "            ]\n",
        "        },\n",
        "        \"neuschwanstein_castle\": {\n",
        "            \"name\": \"Neuschwanstein Castle\",\n",
        "            \"aliases\": [\"Schloss Neuschwanstein\", \"Fairy Tale Castle\", \"Mad King Ludwig's Castle\"],\n",
        "            \"location\": \"Bavaria, Germany\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Neuschwanstein Castle in Germany, the quintessential fairytale castle with its white limestone facade and blue turrets, inspiring Disney's Sleeping Beauty Castle\",\n",
        "                \"the fairytale Neuschwanstein Castle dramatically nestled in the Bavarian Alps, perched on a rugged hill overlooking the Hohenschwangau valley\",\n",
        "                \"Neuschwanstein Castle on a hill, often viewed from Marienbrücke (Mary's Bridge) for a classic postcard shot\",\n",
        "                \"the Romanesque Revival architecture of Neuschwanstein Castle, commissioned by King Ludwig II of Bavaria\",\n",
        "                \"Neuschwanstein Castle surrounded by autumn foliage or dusted with snow in winter\"\n",
        "            ]\n",
        "        },\n",
        "        \"acropolis_of_athens\": {\n",
        "            \"name\": \"Acropolis of Athens\",\n",
        "            \"aliases\": [\"Ακρόπολη Αθηνών\", \"Parthenon\", \"Sacred Rock\"],\n",
        "            \"location\": \"Athens, Greece\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Acropolis of Athens in Greece, the ancient citadel located on a rocky outcrop above the city, crowned by the Parthenon\",\n",
        "                \"the Parthenon, the iconic Doric temple dedicated to the goddess Athena, standing majestically on the Acropolis\",\n",
        "                \"ancient ruins of the Acropolis overlooking the sprawling city of Athens, including the Erechtheion with its Porch of the Caryatids, and the Propylaea\",\n",
        "                \"the Acropolis illuminated at night, a symbol of ancient Greek civilization and democracy\",\n",
        "                \"view of the Acropolis from Filopappou Hill or Lycabettus Hill\"\n",
        "            ]\n",
        "        },\n",
        "        \"santorini_oia\": { # Specified Oia for iconic view\n",
        "            \"name\": \"Santorini (Oia)\",\n",
        "            \"aliases\": [\"Thera\", \"Greek Islands\", \"Oia village Santorini\"],\n",
        "            \"location\": \"Cyclades, Greece\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Oia village in Santorini island, Greece, famous for its whitewashed cave houses and blue-domed churches clinging to cliffs above the Aegean Sea\",\n",
        "                \"iconic whitewashed villages with blue domes in Oia, Santorini, overlooking the volcanic caldera\",\n",
        "                \"breathtaking sunset over the caldera in Oia, Santorini, a world-famous romantic spectacle\",\n",
        "                \"narrow winding pathways and steps through the picturesque village of Oia\",\n",
        "                \"bougainvillea flowers adding splashes of color to the white buildings of Santorini\"\n",
        "            ]\n",
        "        },\n",
        "        \"canals_of_venice\": {\n",
        "            \"name\": \"Canals of Venice\",\n",
        "            \"aliases\": [\"Venetian Canals\", \"Rialto Bridge Venice\"],\n",
        "            \"location\": \"Venice, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"gondolas gliding gracefully through the narrow, winding canals of Venice, Italy, lined with historic, colorful buildings\",\n",
        "                \"the Grand Canal in Venice, its main waterway, bustling with vaporettos (water buses), water taxis, and gondolas, spanned by the iconic Rialto Bridge\",\n",
        "                \"romantic atmosphere of Venetian canals, reflecting the unique architecture of the sinking city, with smaller bridges connecting walkways\",\n",
        "                \"picturesque scenes of Venice's canals, often with laundry hanging between buildings or flower boxes on windowsills\",\n",
        "                \"Rio di Palazzo with the Bridge of Sighs connecting the Doge's Palace to the prisons\"\n",
        "            ]\n",
        "        },\n",
        "        \"florence_cathedral_duomo\": {\n",
        "            \"name\": \"Florence Cathedral (Duomo)\",\n",
        "            \"aliases\": [\"Cattedrale di Santa Maria del Fiore\", \"Il Duomo di Firenze\", \"Brunelleschi's Dome\"],\n",
        "            \"location\": \"Florence, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"Brunelleschi's massive, iconic red-tiled dome atop the Florence Cathedral (Santa Maria del Fiore), dominating the city skyline of Florence\",\n",
        "                \"the intricate Gothic and Renaissance facade of the Florence Duomo, made of white, green, and pink marble, alongside Giotto's Campanile (bell tower) and the Baptistery of St. John\",\n",
        "                \"panoramic view of Florence from the top of Brunelleschi's Dome or Giotto's Campanile, showcasing the sea of red-tiled roofs and the Arno River\",\n",
        "                \"the octagonal Florence Baptistery with its famous bronze doors, particularly Ghiberti's 'Gates of Paradise'\",\n",
        "                \"the grand interior of Florence Cathedral, with its vast nave and frescoes, including Vasari's 'Last Judgment' inside the dome\"\n",
        "            ]\n",
        "        },\n",
        "        \"anne_frank_house\": {\n",
        "            \"name\": \"Anne Frank House\",\n",
        "            \"aliases\": [\"Anne Frank Huis\", \"Secret Annex Amsterdam\"],\n",
        "            \"location\": \"Amsterdam, Netherlands\",\n",
        "            \"prompts\": [\n",
        "                \"the unassuming exterior of the Anne Frank House, a canal house on the Prinsengracht in Amsterdam, where Anne Frank and her family hid during WWII\",\n",
        "                \"the secret annex (Achterhuis) hidden behind a movable bookcase in the Anne Frank House, where the Frank family lived in hiding\",\n",
        "                \"poignant historical site of the Anne Frank House, now a biographical museum dedicated to Jewish wartime diarist Anne Frank and the Holocaust\",\n",
        "                \"long queues of visitors outside the Anne Frank House, waiting to enter the museum\",\n",
        "                \"the preserved rooms and exhibits within the Anne Frank House, telling the story of Anne's life and diary\"\n",
        "            ]\n",
        "        },\n",
        "        \"canals_of_amsterdam\": {\n",
        "            \"name\": \"Canals of Amsterdam\",\n",
        "            \"aliases\": [\"Grachtengordel Amsterdam\", \"Amsterdam Canal Ring\"],\n",
        "            \"location\": \"Amsterdam, Netherlands\",\n",
        "            \"prompts\": [\n",
        "                \"picturesque canals of Amsterdam, part of the Grachtengordel (canal belt), a UNESCO World Heritage site, lined with narrow, gabled canal houses and houseboats\",\n",
        "                \"bicycles parked along the charming bridges that cross Amsterdam's numerous canals, often adorned with flowers\",\n",
        "                \"canal cruise boats navigating the historic waterways of Amsterdam, offering views of 17th-century architecture\",\n",
        "                \"tree-lined canals of Amsterdam in different seasons, reflecting the elegant facades of the canal houses\",\n",
        "                \"the distinctive architecture of Amsterdam's canal houses, with their narrow fronts and decorative gables\"\n",
        "            ]\n",
        "        },\n",
        "        \"charles_bridge_prague\": {\n",
        "            \"name\": \"Charles Bridge\",\n",
        "            \"aliases\": [\"Karlův most\", \"Prague Stone Bridge\"],\n",
        "            \"location\": \"Prague, Czech Republic\",\n",
        "            \"prompts\": [\n",
        "                \"the historic Charles Bridge in Prague, a medieval stone arch bridge adorned with 30 statues of saints, crossing the Vltava River\",\n",
        "                \"view of Prague Castle and St. Vitus Cathedral from Charles Bridge, with artists, musicians, and vendors lining the bridge\",\n",
        "                \"Gothic Old Town Bridge Tower and Lesser Town Bridge Towers guarding both ends of Charles Bridge\",\n",
        "                \"Charles Bridge at dawn or dusk, with fewer crowds and atmospheric lighting, a symbol of Prague\",\n",
        "                \"statues on Charles Bridge, such as the statue of St. John of Nepomuk, often touched for good luck\"\n",
        "            ]\n",
        "        },\n",
        "        \"red_square_st_basils_cathedral\": {\n",
        "            \"name\": \"Red Square & St. Basil's Cathedral\",\n",
        "            \"aliases\": [\"Красная площадь\", \"Собор Василия Блаженного\", \"Moscow Kremlin\"],\n",
        "            \"location\": \"Moscow, Russia\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic, vibrantly colored onion domes of St. Basil's Cathedral (Cathedral of Vasily the Blessed) in Red Square, Moscow, a unique masterpiece of Russian architecture\",\n",
        "                \"Red Square, the historic central square of Moscow, with Lenin's Mausoleum, the fortified walls of the Kremlin, the State Historical Museum, and the GUM department store\",\n",
        "                \"historic and vast Red Square, a UNESCO World Heritage site, a focal point of Russian history and culture\",\n",
        "                \"St. Basil's Cathedral illuminated at night, its swirling patterns and bright colors standing out against the dark sky\",\n",
        "                \"the imposing Spasskaya Tower of the Moscow Kremlin overlooking Red Square\"\n",
        "            ]\n",
        "        },\n",
        "        \"edinburgh_castle\": {\n",
        "            \"name\": \"Edinburgh Castle\",\n",
        "            \"aliases\": [\"Castle Rock Edinburgh\"],\n",
        "            \"location\": \"Edinburgh, UK\",\n",
        "            \"prompts\": [\n",
        "                \"Edinburgh Castle perched dramatically atop Castle Rock, an extinct volcano, dominating the skyline of Edinburgh, Scotland\",\n",
        "                \"historic Scottish fortress, Edinburgh Castle, with its ancient ramparts, Crown Jewels of Scotland (Honours of Scotland), and St. Margaret's Chapel\",\n",
        "                \"view of the Royal Mile leading up to Edinburgh Castle, the historic heart of Edinburgh's Old Town\",\n",
        "                \"the One O'Clock Gun firing from Edinburgh Castle, a daily tradition\",\n",
        "                \"Edinburgh Castle illuminated at night, overlooking the city\"\n",
        "            ]\n",
        "        },\n",
        "        \"matterhorn\": {\n",
        "            \"name\": \"Matterhorn\",\n",
        "            \"aliases\": [\"Monte Cervino\", \"The Horn\"],\n",
        "            \"location\": \"Zermatt, Switzerland / Breuil-Cervinia, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"the distinctive, sharply defined pyramidal peak of the Matterhorn mountain in the Pennine Alps on the border between Switzerland and Italy\",\n",
        "                \"snow-covered Matterhorn against a clear blue sky, often reflected in a tranquil alpine lake like Riffelsee or Stellisee\",\n",
        "                \"iconic alpine scenery surrounding the Matterhorn, a world-famous mountaineering challenge and symbol of the Alps\",\n",
        "                \"the village of Zermatt, Switzerland, with traditional chalets and views of the Matterhorn\",\n",
        "                \"Matterhorn at sunrise or sunset (alpenglow), when the peak is bathed in golden or reddish light\"\n",
        "            ]\n",
        "        },\n",
        "        \"palace_of_versailles\": {\n",
        "            \"name\": \"Palace of Versailles\",\n",
        "            \"aliases\": [\"Château de Versailles\", \"Versailles Palace\"],\n",
        "            \"location\": \"Versailles, France\",\n",
        "            \"prompts\": [\n",
        "                \"the opulent Palace of Versailles, former principal royal residence of France, with its grand Hall of Mirrors (Galerie des Glaces) and lavish state apartments\",\n",
        "                \"expansive formal gardens of Versailles designed by André Le Nôtre, featuring geometric patterns, fountains (like the Latona Fountain), canals, and groves\",\n",
        "                \"luxurious Baroque architecture and lavish interiors of the Palace of Versailles, a UNESCO World Heritage site symbolizing absolute monarchy\",\n",
        "                \"the Grand Trianon and Petit Trianon, smaller palaces within the estate of Versailles, and Marie Antoinette's Hamlet\",\n",
        "                \"the facade of the Palace of Versailles overlooking the Place d'Armes\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 北美地標\n",
        "    \"north_america\": {\n",
        "        \"statue_of_liberty\": {\n",
        "            \"name\": \"Statue of Liberty\",\n",
        "            \"aliases\": [\"Liberty Enlightening the World\", \"Lady Liberty\"],\n",
        "            \"location\": \"New York Harbor, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Statue of Liberty in New York, the colossal neoclassical sculpture on Liberty Island, a symbol of freedom and democracy\",\n",
        "                \"the iconic Statue of Liberty with her torch held high and tabula ansata (tablet), a gift from France to the USA\",\n",
        "                \"Statue of Liberty on Liberty Island, with the Manhattan skyline or Ellis Island in the background\",\n",
        "                \"close-up of Lady Liberty's crowned head or her copper-green patina\",\n",
        "                \"ferry approaching the Statue of Liberty, offering panoramic views\"\n",
        "            ]\n",
        "        },\n",
        "        \"golden_gate_bridge\": {\n",
        "            \"name\": \"Golden Gate Bridge\",\n",
        "            \"aliases\": [\"Golden Gate\", \"GGB\"],\n",
        "            \"location\": \"San Francisco, California, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Golden Gate Bridge in San Francisco, its iconic Art Deco suspension bridge painted in 'International Orange'\",\n",
        "                \"the vibrant red-orange Golden Gate Bridge spanning the Golden Gate strait, often partially shrouded in fog\",\n",
        "                \"Golden Gate Bridge with its distinctive twin towers, soaring cables, and views of Alcatraz Island or the San Francisco skyline\",\n",
        "                \"view of the Golden Gate Bridge from various vantage points like Battery Spencer, Vista Point, or Baker Beach\",\n",
        "                \"cyclists or pedestrians crossing the Golden Gate Bridge\"\n",
        "            ]\n",
        "        },\n",
        "        \"grand_canyon\": {\n",
        "            \"name\": \"Grand Canyon\",\n",
        "            \"aliases\": [\"Grand Canyon National Park\", \"The Canyon\"],\n",
        "            \"location\": \"Arizona, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Grand Canyon in Arizona, a massive, steep-sided canyon carved by the Colorado River, showcasing layers of colorful rock\",\n",
        "                \"vast, awe-inspiring landscape of the Grand Canyon, with its immense scale, depth, and intricate formations\",\n",
        "                \"Colorado River flowing through the bottom of the Grand Canyon, visible from viewpoints like Mather Point or Yavapai Point on the South Rim\",\n",
        "                \"sunset or sunrise over the Grand Canyon, painting the canyon walls in vibrant hues of red, orange, and purple\",\n",
        "                \"hiking trails along the rim or into the Grand Canyon, such as Bright Angel Trail\"\n",
        "            ]\n",
        "        },\n",
        "        \"hollywood_sign\": {\n",
        "            \"name\": \"Hollywood Sign\",\n",
        "            \"aliases\": [\"Hollywoodland Sign\"],\n",
        "            \"location\": \"Mount Lee, Los Angeles, California, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Hollywood Sign in Los Angeles, the iconic white capital letters spelling out 'HOLLYWOOD' on the side of Mount Lee\",\n",
        "                \"the iconic Hollywood Sign overlooking the sprawling cityscape of Hollywood and Los Angeles\",\n",
        "                \"view of the Hollywood Sign from Griffith Observatory, Lake Hollywood Park, or a helicopter tour\",\n",
        "                \"the large, distinctive letters of the Hollywood Sign, a symbol of the American film industry\",\n",
        "                \"Hollywood Sign against a clear blue sky or at sunset with city lights below\"\n",
        "            ]\n",
        "        },\n",
        "        \"white_house\": {\n",
        "            \"name\": \"White House\",\n",
        "            \"aliases\": [\"President's House\", \"Executive Mansion\", \"1600 Pennsylvania Avenue\"],\n",
        "            \"location\": \"Washington D.C., USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the White House in Washington D.C., the official residence and workplace of the President of the United States\",\n",
        "                \"the iconic neoclassical facade of the White House, with its white columns and porticoes (North Portico and South Portico)\",\n",
        "                \"the North Portico of the White House facing Pennsylvania Avenue, or the South Lawn with the Oval Office view\",\n",
        "                \"the White House surrounded by its meticulously manicured gardens and security fencing\",\n",
        "                \"Marine One helicopter landing on the South Lawn of the White House\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_rushmore\": {\n",
        "            \"name\": \"Mount Rushmore\",\n",
        "            \"aliases\": [\"Mount Rushmore National Memorial\", \"Presidents' Mountain\"],\n",
        "            \"location\": \"Keystone, South Dakota, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mount Rushmore National Memorial, featuring the colossal carved faces of U.S. Presidents George Washington, Thomas Jefferson, Theodore Roosevelt, and Abraham Lincoln\",\n",
        "                \"the sculpted faces of four presidents carved into the granite face of Mount Rushmore in the Black Hills of South Dakota\",\n",
        "                \"Mount Rushmore with the Avenue of Flags leading to the Grand View Terrace\",\n",
        "                \"the immense scale and detailed carving of the presidential heads on Mount Rushmore\",\n",
        "                \"Mount Rushmore illuminated at night during the evening lighting ceremony\"\n",
        "            ]\n",
        "        },\n",
        "        \"times_square\": {\n",
        "            \"name\": \"Times Square\",\n",
        "            \"aliases\": [\"The Crossroads of the World\", \"The Great White Way\"],\n",
        "            \"location\": \"New York City, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Times Square in New York City, the bustling commercial intersection and entertainment hub, famous for its dazzling array of brightly lit billboards and advertisements\",\n",
        "                \"bright, massive digital billboards and flashing neon lights of Times Square at night, creating a vibrant and energetic atmosphere\",\n",
        "                \"bustling crowds of tourists and locals, yellow taxis, and costumed characters in Times Square\",\n",
        "                \"the New Year's Eve ball drop ceremony in Times Square\",\n",
        "                \"the TKTS booth with its red steps in Times Square, a popular spot for discounted Broadway tickets\"\n",
        "            ]\n",
        "        },\n",
        "        \"cn_tower\": {\n",
        "            \"name\": \"CN Tower\",\n",
        "            \"aliases\": [\"Canadian National Tower\", \"Toronto Tower\"],\n",
        "            \"location\": \"Toronto, Ontario, Canada\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the CN Tower in Toronto, the iconic slender communications and observation tower dominating the city's skyline\",\n",
        "                \"the tall, freestanding CN Tower with its distinctive main pod housing observation decks, a revolving restaurant, and the EdgeWalk\",\n",
        "                \"view from the top of the CN Tower, looking down through the glass floor or out at Lake Ontario and the Toronto Islands\",\n",
        "                \"CN Tower illuminated at night with programmable LED lights, often changing colors for special occasions\",\n",
        "                \"Toronto skyline featuring the CN Tower as its centerpiece\"\n",
        "            ]\n",
        "        },\n",
        "        \"chichen_itza\": {\n",
        "            \"name\": \"Chichen Itza\",\n",
        "            \"aliases\": [\"El Castillo\", \"Pyramid of Kukulcan\", \"Chichén Itzá\"],\n",
        "            \"location\": \"Yucatan Peninsula, Mexico\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Chichen Itza in Mexico, the ancient Mayan city and UNESCO World Heritage site, with its iconic El Castillo (Pyramid of Kukulcan)\",\n",
        "                \"the massive step-pyramid El Castillo at Chichen Itza, famous for the serpent shadow effect during the equinoxes\",\n",
        "                \"ancient ruins of Chichen Itza, including the Temple of Warriors, the Great Ball Court, and the Observatory (El Caracol)\",\n",
        "                \"intricate stone carvings and Mayan hieroglyphs found on the structures of Chichen Itza\",\n",
        "                \"the sacred cenote (sinkhole) at Chichen Itza, used for sacrifices\"\n",
        "            ]\n",
        "        },\n",
        "        \"niagara_falls\": {\n",
        "            \"name\": \"Niagara Falls\",\n",
        "            \"aliases\": [\"Horseshoe Falls\", \"American Falls\", \"Bridal Veil Falls\"],\n",
        "            \"location\": \"Ontario, Canada / New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"massive cascades of Niagara Falls, including the powerful Horseshoe Falls (Canadian Falls), the American Falls, and the smaller Bridal Veil Falls\",\n",
        "                \"mist rising dramatically from the thundering Niagara Falls, with tour boats like the Maid of the Mist or Hornblower navigating the turbulent waters below\",\n",
        "                \"Rainbow Bridge connecting Canada and the USA, with panoramic views of Niagara Falls\",\n",
        "                \"Niagara Falls illuminated with colorful lights at night, or with fireworks displays\",\n",
        "                \"Goat Island separating the American Falls and Horseshoe Falls, offering close-up views\"\n",
        "            ]\n",
        "        },\n",
        "        \"central_park\": {\n",
        "            \"name\": \"Central Park\",\n",
        "            \"aliases\": [\"Manhattan Central Park\"],\n",
        "            \"location\": \"New York City, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"vast green expanse of Central Park in Manhattan, New York City, an urban oasis surrounded by the towering skyscrapers of the city skyline\",\n",
        "                \"iconic locations within Central Park such as Bethesda Terrace and Fountain, Strawberry Fields (John Lennon memorial), Wollman Rink (ice skating), or the Central Park Carousel\",\n",
        "                \"people enjoying recreational activities like picnicking, boating on The Lake, jogging, or horse-drawn carriage rides in Central Park\",\n",
        "                \"lush lawns, wooded areas, walking paths, and picturesque bridges (like Bow Bridge or Gapstow Bridge) within Central Park\",\n",
        "                \"aerial view of Central Park, highlighting its rectangular shape amidst the dense urban grid of Manhattan\"\n",
        "            ]\n",
        "        },\n",
        "        \"las_vegas_strip\": {\n",
        "            \"name\": \"Las Vegas Strip\",\n",
        "            \"aliases\": [\"The Strip Las Vegas\", \"Las Vegas Boulevard South\"],\n",
        "            \"location\": \"Las Vegas, Nevada, USA\",\n",
        "            \"prompts\": [\n",
        "                \"the dazzling Las Vegas Strip at night, a vibrant spectacle of illuminated mega-resorts, opulent casinos, and world-class entertainment venues\",\n",
        "                \"iconic landmarks and themed hotels on the Las Vegas Strip such as the Bellagio fountains, the Eiffel Tower replica at Paris Las Vegas, the High Roller observation wheel, or the Venetian's canals\",\n",
        "                \"bustling energy, flashing neon signs, and extravagant architecture characterizing the world-famous Las Vegas Strip\",\n",
        "                \"pedestrians walking along the crowded sidewalks of the Las Vegas Strip, taking in the sights and sounds\",\n",
        "                \"the Fountains of Bellagio water show on the Las Vegas Strip\"\n",
        "            ]\n",
        "        },\n",
        "        \"yellowstone_national_park\": {\n",
        "            \"name\": \"Yellowstone National Park\",\n",
        "            \"aliases\": [\"Old Faithful Yellowstone\", \"Grand Prismatic Spring\"],\n",
        "            \"location\": \"Wyoming, Montana, Idaho, USA\",\n",
        "            \"prompts\": [\n",
        "                \"geothermal features of Yellowstone National Park, including the iconic Old Faithful geyser erupting steam and hot water into the air\",\n",
        "                \"the vibrant, rainbow-like colors of the Grand Prismatic Spring, the largest hot spring in the United States, in Yellowstone's Midway Geyser Basin\",\n",
        "                \"wildlife such as bison herds, elk, bears, and wolves roaming freely in the diverse landscapes of Yellowstone National Park, including forests, meadows, and rivers\",\n",
        "                \"the Grand Canyon of the Yellowstone, a dramatic canyon with impressive waterfalls like the Lower Falls\",\n",
        "                \"Mammoth Hot Springs in Yellowstone, with its terraced travertine formations\"\n",
        "            ]\n",
        "        },\n",
        "        \"banff_national_park_lake_louise\": { # Specified Lake Louise\n",
        "            \"name\": \"Banff National Park (Lake Louise / Moraine Lake)\",\n",
        "            \"aliases\": [\"Lake Louise Banff\", \"Moraine Lake Banff\", \"Canadian Rockies\"],\n",
        "            \"location\": \"Alberta, Canada\",\n",
        "            \"prompts\": [\n",
        "                \"the stunning turquoise glacial waters of Lake Louise in Banff National Park, with the majestic Victoria Glacier and Fairmont Chateau Lake Louise in the background\",\n",
        "                \"the equally breathtaking Moraine Lake in Banff National Park, with its vivid blue water backed by the rugged Valley of the Ten Peaks\",\n",
        "                \"stunning Canadian Rockies mountain scenery in Banff National Park, a UNESCO World Heritage site, with snow-capped peaks, alpine meadows, and pristine forests\",\n",
        "                \"canoeing or hiking around Lake Louise or Moraine Lake\",\n",
        "                \"wildlife like elk or grizzly bears sometimes spotted in Banff National Park\"\n",
        "            ]\n",
        "        },\n",
        "        \"space_needle_seattle\": {\n",
        "            \"name\": \"Space Needle\",\n",
        "            \"aliases\": [\"Seattle Space Needle\"],\n",
        "            \"location\": \"Seattle, Washington, USA\",\n",
        "            \"prompts\": [\n",
        "                \"the futuristic Space Needle observation tower in Seattle, Washington, with its distinctive saucer-shaped top and slender hourglass silhouette\",\n",
        "                \"panoramic view of Seattle's skyline, Puget Sound, Elliott Bay, and surrounding mountains like Mount Rainier from the Space Needle's observation deck or revolving restaurant\",\n",
        "                \"Space Needle as an icon of the Pacific Northwest and a legacy of the 1962 World's Fair\",\n",
        "                \"the Space Needle illuminated at night, a prominent feature of Seattle's cityscape\",\n",
        "                \"Chihuly Garden and Glass exhibit located at the base of the Space Needle\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 南美地標\n",
        "    \"south_america\": {\n",
        "        \"machu_picchu\": {\n",
        "            \"name\": \"Machu Picchu\",\n",
        "            \"aliases\": [\"Lost City of the Incas\", \"Machu Pikchu\"],\n",
        "            \"location\": \"Cusco Region, Peru\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Machu Picchu in Peru, the breathtaking ancient Inca citadel set high in the Andes Mountains, often shrouded in mist\",\n",
        "                \"the well-preserved ruins of the Inca city of Machu Picchu, with its intricate stone masonry, temples, plazas, and agricultural terraces\",\n",
        "                \"panoramic view of Machu Picchu ruins with Huayna Picchu mountain rising prominently in the background\",\n",
        "                \"llamas grazing among the ancient stone structures of Machu Picchu\",\n",
        "                \"sunrise over Machu Picchu, revealing its mystical beauty and stunning mountain setting\"\n",
        "            ]\n",
        "        },\n",
        "        \"christ_the_redeemer\": {\n",
        "            \"name\": \"Christ the Redeemer\",\n",
        "            \"aliases\": [\"Cristo Redentor\", \"Rio Jesus Statue\", \"Corcovado Statue\"],\n",
        "            \"location\": \"Rio de Janeiro, Brazil\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Christ the Redeemer statue in Rio de Janeiro, the colossal Art Deco statue of Jesus Christ with outstretched arms, standing atop Corcovado Mountain\",\n",
        "                \"the iconic soapstone statue of Jesus Christ on Corcovado Mountain, overlooking the city of Rio de Janeiro, Sugarloaf Mountain, and Guanabara Bay\",\n",
        "                \"Christ the Redeemer as a symbol of Christianity and a global icon of Rio de Janeiro and Brazil\",\n",
        "                \"view from the base of Christ the Redeemer statue, offering breathtaking panoramic vistas\",\n",
        "                \"Christ the Redeemer statue illuminated at night or silhouetted against a vibrant sunset\"\n",
        "            ]\n",
        "        },\n",
        "        \"iguazu_falls\": {\n",
        "            \"name\": \"Iguazu Falls\",\n",
        "            \"aliases\": [\"Iguaçu Falls\", \"Cataratas del Iguazú\", \"Cataratas do Iguaçu\", \"Devil's Throat Iguazu\"],\n",
        "            \"location\": \"Misiones Province, Argentina / Paraná State, Brazil\",\n",
        "            \"prompts\": [\n",
        "                \"expansive network of hundreds of powerful waterfalls at Iguazu Falls, spanning the border of Argentina and Brazil, surrounded by lush subtropical rainforest\",\n",
        "                \"the immense and thunderous Devil's Throat (Garganta del Diablo / Garganta do Diabo), the largest and most dramatic cataract of Iguazu Falls\",\n",
        "                \"walkways and viewpoints offering close-up, immersive experiences of the mighty Iguazu Falls, often with rainbows forming in the mist\",\n",
        "                \"boat tours venturing near the base of the waterfalls at Iguazu Falls\",\n",
        "                \"diverse wildlife like coatis and colorful birds in the Iguazu National Park surrounding the falls\"\n",
        "            ]\n",
        "        },\n",
        "        \"galapagos_islands\": {\n",
        "            \"name\": \"Galapagos Islands\",\n",
        "            \"aliases\": [\"Archipiélago de Colón\", \"Darwin's Islands\"],\n",
        "            \"location\": \"Ecuador\",\n",
        "            \"prompts\": [\n",
        "                \"unique and fearless wildlife of the Galapagos Islands, such as giant tortoises roaming freely, marine iguanas basking on volcanic rocks, and blue-footed boobies performing their mating dance\",\n",
        "                \"pristine volcanic landscapes, lava fields, and beautiful beaches (like Tortuga Bay) of the Galapagos Islands, a UNESCO World Heritage site that inspired Charles Darwin's theory of evolution\",\n",
        "                \"snorkeling or diving with sea lions, penguins, and diverse marine life in the clear waters surrounding the Galapagos Islands\",\n",
        "                \"various endemic species found only in the Galapagos, like Darwin's finches or flightless cormorants\",\n",
        "                \"cruise ships or small yachts exploring the different islands of the Galapagos archipelago\"\n",
        "            ]\n",
        "        },\n",
        "        \"torres_del_paine_national_park\": {\n",
        "            \"name\": \"Torres del Paine National Park\",\n",
        "            \"aliases\": [\"Parque Nacional Torres del Paine\", \"Paine Towers\"],\n",
        "            \"location\": \"Patagonia, Chile\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic granite peaks (Horns or Towers of Paine) of the Torres del Paine massif in Chilean Patagonia, often reflecting in turquoise glacial lakes like Pehoé or Nordenskjöld\",\n",
        "                \"stunning and wild landscapes of glaciers (like Grey Glacier), vibrant blue lakes, rivers, and mountains in Torres del Paine National Park, a UNESCO Biosphere Reserve\",\n",
        "                \"hiking trails like the 'W' trek or 'O' circuit offering breathtaking views of the dramatic Patagonian scenery in Torres del Paine\",\n",
        "                \"guanacos, condors, and other Patagonian wildlife in their natural habitat within Torres del Paine\",\n",
        "                \"the dramatic, windswept environment of Torres del Paine, known for its unpredictable weather\"\n",
        "            ]\n",
        "        },\n",
        "        \"angel_falls\": {\n",
        "            \"name\": \"Angel Falls\",\n",
        "            \"aliases\": [\"Salto Ángel\", \"Kerepakupai Merú\"],\n",
        "            \"location\": \"Canaima National Park, Venezuela\",\n",
        "            \"prompts\": [\n",
        "                \"Angel Falls, the world's tallest uninterrupted waterfall, cascading spectacularly from the sheer cliff face of Auyán-Tepui, a massive table-top mountain (tepui) in Venezuela's Canaima National Park\",\n",
        "                \"remote and dramatic jungle landscape surrounding Angel Falls, with tepuis rising from the savanna and rainforest\",\n",
        "                \"aerial view of Angel Falls plunging thousands of feet down the Auyán-Tepui, often shrouded in mist\",\n",
        "                \"expeditions by boat and foot through the remote wilderness to reach the base of Angel Falls\",\n",
        "                \"the sheer scale and pristine, untouched beauty of Angel Falls, a natural wonder\"\n",
        "            ]\n",
        "        },\n",
        "        \"salar_de_uyuni\": {\n",
        "            \"name\": \"Salar de Uyuni\",\n",
        "            \"aliases\": [\"Uyuni Salt Flat\"],\n",
        "            \"location\": \"Potosí, Bolivia\",\n",
        "            \"prompts\": [\n",
        "                \"vast, seemingly endless white expanse of the Salar de Uyuni salt flat in Bolivia, the world's largest salt desert, creating a surreal and minimalist landscape\",\n",
        "                \"mirror-like reflections on Salar de Uyuni during the rainy season (December-April), transforming the salt flat into the world's largest natural mirror, blurring the horizon between sky and ground\",\n",
        "                \"Isla Incahuasi (Fish Island) with its giant ancient cacti standing starkly against the white salt crust of Salar de Uyuni\",\n",
        "                \"geometric patterns of salt polygons on the dry Salar de Uyuni\",\n",
        "                \"creative forced perspective photographs taken by tourists on the Salar de Uyuni\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 中東/非洲地標\n",
        "    \"middle_east_africa\": {\n",
        "        \"pyramids_of_giza\": {\n",
        "            \"name\": \"Pyramids of Giza\",\n",
        "            \"aliases\": [\"Great Pyramids\", \"Egyptian Pyramids\", \"Giza Necropolis\"],\n",
        "            \"location\": \"Giza, Egypt (near Cairo)\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Pyramids of Giza in Egypt, the ancient wonder of the world, with the Great Pyramid, Pyramid of Khafre, and Pyramid of Menkaure\",\n",
        "                \"the ancient Egyptian pyramids on the Giza plateau, with the enigmatic Great Sphinx guarding them, against a desert backdrop or the Cairo skyline\",\n",
        "                \"Great Pyramid of Giza, the largest of the three, with the smaller Queen's Pyramids nearby\",\n",
        "                \"camels and horses carrying tourists around the Giza pyramid complex\",\n",
        "                \"sunset or sunrise over the Pyramids of Giza, casting long shadows\"\n",
        "            ]\n",
        "        },\n",
        "        \"burj_khalifa\": {\n",
        "            \"name\": \"Burj Khalifa\",\n",
        "            \"aliases\": [\"Khalifa Tower\", \"Dubai Tower\", \"World's Tallest Building\"],\n",
        "            \"location\": \"Dubai, UAE\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Burj Khalifa in Dubai, the world's tallest building, a sleek, tapering skyscraper piercing the sky\",\n",
        "                \"the ultra-modern skyscraper Burj Khalifa dominating the Dubai skyline with its impressive height and futuristic design\",\n",
        "                \"Burj Khalifa skyscraper rising above the Dubai Fountain and surrounding modern architecture\",\n",
        "                \"view from the observation deck ('At the Top') of Burj Khalifa, offering panoramic views of Dubai and the desert\",\n",
        "                \"Burj Khalifa illuminated with spectacular light shows at night\"\n",
        "            ]\n",
        "        },\n",
        "        \"petra_jordan\": { # Added Jordan to differentiate from any other Petra\n",
        "            \"name\": \"Petra\",\n",
        "            \"aliases\": [\"Rose City\", \"Lost City of Petra\", \"Al-Khazneh Petra\"],\n",
        "            \"location\": \"Ma'an Governorate, Jordan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Petra in Jordan, the ancient Nabataean city carved into rose-red sandstone cliffs, a UNESCO World Heritage site\",\n",
        "                \"the iconic Treasury (Al-Khazneh) in Petra, with its ornate facade intricately carved into a sandstone rock face, revealed at the end of the Siq (narrow gorge)\",\n",
        "                \"ancient city of Petra with its rock-cut architecture, including tombs, temples (like the Monastery, Ad Deir), and colonnaded streets\",\n",
        "                \"the Siq, a narrow, winding gorge that serves as the dramatic main entrance to the city of Petra\",\n",
        "                \"Bedouins with camels or donkeys in the ancient city of Petra\"\n",
        "            ]\n",
        "        },\n",
        "        \"table_mountain\": {\n",
        "            \"name\": \"Table Mountain\",\n",
        "            \"aliases\": [\"Tafelberg\", \"Cape Town Table Mountain\"],\n",
        "            \"location\": \"Cape Town, South Africa\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Table Mountain in Cape Town, the iconic flat-topped mountain majestically overlooking the city, Table Bay, and the Atlantic Ocean\",\n",
        "                \"the flat-topped Table Mountain, often covered by a 'tablecloth' of clouds, with Devil's Peak and Lion's Head adjacent to it\",\n",
        "                \"view from the rotating cable car ascending Table Mountain, or panoramic views from its summit\",\n",
        "                \"Cape Town city nestled at the foot of Table Mountain, with the V&A Waterfront visible\",\n",
        "                \"unique fynbos vegetation found on Table Mountain, part of the Cape Floral Kingdom\"\n",
        "            ]\n",
        "        },\n",
        "        \"sheikh_zayed_grand_mosque\": {\n",
        "            \"name\": \"Sheikh Zayed Grand Mosque\",\n",
        "            \"aliases\": [\"Grand Mosque Abu Dhabi\"],\n",
        "            \"location\": \"Abu Dhabi, UAE\",\n",
        "            \"prompts\": [\n",
        "                \"the stunning, pristine white marble Sheikh Zayed Grand Mosque in Abu Dhabi, with its numerous domes (82 of them) and four towering minarets\",\n",
        "                \"intricate floral designs inlaid with semi-precious stones, gold accents, and massive reflective pools surrounding the Sheikh Zayed Grand Mosque\",\n",
        "                \"the vast main prayer hall of Sheikh Zayed Grand Mosque, featuring the world's largest hand-knotted carpet and one of the world's largest Swarovski crystal chandeliers\",\n",
        "                \"the gleaming white exterior and symmetrical courtyards of Sheikh Zayed Grand Mosque, a masterpiece of modern Islamic architecture\",\n",
        "                \"Sheikh Zayed Grand Mosque illuminated at night with a unique lunar lighting system that changes with the phases of the moon\"\n",
        "            ]\n",
        "        },\n",
        "        \"masai_mara_national_reserve\": {\n",
        "            \"name\": \"Masai Mara National Reserve\",\n",
        "            \"aliases\": [\"Maasai Mara\", \"The Mara\"],\n",
        "            \"location\": \"Kenya\",\n",
        "            \"prompts\": [\n",
        "                \"vast, open savannas of the Masai Mara National Reserve in Kenya, teeming with iconic African wildlife like lions, elephants, giraffes, zebras, and wildebeest\",\n",
        "                \"the Great Migration of millions of wildebeest and zebras crossing the Mara River, often facing crocodiles, during their annual journey (July-October)\",\n",
        "                \"Masai people in their traditional vibrant red shuka robes, often seen near their villages or as safari guides in the Masai Mara\",\n",
        "                \"hot air balloons drifting over the plains of the Masai Mara at sunrise, offering a unique perspective on the landscape and wildlife\",\n",
        "                \"acacia trees silhouetted against a dramatic African sunset in the Masai Mara\"\n",
        "            ]\n",
        "        },\n",
        "        \"victoria_falls\": {\n",
        "            \"name\": \"Victoria Falls\",\n",
        "            \"aliases\": [\"Mosi-oa-Tunya\", \"The Smoke that Thunders\"],\n",
        "            \"location\": \"Livingstone, Zambia / Victoria Falls, Zimbabwe\",\n",
        "            \"prompts\": [\n",
        "                \"the spectacular, vast curtain of falling water at Victoria Falls, one of the largest waterfalls in the world by combined width and height, on the Zambezi River\",\n",
        "                \"a plume of mist (the 'smoke') rising high above Victoria Falls, visible for miles, and frequent rainbows forming in the spray\",\n",
        "                \"views of Victoria Falls from various viewpoints like the Knife-Edge Bridge, Danger Point, or from rainforest trails along the gorge\",\n",
        "                \"adventure activities at Victoria Falls, such as bungee jumping from the Victoria Falls Bridge or white-water rafting on the Zambezi\",\n",
        "                \"the Zambezi River plunging into the deep Batoka Gorge at Victoria Falls\"\n",
        "            ]\n",
        "        },\n",
        "        \"kilimanjaro\": {\n",
        "            \"name\": \"Mount Kilimanjaro\",\n",
        "            \"aliases\": [\"Uhuru Peak\", \"Kibo Kilimanjaro\", \"Africa's Highest Mountain\"],\n",
        "            \"location\": \"Tanzania\",\n",
        "            \"prompts\": [\n",
        "                \"the snow-capped, iconic peak of Mount Kilimanjaro, Africa's highest mountain and the world's tallest freestanding mountain, rising majestically from the plains of Tanzania\",\n",
        "                \"the distinctive flat-topped dormant volcano, Kilimanjaro, with its three volcanic cones (Kibo, Mawenzi, and Shira), a popular and challenging climbing destination\",\n",
        "                \"diverse ecosystems on the slopes of Kilimanjaro, transitioning from rainforest and moorland to alpine desert and arctic summit zones\",\n",
        "                \"porters and climbers on one of the routes (e.g., Machame, Lemosho) ascending Mount Kilimanjaro\",\n",
        "                \"Mount Kilimanjaro at sunrise or sunset, with its glaciers and snowfields gleaming\"\n",
        "            ]\n",
        "        },\n",
        "        \"dead_sea\": {\n",
        "            \"name\": \"Dead Sea\",\n",
        "            \"aliases\": [\"Salt Sea\"],\n",
        "            \"location\": \"Jordan / Israel / Palestine\",\n",
        "            \"prompts\": [\n",
        "                \"people floating effortlessly and buoyantly in the hyper-saline, turquoise waters of the Dead Sea, the lowest point on Earth's land surface\",\n",
        "                \"mineral-rich black mud from the Dead Sea being applied to the skin for therapeutic benefits, with salt formations along the shores\",\n",
        "                \"unique landscape of the Dead Sea, with its calm, dense waters reflecting the arid surrounding mountains and desert\",\n",
        "                \"evaporation ponds for mineral extraction at the southern end of the Dead Sea\",\n",
        "                \"salt crystals encrusting rocks and branches along the coastline of the Dead Sea\"\n",
        "            ]\n",
        "        },\n",
        "        \"dome_of_the_rock\": {\n",
        "            \"name\": \"Dome of the Rock\",\n",
        "            \"aliases\": [\"Qubbat as-Sakhrah\", \"Temple Mount Jerusalem\"],\n",
        "            \"location\": \"Old City of Jerusalem\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic, gleaming golden dome of the Dome of the Rock, an Islamic shrine located on the Temple Mount (Haram al-Sharif) in the Old City of Jerusalem\",\n",
        "                \"the octagonal structure of the Dome of the Rock, adorned with intricate blue and turquoise ceramic tilework, calligraphy, and mosaics\",\n",
        "                \"iconic religious landmark, the Dome of the Rock, a site of great significance in Islam, Judaism, and Christianity, within the historic walls of Jerusalem\",\n",
        "                \"view of the Dome of the Rock from the Mount of Olives, with the Old City in the background\",\n",
        "                \"the interior of the Dome of the Rock (if permissible to depict), showing the Foundation Stone\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 大洋洲地標\n",
        "    \"oceania\": {\n",
        "        \"sydney_opera_house\": {\n",
        "            \"name\": \"Sydney Opera House\",\n",
        "            \"aliases\": [\"Opera House Sydney\", \"Sydney Landmark\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Sydney Opera House in Australia, its iconic white sail-shaped shells creating a distinctive silhouette on Sydney Harbour\",\n",
        "                \"the multi-venue performing arts centre, Sydney Opera House, with its unique shell-like roof structures, a masterpiece of modern architecture\",\n",
        "                \"Sydney Opera House with the Sydney Harbour Bridge in the background, a classic view of Sydney's landmarks\",\n",
        "                \"the Sydney Opera House illuminated at night, often with colorful projections for events like Vivid Sydney\",\n",
        "                \"close-up of the textured, chevron-patterned tiles covering the shells of the Sydney Opera House\"\n",
        "            ]\n",
        "        },\n",
        "        \"uluru\": {\n",
        "            \"name\": \"Uluru\",\n",
        "            \"aliases\": [\"Ayers Rock\", \"The Rock\", \"Uluru-Kata Tjuta National Park\"],\n",
        "            \"location\": \"Northern Territory, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Uluru (Ayers Rock) in Australia, the massive, sacred sandstone monolith rising from the flat desert landscape of the Red Centre\",\n",
        "                \"the immense sandstone monolith of Uluru changing colors dramatically at sunrise or sunset, glowing in shades of red, orange, and purple\",\n",
        "                \"Uluru in the Red Centre of Australia, a significant spiritual site for Indigenous Anangu people, with visible rock caves and ancient rock art\",\n",
        "                \"the distinct shape and texture of Uluru, showing its weathered surface and gullies\",\n",
        "                \"Kata Tjuta (The Olgas) formations visible in the distance from Uluru\"\n",
        "            ]\n",
        "        },\n",
        "        \"great_barrier_reef\": {\n",
        "            \"name\": \"Great Barrier Reef\",\n",
        "            \"aliases\": [\"GBR\", \"World's Largest Coral Reef System\"],\n",
        "            \"location\": \"Queensland, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"an underwater photo of the Great Barrier Reef, showcasing its vibrant and diverse coral formations, colorful fish, and other marine life like sea turtles or manta rays\",\n",
        "                \"colorful hard and soft coral gardens thriving in the clear turquoise waters of the Great Barrier Reef, the world's largest coral reef system\",\n",
        "                \"aerial view of the Great Barrier Reef, revealing the intricate patterns of reefs, islands, and cays stretching along the Queensland coast\",\n",
        "                \"scuba divers or snorkelers exploring the rich biodiversity of the Great Barrier Reef\",\n",
        "                \"Heart Reef, a naturally formed heart-shaped coral formation in the Great Barrier Reef (often seen from the air)\"\n",
        "            ]\n",
        "        },\n",
        "        \"hobbiton_movie_set\": {\n",
        "            \"name\": \"Hobbiton Movie Set\",\n",
        "            \"aliases\": [\"The Shire Tour\", \"Lord of the Rings Set NZ\", \"Hobbiton New Zealand\"],\n",
        "            \"location\": \"Matamata, Waikato, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Hobbiton Movie Set in New Zealand, the picturesque movie set for The Shire from 'The Lord of the Rings' and 'The Hobbit' trilogies\",\n",
        "                \"charming, brightly colored circular Hobbit hole doors built into rolling green hills at the Hobbiton Movie Set, with meticulously tended gardens\",\n",
        "                \"the Green Dragon Inn at Hobbiton, a faithfully reconstructed pub where visitors can enjoy a drink\",\n",
        "                \"the Party Tree and Mill at Hobbiton, iconic locations from the movies, set within a lush pastoral landscape\",\n",
        "                \"guided tour groups exploring the whimsical and detailed Hobbiton Movie Set\"\n",
        "            ]\n",
        "        },\n",
        "        \"sydney_harbour_bridge\": {\n",
        "            \"name\": \"Sydney Harbour Bridge\",\n",
        "            \"aliases\": [\"The Coathanger Sydney\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic steel through arch of the Sydney Harbour Bridge, affectionately known as 'The Coathanger', spanning Sydney Harbour\",\n",
        "                \"people participating in the Sydney Harbour BridgeClimb, ascending the arch for panoramic views of the city and harbour\",\n",
        "                \"view of Sydney Harbour featuring both the Opera House and the Harbour Bridge together, a quintessential Sydney scene\",\n",
        "                \"ferries and sailboats passing under the massive Sydney Harbour Bridge\",\n",
        "                \"fireworks display over the Sydney Harbour Bridge during New Year's Eve celebrations\"\n",
        "            ]\n",
        "        },\n",
        "        \"fiordland_national_park_milford_sound\": { # Specified Milford Sound\n",
        "            \"name\": \"Fiordland National Park (Milford Sound / Doubtful Sound)\",\n",
        "            \"aliases\": [\"Milford Sound New Zealand\", \"Doubtful Sound Fiordland\"],\n",
        "            \"location\": \"South Island, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"dramatic fiords with sheer, towering cliffs and cascading waterfalls (like Stirling Falls or Bowen Falls) in Fiordland National Park, New Zealand, particularly Milford Sound\",\n",
        "                \"the iconic Mitre Peak rising sharply from the dark, reflective waters of Milford Sound in Fiordland, often shrouded in mist\",\n",
        "                \"boat cruises navigating through the stunning natural scenery of Milford Sound or the more remote Doubtful Sound, with seals, dolphins, or penguins sometimes spotted\",\n",
        "                \"lush rainforest clinging to the steep mountain sides of Fiordland National Park\",\n",
        "                \"the dramatic, moody atmosphere of Fiordland, known for its high rainfall and untouched wilderness\"\n",
        "            ]\n",
        "        },\n",
        "        \"bondi_beach\": {\n",
        "            \"name\": \"Bondi Beach\",\n",
        "            \"aliases\": [\"Bondi Sydney\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"the famous crescent-shaped Bondi Beach in Sydney, a popular destination with golden sand, turquoise waves, surfers, and sunbathers\",\n",
        "                \"Bondi Icebergs Club swimming pool, an ocean pool with waves crashing into it, located at the southern end of Bondi Beach\",\n",
        "                \"vibrant beach culture, surf lifesavers in their distinctive red and yellow uniforms, and bustling cafes along the promenade at Bondi Beach\",\n",
        "                \"the Bondi to Coogee coastal walk, offering stunning ocean views starting from Bondi Beach\",\n",
        "                \"aerial view of Bondi Beach, showcasing its iconic shape and lively atmosphere\"\n",
        "            ]\n",
        "        },\n",
        "        \"aoraki_mount_cook_national_park\": {\n",
        "            \"name\": \"Aoraki / Mount Cook National Park\",\n",
        "            \"aliases\": [\"Mount Cook New Zealand\", \"Lake Pukaki Mount Cook\", \"Hooker Valley Track\"],\n",
        "            \"location\": \"South Island, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic, snow-capped pyramid peak of Aoraki / Mount Cook, New Zealand's highest mountain, dominating the Southern Alps\",\n",
        "                \"glaciers like Tasman Glacier, alpine lakes with milky turquoise water (such as Lake Pukaki or Lake Tekapo often framed by colorful lupins in summer), and rugged mountain scenery in Aoraki / Mount Cook National Park\",\n",
        "                \"stargazing in the Aoraki Mackenzie International Dark Sky Reserve, with the silhouette of Aoraki / Mount Cook against a starry night sky\",\n",
        "                \"hiking trails like the Hooker Valley Track, offering spectacular views of Aoraki / Mount Cook, glaciers, and icebergs in Hooker Lake\",\n",
        "                \"the Hermitage Hotel or other alpine lodges with views of Aoraki / Mount Cook\"\n",
        "            ]\n",
        "        },\n",
        "        \"twelve_apostles_great_ocean_road\": { # Specified Great Ocean Road\n",
        "            \"name\": \"The Twelve Apostles, Great Ocean Road\",\n",
        "            \"aliases\": [\"Twelve Apostles Victoria\", \"Great Ocean Road Australia\"],\n",
        "            \"location\": \"Victoria, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"limestone stacks known as The Twelve Apostles (though fewer than twelve remain) rising dramatically from the Southern Ocean along the scenic Great Ocean Road in Victoria, Australia\",\n",
        "                \"coastal scenery with rugged cliffs, powerful wave erosion, and the iconic sea stacks of The Twelve Apostles site, especially at sunrise or sunset\",\n",
        "                \"sunset or sunrise over The Twelve Apostles rock formations, casting golden light and long shadows\",\n",
        "                \"viewing platforms offering panoramic vistas of The Twelve Apostles and the surrounding coastline\",\n",
        "                \"other nearby rock formations along the Great Ocean Road, like Loch Ard Gorge or London Arch (formerly London Bridge)\"\n",
        "            ]\n",
        "        },\n",
        "         \"easter_island_moai\": {\n",
        "            \"name\": \"Moai Statues, Easter Island\",\n",
        "            \"aliases\": [\n",
        "                \"Easter Island Heads\",\n",
        "                \"Rapa Nui Moai\",\n",
        "                \"復活節島摩艾石像\",\n",
        "                \"拉帕努伊島石像\",\n",
        "                \"摩艾\"\n",
        "            ],\n",
        "            \"location\": \"Easter Island (Rapa Nui), Chile\",\n",
        "            \"prompts\": [\n",
        "                \"colossal monolithic human figures known as moai, carved from volcanic rock, standing on Easter Island (Rapa Nui)\",\n",
        "                \"iconic giant stone heads and torsos of the moai statues with long ears and stoic expressions, dotting the coastal and inland landscapes of Easter Island\",\n",
        "                \"the mysterious moai statues of Rapa Nui, some with red scoria topknots (pukao), on ceremonial platforms called ahu\",\n",
        "                \"Ahu Tongariki featuring a line-up of fifteen imposing moai statues against the Pacific Ocean, Easter Island\",\n",
        "                \"moai statues in the Rano Raraku quarry, where they were carved, some partially buried or appearing to emerge from the hillside\",\n",
        "                \"the unique archaeological site of Easter Island, showcasing hundreds of ancient monolithic moai, a testament to Rapa Nui culture\",\n",
        "                \"weathered stone giants of Easter Island, their distinct profiles silhouetted against the sky or ocean, conveying a sense of ancient mystery\",\n",
        "                \"close-up of a moai's characteristic features: heavy brow, elongated nose, thin lips, and often deep eye sockets, Easter Island\",\n",
        "                \"a line of massive moai statues on an ahu platform overlooking the sea, representing deified ancestors of Rapa Nui\",\n",
        "                \"the remote and windswept landscape of Easter Island, punctuated by the enigmatic presence of its ancient moai statues\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 方便直接查詢所有地標\n",
        "ALL_LANDMARKS = {}\n",
        "for region, landmarks in LANDMARK_DATA.items():\n",
        "    for landmark_id, landmark_info in landmarks.items():\n",
        "        ALL_LANDMARKS[landmark_id] = landmark_info\n",
        "\n",
        "# 獲取所有地標提示列表（用於CLIP分析）\n",
        "def get_all_landmark_prompts():\n",
        "    \"\"\"\n",
        "    返回所有地標的提示列表，用於CLIP分析\n",
        "\n",
        "    Returns:\n",
        "        list: 提示列表\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    for landmark_id, landmark_info in ALL_LANDMARKS.items():\n",
        "        # 使用第一個提示作為主要提示\n",
        "        prompts.append(landmark_info[\"prompts\"][0])\n",
        "    return prompts\n",
        "\n",
        "# 獲取地標名稱到ID的映射\n",
        "def get_landmark_name_to_id_map():\n",
        "    \"\"\"\n",
        "    返回地標名稱到ID的映射\n",
        "\n",
        "    Returns:\n",
        "        dict: {地標名稱: 地標ID}\n",
        "    \"\"\"\n",
        "    name_to_id = {}\n",
        "    for landmark_id, landmark_info in ALL_LANDMARKS.items():\n",
        "        name_to_id[landmark_info[\"name\"]] = landmark_id\n",
        "        # 也添加所有別名\n",
        "        for alias in landmark_info[\"aliases\"]:\n",
        "            name_to_id[alias] = landmark_id\n",
        "    return name_to_id\n",
        "\n",
        "# 獲取某個區域的所有地標ID\n",
        "def get_landmarks_by_region(region):\n",
        "    \"\"\"\n",
        "    返回指定區域的所有地標ID\n",
        "\n",
        "    Args:\n",
        "        region (str): 區域名稱\n",
        "\n",
        "    Returns:\n",
        "        list: 地標ID列表\n",
        "    \"\"\"\n",
        "    if region not in LANDMARK_DATA:\n",
        "        return []\n",
        "    return list(LANDMARK_DATA[region].keys())\n",
        "\n",
        "# 獲取每個地標的代表性提示\n",
        "def get_landmark_prompt(landmark_id):\n",
        "    \"\"\"\n",
        "    返回指定地標的代表性提示\n",
        "\n",
        "    Args:\n",
        "        landmark_id (str): 地標ID\n",
        "\n",
        "    Returns:\n",
        "        str: 提示文本\n",
        "    \"\"\"\n",
        "    if landmark_id not in ALL_LANDMARKS:\n",
        "        return None\n",
        "    return ALL_LANDMARKS[landmark_id][\"prompts\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKbGJYo_ESn4"
      },
      "outputs": [],
      "source": [
        "# %%writefile landmark_activities.py\n",
        "\n",
        "\"\"\"\n",
        "Activity suggestions for specific landmarks.\n",
        "This module provides custom activity recommendations for recognized landmarks.\n",
        "\"\"\"\n",
        "\n",
        "LANDMARK_ACTIVITIES = {\n",
        "    # 亞洲地標 (Asia)\n",
        "    \"taipei_101\": [\n",
        "        \"Visiting the observation deck (89F, 91F, 101F) for panoramic city and mountain views\",\n",
        "        \"Shopping at the luxury mall at the base (Taipei 101 Mall)\",\n",
        "        \"Photographing the cityscape, especially at sunset or during the New Year's Eve fireworks display\",\n",
        "        \"Dining at high-altitude restaurants within the tower (e.g., Din Tai Fung, Starbucks on 35F)\",\n",
        "        \"Learning about the engineering marvels, including the tuned mass damper, through exhibits\",\n",
        "        \"Admiring the public art installations around the building and mall\"\n",
        "    ],\n",
        "    \"taroko_gorge\": [\n",
        "        \"Hiking scenic trails like Shakadang Trail (Mysterious Valley Trail), Baiyang Waterfall Trail (Water Curtain Cave), or Lushui Trail\",\n",
        "        \"Photographing the sheer marble cliffs, tunnels, and the turquoise Liwu River\",\n",
        "        \"Visiting the Eternal Spring Shrine (Changchun Shrine) and Bell Tower\",\n",
        "        \"Exploring Swallow Grotto (Yanzikou) and the Tunnel of Nine Turns (Jiuqudong) for close-up gorge views\",\n",
        "        \"Learning about the geology, ecology, and indigenous Truku culture at the visitor center\",\n",
        "        \"Cycling along parts of the gorge road (with extreme caution due to traffic and tunnels)\"\n",
        "    ],\n",
        "    \"sun_moon_lake\": [\n",
        "        \"Taking a boat tour across the lake, visiting Lalu Island, Xuanguang Temple, and Ita Thao Pier\",\n",
        "        \"Cycling or walking on the dedicated bike paths encircling the lake (e.g., Xiangshan to Shuishe section)\",\n",
        "        \"Visiting Wenwu Temple and Ci'en Pagoda for stunning lake views and cultural insights\",\n",
        "        \"Riding the Sun Moon Lake Ropeway (cable car) for aerial views and access to the Formosan Aboriginal Culture Village\",\n",
        "        \"Enjoying local Thao aboriginal cuisine and street food at Ita Thao village\",\n",
        "        \"Photographing the serene lake landscapes, especially at sunrise, sunset, or when mist-covered\"\n",
        "    ],\n",
        "    \"jiufen_old_street\": [\n",
        "        \"Wandering through the narrow, lantern-lined alleyways of Jiufen Old Street, especially Shuqi Road\",\n",
        "        \"Sampling local Taiwanese snacks like taro balls, fish balls, and peanut ice cream rolls\",\n",
        "        \"Visiting traditional teahouses (e.g., A-Mei Tea House) for tea and panoramic coastal views\",\n",
        "        \"Photographing the nostalgic atmosphere, red lanterns, and views of Keelung Mountain and the coastline\",\n",
        "        \"Shopping for local crafts, souvenirs, and ocarinas\",\n",
        "        \"Learning about Jiufen's gold mining history at the Gold Museum in nearby Jinguashi (optional day trip extension)\"\n",
        "    ],\n",
        "    \"kenting_national_park\": [\n",
        "        \"Relaxing, swimming, or surfing at popular beaches like Nanwan (South Bay), Baishawan (White Sand Bay), or Little Bay (Xiaowan)\",\n",
        "        \"Visiting Eluanbi Park to see the iconic Eluanbi Lighthouse, Taiwan's southernmost point\",\n",
        "        \"Exploring unique geological formations like Sail Rock (Chuanfanshi), Longpan Park's limestone cliffs, and Maobitou's coastal terrain\",\n",
        "        \"Snorkeling or scuba diving in the coral-rich waters (e.g., Houbihu Marine Protected Area)\",\n",
        "        \"Hiking trails in Sheding Nature Park or Kenting Forest Recreation Area\",\n",
        "        \"Enjoying the vibrant atmosphere and street food at Kenting Night Market on Kenting Street\"\n",
        "    ],\n",
        "    \"national_palace_museum_tw\": [\n",
        "        \"Viewing renowned masterpieces like the Jadeite Cabbage, Meat-shaped Stone, and Mao Gong Ding\",\n",
        "        \"Exploring extensive collections of Chinese imperial artifacts, calligraphy, paintings, ceramics, and bronzes\",\n",
        "        \"Taking a guided tour or using an audio guide to understand the historical and cultural context of the exhibits\",\n",
        "        \"Admiring the classical Chinese palace-style architecture of the museum building\",\n",
        "        \"Visiting the serene Zhishan Garden, a traditional Chinese garden adjacent to the museum\",\n",
        "        \"Attending special exhibitions and cultural events hosted by the museum\"\n",
        "    ],\n",
        "    \"alishan_national_scenic_area\": [\n",
        "        \"Watching the famous sunrise over a sea of clouds from Chushan or Ogasawara Mountain viewing platforms\",\n",
        "        \"Riding the Alishan Forest Railway on one of its scenic mountain routes (e.g., to Shenmu 'Sacred Tree' Station)\",\n",
        "        \"Hiking through misty forests of ancient giant trees (Taiwan red cypress and cedar) along trails like the Giant Tree Plank Trail\",\n",
        "        \"Visiting the Sister Ponds (Jiemei Tan) and Shouzhen Temple\",\n",
        "        \"Learning about Alishan's tea culture and sampling high-mountain oolong tea at local plantations\",\n",
        "        \"Photographing the cherry blossoms in spring or fireflies in summer\"\n",
        "    ],\n",
        "    \"shilin_night_market\": [\n",
        "        \"Sampling a wide variety of iconic Taiwanese street foods like oyster omelets, stinky tofu, giant fried chicken cutlets, and bubble tea\",\n",
        "        \"Exploring the bustling maze of food stalls, clothing shops, and souvenir vendors in the outdoor and underground sections\",\n",
        "        \"Playing traditional night market games like claw machines, balloon darts, and shrimp fishing\",\n",
        "        \"Shopping for trendy apparel, accessories, and electronics at affordable prices\",\n",
        "        \"Experiencing the vibrant and energetic atmosphere of one of Taipei's largest and most famous night markets\",\n",
        "        \"Trying unique snacks like flame-torched beef cubes or cheese-filled potatoes\"\n",
        "    ],\n",
        "    \"tokyo_tower\": [\n",
        "        \"Ascending to the main (150m) and top (250m) observation decks for panoramic views of Tokyo, including Mount Fuji on clear days\",\n",
        "        \"Photographing the tower, especially when illuminated with its iconic orange lights or special seasonal displays\",\n",
        "        \"Visiting the official 'FootTown' at the base, featuring souvenir shops, cafes, an aquarium, and an e-sports park\",\n",
        "        \"Enjoying refreshments or a meal at the tower's cafes or restaurants with city views\",\n",
        "        \"Learning about the tower's history, construction, and its role as a broadcasting tower\",\n",
        "        \"Visiting nearby Zojoji Temple for a cultural contrast and photo opportunities with the tower in the background\"\n",
        "    ],\n",
        "    \"mount_fuji\": [\n",
        "        \"Climbing to the summit during the official climbing season (typically early July to early September) via one of the four main trails\",\n",
        "        \"Photographing the iconic snow-capped conical peak from various viewpoints like the Fuji Five Lakes (especially Lake Kawaguchiko or Lake Yamanakako), Chureito Pagoda, or Hakone\",\n",
        "        \"Visiting the Fuji Five Lakes region for activities like boating, fishing, hot springs (onsen), and museums (e.g., Itchiku Kubota Art Museum)\",\n",
        "        \"Hiking or nature walking around the lower slopes, Aokigahara forest (Jukai), or Oshino Hakkai (traditional village with eight spring ponds)\",\n",
        "        \"Visiting Fuji-Q Highland amusement park for thrill rides with views of Mount Fuji\",\n",
        "        \"Learning about its volcanic geology, cultural significance (UNESCO World Heritage site), and spiritual importance in Shintoism and Buddhism\"\n",
        "    ],\n",
        "    \"kinkaku_ji\": [\n",
        "        \"Admiring and photographing the stunning Golden Pavilion (Shariden) meticulously covered in gold leaf, reflected in the Mirror Pond (Kyōko-chi)\",\n",
        "        \"Strolling through the meticulously maintained Japanese Muromachi period stroll garden (kaiyū-shiki teien)\",\n",
        "        \"Learning about the Zen Buddhist history of the temple, originally a retirement villa for Shogun Ashikaga Yoshimitsu\",\n",
        "        \"Observing the distinct architectural styles of each of the three floors of the pavilion\",\n",
        "        \"Making a wish by tossing coins at designated spots for good luck\",\n",
        "        \"Enjoying matcha tea and traditional sweets at the Sekkatei Teahouse or nearby tea houses (check availability)\"\n",
        "    ],\n",
        "    \"fushimi_inari_shrine\": [\n",
        "        \"Walking through the thousands of vibrant vermilion (shu-iro) torii gates that form tunnels along the mountain trails\",\n",
        "        \"Hiking the entire 4km (2-3 hour) trail up the sacred Mount Inari, exploring the network of paths and smaller shrines\",\n",
        "        \"Photographing the iconic, seemingly endless tunnels of torii gates, a symbol of prosperity and good fortune\",\n",
        "        \"Visiting the main shrine buildings (Go-Honden) at the base and offering prayers to Inari, the Shinto god of rice, sake, and business\",\n",
        "        \"Exploring smaller sub-shrines (otsuka) and atmospheric graveyards along the mountain trails\",\n",
        "        \"Looking for numerous fox statues (kitsune), considered messengers of Inari, often holding keys or jewels in their mouths\"\n",
        "    ],\n",
        "    \"shibuya_crossing\": [\n",
        "        \"Experiencing the 'scramble' by walking across the multi-directional intersection with hundreds of other pedestrians\",\n",
        "        \"Photographing or video recording the iconic crossing from a high vantage point, such as the Starbucks in the Tsutaya building or Mag's Park rooftop at Magnet by Shibuya109\",\n",
        "        \"People-watching and soaking in the vibrant, energetic atmosphere of modern Tokyo\",\n",
        "        \"Visiting the Hachiko statue, a famous meeting spot dedicated to the loyal Akita dog, located outside Shibuya Station\",\n",
        "        \"Shopping at the numerous department stores (e.g., Shibuya 109, Shibuya Sky) and trendy boutiques in the surrounding area\",\n",
        "        \"Exploring nearby entertainment venues, restaurants, and nightlife options\"\n",
        "    ],\n",
        "    \"tokyo_skytree\": [\n",
        "        \"Ascending to the Tembo Deck (350m) and Tembo Galleria (450m) for breathtaking panoramic views of Tokyo and beyond, including Mount Fuji on clear days\",\n",
        "        \"Photographing the modern architectural marvel, especially when illuminated with its signature 'Iki' (sky blue) or 'Miyabi' (purple) lights\",\n",
        "        \"Walking on the glass floor section of the Tembo Deck for a thrilling view downwards\",\n",
        "        \"Shopping and dining at Tokyo Solamachi, the large entertainment complex at the base of the Skytree, which includes an aquarium and planetarium\",\n",
        "        \"Learning about the tower's earthquake-resistant design and construction\",\n",
        "        \"Visiting nearby Sumida River for a different perspective of the tower and leisurely walks\"\n",
        "    ],\n",
        "    \"senso_ji_temple\": [\n",
        "        \"Entering through the Kaminarimon (Thunder Gate) with its giant red lantern and statues of Raijin and Fujin\",\n",
        "        \"Walking along Nakamise-dori, the bustling market street leading to the temple, lined with stalls selling traditional snacks, crafts, and souvenirs\",\n",
        "        \"Visiting the main hall (Hondo) dedicated to Kannon Bosatsu (Bodhisattva of Compassion) and the five-story pagoda\",\n",
        "        \"Wafting incense smoke from the large cauldron (jokoro) over oneself for good health and luck\",\n",
        "        \"Photographing the vibrant temple complex, its traditional architecture, and the lively atmosphere\",\n",
        "        \"Exploring the quieter Asakusa Shrine (a Shinto shrine) located next to Senso-ji\"\n",
        "    ],\n",
        "    \"osaka_castle\": [\n",
        "        \"Exploring the interior of the reconstructed castle keep (tenshukaku), which now serves as a museum detailing the castle's history and Toyotomi Hideyoshi\",\n",
        "        \"Ascending to the observation deck on the top floor of the castle keep for panoramic views of Osaka city and Osaka Castle Park\",\n",
        "        \"Strolling through Osaka Castle Park, enjoying the vast green spaces, moats, stone walls, and seasonal blooms (especially cherry blossoms in spring and plum blossoms in late winter)\",\n",
        "        \"Photographing the majestic castle, its golden embellishments, and its reflection in the moat\",\n",
        "        \"Visiting Nishinomaru Garden within the park for beautiful views of the castle (especially during cherry blossom season, requires separate admission)\",\n",
        "        \"Learning about the historical sieges and significance of Osaka Castle in Japanese history\"\n",
        "    ],\n",
        "    \"dotonbori\": [\n",
        "        \"Taking iconic photos with the Glico Running Man billboard and other extravagant 3D signs (e.g., Kani Doraku crab, Zubora-ya pufferfish)\",\n",
        "        \"Strolling along the Dotonbori canal and its vibrant pedestrianized streets, especially at night when the neon lights are dazzling\",\n",
        "        \"Sampling famous Osakan street food (kuidaore) like takoyaki, okonomiyaki, kushikatsu, and ramen from numerous stalls and restaurants\",\n",
        "        \"Taking a Tonbori River Cruise for a different perspective of the district from the water\",\n",
        "        \"Shopping for souvenirs, fashion, and unique Japanese goods in the area\",\n",
        "        \"Experiencing the lively entertainment, including arcades, theaters (like Shochikuza for kabuki), and karaoke bars\"\n",
        "    ],\n",
        "    \"arashiyama_bamboo_grove\": [\n",
        "        \"Walking or cycling along the enchanting pathway through the towering stalks of the Sagano Bamboo Forest\",\n",
        "        \"Listening to the rustling sound of the bamboo leaves in the wind, a designated 'Soundscape of Japan'\",\n",
        "        \"Photographing the magical light filtering through the dense green bamboo canopy\",\n",
        "        \"Visiting nearby Tenryu-ji Temple (a UNESCO World Heritage site) with its beautiful garden that backs onto the bamboo grove\",\n",
        "        \"Crossing the Togetsukyo Bridge ('Moon Crossing Bridge') over the Hozugawa River for scenic views of Arashiyama\",\n",
        "        \"Renting a rowboat on the Hozugawa River or taking the Sagano Romantic Train for more scenic views of the area\"\n",
        "    ],\n",
        "    \"itsukushima_shrine\": [\n",
        "        \"Photographing the iconic 'floating' vermilion O-Torii Gate, especially during high tide when it appears to float on the water, and at sunset\",\n",
        "        \"Exploring the Itsukushima Shrine complex (a UNESCO World Heritage site), built on stilts over the water, with its distinctive red-lacquered corridors and halls\",\n",
        "        \"Walking out to the O-Torii Gate during low tide to see it up close (check tide schedules)\",\n",
        "        \"Interacting with the friendly wild sika deer that roam freely on Miyajima Island\",\n",
        "        \"Taking the Miyajima Ropeway up Mount Misen for panoramic views of the Seto Inland Sea and hiking its trails\",\n",
        "        \"Sampling local Miyajima delicacies like grilled oysters and momiji manju (maple leaf-shaped cakes)\"\n",
        "    ],\n",
        "    \"gyeongbokgung_palace\": [\n",
        "        \"Exploring the main halls like Geunjeongjeon (Throne Hall) and pavilions like Gyeonghoeru (Royal Banquet Hall on a pond)\",\n",
        "        \"Watching the impressive Royal Guard Changing Ceremony (Sumunjang Gyedaeui) held several times a day at Gwanghwamun and Heungnyemun Gates\",\n",
        "        \"Renting a Hanbok (traditional Korean attire) from nearby shops to enter the palace for free and for an immersive photo experience\",\n",
        "        \"Visiting the National Folk Museum of Korea and the National Palace Museum of Korea, both located within the palace grounds\",\n",
        "        \"Taking a guided tour (available in multiple languages) to learn about the Joseon Dynasty's history and palace architecture\",\n",
        "        \"Photographing the intricate Dancheong (colorful painted patterns) on the wooden structures and the serene Hyangwonjeong Pavilion\"\n",
        "    ],\n",
        "    \"n_seoul_tower\": [\n",
        "        \"Taking a scenic cable car ride up Namsan Mountain to reach the N Seoul Tower\",\n",
        "        \"Ascending to the observatory (digital and analog) for breathtaking 360-degree panoramic views of Seoul's cityscape, day and night\",\n",
        "        \"Attaching a 'love lock' with a personal message to the famous railings and tree-like structures on the tower's outdoor terrace\",\n",
        "        \"Dining at the revolving N.Grill restaurant or other cafes and eateries within the tower complex, enjoying the views\",\n",
        "        \"Photographing the city skyline, especially during sunset or when the city lights twinkle at night; the tower itself is also beautifully illuminated\",\n",
        "        \"Exploring Namsan Park surrounding the tower, enjoying its walking trails, botanical gardens, and the Namsan Beacon Mounds\"\n",
        "    ],\n",
        "    \"bukchon_hanok_village\": [\n",
        "        \"Walking respectfully through the narrow, hilly alleyways lined with hundreds of well-preserved traditional Korean houses (Hanoks)\",\n",
        "        \"Photographing the beautiful tiled roofs, wooden beams, and stone walls of the Hanoks, often with views of modern Seoul in the background\",\n",
        "        \"Visiting small, private museums, cultural centers, and craft workshops (e.g., for Gahoe Museum, Donglim Knot Museum, or embroidery workshops) within the village\",\n",
        "        \"Renting a Hanbok to enhance the experience and take memorable photos in the traditional setting\",\n",
        "        \"Observing the 'Eight Scenic Spots of Bukchon' for the best photo opportunities and views (look for photo spot markers)\",\n",
        "        \"Enjoying tea at a traditional Hanok teahouse or Browse unique artisan shops while being mindful of it being a residential area\"\n",
        "    ],\n",
        "    \"myeongdong_shopping_street\": [\n",
        "        \"Shopping for Korean cosmetics and skincare products from numerous flagship stores and local brands\",\n",
        "        \"Exploring trendy fashion boutiques, shoe stores, and accessory shops catering to K-fashion enthusiasts\",\n",
        "        \"Indulging in a wide variety of delicious Korean street food from bustling stalls (e.g., tteokbokki, gyeranppang, tornado potato, grilled cheese lobster)\",\n",
        "        \"Visiting large department stores like Lotte Department Store and Shinsegae Department Store for luxury goods and diverse shopping\",\n",
        "        \"Catching K-pop related events, Browse K-pop merchandise stores, or spotting advertisements featuring K-pop idols\",\n",
        "        \"Visiting Myeongdong Cathedral, a historic Gothic-style Catholic church, as a peaceful contrast to the shopping frenzy\"\n",
        "    ],\n",
        "    \"dmz_korea\": [\n",
        "        \"Taking a guided tour to the Korean Demilitarized Zone (DMZ), including the Joint Security Area (JSA/Panmunjom) if accessible\",\n",
        "        \"Visiting the Third Infiltration Tunnel, one of several tunnels dug by North Korea under the DMZ\",\n",
        "        \"Looking into North Korea from observation posts like Dora Observatory\",\n",
        "        \"Learning about the history of the Korean War, the division of Korea, and ongoing inter-Korean relations at the DMZ Exhibition Hall or Imjingak Park\",\n",
        "        \"Seeing the Bridge of No Return and the Freedom House (within JSA)\",\n",
        "        \"Reflecting on the poignant reminders of a divided nation and hopes for reunification\"\n",
        "    ],\n",
        "    \"busan_gamcheon_culture_village\": [\n",
        "        \"Exploring the maze-like alleyways adorned with vibrant street art, colorful murals, and whimsical art installations\",\n",
        "        \"Photographing the brightly painted terraced houses cascading down the hillside, often called the 'Machu Picchu of Busan' or 'Santorini of Korea'\",\n",
        "        \"Following a stamp tour map to discover hidden artworks and viewpoints throughout the village\",\n",
        "        \"Visiting small art galleries, quirky shops, and charming cafes run by local artists and residents\",\n",
        "        \"Taking photos with iconic sculptures like 'The Little Prince and the Desert Fox' overlooking the village\",\n",
        "        \"Enjoying panoramic views of the village and the port of Busan from various observation decks\"\n",
        "    ],\n",
        "    \"jeju_island\": [\n",
        "        \"Hiking Hallasan, South Korea's highest mountain and a dormant volcano, or exploring its surrounding national park trails\",\n",
        "        \"Visiting Seongsan Ilchulbong (Sunrise Peak), a UNESCO World Heritage tuff cone, especially for sunrise views\",\n",
        "        \"Exploring Manjanggul Cave, one of the longest lava tubes in the world (UNESCO site)\",\n",
        "        \"Relaxing on beautiful beaches like Hyeopjae Beach (with views of Biyangdo Island) or Jungmun Saekdal Beach (popular for surfing)\",\n",
        "        \"Chasing waterfalls such as Cheonjeyeon Falls ('Pond of God') or Jeongbang Falls (falls directly into the ocean)\",\n",
        "        \"Discovering unique geological formations like Jusangjeolli Cliffs (hexagonal lava pillars) and Yongduam Rock (Dragon Head Rock)\"\n",
        "    ],\n",
        "    \"changdeokgung_palace_secret_garden\": [\n",
        "        \"Taking a mandatory guided tour of the Huwon (Secret Garden), a stunningly beautiful and expansive rear garden of Changdeokgung Palace (UNESCO World Heritage site)\",\n",
        "        \"Admiring the harmonious blend of traditional Korean palace architecture (pavilions, halls) with the natural landscape (ponds, streams, ancient trees) within the Secret Garden\",\n",
        "        \"Exploring the main palace buildings of Changdeokgung, such as Injeongjeon (main throne hall) and Donhwamun Gate\",\n",
        "        \"Photographing the serene Buyongji Pond with Buyongjeong Pavilion and Juhamnu Pavilion in the Secret Garden\",\n",
        "        \"Learning about the lives of the Joseon Dynasty royal family who used this palace and garden for leisure and study\",\n",
        "        \"Appreciating the palace's design, which is considered more integrated with its natural surroundings than other Seoul palaces\"\n",
        "    ],\n",
        "    \"great_wall\": [\n",
        "        \"Hiking or walking along various restored sections like Mutianyu (family-friendly, cable car/chairlift options), Badaling (most famous, can be crowded), or Jinshanling and Simatai (more rugged, great for photography, partially restored)\",\n",
        "        \"Taking a cable car, chairlift, or toboggan ride at sections like Mutianyu for easier access and fun descent\",\n",
        "        \"Photographing the vast structure snaking across diverse mountainous landscapes, with its watchtowers and fortifications\",\n",
        "        \"Learning about the history of its construction (spanning many dynasties), its purpose as a defensive barrier, and the legends associated with it\",\n",
        "        \"Participating in guided tours to understand the historical context and logistical details of visiting specific sections\",\n",
        "        \"Considering a visit to less crowded, 'wild' sections (with caution and appropriate preparation) for a more adventurous experience\"\n",
        "    ],\n",
        "    \"forbidden_city\": [\n",
        "        \"Exploring the vast imperial palace complex, walking from the Meridian Gate (Wumen) through numerous courtyards and halls to the Gate of Divine Might (Shenwumen)\",\n",
        "        \"Admiring the magnificent traditional Chinese palatial architecture, intricate roof details, dragon motifs, and symbolic color schemes (yellow and red)\",\n",
        "        \"Visiting key structures like the Hall of Supreme Harmony (Taihedian), Hall of Central Harmony (Zhonghedian), and Hall of Preserving Harmony (Baohedian) on the Outer Court\",\n",
        "        \"Exploring the Inner Court, including the Palace of Heavenly Purity (Qianqinggong), Hall of Union (Jiaotaidian), and Palace of Earthly Tranquility (Kunninggong)\",\n",
        "        \"Visiting the Palace Museum's extensive collections of imperial treasures, including ceramics, paintings, jade, and clocks, housed in various side halls\",\n",
        "        \"Strolling through the Imperial Garden (Yuhuayuan) at the northern end of the complex\"\n",
        "    ],\n",
        "    \"terracotta_army\": [\n",
        "        \"Viewing the thousands of life-sized terracotta warriors, archers, chariots, and horses arranged in battle formation in the three main excavation pits (Pit 1, Pit 2, Pit 3)\",\n",
        "        \"Admiring the individual details of the soldiers, each with unique facial expressions, hairstyles, and armor, reflecting the incredible craftsmanship\",\n",
        "        \"Visiting the Exhibition Hall of Bronze Chariots to see the two remarkably preserved and intricate bronze chariots and horses\",\n",
        "        \"Learning about Emperor Qin Shi Huang, the first emperor of China, and his quest for immortality that led to the creation of this mausoleum army\",\n",
        "        \"Taking a guided tour or using an audio guide for in-depth historical context and insights into the archaeological discoveries\",\n",
        "        \"Photographing the impressive scale of the pits and the ranks of warriors (flash photography is usually prohibited)\"\n",
        "    ],\n",
        "    \"the_bund\": [\n",
        "        \"Strolling along the wide waterfront promenade (Zhongshan East First Road) to admire the grand colonial-era buildings in various architectural styles (e.g., Gothic, Baroque, Art Deco) – the 'museum of international architecture'\",\n",
        "        \"Photographing the spectacular modern skyline of Pudong across the Huangpu River, featuring the Oriental Pearl Tower, Shanghai Tower, and Shanghai World Financial Center, especially stunning at night\",\n",
        "        \"Taking a Huangpu River cruise (day or night) for panoramic views of both the historic Bund and the futuristic Pudong skyline\",\n",
        "        \"Visiting the interiors of some heritage buildings (many now house banks, hotels, or luxury shops) or admiring their detailed facades\",\n",
        "        \"Dining at upscale restaurants or enjoying drinks at rooftop bars within the Bund buildings, offering magnificent views\",\n",
        "        \"Observing locals engaging in morning tai chi, evening strolls, or public dancing along the promenade\"\n",
        "    ],\n",
        "    \"li_river_guilin\": [\n",
        "        \"Taking a scenic boat cruise along the Li River from Guilin to Yangshuo (or vice versa) to admire the stunning karst mountain landscapes\",\n",
        "        \"Photographing the picturesque limestone peaks, bamboo groves, rice paddies, and water buffalo along the riverbanks – scenes often depicted in traditional Chinese paintings\",\n",
        "        \"Opting for a traditional bamboo raft ride (motorized) on sections of the Li River or the Yulong River (a tributary near Yangshuo) for a closer experience with the scenery\",\n",
        "        \"Exploring the Reed Flute Cave or Seven Star Park in Guilin before or after the river cruise\",\n",
        "        \"Visiting Xingping Town along the Li River, known for the landscape depicted on the 20 RMB banknote\",\n",
        "        \"Cycling or hiking in the countryside around Yangshuo to further explore the karst scenery\"\n",
        "    ],\n",
        "    \"potala_palace\": [\n",
        "        \"Exploring the majestic Potala Palace, a UNESCO World Heritage site, former winter residence of the Dalai Lamas, with its White Palace (administrative) and Red Palace (religious sections)\",\n",
        "        \"Admiring the unique Tibetan architecture, including massive stone walls, golden roofs, intricate murals, thangkas, and numerous chapels and tombs of past Dalai Lamas\",\n",
        "        \"Ascending the numerous staircases (visitors need to be acclimatized to the high altitude of Lhasa)\",\n",
        "        \"Photographing the imposing palace from various viewpoints, such as Chakpori Hill (for sunrise/sunset views) or Potala Palace Square\",\n",
        "        \"Learning about Tibetan Buddhism, the history of the Dalai Lamas, and the cultural significance of the palace\",\n",
        "        \"Observing pilgrims performing kora (circumambulation) around the palace\"\n",
        "    ],\n",
        "    \"zhangjiajie_national_forest_park\": [\n",
        "        \"Admiring the towering quartz-sandstone pillars and peaks, often shrouded in mist, that inspired the 'Hallelujah Mountains' in the movie Avatar (especially in the Yuanjiajie area)\",\n",
        "        \"Riding the Bailong Elevator (Hundred Dragons Elevator), a massive glass elevator built onto the side of a cliff, for dramatic views\",\n",
        "        \"Walking across the Zhangjiajie Grand Canyon Glass Bridge (requires separate entry/location from the main park but often combined in tours) for a thrilling experience\",\n",
        "        \"Taking cable cars, like the one to Tianzi Mountain or Huangshizhai, for breathtaking panoramic vistas\",\n",
        "        \"Hiking along scenic trails, such as the Golden Whip Stream, to enjoy the lush forests, clear streams, and unique rock formations from below\",\n",
        "        \"Exploring other key areas like Tianmen Mountain (Heaven's Gate Mountain, often a separate visit) with its cable car, skywalk, and Tianmen Cave\"\n",
        "    ],\n",
        "    \"west_lake_hangzhou\": [\n",
        "        \"Taking a leisurely boat ride on the serene West Lake to enjoy its scenic beauty and visit islands like Xiaoyingzhou (Three Ponds Mirroring the Moon)\",\n",
        "        \"Walking or cycling along the Su Causeway (Sudi) and Bai Causeway (Baidi), lined with willow and peach trees\",\n",
        "        \"Admiring iconic landmarks such as Leifeng Pagoda (rebuilt), Broken Bridge (Duan Qiao, famous in legend), and the Mid-Lake Pavilion\",\n",
        "        \"Visiting traditional gardens and temples around the lake, like Lingyin Temple (Temple of the Soul's Retreat) and Guo's Villa\",\n",
        "        \"Watching the 'Impression West Lake' outdoor musical performance on the lake at night (seasonal, created by Zhang Yimou)\",\n",
        "        \"Photographing the picturesque landscapes, especially during different seasons (e.g., lotus blooms in summer, osmanthus in autumn)\"\n",
        "    ],\n",
        "    \"summer_palace_beijing\": [\n",
        "        \"Strolling through the vast imperial garden, a masterpiece of Chinese landscape garden design, centered around Longevity Hill and Kunming Lake\",\n",
        "        \"Taking a boat ride on Kunming Lake, especially a traditional dragon boat\",\n",
        "        \"Walking along the Long Corridor (Chang Lang), a covered walkway decorated with thousands of paintings\",\n",
        "        \"Visiting key structures like the Hall of Benevolence and Longevity (Renshoudian), Tower of Buddhist Incense (Foxiangge) on Longevity Hill, and the Marble Boat\",\n",
        "        \"Exploring Suzhou Street, a recreated canal-side shopping street from imperial times\",\n",
        "        \"Admiring the beautiful traditional Chinese architecture, bridges (like the Seventeen-Arch Bridge), and landscaped gardens\"\n",
        "    ],\n",
        "    \"petronas_towers\": [\n",
        "        \"Visiting the Skybridge, the double-decker bridge connecting the two towers on the 41st and 42nd floors, for close-up views and a unique perspective (book tickets in advance)\",\n",
        "        \"Ascending to the Observation Deck on the 86th floor of Tower 2 for breathtaking panoramic views of Kuala Lumpur's skyline\",\n",
        "        \"Photographing the iconic twin skyscrapers, an architectural marvel, especially when brilliantly illuminated at night\",\n",
        "        \"Shopping at the upscale Suria KLCC mall located at the base of the towers, featuring luxury brands and diverse retail options\",\n",
        "        \"Relaxing or strolling in the beautifully landscaped KLCC Park, which includes a man-made lake (Lake Symphony) with water fountain shows, a jogging track, and a children's playground\",\n",
        "        \"Visiting nearby attractions like Petrosains Discovery Centre (interactive science museum) or Aquaria KLCC (oceanarium)\"\n",
        "    ],\n",
        "    \"marina_bay_sands\": [\n",
        "        \"Visiting the Sands SkyPark Observation Deck on the 57th floor for stunning 360-degree panoramic views of Singapore's skyline, Gardens by the Bay, and the Singapore Strait\",\n",
        "        \"Swimming in the world-famous rooftop infinity pool (exclusive access for Marina Bay Sands hotel guests)\",\n",
        "        \"Shopping at The Shoppes at Marina Bay Sands, a luxury mall featuring international brands, a canal with sampan rides, and the Digital Light Canvas\",\n",
        "        \"Watching the 'Spectra – A Light & Water Show' in the evening, a spectacular outdoor multimedia presentation over Marina Bay\",\n",
        "        \"Visiting the ArtScience Museum, with its iconic lotus-inspired design, showcasing art, science, culture, and technology exhibitions\",\n",
        "        \"Dining at celebrity chef restaurants or exploring diverse culinary options within the integrated resort, and trying your luck at the casino\"\n",
        "    ],\n",
        "    \"gardens_by_the_bay\": [\n",
        "        \"Exploring the two massive cooled conservatories: the Flower Dome (showcasing exotic plants from Mediterranean and semi-arid regions) and the Cloud Forest (featuring a stunning indoor waterfall and plants from tropical highlands)\",\n",
        "        \"Walking along the OCBC Skyway, an aerial walkway suspended between two Supertrees, for panoramic views of the Supertree Grove and surrounding gardens\",\n",
        "        \"Watching the 'Garden Rhapsody' light and sound show at Supertree Grove in the evening, where the Supertrees come alive with dazzling lights synchronized to music\",\n",
        "        \"Strolling through the various outdoor themed gardens, such as the Heritage Gardens, Serene Garden, and the outdoor art sculptures\",\n",
        "        \"Photographing the unique horticultural displays, futuristic Supertrees, and innovative sustainable architecture\",\n",
        "        \"Letting children play at the Far East Organization Children's Garden with its water play areas and treehouses\"\n",
        "    ],\n",
        "    \"taj_mahal\": [\n",
        "        \"Admiring the breathtaking beauty and perfect symmetry of the ivory-white marble mausoleum, a UNESCO World Heritage site and a symbol of eternal love\",\n",
        "        \"Photographing the iconic structure from various angles, especially during sunrise or sunset when the light casts different hues on the marble, and its reflection in the central water channels\",\n",
        "        \"Strolling through the formal Mughal gardens (Charbagh) that surround the mausoleum, with their pathways, fountains, and reflecting pools\",\n",
        "        \"Learning about the poignant love story of Mughal emperor Shah Jahan and his wife Mumtaz Mahal, for whom the Taj Mahal was built\",\n",
        "        \"Observing the intricate marble inlay work (pietra dura) featuring semi-precious stones, and the detailed calligraphy on the monument's facade\",\n",
        "        \"Visiting the mosque and the guesthouse (jawab) that flank the main mausoleum, providing architectural balance\"\n",
        "    ],\n",
        "    \"angkor_wat\": [\n",
        "        \"Exploring the vast temple complex of Angkor Wat, the world's largest religious monument, admiring its iconic five lotus-bud towers and intricate bas-reliefs\",\n",
        "        \"Watching the sunrise over Angkor Wat, a magical experience as the temple silhouette emerges against the colorful sky (can be very crowded)\",\n",
        "        \"Taking a guided tour to understand the history of the Khmer Empire, the Hindu and Buddhist symbolism, and the architectural features of the temple\",\n",
        "        \"Examining the detailed stone carvings and extensive galleries depicting scenes from Hindu epics like the Ramayana and Mahabharata, and historical events\",\n",
        "        \"Photographing the temple's reflection in the surrounding moat and its grandeur from different perspectives\",\n",
        "        \"Visiting other nearby temples in the Angkor Archaeological Park, such as Angkor Thom (Bayon, Baphuon), Ta Prohm (Tomb Raider temple), and Banteay Srei\"\n",
        "    ],\n",
        "    \"ha_long_bay\": [\n",
        "        \"Taking an overnight cruise or a day boat trip to explore the stunning seascape of thousands of limestone karsts and islets rising from the emerald green waters (UNESCO World Heritage site)\",\n",
        "        \"Kayaking or taking a bamboo boat ride through hidden lagoons, caves, and around the towering rock formations for a closer experience\",\n",
        "        \"Visiting impressive caves and grottoes, such as Thien Cung Cave (Heavenly Palace Cave) or Dau Go Cave (Wooden Stakes Cave), with their stalactites and stalagmites\",\n",
        "        \"Swimming in the calm waters or relaxing on small, secluded beaches (e.g., Titop Island beach)\",\n",
        "        \"Photographing the breathtaking and often misty scenery, especially at sunrise or sunset\",\n",
        "        \"Learning about the local culture by visiting floating fishing villages or pearl farms\"\n",
        "    ],\n",
        "    \"mount_everest\": [\n",
        "        \"Trekking to Everest Base Camp (South Base Camp in Nepal or North Base Camp in Tibet) for close-up views of Mount Everest and the surrounding Himalayan giants (requires significant preparation and acclimatization)\",\n",
        "        \"Taking a scenic mountain flight from Kathmandu for breathtaking aerial views of Mount Everest and the Himalayan range (a popular option for non-trekkers)\",\n",
        "        \"Photographing the world's highest peak, especially during sunrise or sunset when alpenglow illuminates the summit\",\n",
        "        \"Learning about Sherpa culture and mountaineering history in villages like Namche Bazaar (on the Nepal EBC trek)\",\n",
        "        \"Visiting monasteries like Tengboche Monastery (Nepal) for spiritual insights and stunning mountain backdrops\",\n",
        "        \"For experienced mountaineers: attempting to summit Mount Everest (a highly challenging and expensive endeavor)\"\n",
        "    ],\n",
        "    \"bagan\": [\n",
        "        \"Exploring the vast archaeological zone, home to thousands of ancient Buddhist temples, pagodas, and stupas dating from the 9th to 13th centuries (UNESCO World Heritage site)\",\n",
        "        \"Renting an e-bike or horse cart to navigate the sandy tracks and discover both major temples (like Ananda, Shwezigon, Thatbyinnyu, Dhammayangyi) and smaller, hidden gems\",\n",
        "        \"Watching the sunrise or sunset over the temple-strewn plains from a high vantage point (e.g., a designated viewing mound or a temple terrace where permitted)\",\n",
        "        \"Taking a hot air balloon ride over Bagan at sunrise for an unforgettable panoramic view of the temples (seasonal, typically October to April)\",\n",
        "        \"Photographing the unique landscape of ancient religious structures against the backdrop of the Irrawaddy River and distant hills\",\n",
        "        \"Learning about the history of the Pagan Kingdom and Buddhist art and architecture through temple murals and local guides\"\n",
        "    ],\n",
        "    \"grand_palace_wat_phra_kaew\": [\n",
        "        \"Exploring the magnificent Grand Palace complex, the former official residence of the Kings of Siam (Thailand), with its stunning traditional Thai architecture\",\n",
        "        \"Visiting Wat Phra Kaew (Temple of the Emerald Buddha) within the palace grounds to see the highly revered Emerald Buddha statue, carved from a single jade stone\",\n",
        "        \"Admiring the intricate details of the golden spires (chedis), colorful mosaics made of glass and porcelain, ornate gables, and mythical guardian statues (yakshas and kinnaras)\",\n",
        "        \"Photographing the dazzling exteriors of the royal halls (e.g., Chakri Maha Prasat Hall), temples, and courtyards\",\n",
        "        \"Learning about Thai history, royal traditions, and Buddhist art and iconography (dressing respectfully is required: no shorts, sleeveless shirts)\",\n",
        "        \"Observing the Ramakien murals (Thai version of the Ramayana) that adorn the walls of the cloister surrounding Wat Phra Kaew\"\n",
        "    ],\n",
        "\n",
        "    # 歐洲地標 (Europe)\n",
        "    \"eiffel_tower\": [\n",
        "        \"Ascending to the different observation platforms (1st floor, 2nd floor, summit) for stunning panoramic views of Paris\",\n",
        "        \"Enjoying a romantic meal or champagne at Le Jules Verne restaurant (2nd floor) or other tower eateries\",\n",
        "        \"Picnicking on the Champ de Mars park with the Eiffel Tower as a magnificent backdrop\",\n",
        "        \"Photographing the iconic structure day and night, especially during the hourly sparkling lights show after sunset\",\n",
        "        \"Taking a Seine River cruise that offers unique perspectives of the tower from the water\",\n",
        "        \"Learning about its history, engineering, and construction at the first-floor exhibition or through guided tours\"\n",
        "    ],\n",
        "    \"louvre_museum\": [\n",
        "        \"Viewing iconic masterpieces like the Mona Lisa, Venus de Milo, Winged Victory of Samothrace, and Liberty Leading the People\",\n",
        "        \"Exploring diverse and extensive art collections spanning from ancient civilizations (Egyptian, Greek, Roman) to 19th-century European painting and sculpture\",\n",
        "        \"Taking a guided tour or using an audio guide to navigate the vast museum and focus on key exhibits or specific interests\",\n",
        "        \"Admiring the architecture of the former royal palace (Louvre Palace) and the modern glass Louvre Pyramid designed by I. M. Pei\",\n",
        "        \"Strolling through the Tuileries Garden (Jardin des Tuileries) adjacent to the museum, leading towards Place de la Concorde\",\n",
        "        \"Photographing the impressive exterior, the pyramid, and select artworks (where permitted without flash)\"\n",
        "    ],\n",
        "    \"mont_saint_michel\": [\n",
        "        \"Walking up the winding Grande Rue, lined with shops and restaurants, to reach the magnificent Benedictine Abbey at the summit\",\n",
        "        \"Taking a guided tour (or audio guide) of the Mont Saint-Michel Abbey to explore its Romanesque and Gothic sections, cloister, and refectory\",\n",
        "        \"Admiring the breathtaking views of the surrounding bay and tidal flats from the abbey terraces and ramparts\",\n",
        "        \"Photographing the island commune at different times of the day and tides, especially during high tide when it's completely surrounded by water, or at sunrise/sunset\",\n",
        "        \"Exploring the small museums, chapels, and historic houses within the village\",\n",
        "        \"Witnessing the dramatic tidal changes (some of the highest in Europe) from a safe vantage point on the island or the mainland causeway\"\n",
        "    ],\n",
        "    \"arc_de_triomphe\": [\n",
        "        \"Climbing the stairs (or taking the elevator part-way) to the rooftop observation deck for panoramic 360-degree views of Paris, including the Champs-Élysées, Eiffel Tower, Sacré-Cœur Basilica, and La Défense\",\n",
        "        \"Admiring the intricate Neoclassical sculptures and reliefs on the arch's facade, depicting scenes from French military history, particularly Napoleonic victories\",\n",
        "        \"Visiting the Tomb of the Unknown Soldier beneath the arch and witnessing the rekindling of the eternal flame each evening at 6:30 PM\",\n",
        "        \"Photographing the monument, the twelve avenues radiating from Place Charles de Gaulle (formerly Place de l'Étoile), and the surrounding cityscape\",\n",
        "        \"Learning about its historical significance and the events it commemorates through the small museum inside the arch\",\n",
        "        \"Observing major events like the Bastille Day military parade (July 14th) which passes through the arch\"\n",
        "    ],\n",
        "    \"big_ben\": [ # Elizabeth Tower\n",
        "        \"Photographing the iconic clock tower (officially Elizabeth Tower), the Great Bell (Big Ben), and the adjacent Houses of Parliament (Palace of Westminster) from Westminster Bridge or Parliament Square\",\n",
        "        \"Hearing the famous chimes of Big Ben, especially the distinctive Westminster Quarters\",\n",
        "        \"Taking a guided tour of the Houses of Parliament (when Parliament is not in session, book in advance) to see inside this historic building\",\n",
        "        \"Walking along the South Bank of the River Thames for classic views of Big Ben and the Houses of Parliament, especially at dusk or night when illuminated\",\n",
        "        \"Visiting nearby attractions such as Westminster Abbey, the Churchill War Rooms, and the London Eye\",\n",
        "        \"Learning about its history, recent restoration, and the workings of the UK Parliament\"\n",
        "    ],\n",
        "    \"stonehenge\": [\n",
        "        \"Walking the designated pathway around the prehistoric stone circle, observing the massive sarsen stones and smaller bluestones\",\n",
        "        \"Listening to the informative audio guide (available in multiple languages) to learn about the history, construction phases, and various theories about Stonehenge's purpose (e.g., astronomical observatory, burial site, ceremonial center)\",\n",
        "        \"Visiting the world-class exhibition and visitor centre to see archaeological finds, reconstructions of a Neolithic village, and interactive displays\",\n",
        "        \"Photographing the mysterious ancient monument against the backdrop of Salisbury Plain, especially during sunrise or sunset for dramatic lighting (special access may be required for inner circle access during these times)\",\n",
        "        \"Considering the astronomical alignments, particularly during the summer and winter solstices when special events are often held\",\n",
        "        \"Exploring the surrounding landscape, which is rich in other Neolithic and Bronze Age sites, including Woodhenge and Durrington Walls\"\n",
        "    ],\n",
        "    \"tower_of_london\": [\n",
        "        \"Taking a captivating tour led by a Yeoman Warder (Beefeater), who shares fascinating stories, historical anecdotes, and traditions of the Tower\",\n",
        "        \"Viewing the spectacular Crown Jewels, a dazzling collection of royal regalia including crowns, orbs, and sceptres, housed securely in the Jewel House\",\n",
        "        \"Exploring the White Tower, the oldest part of the castle (a Norman keep), which houses the Royal Armouries collection\",\n",
        "        \"Walking the ancient ramparts and learning about the Tower's multifaceted history as a royal palace, fortress, prison, and place of execution\",\n",
        "        \"Seeing the famous resident ravens and learning about the legend that the kingdom and Tower will fall if they leave\",\n",
        "        \"Visiting sites of historical significance such as Traitors' Gate, the Bloody Tower, and the execution site on Tower Green\"\n",
        "    ],\n",
        "    \"buckingham_palace\": [\n",
        "        \"Watching the iconic Changing of the Guard ceremony (check schedule and arrive early for a good view), a display of British pageantry with guards in red tunics and bearskin hats\",\n",
        "        \"Photographing the grand facade of Buckingham Palace, the official London residence of the UK monarch, and the impressive Victoria Memorial in front\",\n",
        "        \"Touring the magnificent State Rooms during the Summer Opening (typically July to September, when the King is not in residence, book tickets in advance)\",\n",
        "        \"Visiting the Queen's Gallery to see rotating exhibitions of artworks and treasures from the Royal Collection\",\n",
        "        \"Exploring the Royal Mews to see historic royal carriages and vehicles\",\n",
        "        \"Strolling through St. James's Park or Green Park, adjacent to the palace, for pleasant walks and views\"\n",
        "    ],\n",
        "    \"colosseum\": [\n",
        "        \"Taking a guided historical tour (or using an audio guide) to learn about the gladiatorial contests, wild animal hunts, public spectacles, and the lives of Roman citizens and emperors associated with the amphitheater\",\n",
        "        \"Exploring the different levels of the ancient Flavian Amphitheatre, including the arena floor (if accessible with your ticket), the hypogeum (underground tunnels and chambers), and the upper tiers for panoramic views\",\n",
        "        \"Photographing the imposing structure, a symbol of Imperial Rome, noting its architectural features like arches, columns, and the remaining sections of the outer wall\",\n",
        "        \"Visiting the adjacent Roman Forum (Foro Romano) and Palatine Hill (Colle Palatino), which are usually included in a combined ticket, to explore the heart of ancient Roman life, politics, and mythology\",\n",
        "        \"Learning about Roman engineering, architecture, and the social importance of the games held in the Colosseum\",\n",
        "        \"Imagining the roar of the crowds and the dramatic events that once unfolded within its ancient walls, especially when illuminated at night\"\n",
        "    ],\n",
        "    \"leaning_tower_of_pisa\": [\n",
        "        \"Climbing the spiral staircase of 294 steps to the top of the leaning bell tower (Torre Pendente di Pisa) for panoramic views of Pisa and the Piazza dei Miracoli (book tickets well in advance as numbers are limited)\",\n",
        "        \"Taking the classic and fun forced-perspective photo where you appear to be 'holding up' or 'pushing over' the Leaning Tower\",\n",
        "        \"Visiting the magnificent Pisa Cathedral (Duomo di Santa Maria Assunta) and the impressive Baptistery of St. John (Battistero di San Giovanni) located in the same Square of Miracles (Piazza dei Miracoli)\",\n",
        "        \"Admiring the beautiful Romanesque architecture of white marble that characterizes the entire complex\",\n",
        "        \"Strolling around the well-manicured lawns of the Piazza dei Miracoli and exploring the Camposanto Monumentale (monumental cemetery)\",\n",
        "        \"Learning about the history of the tower's construction, the reasons for its unintended tilt, and the centuries of efforts to stabilize it\"\n",
        "    ],\n",
        "    \"trevi_fountain\": [\n",
        "        \"Tossing a coin over your right shoulder with your left hand into the fountain – tradition holds that this ensures your return to Rome (toss two coins for a new romance, three for marriage)\",\n",
        "        \"Admiring the spectacular Baroque sculptures depicting Oceanus (god of the sea) on a shell-shaped chariot pulled by sea horses and tritons, set against the backdrop of Palazzo Poli\",\n",
        "        \"Photographing the magnificent fountain, one of the most famous in the world, especially beautiful when illuminated at night (be prepared for crowds)\",\n",
        "        \"Enjoying delicious Italian gelato from a nearby gelateria while people-watching and soaking in the lively atmosphere\",\n",
        "        \"Learning about the history and design of the fountain, completed by Nicola Salvi and Giuseppe Pannini, and its connection to ancient Roman aqueducts\",\n",
        "        \"Visiting at different times of day, such as early morning, to experience it with fewer crowds and different lighting conditions\"\n",
        "    ],\n",
        "    \"st_peters_basilica\": [\n",
        "        \"Exploring the vast and awe-inspiring interior of St. Peter's Basilica, the largest Christian church in the world and a masterpiece of Renaissance architecture\",\n",
        "        \"Admiring Michelangelo's magnificent dome from the inside and considering climbing to the top (cupola) for breathtaking panoramic views of St. Peter's Square, Vatican City, and Rome (requires a ticket, involves stairs and an elevator option for part of the way)\",\n",
        "        \"Viewing renowned masterpieces such as Michelangelo's Pietà (sculpture of Mary holding Christ's body), Bernini's bronze Baldachin over the papal altar, and various ornate chapels and papal tombs\",\n",
        "        \"Visiting the Vatican Grottoes (Papal Tombs) located beneath the basilica, where many popes are interred\",\n",
        "        \"Attending a Papal Mass, audience, or the Angelus prayer in St. Peter's Square if your visit coincides with these events (check Vatican schedules)\",\n",
        "        \"Strolling through the immense St. Peter's Square (Piazza San Pietro), designed by Bernini, with its grand colonnades, central obelisk, and twin fountains\"\n",
        "    ],\n",
        "    \"sagrada_familia\": [\n",
        "        \"Admiring the extraordinary and unique facades of Antoni Gaudí's unfinished masterpiece: the Nativity Facade (celebrating Christ's birth), the Passion Facade (depicting his suffering), and the still-under-construction Glory Facade\",\n",
        "        \"Exploring the breathtaking interior, a forest of tree-like columns that branch out to support the roof, illuminated by vibrant stained-glass windows that create an ethereal play of light and color\",\n",
        "        \"Taking a guided tour or using an audio guide (highly recommended) to understand Gaudí's visionary architectural concepts, complex symbolism, and the ongoing construction process (book tickets well in advance online)\",\n",
        "        \"Ascending one of the towers (Nativity or Passion, requires separate ticket and booking) for close-up views of the spires and panoramic vistas of Barcelona\",\n",
        "        \"Visiting the museum located underneath the basilica to learn about Gaudí's life, design models, construction techniques, and the history of the Sagrada Família\",\n",
        "        \"Photographing the incredibly detailed architectural elements, both inside and out, reflecting Gaudí's deep connection with nature and spirituality\"\n",
        "    ],\n",
        "    \"alhambra\": [\n",
        "        \"Exploring the Nasrid Palaces, the heart of the Alhambra, with their exquisite stucco work, intricate geometric tile mosaics (azulejos), delicate muqarnas (stalactite vaulting), and tranquil courtyards like the Court of the Lions and Court of the Myrtles (book tickets well in advance, as entry is timed and limited)\",\n",
        "        \"Wandering through the serene Generalife gardens, the summer palace of the Nasrid rulers, with its beautiful patios, fountains, flowerbeds, and scenic pathways\",\n",
        "        \"Visiting the Alcazaba, the oldest part of the Alhambra, a formidable fortress with towers offering panoramic views over the city of Granada and the surrounding landscape\",\n",
        "        \"Admiring the Palace of Charles V, a contrasting Renaissance-style building within the Alhambra complex, now housing museums\",\n",
        "        \"Photographing the stunning Moorish architecture, intricate details, and the interplay of light, water, and shadow throughout the complex\",\n",
        "        \"Learning about the history of the last Muslim emirs in Spain, the Reconquista, and the subsequent Christian modifications to the palace\"\n",
        "    ],\n",
        "    \"brandenburg_gate\": [\n",
        "        \"Walking through the iconic neoclassical triumphal arch, a potent symbol of German history, division, and reunification\",\n",
        "        \"Photographing the gate, especially when illuminated at night, and the Quadriga statue (a chariot drawn by four horses, driven by Victoria, the Roman goddess of victory) that crowns it\",\n",
        "        \"Visiting Pariser Platz, the grand square in front of the gate, which also houses embassies (e.g., US, French) and the Hotel Adlon\",\n",
        "        \"Learning about its historical significance, from its construction under King Frederick William II of Prussia to its role during the Napoleonic Wars, the Nazi era, the Cold War (when it stood near the Berlin Wall), and German reunification\",\n",
        "        \"Reflecting at nearby historical sites such as the Reichstag Building (German Parliament), the Memorial to the Murdered Jews of Europe, and the remnants of the Berlin Wall\",\n",
        "        \"Observing the bustling atmosphere and often, street performers or public events taking place in Pariser Platz\"\n",
        "    ],\n",
        "    \"neuschwanstein_castle\": [\n",
        "        \"Taking a mandatory guided tour of the fairytale-like interiors of King Ludwig II's dream castle, inspired by Richard Wagner's operas and medieval legends (tickets must be purchased in Hohenschwangau village and are timed; book online in advance to secure a spot)\",\n",
        "        \"Photographing the castle from Marienbrücke (Mary's Bridge), a pedestrian bridge offering the classic, breathtaking postcard view of Neuschwanstein perched on its rugged hill with the Bavarian Alps in the background\",\n",
        "        \"Hiking, taking a horse-drawn carriage, or riding a shuttle bus up the steep road from Hohenschwangau village to the castle entrance\",\n",
        "        \"Admiring the scenic beauty of the Bavarian Alps, forests, and nearby lakes (Alpsee and Schwansee) surrounding the castle\",\n",
        "        \"Learning about the eccentric 'Mad' King Ludwig II of Bavaria, his passion for art and architecture, and the romantic inspirations behind the castle's design\",\n",
        "        \"Visiting the nearby Hohenschwangau Castle, King Ludwig II's childhood home, for more royal history and contrasting architectural style\"\n",
        "    ],\n",
        "    \"acropolis_of_athens\": [\n",
        "        \"Exploring the Parthenon, the magnificent Doric temple dedicated to the goddess Athena Parthenos, an enduring symbol of Ancient Greece, democracy, and Western civilization\",\n",
        "        \"Visiting other significant ancient structures on the Sacred Rock, such as the Erechtheion (with its iconic Porch of the Caryatids), the Propylaea (the monumental gateway), and the Temple of Athena Nike\",\n",
        "        \"Walking to the ancient Theatre of Dionysus on the southern slope, considered the birthplace of Greek tragedy, and the well-preserved Odeon of Herodes Atticus (still used for performances)\",\n",
        "        \"Enjoying breathtaking panoramic views of Athens, including the Plaka district, Mount Lycabettus, and the Saronic Gulf, from the summit of the Acropolis\",\n",
        "        \"Visiting the Acropolis Museum, located at the foot of the Acropolis, to see original sculptures, friezes (including parts of the Parthenon Marbles), and artifacts found on the site, displayed in a modern architectural setting\",\n",
        "        \"Photographing the ancient ruins against the backdrop of the modern city, especially beautiful during sunrise or sunset\"\n",
        "    ],\n",
        "    \"santorini_oia\": [\n",
        "        \"Exploring the charming, narrow, winding pathways of Oia village, famous for its whitewashed cave houses (yposkafa), blue-domed churches, and vibrant bougainvillea\",\n",
        "        \"Watching and photographing the world-renowned sunset over the caldera from Oia, typically from the ruins of the Venetian castle (Kastro) or designated sunset viewing spots (arrive very early to secure a good spot as it gets extremely crowded)\",\n",
        "        \"Taking a boat tour to the volcanic islands of Nea Kameni (to hike on the crater) and Palea Kameni (to swim in the hot springs), and Thirassia island\",\n",
        "        \"Relaxing on unique volcanic sand beaches around Santorini, such as Red Beach (Kokkini Paralia), Perissa Beach, or Kamari Beach (Oia itself is on cliffs, not a beach town)\",\n",
        "        \"Hiking the scenic caldera trail between Fira (the capital) and Oia (approx. 3-4 hours) for stunning views\",\n",
        "        \"Indulging in local Santorinian cuisine and distinctive Assyrtiko wines at cliffside restaurants with caldera views\"\n",
        "    ],\n",
        "    \"canals_of_venice\": [\n",
        "        \"Taking a classic gondola ride through the narrow, picturesque canals, often accompanied by a serenading gondolier\",\n",
        "        \"Exploring the city on foot, getting lost in the maze-like streets (calli) and discovering charming squares (campi) and countless bridges\",\n",
        "        \"Cruising along the Grand Canal on a vaporetto (public water bus) to see famous landmarks like the Rialto Bridge, Doge's Palace, and Ca' d'Oro from the water\",\n",
        "        \"Photographing the unique cityscape with its historic buildings seemingly rising from the water, colorful reflections, and bustling canal life\",\n",
        "        \"Visiting iconic sights such as St. Mark's Square (Piazza San Marco), St. Mark's Basilica, and the Doge's Palace\",\n",
        "        \"Enjoying cicchetti (Venetian tapas) and wine at traditional bacari (local bars)\"\n",
        "    ],\n",
        "    \"florence_cathedral_duomo\": [ # Cattedrale di Santa Maria del Fiore\n",
        "        \"Admiring Brunelleschi's magnificent red-tiled dome, an architectural marvel of the Renaissance, and climbing to the top (463 steps, book well in advance) for breathtaking panoramic views of Florence\",\n",
        "        \"Exploring the interior of the Florence Cathedral (Cattedrale di Santa Maria del Fiore), noting its Gothic architecture, stained glass windows, and Vasari's frescoes of the Last Judgment inside the dome\",\n",
        "        \"Visiting Giotto's Campanile (bell tower) and climbing its 414 steps for another stunning perspective of the Duomo and the city\",\n",
        "        \"Admiring the Florence Baptistery (Battistero di San Giovanni) with its famous bronze doors, especially Ghiberti's 'Gates of Paradise'\",\n",
        "        \"Visiting the Museo dell'Opera del Duomo to see original artworks from the Duomo complex, including Ghiberti's original doors and Michelangelo's 'The Deposition' Pietà\",\n",
        "        \"Photographing the intricate white, green, and pink marble facade of the Duomo, Campanile, and Baptistery in Piazza del Duomo\"\n",
        "    ],\n",
        "    \"anne_frank_house\": [\n",
        "        \"Taking a poignant and reflective tour through the Secret Annex (Achterhuis) where Anne Frank and her family hid from Nazi persecution during World War II (book tickets online months in advance, as they sell out quickly)\",\n",
        "        \"Viewing Anne Frank's original diary and other personal belongings displayed in the museum\",\n",
        "        \"Learning about the lives of the people who hid in the annex, their helpers, and the historical context of the Holocaust and Jewish persecution in Amsterdam\",\n",
        "        \"Reflecting on Anne's story, her writings, and the enduring messages of tolerance, human rights, and hope\",\n",
        "        \"Visiting the museum exhibitions that provide further information about the persecution of Jews during the war and contemporary issues of discrimination\",\n",
        "        \"Seeing the unassuming exterior of the canal house on Prinsengracht 263 and imagining the hidden life within\"\n",
        "    ],\n",
        "    \"canals_of_amsterdam\": [\n",
        "        \"Taking a scenic canal cruise (day or evening) through the Grachtengordel (canal belt), a UNESCO World Heritage site, to admire the historic gabled canal houses, bridges, and houseboats\",\n",
        "        \"Renting a private boat or pedal boat (canal bike) to explore the canals at your own pace\",\n",
        "        \"Walking or cycling along the picturesque canals, such as Prinsengracht, Keizersgracht, and Herengracht, enjoying the charming atmosphere\",\n",
        "        \"Photographing the iconic canal scenes, including narrow houses, beautiful bridges (like Magere Brug 'Skinny Bridge'), and reflections in the water\",\n",
        "        \"Visiting canal house museums like Museum Willet-Holthuysen or Museum Van Loon to see how wealthy Amsterdammers lived in the Golden Age\",\n",
        "        \"Enjoying a drink or meal at a waterside cafe or restaurant along the canals\"\n",
        "    ],\n",
        "    \"charles_bridge_prague\": [\n",
        "        \"Walking across the historic Charles Bridge (Karlův most), a medieval stone arch bridge connecting the Old Town and Lesser Town (Malá Strana) over the Vltava River\",\n",
        "        \"Admiring the 30 statues and statuaries of saints that line the bridge, including the famous statue of St. John of Nepomuk (touching the plaque is said to bring good luck or ensure a return to Prague)\",\n",
        "        \"Enjoying panoramic views of Prague Castle, St. Vitus Cathedral, the Vltava River, and the surrounding city skyline from the bridge\",\n",
        "        \"Photographing the bridge, its Gothic towers (Old Town Bridge Tower and Lesser Town Bridge Towers), and the bustling atmosphere, especially beautiful at dawn, dusk, or at night\",\n",
        "        \"Observing street artists, musicians, and vendors who often line the bridge (can be very crowded during peak season)\",\n",
        "        \"Climbing one of the bridge towers for a higher vantage point and stunning photos\"\n",
        "    ],\n",
        "    \"red_square_st_basils_cathedral\": [\n",
        "        \"Admiring the iconic, vibrantly colored onion domes of St. Basil's Cathedral (Cathedral of Vasily the Blessed), a unique masterpiece of Russian architecture, located at the southern end of Red Square\",\n",
        "        \"Exploring Red Square (Krasnaya Ploshchad), the historic central square of Moscow, and visiting other significant landmarks such as Lenin's Mausoleum, the fortified walls of the Moscow Kremlin, the State Historical Museum, and the GUM department store\",\n",
        "        \"Taking a guided tour or visiting the interior of St. Basil's Cathedral (now a museum) to see its chapels and learn about its history\",\n",
        "        \"Photographing the stunning ensemble of Red Square, especially the contrast between St. Basil's, the Kremlin towers, and the red brick of the Historical Museum\",\n",
        "        \"Learning about the historical events that have taken place in Red Square, a UNESCO World Heritage site and a focal point of Russian history and culture\",\n",
        "        \"Visiting the GUM department store for its unique architecture, high-end shops, and traditional Russian ice cream\"\n",
        "    ],\n",
        "    \"edinburgh_castle\": [\n",
        "        \"Exploring the historic fortress perched atop Castle Rock, dominating the skyline of Edinburgh\",\n",
        "        \"Viewing the Honours of Scotland (the Scottish Crown Jewels) and the Stone of Destiny, ancient symbols of Scottish royalty\",\n",
        "        \"Visiting St. Margaret's Chapel, the oldest surviving building in Edinburgh, and the Great Hall with its impressive timber roof and collection of arms and armour\",\n",
        "        \"Witnessing the firing of the One O'Clock Gun (Monday to Saturday), a time-honored tradition\",\n",
        "        \"Walking along the castle ramparts for panoramic views of Edinburgh city, including the Royal Mile, Arthur's Seat, and the Firth of Forth\",\n",
        "        \"Learning about the castle's rich and often turbulent history, its role in Scottish wars, and its famous residents through exhibitions and guided tours\"\n",
        "    ],\n",
        "    \"matterhorn\": [\n",
        "        \"Photographing the iconic pyramidal peak of the Matterhorn, one of the world's most recognizable mountains, from Zermatt (Switzerland) or Breuil-Cervinia (Italy)\",\n",
        "        \"Taking a cable car or cogwheel train to viewpoints like Gornergrat (for stunning Matterhorn and glacier views), Klein Matterhorn (Matterhorn Glacier Paradise - Europe's highest cable car station), or Sunnegga/Rothorn for different perspectives\",\n",
        "        \"Hiking or mountain biking on the numerous trails around Zermatt that offer spectacular views of the Matterhorn and surrounding Alpine scenery (e.g., Riffelsee lake trail for reflections)\",\n",
        "        \"Skiing or snowboarding in the Zermatt-Cervinia ski area, which offers year-round skiing on the Theodul Glacier with the Matterhorn as a backdrop\",\n",
        "        \"Learning about the history of the first ascent and mountaineering in the region at the Matterhorn Museum (Zermatlantis) in Zermatt\",\n",
        "        \"Enjoying Alpine cuisine and the charming car-free village atmosphere of Zermatt\"\n",
        "    ],\n",
        "    \"palace_of_versailles\": [\n",
        "        \"Exploring the opulent State Apartments of the Palace of Versailles, including the magnificent Hall of Mirrors (Galerie des Glaces), the King's Grand Apartment, and the Queen's Grand Apartment\",\n",
        "        \"Wandering through the vast and meticulously designed Gardens of Versailles (Jardins de Versailles) by André Le Nôtre, with their formal parterres, fountains (musical fountain shows are held on certain days), canals, and groves\",\n",
        "        \"Visiting the Grand Trianon and Petit Trianon, smaller palaces within the estate, offering a more intimate glimpse into royal life, and Marie Antoinette's Hamlet (Le Hameau de la Reine), a rustic retreat\",\n",
        "        \"Taking a guided tour or using an audio guide to learn about the history of the French monarchy (especially Louis XIV, Louis XV, and Louis XVI), courtly life, and the significant historical events that took place at Versailles (like the signing of the Treaty of Versailles)\",\n",
        "        \"Renting a boat on the Grand Canal or exploring the gardens by bicycle or electric golf cart\",\n",
        "        \"Photographing the lavish Baroque architecture, gilded interiors, impressive sculptures, and expansive landscapes\"\n",
        "    ],\n",
        "\n",
        "    # 北美地標 (North America)\n",
        "    \"statue_of_liberty\": [\n",
        "        \"Taking a ferry from Battery Park (Manhattan) or Liberty State Park (New Jersey) to Liberty Island\",\n",
        "        \"Visiting the Statue of Liberty Museum to learn about its history, construction, symbolism, and Frederic Auguste Bartholdi's design\",\n",
        "        \"Accessing the pedestal for closer views of the statue and panoramic views of New York Harbor and the Manhattan skyline (requires advance booking)\",\n",
        "        \"Climbing to the crown for a unique, albeit small, viewing experience (requires very limited, advance booking months ahead)\",\n",
        "        \"Combining the visit with a trip to Ellis Island and the National Museum of Immigration, which is usually included in the same ferry ticket\",\n",
        "        \"Walking around the perimeter of Liberty Island for different photo opportunities of Lady Liberty and the surrounding views\"\n",
        "    ],\n",
        "    \"golden_gate_bridge\": [\n",
        "        \"Walking or biking across the bridge on the dedicated pedestrian and bicycle paths (check access times for each side)\",\n",
        "        \"Photographing the iconic Art Deco suspension bridge, painted in 'International Orange,' from various renowned viewpoints like Battery Spencer (Marin Headlands), Vista Point (north end), Fort Point National Historic Site (south end, underneath the bridge), or Baker Beach\",\n",
        "        \"Visiting the Golden Gate Bridge Welcome Center (south end) to learn about the bridge's history, engineering marvels, and see exhibits\",\n",
        "        \"Driving across the bridge for a classic experience (toll applies southbound into San Francisco)\",\n",
        "        \"Exploring the Golden Gate National Recreation Area, which encompasses areas on both sides of the bridge offering trails and views\",\n",
        "        \"Taking a bay cruise that sails under the Golden Gate Bridge and around Alcatraz Island for different perspectives\"\n",
        "    ],\n",
        "    \"grand_canyon\": [\n",
        "        \"Hiking along the Rim Trail or venturing down into the canyon on trails like Bright Angel Trail or South Kaibab Trail (South Rim) or North Kaibab Trail (North Rim) – be aware of difficulty, heat, and need for water\",\n",
        "        \"Taking a mule ride along the rim or into the canyon (book well in advance as these are very popular)\",\n",
        "        \"Watching and photographing the spectacular sunrise or sunset over the canyon from popular viewpoints like Mather Point, Yavapai Point, Hopi Point (South Rim), or Bright Angel Point (North Rim) as the canyon walls change colors dramatically\",\n",
        "        \"Visiting various viewpoints along the South Rim Drive (using the free park shuttle buses for much of the year) or the North Rim Scenic Drives\",\n",
        "        \"Taking a helicopter or fixed-wing aircraft tour for a breathtaking aerial perspective of the vastness of the Grand Canyon (optional, can be costly)\",\n",
        "        \"Learning about the geology, ecology, and human history (including Native American cultures) at visitor centers and ranger programs\"\n",
        "    ],\n",
        "    \"hollywood_sign\": [\n",
        "        \"Hiking to viewpoints for relatively close-up views of the sign, such as from trails in Griffith Park (e.g., Hollyridge Trail, Wonder View Trail, or near Griffith Observatory) or from Lake Hollywood Park (great for ground-level photos with the sign)\",\n",
        "        \"Photographing the iconic white capital letters on Mount Lee from various locations throughout Hollywood and Los Angeles, including the Hollywood & Highland Center observation decks\",\n",
        "        \"Visiting Griffith Observatory for excellent panoramic views of the Hollywood Sign, the Los Angeles basin, and the Pacific Ocean (on clear days), as well as its science exhibits\",\n",
        "        \"Learning about the history of the sign (originally 'HOLLYWOODLAND') and its significance as a symbol of the American film industry\",\n",
        "        \"Driving through the Hollywood Hills for different perspectives (be mindful of residential areas and parking restrictions)\",\n",
        "        \"Taking a guided Hollywood tour that often includes stops at optimal sign viewing locations\"\n",
        "    ],\n",
        "    \"white_house\": [\n",
        "        \"Viewing and photographing the iconic exterior of the White House from the North Side (Pennsylvania Avenue, in front of Lafayette Square) or the South Side (from the Ellipse)\",\n",
        "        \"Taking a public tour of select rooms in the East Wing (requires advance request through a U.S. Member of Congress for citizens, or through one's embassy for foreign nationals, months in advance; security is very strict)\",\n",
        "        \"Visiting the White House Visitor Center (located nearby) for exhibits on the history of the White House, its architecture, furnishings, first families, and presidential life\",\n",
        "        \"Exploring President's Park, which includes Lafayette Square to the north (with statues of revolutionary war heroes) and the Ellipse to the south\",\n",
        "        \"Learning about the history of the U.S. presidency and the symbolic importance of the White House as the executive mansion\",\n",
        "        \"Observing any official motorcades or security measures, which can be a unique part of the D.C. experience\"\n",
        "    ],\n",
        "    \"mount_rushmore\": [\n",
        "        \"Viewing and photographing the colossal carved faces of U.S. Presidents George Washington, Thomas Jefferson, Theodore Roosevelt, and Abraham Lincoln in the granite of Mount Rushmore\",\n",
        "        \"Walking the Presidential Trail, a boardwalk loop that provides closer views and different angles of the sculptures\",\n",
        "        \"Visiting the Lincoln Borglum Visitor Center and Museum to learn about the history of the carving, the sculptor Gutzon Borglum, the tools and techniques used, and the depicted presidents\",\n",
        "        \"Attending the evening lighting ceremony (held seasonally, typically May to September), which includes a ranger talk and the illumination of the monument\",\n",
        "        \"Exploring the Sculptor's Studio to see original plaster models and tools used in the carving process\",\n",
        "        \"Learning about the significance of each president chosen and the broader history of the United States represented by the memorial\"\n",
        "    ],\n",
        "    \"times_square\": [\n",
        "        \"Experiencing the dazzling and overwhelming display of massive digital billboards, flashing neon lights, and advertisements that illuminate the square 24/7\",\n",
        "        \"People-watching in one of the world's busiest and most famous pedestrian intersections, soaking in the vibrant and energetic atmosphere\",\n",
        "        \"Attending a Broadway show in the renowned Theater District, which is centered around Times Square (purchase tickets in advance or try the TKTS booth for same-day discounts)\",\n",
        "        \"Shopping at flagship stores of international brands, unique boutiques, and souvenir shops that line the square\",\n",
        "        \"Dining at diverse restaurants, from themed eateries and fast-food chains to upscale dining options\",\n",
        "        \"Photographing the iconic scenery, costumed characters (be aware they may expect tips), and the general buzz, especially stunning at night or during the New Year's Eve ball drop\"\n",
        "    ],\n",
        "    \"cn_tower\": [\n",
        "        \"Ascending via high-speed glass-fronted elevators to the main observation levels: the LookOut Level (with floor-to-ceiling panoramic window walls) and the famous Glass Floor (for a thrilling view 342m/1,122ft straight down)\",\n",
        "        \"Going even higher to the SkyPod, one of the highest observation platforms in the world (an additional 33 storeys above the main observation level, requires separate ticket)\",\n",
        "        \"Experiencing the EdgeWalk (seasonal, weather permitting), the world’s highest full-circle, hands-free walk on a 1.5m (5ft) wide ledge encircling the top of the Tower’s main pod, 356m/1,168ft above the ground (for thrill-seekers, book well in advance)\",\n",
        "        \"Dining at the award-winning 360 Restaurant, a revolving restaurant that completes a full rotation approximately every 72 minutes, offering stunning views and a cellar in the sky\",\n",
        "        \"Photographing the panoramic cityscape of Toronto, Lake Ontario, and on clear days, even Niagara Falls or New York State\",\n",
        "        \"Learning about the tower's construction, engineering, and its role as a communications tower through exhibits and informational displays\"\n",
        "    ],\n",
        "    \"chichen_itza\": [\n",
        "        \"Exploring the magnificent El Castillo (Pyramid of Kukulcán), the iconic step-pyramid that dominates the site, and learning about its Mayan astronomical alignments (e.g., the serpent shadow effect during the spring and autumn equinoxes)\",\n",
        "        \"Visiting other significant structures within the ancient Mayan city, such as the Great Ball Court (the largest in Mesoamerica), the Temple of the Warriors (with its Chac Mool figure and colonnades), the Group of a Thousand Columns, and the Observatory (El Caracol)\",\n",
        "        \"Observing the intricate stone carvings, Mayan hieroglyphs, and depictions of deities like Kukulcán (the feathered serpent) and Chaac (the rain god) on the buildings\",\n",
        "        \"Swimming in a nearby sacred cenote (natural sinkhole), such as Ik Kil or Yokdzonot, for a refreshing break after exploring the hot ruins (often combined with Chichen Itza tours)\",\n",
        "        \"Taking a guided tour (highly recommended) to understand the rich history, culture, rituals, and astronomical knowledge of the Mayan civilization that flourished at Chichen Itza (a UNESCO World Heritage site)\",\n",
        "        \"Photographing the impressive pyramids, ancient temples, and unique architectural features of this important archaeological site\"\n",
        "    ],\n",
        "    \"niagara_falls\": [\n",
        "        \"Taking the 'Maid of the Mist' (USA side) or 'Hornblower Niagara Cruises/Niagara City Cruises' (Canada side) boat tour for an up-close and powerful experience of the mist and roar of the Horseshoe Falls, American Falls, and Bridal Veil Falls\",\n",
        "        \"Experiencing the 'Cave of the Winds' (USA side), where you walk on wooden walkways near the base of the Bridal Veil Falls and get drenched by the spray\",\n",
        "        \"Walking along the Niagara Parkway (Canada) or within Niagara Falls State Park (USA) for various viewpoints of the falls, including Terrapin Point (USA) and Table Rock Centre (Canada)\",\n",
        "        \"Viewing the falls illuminated in vibrant colors at night, and enjoying seasonal fireworks displays over the falls\",\n",
        "        \"Visiting Journey Behind the Falls (Canada) to descend and walk through tunnels behind the Horseshoe Falls\",\n",
        "        \"Exploring other attractions in the Niagara Parks area, such as Queen Victoria Park, Clifton Hill (Canada side for entertainment), or taking a helicopter tour for an aerial view\"\n",
        "    ],\n",
        "    \"central_park\": [\n",
        "        \"Strolling or biking through the vast network of paths, exploring iconic areas like The Mall and Literary Walk, Bethesda Terrace and Fountain, Strawberry Fields (John Lennon memorial), and Conservatory Water (for model sailboat racing)\",\n",
        "        \"Having a picnic on the Great Lawn or Sheep Meadow with views of the surrounding Manhattan skyline\",\n",
        "        \"Renting a rowboat or taking a gondola ride on The Lake, passing under Bow Bridge\",\n",
        "        \"Visiting Central Park Zoo, the Central Park Carousel, or Wollman Rink (ice skating in winter, other activities in summer)\",\n",
        "        \"Exploring the more rugged northern section with the North Woods and Harlem Meer, or the formal Conservatory Garden\",\n",
        "        \"Attending free events like Shakespeare in the Park (summer), concerts by the New York Philharmonic, or SummerStage performances\"\n",
        "    ],\n",
        "    \"las_vegas_strip\": [\n",
        "        \"Walking along Las Vegas Boulevard South to see the extravagant themed mega-resorts and casinos, such as Bellagio (with its famous fountains), Venetian (with canals and gondola rides), Caesars Palace, Luxor (pyramid and sphinx), and Paris Las Vegas (Eiffel Tower replica)\",\n",
        "        \"Watching free street-side shows like the Fountains of Bellagio water ballet or the Mirage Volcano eruption\",\n",
        "        \"Trying your luck at casino games (responsibly, if you choose to gamble)\",\n",
        "        \"Attending a world-class show, concert, or residency featuring top entertainers\",\n",
        "        \"Shopping at high-end retail promenades like The Forum Shops at Caesars, Grand Canal Shoppes at The Venetian, or Crystals at CityCenter\",\n",
        "        \"Dining at celebrity chef restaurants or enjoying diverse culinary experiences, and experiencing the vibrant nightlife with clubs and bars\"\n",
        "    ],\n",
        "    \"yellowstone_national_park\": [\n",
        "        \"Watching the eruption of Old Faithful geyser and exploring the Upper Geyser Basin, home to the world's largest concentration of geysers\",\n",
        "        \"Admiring the vibrant colors of Grand Prismatic Spring in the Midway Geyser Basin and other geothermal features like mudpots and fumaroles at Mammoth Hot Springs' travertine terraces\",\n",
        "        \"Wildlife viewing: looking for bison, elk, grizzly bears, wolves, pronghorn, and bighorn sheep in areas like Lamar Valley (often called 'America's Serengeti') and Hayden Valley\",\n",
        "        \"Visiting the Grand Canyon of the Yellowstone to see the impressive Upper and Lower Falls of the Yellowstone River from viewpoints like Artist Point\",\n",
        "        \"Driving the scenic Grand Loop Road to access various park attractions and enjoying hikes on numerous trails of varying difficulty\",\n",
        "        \"Boating, fishing, or simply enjoying the views at Yellowstone Lake, North America's largest high-elevation lake\"\n",
        "    ],\n",
        "    \"banff_national_park_lake_louise\": [ # and Moraine Lake\n",
        "        \"Photographing the stunning turquoise waters of Lake Louise with the Victoria Glacier and the iconic Fairmont Chateau Lake Louise in the background; also visit the equally breathtaking Moraine Lake with its vivid blue water framed by the Valley of the Ten Peaks (access to Moraine Lake is restricted, plan ahead with shuttle or tour)\",\n",
        "        \"Canoeing or kayaking on Lake Louise or Moraine Lake for an unforgettable experience amidst the majestic mountain scenery\",\n",
        "        \"Hiking popular trails such as the Lake Agnes Teahouse Trail, Plain of Six Glaciers Trail (from Lake Louise), or the Rockpile Trail and Lakeshore Trail (at Moraine Lake)\",\n",
        "        \"Taking the Lake Louise Gondola (or Banff Gondola near Banff town) for panoramic views of the Canadian Rockies, glaciers, and valleys\",\n",
        "        \"Wildlife viewing for animals like elk, deer, bighorn sheep, and occasionally bears (maintain a safe distance)\",\n",
        "        \"Exploring the charming town of Banff, Johnston Canyon, or driving the scenic Icefields Parkway towards Jasper National Park\"\n",
        "    ],\n",
        "    \"space_needle_seattle\": [\n",
        "        \"Taking a 41-second elevator ride to the 520-foot high observation deck for 360-degree panoramic views of Seattle's skyline, Elliott Bay, Puget Sound, the Olympic Mountains, Cascade Mountains, and Mount Rainier on clear days\",\n",
        "        \"Stepping out onto 'The Loupe,' the world's first and only revolving glass floor, offering thrilling downward views of the city and the Needle's structure\",\n",
        "        \"Enjoying a meal or drinks at 'The Loupe Lounge' (revolving glass floor level) or other dining options within the Space Needle\",\n",
        "        \"Photographing the iconic futuristic structure, a symbol of Seattle and the 1962 World's Fair, from various angles and at different times of day (especially sunset or when illuminated at night)\",\n",
        "        \"Learning about the history of the Space Needle and Seattle through interactive exhibits on the observation deck\",\n",
        "        \"Visiting nearby attractions at Seattle Center, such as the Chihuly Garden and Glass, Museum of Pop Culture (MoPOP), or Pacific Science Center\"\n",
        "    ],\n",
        "\n",
        "    # 南美地標 (South America)\n",
        "    \"machu_picchu\": [\n",
        "        \"Exploring the remarkably preserved ancient Inca citadel, including the Temple of the Sun, Intihuatana stone, Royal Tomb, residential areas, and agricultural terraces\",\n",
        "        \"Hiking Huayna Picchu or Machu Picchu Mountain for breathtaking panoramic views of the ruins and surrounding Andes (requires separate, pre-booked tickets well in advance as permits are limited)\",\n",
        "        \"Taking a guided tour (highly recommended) to learn about Inca history, cosmology, architecture, and the possible purposes of this enigmatic 'Lost City of the Incas' (a UNESCO World Heritage site)\",\n",
        "        \"Photographing the stunning landscape of stone ruins nestled dramatically in the cloud-forested mountains, especially during sunrise or late afternoon for optimal lighting\",\n",
        "        \"Watching the sunrise over Machu Picchu (if staying in Aguas Calientes or taking an early bus/train to arrive before dawn)\",\n",
        "        \"Visiting the Sun Gate (Inti Punku) for a classic first view of Machu Picchu if hiking a portion of the Inca Trail, or the Inca Bridge for a glimpse of Inca engineering\"\n",
        "    ],\n",
        "    \"christ_the_redeemer\": [\n",
        "        \"Taking the historic cog train (Trem do Corcovado) or an official van up Corcovado Mountain through Tijuca National Park to reach the statue\",\n",
        "        \"Admiring the colossal Art Deco statue of Jesus Christ with outstretched arms, a global icon of Rio de Janeiro and Brazil, and one of the New Seven Wonders of the World\",\n",
        "        \"Enjoying breathtaking 360-degree panoramic views of Rio de Janeiro, including Sugarloaf Mountain, Copacabana and Ipanema beaches, Guanabara Bay, and the Rodrigo de Freitas Lagoon\",\n",
        "        \"Photographing the statue from its base and the spectacular surrounding cityscape and landscape\",\n",
        "        \"Visiting the small chapel located at the base of the statue, dedicated to Our Lady of Aparecida, the patron saint of Brazil\",\n",
        "        \"Learning about the history, construction, and significance of the monument through informational plaques or guided tours\"\n",
        "    ],\n",
        "    \"iguazu_falls\": [\n",
        "        \"Exploring the extensive network of walkways and viewpoints on both the Argentinian side (Parque Nacional Iguazú) and the Brazilian side (Parque Nacional do Iguaçu) for different perspectives of the hundreds of waterfalls\",\n",
        "        \"Experiencing the immense power and roar of the Devil's Throat (Garganta del Diablo / Garganta do Diabo), the largest and most dramatic cataract, from viewing platforms that extend over the falls\",\n",
        "        \"Taking a thrilling boat tour (e.g., Gran Aventura on the Argentinian side or Macuco Safari on the Brazilian side) that goes close to and even under some of the falls (expect to get soaked!)\",\n",
        "        \"Walking the Upper Circuit and Lower Circuit trails on the Argentinian side for varied views and close encounters with different sections of the falls\",\n",
        "        \"Photographing the spectacular waterfalls, lush subtropical rainforest, and frequent rainbows that form in the mist\",\n",
        "        \"Wildlife spotting in the surrounding national parks, looking for coatis, toucans, monkeys, and colorful butterflies\"\n",
        "    ],\n",
        "    \"galapagos_islands\": [\n",
        "        \"Taking a multi-day cruise on a small ship or yacht to visit various islands, as each island offers unique landscapes and wildlife viewing opportunities (the most common way to explore)\",\n",
        "        \"Snorkeling or scuba diving in the rich marine environment to see sea lions, marine iguanas, Galapagos penguins, sea turtles, sharks (like hammerheads and Galapagos sharks), rays, and colorful fish\",\n",
        "        \"Observing unique and fearless wildlife up close (maintaining a respectful distance as per park rules), such as giant tortoises in their natural habitat (e.g., at El Chato Tortoise Reserve on Santa Cruz Island), blue-footed boobies, frigatebirds with inflated red pouches, and land iguanas\",\n",
        "        \"Hiking on volcanic landscapes, lava fields, and pristine beaches, learning about the geology and evolutionary history of the islands that inspired Charles Darwin\",\n",
        "        \"Visiting the Charles Darwin Research Station on Santa Cruz Island to learn about conservation efforts and the tortoise breeding program\",\n",
        "        \"Kayaking, birdwatching, and photographing the extraordinary biodiversity and unique natural beauty of this UNESCO World Heritage site\"\n",
        "    ],\n",
        "    \"torres_del_paine_national_park\": [\n",
        "        \"Hiking famous multi-day treks like the 'W Trek' (typically 4-5 days) or the 'O Circuit' (full loop, 8-10 days) for stunning views of the granite Paine Towers, Cuernos del Paine (Horns), glaciers, lakes, and Patagonian landscapes\",\n",
        "        \"Undertaking day hikes to iconic viewpoints, such as the Base of the Towers (Mirador Las Torres), Mirador Cuernos, or viewpoints overlooking Grey Glacier and Lake Pehoé\",\n",
        "        \"Photographing the dramatic granite peaks, turquoise glacial lakes (like Pehoé, Nordenskjöld, Sarmiento), vast ice fields (Southern Patagonian Ice Field), and unique flora and fauna\",\n",
        "        \"Wildlife viewing for animals such as guanacos, condors, foxes, and occasionally pumas (though elusive)\",\n",
        "        \"Taking a boat trip on Lake Grey to get close to the face of Grey Glacier, or a catamaran across Lake Pehoé\",\n",
        "        \"Experiencing the wild and unpredictable Patagonian weather, and enjoying the pristine, rugged beauty of this renowned national park (a UNESCO Biosphere Reserve)\"\n",
        "    ],\n",
        "    \"angel_falls\": [\n",
        "        \"Taking a multi-day expedition (typically 3 days/2 nights) by motorized dugout canoe (curiara) up the Carrao and Churún rivers through Canaima National Park to reach the base of Angel Falls (Salto Ángel), the world's tallest uninterrupted waterfall\",\n",
        "        \"Hiking through the rainforest from the river camp to a viewpoint near the base of the falls (Mirador Laime) to witness the spectacular cascade plunging from the summit of Auyán-Tepui\",\n",
        "        \"Swimming in pools at the base of the falls or in the river (depending on conditions and guide advice)\",\n",
        "        \"Spending nights in hammocks at rustic jungle camps, experiencing the sounds and atmosphere of the remote wilderness\",\n",
        "        \"Taking a scenic overflight by small plane from Canaima or Ciudad Bolívar for a breathtaking aerial view of Angel Falls and the vast expanse of Auyán-Tepui (often done as part of a tour or separately)\",\n",
        "        \"Learning about the indigenous Pemón culture and the unique geology of the tepuis (table-top mountains) in Canaima National Park (a UNESCO World Heritage site)\"\n",
        "    ],\n",
        "    \"salar_de_uyuni\": [\n",
        "        \"Taking a multi-day 4x4 jeep tour (typically 1 to 4 days) across the vast Salar de Uyuni, the world's largest salt flat, and the surrounding Altiplano region\",\n",
        "        \"During the dry season (May-November): Experiencing the seemingly endless white expanse of hexagonal salt patterns, visiting Incahuasi Island (Fish Island) with its giant ancient cacti and panoramic views, and taking creative forced-perspective photographs\",\n",
        "        \"During the rainy season (December-April): Witnessing the breathtaking 'world's largest mirror' effect when a thin layer of water covers the salt flat, creating stunning reflections of the sky and clouds (access can be limited)\",\n",
        "        \"Visiting the 'train cemetery' (Cementerio de Trenes) just outside Uyuni town, with its rusted antique steam locomotives\",\n",
        "        \"Seeing the salt harvesting mounds and the original salt hotel (Palacio de Sal, now a museum), and learning about salt extraction\",\n",
        "        \"Exploring the surrounding Altiplano highlights on longer tours, such as colorful lagoons (Laguna Colorada with flamingos, Laguna Verde), geysers (Sol de Mañana), hot springs (Termas de Polques), and dramatic volcanic landscapes\"\n",
        "    ],\n",
        "\n",
        "    # 中東/非洲地標 (Middle East / Africa)\n",
        "    \"pyramids_of_giza\": [\n",
        "        \"Exploring the exteriors of the three main pyramids: the Great Pyramid of Giza (Pyramid of Khufu), the Pyramid of Khafre, and the Pyramid of Menkaure\",\n",
        "        \"Entering one of the pyramids (requires separate ticket, can be claustrophobic, limited access) to see the internal chambers\",\n",
        "        \"Visiting the Great Sphinx of Giza, the colossal limestone statue with the body of a lion and the head of a human, and the adjacent Valley Temple of Khafre\",\n",
        "        \"Taking a camel or horse ride across the Giza plateau for different perspectives and classic photo opportunities of the pyramids against the desert backdrop\",\n",
        "        \"Visiting the Solar Boat Museum (Khufu Ship Museum) next to the Great Pyramid to see a remarkably preserved ancient Egyptian funerary boat\",\n",
        "        \"Attending the Sound and Light Show in the evening, where the pyramids and Sphinx are illuminated with accompanying narration about ancient Egyptian history (optional)\"\n",
        "    ],\n",
        "    \"burj_khalifa\": [\n",
        "        \"Ascending to one of the world's highest observation decks: 'At the Top' on levels 124 and 125, or the more exclusive 'At the Top, SKY' on level 148, for breathtaking panoramic views of Dubai's futuristic skyline, the desert, and the Arabian Gulf\",\n",
        "        \"Photographing the stunning views, especially during sunset or at night when the city lights up\",\n",
        "        \"Dining at At.mosphere, the restaurant and lounge on level 122, one of the world's highest restaurants\",\n",
        "        \"Watching the spectacular Dubai Fountain show, a choreographed water and light display at the base of the Burj Khalifa on Burj Lake (best viewed from the Waterfront Promenade of The Dubai Mall or a nearby restaurant)\",\n",
        "        \"Learning about the engineering, architecture, and construction of the world's tallest building through interactive exhibits at the observation deck levels\",\n",
        "        \"Shopping at The Dubai Mall, one of the world's largest shopping malls, which is connected to the Burj Khalifa and also houses the Dubai Aquarium & Underwater Zoo\"\n",
        "    ],\n",
        "    \"petra_jordan\": [ # (Was \"petra\")\n",
        "        \"Walking through the Siq, a narrow, winding sandstone gorge that serves as the dramatic main entrance to the ancient Nabataean city of Petra\",\n",
        "        \"Emerging from the Siq to behold the iconic Al-Khazneh (The Treasury), an elaborately carved temple facade, one of the most famous archaeological sites in the world\",\n",
        "        \"Exploring the vast archaeological site, including the Street of Facades, the Theatre, the Royal Tombs, the Colonnaded Street, and the Great Temple\",\n",
        "        \"Hiking up the 800+ steps to Ad Deir (The Monastery), another magnificent rock-cut facade offering stunning views (a significant but rewarding climb)\",\n",
        "        \"Photographing the 'Rose City' with its unique rock-cut architecture and dramatic desert landscape, noting how the sandstone changes color throughout the day\",\n",
        "        \"Learning about the history of the Nabataean civilization, their ingenuity in water management, and their role as a trading hub, through a local guide or the Petra Museum\"\n",
        "    ],\n",
        "    \"table_mountain\": [\n",
        "        \"Taking the rotating aerial cableway (Table Mountain Aerial Cableway) to the summit for spectacular 360-degree views of Cape Town, Table Bay, Robben Island, the Cape Peninsula, and the Atlantic Ocean\",\n",
        "        \"Hiking up one of the many trails to the summit, such as Platteklip Gorge (the most direct but steep), Skeleton Gorge (more scenic, starting from Kirstenbosch Gardens), or India Venster (more challenging, for experienced hikers)\",\n",
        "        \"Walking along the well-maintained pathways on the flat-topped summit, exploring different viewpoints, and enjoying the unique fynbos vegetation (part of the Cape Floral Kingdom, a UNESCO World Heritage site)\",\n",
        "        \"Photographing the panoramic vistas, the city nestled below, and the dramatic cloud formations known as the 'tablecloth' that sometimes cover the mountain\",\n",
        "        \"Abseiling from the top of Table Mountain (for adventure seekers, with registered operators)\",\n",
        "        \"Enjoying refreshments or a meal at the café or restaurant on the summit while taking in the views\"\n",
        "    ],\n",
        "    \"sheikh_zayed_grand_mosque\": [\n",
        "        \"Taking a guided tour (free, offered regularly) to learn about the mosque's stunning architecture, Islamic art, cultural significance, and design elements\",\n",
        "        \"Admiring the pristine white Macedonian marble exterior, the 82 domes of various sizes, the four towering minarets, and the intricate floral designs inlaid with semi-precious stones\",\n",
        "        \"Exploring the vast main prayer hall, which houses the world's largest hand-knotted carpet and one of the world's largest Swarovski crystal chandeliers\",\n",
        "        \"Walking through the serene courtyards (sahan) with their reflective pools that beautifully mirror the mosque's columns and arches\",\n",
        "        \"Photographing the breathtaking beauty of the mosque, both during the day (when the white marble gleams) and at night (when it is illuminated by a unique lunar lighting system that changes with the phases of the moon)\",\n",
        "        \"Respecting the dress code (modest attire required for all visitors; abayas provided for women if needed) and behaving reverently within the sacred space\"\n",
        "    ],\n",
        "    \"masai_mara_national_reserve\": [\n",
        "        \"Going on multiple game drives (early morning and late afternoon are often best) in a 4x4 safari vehicle with an experienced guide to spot the 'Big Five' (lion, leopard, elephant, rhino, buffalo) and other wildlife like cheetahs, giraffes, zebras, wildebeest, hyenas, and numerous bird species\",\n",
        "        \"Witnessing the Great Migration (typically July to October), where millions of wildebeest and zebras cross the Mara River from Tanzania's Serengeti, facing crocodiles and predators (a dramatic natural spectacle)\",\n",
        "        \"Taking a hot air balloon safari at sunrise over the Masai Mara plains for a breathtaking panoramic view of the landscape and wildlife, followed by a champagne breakfast in the bush\",\n",
        "        \"Visiting a traditional Maasai village (manyatta) to learn about Maasai culture, customs, traditions, and their way of life (usually arranged through lodges or tour operators)\",\n",
        "        \"Enjoying bush breakfasts, lunches, or sundowner drinks in scenic spots within the reserve\",\n",
        "        \"Nature walks with armed rangers (where permitted) for a different perspective on the flora and fauna, or birdwatching (the Mara has a rich avian diversity)\"\n",
        "    ],\n",
        "    \"victoria_falls\": [\n",
        "        \"Viewing the spectacular curtain of falling water from various viewpoints on both the Zambian side (e.g., Knife-Edge Bridge, Boiling Pot trail) and the Zimbabwean side (e.g., Main Falls, Rainbow Falls, Danger Point) of the Zambezi River\",\n",
        "        \"Feeling the immense spray (the 'Smoke that Thunders' or Mosi-oa-Tunya) and hearing the roar of one of the world's largest waterfalls by combined width and height\",\n",
        "        \"Taking a guided tour of the rainforest trails on the Zimbabwean side, which offer numerous perspectives of the falls\",\n",
        "        \"Experiencing thrilling adventure activities such as white-water rafting or kayaking on the powerful Zambezi River below the falls (seasonal), bungee jumping from the Victoria Falls Bridge, or gorge swinging\",\n",
        "        \"Taking a helicopter or microlight flight ('Flight of Angels') over Victoria Falls for breathtaking aerial views\",\n",
        "        \"Enjoying a sunset cruise on the upper Zambezi River, spotting wildlife like hippos, crocodiles, and birds, or visiting Livingstone Island and swimming in Devil's Pool or Angel's Pool at the edge of the falls (seasonal, Zambian side only, requires guided tour)\"\n",
        "    ],\n",
        "    \"kilimanjaro\": [\n",
        "        \"Attempting to climb Mount Kilimanjaro, Africa's highest peak and the world's tallest freestanding mountain, via one of several routes (e.g., Machame, Lemosho, Marangu, Rongai) with a licensed guide and porters (a challenging multi-day trek requiring good physical condition and acclimatization)\",\n",
        "        \"Experiencing the diverse ecological zones on the ascent, from lush rainforest and moorland to alpine desert and the arctic summit zone with its glaciers and snowfields\",\n",
        "        \"Reaching Uhuru Peak (5,895m / 19,341ft) on Kibo, the highest of Kilimanjaro's three volcanic cones, typically at sunrise for spectacular views\",\n",
        "        \"Photographing the stunning mountain scenery, unique flora (like giant groundsels and lobelias), and the iconic snow-capped summit\",\n",
        "        \"Learning about the geology of the dormant volcano and the local Chagga culture from guides and porters\",\n",
        "        \"For those not climbing: Enjoying views of Kilimanjaro from nearby towns like Moshi or Arusha (Tanzania), or Amboseli National Park (Kenya) on clear days, or taking a scenic flight around the mountain\"\n",
        "    ],\n",
        "    \"dead_sea\": [\n",
        "        \"Effortlessly floating in the hyper-saline waters of the Dead Sea, an experience unique due to the water's high salt and mineral concentration (avoid getting water in your eyes)\",\n",
        "        \"Applying the mineral-rich black mud from the Dead Sea shores onto your skin, known for its therapeutic and cosmetic benefits, then rinsing off in the sea or showers\",\n",
        "        \"Relaxing at one of the resorts or public beaches along the shores in Jordan or Israel, often equipped with facilities like showers, pools, and spas\",\n",
        "        \"Photographing the unique landscape of the Dead Sea (the lowest point on Earth's land surface), with its calm, dense turquoise waters reflecting the arid surrounding mountains and desert, and distinctive salt formations\",\n",
        "        \"Learning about the history, geology, and unique ecosystem of the Dead Sea, and the challenges it faces (e.g., receding water levels)\",\n",
        "        \"Visiting nearby historical and natural sites, such as Masada and Ein Gedi (Israel side) or Mujib Biosphere Reserve and Ma'in Hot Springs (Jordan side)\"\n",
        "    ],\n",
        "    \"dome_of_the_rock\": [\n",
        "        \"Admiring the iconic, gleaming golden dome of the Dome of the Rock (Qubbat as-Sakhrah), an Islamic shrine located on the Temple Mount (Haram al-Sharif) in the Old City of Jerusalem (access for non-Muslims to the Temple Mount plaza is restricted to specific hours and days, and entry into the Dome of the Rock itself is generally not permitted for non-Muslims)\",\n",
        "        \"Observing the octagonal structure of the Dome of the Rock, adorned with intricate blue and turquoise ceramic tilework, Quranic calligraphy, and mosaics, from the Temple Mount plaza\",\n",
        "        \"Photographing this significant religious landmark, a site of immense importance in Islam, Judaism (as the location of the First and Second Temples), and Christianity, from various viewpoints within and outside the Old City (e.g., from the Mount of Olives)\",\n",
        "        \"Exploring the wider Temple Mount/Haram al-Sharif plaza, also home to Al-Aqsa Mosque (entry for non-Muslims generally not permitted into the mosque building) and other smaller Islamic structures, while respecting the site's sanctity and rules\",\n",
        "        \"Learning about the history and religious significance of the Foundation Stone (Even HaShetiya in Hebrew, As-Sakhrah in Arabic) which the Dome of the Rock enshrines, believed to be the site where Abraham prepared to sacrifice his son, and from where Prophet Muhammad is said to have ascended to heaven\",\n",
        "        \"Visiting other holy sites within the Old City of Jerusalem, such as the Western Wall, the Church of the Holy Sepulchre, and walking the Via Dolorosa\"\n",
        "    ],\n",
        "\n",
        "    # 大洋洲地標 (Oceania)\n",
        "    \"sydney_opera_house\": [\n",
        "        \"Taking a guided architectural tour to learn about its history, innovative design by Jørn Utzon, construction challenges, and its various performance venues (e.g., Concert Hall, Joan Sutherland Theatre)\",\n",
        "        \"Attending a world-class performance, such as opera, ballet, classical music concert, theatre, or contemporary music show, inside one of its iconic halls (book tickets in advance)\",\n",
        "        \"Photographing the iconic white sail-like shells from various angles and vantage points, such as from a ferry on Sydney Harbour, Mrs Macquarie's Chair, Circular Quay, or while walking across the Sydney Harbour Bridge\",\n",
        "        \"Dining at one of the many restaurants or enjoying drinks at bars with stunning harbour views located at the Opera House, like Opera Bar or Portside Sydney\",\n",
        "        \"Walking around the exterior promenade, admiring the building's unique form up close, and enjoying the bustling atmosphere of Circular Quay\",\n",
        "        \"Visiting the gift shop for souvenirs, or attending free outdoor events and festivals that sometimes take place on the forecourt\"\n",
        "    ],\n",
        "    \"uluru\": [\n",
        "        \"Walking the full Uluru base walk (approximately 10.6 km / 6.6 miles loop, takes about 3-4 hours) to experience the immense scale and diverse features of the monolith up close, including waterholes, rock art sites, and unique geological formations (best done early morning or late afternoon to avoid heat)\",\n",
        "        \"Watching and photographing the spectacular color changes of Uluru at sunrise and sunset from designated viewing areas (Talinguru Nyakunytjaku for sunrise, Uluru sunset viewing area for sunset)\",\n",
        "        \"Taking a guided tour led by an Anangu (local Aboriginal people) guide to learn about the cultural significance, Dreamtime stories (Tjukurpa), and traditional laws associated with Uluru (highly recommended for a deeper understanding)\",\n",
        "        \"Visiting the Uluru-Kata Tjuta Cultural Centre to gain insights into Anangu culture, art, and land management practices\",\n",
        "        \"Exploring the nearby Kata Tjuta (The Olgas) rock formations, particularly the Walpa Gorge walk or the Valley of the Winds walk, for different but equally stunning desert landscapes\",\n",
        "        \"Stargazing in the clear desert night sky (Uluru is in a remote area with minimal light pollution), or participating in an Sounds of Silence or Field of Light Uluru experience (optional, requires booking)\"\n",
        "    ],\n",
        "    \"great_barrier_reef\": [\n",
        "        \"Snorkeling or scuba diving from a boat tour or island resort to explore the vibrant coral reefs, encounter colorful tropical fish, sea turtles, manta rays, reef sharks, and other diverse marine life (many tour options cater to different skill levels)\",\n",
        "        \"Taking a glass-bottom boat tour or a semi-submersible tour to view the coral and marine life without getting wet, suitable for all ages\",\n",
        "        \"Going on a scenic helicopter or seaplane flight for a breathtaking aerial perspective of the reef's intricate patterns, turquoise waters, islands, and cays (e.g., seeing Heart Reef from the air)\",\n",
        "        \"Visiting a pontoon stationed on the outer reef, which often includes facilities like underwater observatories, snorkeling platforms, and introductory dive options\",\n",
        "        \"Learning about marine conservation, the ecology of the Great Barrier Reef (a UNESCO World Heritage site), and the threats it faces (e.g., climate change, coral bleaching) through onboard marine biologist talks or visitor centers\",\n",
        "        \"Sailing or taking a catamaran cruise through the Whitsunday Islands or other reef areas, often including stops for snorkeling, swimming, and relaxing on pristine beaches like Whitehaven Beach\"\n",
        "    ],\n",
        "    \"hobbiton_movie_set\": [\n",
        "        \"Taking a fully guided walking tour through the 12-acre movie set, visiting numerous Hobbit Holes with their distinctive round doors and charming details, as seen in 'The Lord of the Rings' and 'The Hobbit' trilogies\",\n",
        "        \"Photographing iconic locations such as Bag End (Bilbo and Frodo Baggins' home), the Party Tree, the Mill, and the double-arched stone bridge\",\n",
        "        \"Enjoying a complimentary, specially brewed beverage (ale, cider, or non-alcoholic ginger beer) at The Green Dragon Inn, a faithfully reconstructed pub from the movies\",\n",
        "        \"Listening to fascinating behind-the-scenes stories and filmmaking secrets from your guide about how the Hobbiton set was created and used in the films\",\n",
        "        \"Shopping for Middle-earth themed souvenirs, Weta Workshop collectibles, and other memorabilia at the Hobbiton Shire Store\",\n",
        "        \"Immersing oneself in the picturesque, meticulously maintained landscape of The Shire, with its rolling green hills, gardens, and charming atmosphere, located on a working sheep farm\"\n",
        "    ],\n",
        "    \"sydney_harbour_bridge\": [\n",
        "        \"Undertaking the BridgeClimb Sydney experience, climbing the steel arches of the bridge for breathtaking 360-degree panoramic views of Sydney Harbour, the Opera House, the city skyline, and beyond (various climb options available, book in advance)\",\n",
        "        \"Walking or cycling across the bridge on the dedicated pedestrian walkway (eastern side) or cycleway (western side) for free, enjoying fantastic views and photo opportunities\",\n",
        "        \"Visiting the Pylon Lookout on the southeastern pylon for historical exhibits about the bridge's construction and impressive views from its observation deck\",\n",
        "        \"Photographing the iconic 'Coathanger' from various vantage points, such as Mrs Macquarie's Chair, Luna Park, McMahon's Point, or from a ferry on the harbour\",\n",
        "        \"Taking a ferry ride under the bridge for a different perspective of its massive scale and engineering\",\n",
        "        \"Learning about the history, design, and construction of this engineering marvel, which opened in 1932\"\n",
        "    ],\n",
        "    \"fiordland_national_park_milford_sound\": [ # and Doubtful Sound\n",
        "        \"Taking a scenic boat cruise (day cruise or overnight cruise) on Milford Sound to experience its dramatic fiord scenery, with sheer cliffs (like Mitre Peak), cascading waterfalls (e.g., Stirling Falls, Bowen Falls), lush rainforest, and often, mist-shrouded peaks\",\n",
        "        \"Kayaking on Milford Sound or Doubtful Sound for a more intimate and peaceful experience of the fiords, getting closer to the shoreline and wildlife\",\n",
        "        \"Spotting wildlife such as New Zealand fur seals basking on rocks, dolphins, Fiordland crested penguins (seasonal), and various seabirds\",\n",
        "        \"Exploring Doubtful Sound, a larger and more remote fiord, often via a tour involving a cruise across Lake Manapouri and a bus trip over Wilmot Pass\",\n",
        "        \"Hiking parts of famous multi-day tracks like the Milford Track (requires advance booking months or even years ahead) or Kepler Track, or shorter day walks accessible from the Milford Road\",\n",
        "        \"Photographing the awe-inspiring, moody, and pristine landscapes of Fiordland National Park (a UNESCO World Heritage site), known for its high rainfall and dramatic beauty\"\n",
        "    ],\n",
        "    \"bondi_beach\": [\n",
        "        \"Swimming, surfing, or sunbathing on the famous crescent-shaped golden sands of Bondi Beach, one of Australia's most iconic beaches\",\n",
        "        \"Learning to surf at one of the surf schools located at Bondi Beach\",\n",
        "        \"Walking or jogging the scenic Bondi to Coogee Coastal Walk (approx. 6km), offering stunning ocean views, dramatic cliffs, and access to other beaches like Tamarama and Bronte\",\n",
        "        \"Visiting the Bondi Icebergs Club, a historic swimming club with its famous ocean pool that waves often crash into, and enjoying a meal or drink at its restaurant with panoramic beach views\",\n",
        "        \"Exploring the vibrant Campbell Parade, the street fronting the beach, lined with cafes, restaurants, surf shops, and fashion boutiques\",\n",
        "        \"People-watching and soaking in the lively beach culture, or visiting the Bondi Markets (on weekends) for local crafts, fashion, and food\"\n",
        "    ],\n",
        "    \"aoraki_mount_cook_national_park\": [\n",
        "        \"Hiking popular trails such as the Hooker Valley Track (relatively easy, 3-hour return) for spectacular views of Aoraki/Mount Cook, Mueller Glacier, Hooker Lake (with icebergs), and suspension bridges\",\n",
        "        \"Admiring New Zealand's highest peak, Aoraki/Mount Cook, and the surrounding majestic Southern Alps, glaciers, and turquoise glacial lakes like Lake Pukaki and Lake Tekapo (often framed by colorful lupins in summer - Nov/Dec)\",\n",
        "        \"Stargazing in the Aoraki Mackenzie International Dark Sky Reserve, one of the best places in the world for viewing the night sky due to its clear, dark conditions (guided stargazing tours available)\",\n",
        "        \"Taking a scenic helicopter or ski plane flight for breathtaking aerial views of the mountains and glaciers, possibly including a snow landing on Tasman Glacier\",\n",
        "        \"Visiting the Sir Edmund Hillary Alpine Centre at The Hermitage Hotel to learn about the region's mountaineering history, flora, fauna, and geology\",\n",
        "        \"Experienced mountaineering or glacier hiking with qualified guides (for advanced adventurers)\"\n",
        "    ],\n",
        "    \"twelve_apostles_great_ocean_road\": [\n",
        "        \"Viewing and photographing the iconic limestone stacks known as The Twelve Apostles (though fewer than twelve now remain due to erosion) rising dramatically from the Southern Ocean, from the designated clifftop viewing platforms\",\n",
        "        \"Visiting at sunrise or sunset for the most spectacular lighting conditions, as the stacks change color and long shadows are cast (be prepared for crowds during these times)\",\n",
        "        \"Walking along the boardwalks and pathways to different lookout points offering various perspectives of The Twelve Apostles and the rugged coastline\",\n",
        "        \"Exploring other nearby dramatic rock formations and coastal features along this section of the Great Ocean Road, such as Loch Ard Gorge (site of a famous shipwreck), Gibson Steps (descend to the beach for a different view of some stacks), The Arch, London Bridge (now London Arch), and The Grotto\",\n",
        "        \"Taking a scenic helicopter flight over The Twelve Apostles and the Shipwreck Coast for a breathtaking aerial view (optional)\",\n",
        "        \"Learning about the geology of the limestone formations, the power of coastal erosion, and the maritime history of the area at the Twelve Apostles Visitor Centre\"\n",
        "    ],\n",
        "    \"easter_island_moai\": [\n",
        "        \"Exploring Rano Raraku, the volcanic crater quarry where hundreds of moai were carved and many still stand in various stages of completion, some half-buried\",\n",
        "        \"Visiting Ahu Tongariki to witness the impressive sight of fifteen restored moai standing on the largest ceremonial platform on the island, especially spectacular at sunrise\",\n",
        "        \"Relaxing or swimming at Anakena Beach, a picturesque white coral sand beach with palm trees, featuring Ahu Nau Nau with its well-preserved moai (some with topknots) and Ahu Ature Huki\",\n",
        "        \"Hiking to the rim of the Rano Kau volcano to see its stunning crater lake and visiting the nearby ceremonial village of Orongo, known for its Birdman cult petroglyphs and dramatic cliffside location\",\n",
        "        \"Discovering Ahu Akivi, a unique inland platform with seven moai that face the ocean, aligned with the equinox\",\n",
        "        \"Learning about Rapa Nui culture, history, and the mysteries of the moai at the Museo Antropológico Sebastián Englert in Hanga Roa\",\n",
        "        \"Photographing the diverse moai sites across the island, such as Ahu Tahai (near Hanga Roa, good for sunset), Puna Pau (quarry for the red scoria pukao topknots), and Te Pito Kura (site of a large fallen moai and a magnetic stone)\",\n",
        "        \"Attending a traditional Rapa Nui cultural performance (dance and music) or experiencing a Curanto (traditional underground feast)\",\n",
        "        \"Stargazing in the exceptionally clear night skies due to the island's remote location and lack of light pollution\",\n",
        "        \"Renting a car, scooter, or bicycle to independently explore the island's numerous archaeological sites and natural beauty, or taking a guided tour for deeper insights\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGMFM5vdBhdP"
      },
      "outputs": [],
      "source": [
        "# %%writefile clip_zero_shot_classifier.py\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional, Union, Any\n",
        "\n",
        "# from landmark_data import ALL_LANDMARKS, get_all_landmark_prompts\n",
        "\n",
        "class CLIPZeroShotClassifier:\n",
        "    \"\"\"\n",
        "    使用CLIP模型進行零樣本分類，專注於識別世界知名地標。\n",
        "    作為YOLO檢測的補充，處理標準對象檢測無法識別的地標建築。\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str = \"ViT-L/14\", device: str = None):\n",
        "        \"\"\"\n",
        "        初始化CLIP零樣本分類器\n",
        "\n",
        "        Args:\n",
        "            model_name: CLIP模型名稱，默認為\"ViT-L/14\"\n",
        "            device: 運行設備，None則自動選擇\n",
        "        \"\"\"\n",
        "        # 設置運行設備\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        print(f\"Initializing CLIP Zero-Shot Landmark Classifier ({model_name}) on {self.device}\")\n",
        "        try:\n",
        "            self.model, self.preprocess = clip.load(model_name, device=self.device)\n",
        "            print(f\"Successfully loaded CLIP model\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CLIP model: {e}\")\n",
        "            raise\n",
        "\n",
        "        # 加載地標數據\n",
        "        try:\n",
        "            self.landmark_data = ALL_LANDMARKS\n",
        "            self.landmark_prompts = get_all_landmark_prompts()\n",
        "            print(f\"Loaded {len(self.landmark_prompts)} landmark prompts for classification\")\n",
        "\n",
        "            # 預計算地標文本特徵\n",
        "            self.landmark_text_features = self._precompute_text_features(self.landmark_prompts)\n",
        "\n",
        "            # 創建地標ID到索引的映射，可快速查找\n",
        "            self.landmark_id_to_index = {landmark_id: i for i, landmark_id in enumerate(ALL_LANDMARKS.keys())}\n",
        "\n",
        "            # 初始化批處理參數\n",
        "            self.batch_size = 16  # 默認批處理大小\n",
        "            self.confidence_threshold_multipliers = {\n",
        "                \"close_up\": 0.9,     # 近景標準閾值\n",
        "                \"partial\": 0.6,      # 部分可見降低閾值要求\n",
        "                \"distant\": 0.5,      # 遠景更低閾值要求\n",
        "                \"full_image\": 0.7    # 整張圖像需要更高閾值\n",
        "            }\n",
        "\n",
        "            self.landmark_type_thresholds = {\n",
        "                \"tower\": 0.5,         # 塔型建築需要更高閾值\n",
        "                \"skyscraper\": 0.4,    # 摩天大樓使用較低閾值\n",
        "                \"building\": 0.55,     # 一般建築物閾值略微降低\n",
        "                \"monument\": 0.5,      # 紀念碑閾值\n",
        "                \"natural\": 0.6        # 自然地標可以使用較低閾值\n",
        "            }\n",
        "\n",
        "            # 初始化結果快取\n",
        "            self.results_cache = {}  # 使用圖像hash作為鍵\n",
        "            self.cache_max_size = 100  # 最大快取項目數\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"Warning: landmark_data.py not found. Landmark classification will be limited\")\n",
        "            self.landmark_data = {}\n",
        "            self.landmark_prompts = []\n",
        "            self.landmark_text_features = None\n",
        "            self.landmark_id_to_index = {}\n",
        "            self.results_cache = {}\n",
        "\n",
        "    def _get_image_hash(self, image):\n",
        "        \"\"\"\n",
        "        為圖像生成簡單的 hash 值用於快取\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy 數組\n",
        "\n",
        "        Returns:\n",
        "            str: 圖像的 hash 值\n",
        "        \"\"\"\n",
        "        if isinstance(image, np.ndarray):\n",
        "            # 對於 numpy 數組，降採樣並計算簡單 hash\n",
        "            small_img = image[::10, ::10] if image.ndim == 3 else image\n",
        "            return hash(small_img.tobytes())\n",
        "        else:\n",
        "            # 對於 PIL 圖像，調整大小後轉換為 bytes\n",
        "            small_img = image.resize((32, 32))\n",
        "            return hash(small_img.tobytes())\n",
        "\n",
        "    def _manage_cache(self):\n",
        "        \"\"\"\n",
        "        管理結果快取大小\n",
        "        \"\"\"\n",
        "        if len(self.results_cache) > self.cache_max_size:\n",
        "            oldest_key = next(iter(self.results_cache))\n",
        "            del self.results_cache[oldest_key]\n",
        "\n",
        "    def set_batch_size(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        設置批處理大小\n",
        "\n",
        "        Args:\n",
        "            batch_size: 新的批處理大小\n",
        "        \"\"\"\n",
        "        self.batch_size = max(1, batch_size)\n",
        "        print(f\"Batch size set to {self.batch_size}\")\n",
        "\n",
        "\n",
        "    def adjust_confidence_threshold(self, detection_type: str, multiplier: float):\n",
        "        \"\"\"\n",
        "        調整特定檢測類型的置信度閾值乘數\n",
        "\n",
        "        Args:\n",
        "            detection_type: 檢測類型 ('close_up', 'partial', 'distant', 'full_image')\n",
        "            multiplier: 置信度閾值乘數\n",
        "        \"\"\"\n",
        "        if detection_type in self.confidence_threshold_multipliers:\n",
        "            self.confidence_threshold_multipliers[detection_type] = max(0.1, min(1.5, multiplier))\n",
        "            print(f\"Adjusted confidence threshold multiplier for {detection_type} to {multiplier}\")\n",
        "        else:\n",
        "            print(f\"Unknown detection type: {detection_type}\")\n",
        "\n",
        "\n",
        "    def _precompute_text_features(self, text_prompts: List[str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        預計算文本提示的CLIP特徵，提高批處理效率\n",
        "\n",
        "        Args:\n",
        "            text_prompts: 文本提示列表\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 預計算的文本特徵\n",
        "        \"\"\"\n",
        "        if not text_prompts:\n",
        "            return None\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Process in batches to avoid CUDA memory issues\n",
        "            batch_size = 128  # Adjust based on GPU memory\n",
        "            features_list = []\n",
        "\n",
        "            for i in range(0, len(text_prompts), batch_size):\n",
        "                batch_prompts = text_prompts[i:i+batch_size]\n",
        "                text_tokens = clip.tokenize(batch_prompts).to(self.device)\n",
        "                batch_features = self.model.encode_text(text_tokens)\n",
        "                batch_features = batch_features / batch_features.norm(dim=-1, keepdim=True)\n",
        "                features_list.append(batch_features)\n",
        "\n",
        "            # Concatenate all batches\n",
        "            if len(features_list) > 1:\n",
        "                text_features = torch.cat(features_list, dim=0)\n",
        "            else:\n",
        "                text_features = features_list[0]\n",
        "\n",
        "        return text_features\n",
        "\n",
        "    def _perform_pyramid_analysis(self,\n",
        "                         image: Union[Image.Image, np.ndarray],\n",
        "                         levels: int = 4,\n",
        "                         base_threshold: float = 0.25,\n",
        "                         aspect_ratios: List[float] = [1.0, 0.75, 1.5]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Performs multi-scale pyramid analysis on the image to improve landmark detection.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "            levels: Number of pyramid levels\n",
        "            base_threshold: Base confidence threshold\n",
        "            aspect_ratios: Different aspect ratios to try (for tall buildings vs wide landscapes)\n",
        "\n",
        "        Returns:\n",
        "            Dict: Results of pyramid analysis\n",
        "        \"\"\"\n",
        "        # Ensure image is PIL format\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        width, height = image.size\n",
        "        pyramid_results = []\n",
        "\n",
        "        # 對每個縮放和縱橫比組合進行處理\n",
        "        for level in range(levels):\n",
        "            # 計算縮放因子\n",
        "            scale_factor = 1.0 - (level * 0.2)\n",
        "\n",
        "            for aspect_ratio in aspect_ratios:\n",
        "                # 計算新尺寸，保持面積近似不變\n",
        "                if aspect_ratio != 1.0:\n",
        "                    # 保持面積近似不變的情況下調整縱橫比\n",
        "                    new_width = int(width * scale_factor * (1/aspect_ratio)**0.5)\n",
        "                    new_height = int(height * scale_factor * aspect_ratio**0.5)\n",
        "                else:\n",
        "                    new_width = int(width * scale_factor)\n",
        "                    new_height = int(height * scale_factor)\n",
        "\n",
        "                # 調整圖像大小\n",
        "                scaled_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "                # 預處理圖像\n",
        "                image_input = self.preprocess(scaled_image).unsqueeze(0).to(self.device)\n",
        "\n",
        "                # 獲取圖像特徵\n",
        "                with torch.no_grad():\n",
        "                    image_features = self.model.encode_image(image_input)\n",
        "                    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                    # 計算相似度\n",
        "                    similarity = (100.0 * image_features @ self.landmark_text_features.T).softmax(dim=-1)\n",
        "                    similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "                # 找到最佳匹配\n",
        "                best_idx = similarity.argmax().item()\n",
        "                best_score = similarity[best_idx]\n",
        "\n",
        "                if best_score >= base_threshold:\n",
        "                    landmark_id = list(self.landmark_data.keys())[best_idx]\n",
        "                    landmark_info = self.landmark_data[landmark_id]\n",
        "\n",
        "                    pyramid_results.append({\n",
        "                        \"landmark_id\": landmark_id,\n",
        "                        \"landmark_name\": landmark_info[\"name\"],\n",
        "                        \"confidence\": float(best_score),\n",
        "                        \"scale_factor\": scale_factor,\n",
        "                        \"aspect_ratio\": aspect_ratio,\n",
        "                        \"location\": landmark_info[\"location\"]\n",
        "                    })\n",
        "\n",
        "        # 按置信度排序\n",
        "        pyramid_results.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
        "\n",
        "        return {\n",
        "            \"is_landmark\": len(pyramid_results) > 0,\n",
        "            \"results\": pyramid_results,\n",
        "            \"best_result\": pyramid_results[0] if pyramid_results else None\n",
        "        }\n",
        "\n",
        "    def _enhance_features(self, image: Union[Image.Image, np.ndarray]) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Enhances image features to improve landmark detection.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "\n",
        "        Returns:\n",
        "            PIL.Image: Enhanced image\n",
        "        \"\"\"\n",
        "        # Ensure image is PIL format\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # Convert to numpy for processing\n",
        "        img_array = np.array(image)\n",
        "\n",
        "        # Skip processing for grayscale images\n",
        "        if len(img_array.shape) < 3:\n",
        "            return image\n",
        "\n",
        "        # Apply adaptive contrast enhancement\n",
        "        # Convert to LAB color space\n",
        "        from skimage import color, exposure\n",
        "        try:\n",
        "            # Convert to LAB color space\n",
        "            if img_array.shape[2] == 4:  # Handle RGBA\n",
        "                img_array = img_array[:,:,:3]\n",
        "\n",
        "            lab = color.rgb2lab(img_array[:,:,:3] / 255.0)\n",
        "            l_channel = lab[:,:,0]\n",
        "\n",
        "            # Enhance contrast of L channel\n",
        "            p2, p98 = np.percentile(l_channel, (2, 98))\n",
        "            l_channel_enhanced = exposure.rescale_intensity(l_channel, in_range=(p2, p98))\n",
        "\n",
        "            # Replace L channel and convert back to RGB\n",
        "            lab[:,:,0] = l_channel_enhanced\n",
        "            enhanced_img = color.lab2rgb(lab) * 255.0\n",
        "            enhanced_img = enhanced_img.astype(np.uint8)\n",
        "\n",
        "            return Image.fromarray(enhanced_img)\n",
        "        except ImportError:\n",
        "            print(\"Warning: skimage not available for feature enhancement\")\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            print(f\"Error in feature enhancement: {e}\")\n",
        "            return image\n",
        "\n",
        "    def _determine_landmark_type(self, landmark_id):\n",
        "        \"\"\"\n",
        "        自動判斷地標類型，基於地標數據和命名\n",
        "\n",
        "        Returns:\n",
        "            str: 地標類型，用於調整閾值\n",
        "        \"\"\"\n",
        "        if not landmark_id:\n",
        "            return \"building\"  # 預設類型\n",
        "\n",
        "        # 獲取地標詳細數據\n",
        "        landmark_data = self.landmark_data if hasattr(self, 'landmark_data') else {}\n",
        "        landmark_info = landmark_data.get(landmark_id, {})\n",
        "\n",
        "        # 獲取地標相關文本\n",
        "        landmark_id_lower = landmark_id.lower()\n",
        "        landmark_name = landmark_info.get(\"name\", \"\").lower()\n",
        "        landmark_location = landmark_info.get(\"location\", \"\").lower()\n",
        "        landmark_aliases = [alias.lower() for alias in landmark_info.get(\"aliases\", [])]\n",
        "\n",
        "        # 合併所有文本數據用於特徵判斷\n",
        "        combined_text = \" \".join([landmark_id_lower, landmark_name] + landmark_aliases)\n",
        "\n",
        "        # 地標類型的特色特徵\n",
        "        type_features = {\n",
        "            \"skyscraper\": [\"skyscraper\", \"tall\", \"tower\", \"高樓\", \"摩天\", \"大厦\", \"タワー\"],\n",
        "            \"tower\": [\"tower\", \"bell\", \"clock\", \"塔\", \"鐘樓\", \"タワー\", \"campanile\"],\n",
        "            \"monument\": [\"monument\", \"memorial\", \"statue\", \"紀念\", \"雕像\", \"像\", \"memorial\"],\n",
        "            \"natural\": [\"mountain\", \"lake\", \"canyon\", \"falls\", \"beach\", \"山\", \"湖\", \"峽谷\", \"瀑布\", \"海灘\"],\n",
        "            \"temple\": [\"temple\", \"shrine\", \"寺\", \"神社\", \"廟\"],\n",
        "            \"palace\": [\"palace\", \"castle\", \"宮\", \"城\", \"皇宮\", \"宫殿\"],\n",
        "            \"distinctive\": [\"unique\", \"leaning\", \"slanted\", \"傾斜\", \"斜\", \"獨特\", \"傾く\"]\n",
        "        }\n",
        "\n",
        "        # 檢查是否位於亞洲地區\n",
        "        asian_regions = [\"china\", \"japan\", \"korea\", \"taiwan\", \"singapore\", \"vietnam\", \"thailand\",\n",
        "                        \"hong kong\", \"中國\", \"日本\", \"韓國\", \"台灣\", \"新加坡\", \"越南\", \"泰國\", \"香港\"]\n",
        "        is_asian = any(region in landmark_location for region in asian_regions)\n",
        "\n",
        "        # 判斷地標類型\n",
        "        best_type = None\n",
        "        max_matches = 0\n",
        "\n",
        "        for type_name, features in type_features.items():\n",
        "            # 計算特徵詞匹配數量\n",
        "            matches = sum(1 for feature in features if feature in combined_text)\n",
        "            if matches > max_matches:\n",
        "                max_matches = matches\n",
        "                best_type = type_name\n",
        "\n",
        "        # 處理亞洲地區特例\n",
        "        if is_asian and best_type == \"tower\":\n",
        "            best_type = \"skyscraper\"  # 亞洲地區的塔型建築閾值較低\n",
        "\n",
        "        # 特例處理：檢測傾斜建築\n",
        "        if any(term in combined_text for term in [\"leaning\", \"slanted\", \"tilt\", \"inclined\", \"斜\", \"傾斜\"]):\n",
        "            return \"distinctive\"  # 傾斜建築需要特殊處理\n",
        "\n",
        "        return best_type if best_type and max_matches > 0 else \"building\"  # 預設為一般建築\n",
        "\n",
        "    def classify_image_region(self,\n",
        "                    image: Union[Image.Image, np.ndarray],\n",
        "                    box: List[float],\n",
        "                    threshold: float = 0.25,\n",
        "                    detection_type: str = \"close_up\") -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        對圖像的特定區域進行地標分類，具有增強的多尺度和部分識別能力\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像 (PIL Image 或 numpy數組)\n",
        "            box: 邊界框 [x1, y1, x2, y2]\n",
        "            threshold: 基礎分類置信度閾值\n",
        "            detection_type: 檢測類型，影響置信度調整\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標分類結果\n",
        "        \"\"\"\n",
        "        # 確保圖像是PIL格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 生成圖像區域的hash用於快取\n",
        "        region_key = (self._get_image_hash(image), tuple(box), detection_type)\n",
        "        if region_key in self.results_cache:\n",
        "            return self.results_cache[region_key]\n",
        "\n",
        "        # 裁剪區域\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cropped_image = image.crop((x1, y1, x2, y2))\n",
        "        enhanced_image = self._enhance_features(cropped_image)\n",
        "\n",
        "        # 分析視角信息\n",
        "        viewpoint_info = self._analyze_viewpoint(enhanced_image)\n",
        "        dominant_viewpoint = viewpoint_info[\"dominant_viewpoint\"]\n",
        "\n",
        "        # 計算區域信息\n",
        "        region_width = x2 - x1\n",
        "        region_height = y2 - y1\n",
        "        image_width, image_height = image.size\n",
        "\n",
        "        # 根據區域大小判斷可能的檢測類型\n",
        "        region_area_ratio = (region_width * region_height) / (image_width * image_height)\n",
        "        if detection_type == \"auto\":\n",
        "            if region_area_ratio > 0.5:\n",
        "                detection_type = \"close_up\"\n",
        "            elif region_area_ratio > 0.2:\n",
        "                detection_type = \"partial\"\n",
        "            else:\n",
        "                detection_type = \"distant\"\n",
        "\n",
        "        # 根據視角調整檢測類型\n",
        "        if dominant_viewpoint == \"close_up\" and detection_type != \"close_up\":\n",
        "            detection_type = \"close_up\"\n",
        "        elif dominant_viewpoint == \"distant\" and detection_type != \"distant\":\n",
        "            detection_type = \"distant\"\n",
        "        elif dominant_viewpoint == \"angled_view\":\n",
        "            detection_type = \"partial\"  # 角度視圖可能是部分可見\n",
        "\n",
        "        # 調整置信度閾值\n",
        "        base_multiplier = self.confidence_threshold_multipliers.get(detection_type, 1.0)\n",
        "        adjusted_threshold = threshold * base_multiplier\n",
        "\n",
        "        # 調整多尺度處理的尺度範圍和縱橫比 - 增強對傾斜建築的支持\n",
        "        scales = [1.0]  # 默認尺度\n",
        "\n",
        "        # 基於視角選擇合適的尺度和縱橫比\n",
        "        if detection_type in [\"partial\", \"distant\"]:\n",
        "            scales = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]  # 標準範圍\n",
        "\n",
        "        # 如果是特殊視角，進一步調整尺度和縱橫比 - 新增\n",
        "        if dominant_viewpoint in [\"angled_view\", \"low_angle\"]:\n",
        "            scales = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4]  # 更寬的範圍\n",
        "\n",
        "        # 準備縱橫比 - 同時支持水平和垂直地標\n",
        "        aspect_ratios = [1.0, 0.8, 1.2]  # 標準縱橫比\n",
        "\n",
        "        # 針對可能的傾斜建築增加更多縱橫比 - 新增\n",
        "        if dominant_viewpoint in [\"angled_view\", \"unique_feature\"]:\n",
        "            aspect_ratios = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.5]  # 更多樣的縱橫比\n",
        "\n",
        "        best_result = {\n",
        "            \"landmark_id\": None,\n",
        "            \"landmark_name\": None,\n",
        "            \"confidence\": 0.0,\n",
        "            \"is_landmark\": False\n",
        "        }\n",
        "\n",
        "        # 多尺度和縱橫比分析\n",
        "        for scale in scales:\n",
        "            for aspect_ratio in aspect_ratios:\n",
        "                # 縮放裁剪區域\n",
        "                current_width, current_height = cropped_image.size\n",
        "\n",
        "                # 計算新尺寸，保持面積不變但調整縱橫比\n",
        "                if aspect_ratio != 1.0:\n",
        "                    new_width = int(current_width * scale * (1/aspect_ratio)**0.5)\n",
        "                    new_height = int(current_height * scale * aspect_ratio**0.5)\n",
        "                else:\n",
        "                    new_width = int(current_width * scale)\n",
        "                    new_height = int(current_height * scale)\n",
        "\n",
        "                # 確保尺寸至少為1像素\n",
        "                new_width = max(1, new_width)\n",
        "                new_height = max(1, new_height)\n",
        "\n",
        "                # 縮放圖像\n",
        "                try:\n",
        "                    scaled_image = cropped_image.resize((new_width, new_height), Image.LANCZOS)\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to resize image to {new_width}x{new_height}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # 預處理裁剪圖像\n",
        "                try:\n",
        "                    image_input = self.preprocess(scaled_image).unsqueeze(0).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to preprocess image: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # 獲取圖像特徵\n",
        "                with torch.no_grad():\n",
        "                    try:\n",
        "                        image_features = self.model.encode_image(image_input)\n",
        "                        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "                        # 計算與地標提示的相似度\n",
        "                        similarity = (100.0 * image_features @ self.landmark_text_features.T).softmax(dim=-1)\n",
        "                        similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "                        # 找到最佳匹配\n",
        "                        best_idx = similarity.argmax().item()\n",
        "                        best_score = similarity[best_idx]\n",
        "\n",
        "                        # 如果當前尺度結果更好，則更新\n",
        "                        if best_score > best_result[\"confidence\"]:\n",
        "                            landmark_id = list(self.landmark_data.keys())[best_idx]\n",
        "                            landmark_info = self.landmark_data[landmark_id]\n",
        "\n",
        "                            best_result = {\n",
        "                                \"landmark_id\": landmark_id,\n",
        "                                \"landmark_name\": landmark_info[\"name\"],\n",
        "                                \"location\": landmark_info[\"location\"],\n",
        "                                \"confidence\": float(best_score),\n",
        "                                \"is_landmark\": best_score >= adjusted_threshold,\n",
        "                                \"scale_used\": scale,\n",
        "                                \"aspect_ratio_used\": aspect_ratio,\n",
        "                                \"viewpoint\": dominant_viewpoint\n",
        "                            }\n",
        "\n",
        "                            # 添加額外可用信息\n",
        "                            for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                                if key in landmark_info:\n",
        "                                    best_result[key] = landmark_info[key]\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error in calculating similarity: {e}\")\n",
        "                        continue\n",
        "\n",
        "        # 只有在有識別出地標ID且信心度足夠高時才應用地標類型閾值調整\n",
        "        if best_result[\"landmark_id\"]:\n",
        "            landmark_type = self._determine_landmark_type(best_result[\"landmark_id\"])\n",
        "\n",
        "            # 檢測是否為特殊類型的建築如斜塔\n",
        "            if landmark_type == \"distinctive\":\n",
        "                # 特殊建築的閾值降低25%\n",
        "                type_multiplier = 0.75\n",
        "            else:\n",
        "                # 使用已有的類型閾值\n",
        "                type_multiplier = self.landmark_type_thresholds.get(landmark_type, 1.0) / 0.5\n",
        "\n",
        "            # 更新判斷是否為地標的標準\n",
        "            final_threshold = adjusted_threshold * type_multiplier\n",
        "            best_result[\"is_landmark\"] = best_result[\"confidence\"] >= final_threshold\n",
        "            best_result[\"landmark_type\"] = landmark_type  # 添加地標類型信息\n",
        "            best_result[\"threshold_applied\"] = final_threshold  # 記錄應用的閾值\n",
        "\n",
        "        # 快取結果\n",
        "        self.results_cache[region_key] = best_result\n",
        "        self._manage_cache()\n",
        "\n",
        "        return best_result\n",
        "\n",
        "    def classify_batch_regions(self,\n",
        "                              image: Union[Image.Image, np.ndarray],\n",
        "                              boxes: List[List[float]],\n",
        "                              threshold: float = 0.28) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        批量處理多個圖像區域，提高效率\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            boxes: 邊界框列表\n",
        "            threshold: 置信度閾值\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: 分類結果列表\n",
        "        \"\"\"\n",
        "        if not self.landmark_text_features is not None:\n",
        "            return [{\"is_landmark\": False, \"confidence\": 0.0} for _ in boxes]\n",
        "\n",
        "        # 確保圖像是PIL格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 無框可處理時\n",
        "        if not boxes:\n",
        "            return []\n",
        "\n",
        "        # 裁剪並預處理所有區域\n",
        "        cropped_inputs = []\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cropped_image = image.crop((x1, y1, x2, y2))\n",
        "            processed_image = self.preprocess(cropped_image).unsqueeze(0)\n",
        "            cropped_inputs.append(processed_image)\n",
        "\n",
        "        # batch process\n",
        "        batch_tensor = torch.cat(cropped_inputs).to(self.device)\n",
        "\n",
        "        # batch encoding\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(batch_tensor)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度\n",
        "            similarity = (100.0 * image_features @ self.landmark_text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy() if self.device == \"cuda\" else similarity.numpy()\n",
        "\n",
        "        # 處理每個區域的結果\n",
        "        results = []\n",
        "        for i, sim in enumerate(similarity):\n",
        "            best_idx = sim.argmax().item()\n",
        "            best_score = sim[best_idx]\n",
        "\n",
        "            if best_score >= threshold:\n",
        "                landmark_id = list(self.landmark_data.keys())[best_idx]\n",
        "                landmark_info = self.landmark_data[landmark_id]\n",
        "\n",
        "                results.append({\n",
        "                    \"landmark_id\": landmark_id,\n",
        "                    \"landmark_name\": landmark_info[\"name\"],\n",
        "                    \"location\": landmark_info[\"location\"],\n",
        "                    \"confidence\": float(best_score),\n",
        "                    \"is_landmark\": True,\n",
        "                    \"box\": boxes[i]\n",
        "                })\n",
        "            else:\n",
        "                results.append({\n",
        "                    \"landmark_id\": None,\n",
        "                    \"landmark_name\": None,\n",
        "                    \"confidence\": float(best_score),\n",
        "                    \"is_landmark\": False,\n",
        "                    \"box\": boxes[i]\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search_entire_image(self,\n",
        "                        image: Union[Image.Image, np.ndarray],\n",
        "                        threshold: float = 0.35,\n",
        "                        detailed_analysis: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        檢查整張圖像是否包含地標，具有增強的分析能力\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            threshold: 置信度閾值\n",
        "            detailed_analysis: 是否進行詳細分析，包括多區域檢測\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標分類結果\n",
        "        \"\"\"\n",
        "        # 確保圖像是PIL格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 檢查快取\n",
        "        image_key = (self._get_image_hash(image), \"entire_image\", detailed_analysis)\n",
        "        if image_key in self.results_cache:\n",
        "            return self.results_cache[image_key]\n",
        "\n",
        "        # 調整閾值\n",
        "        adjusted_threshold = threshold * self.confidence_threshold_multipliers.get(\"full_image\", 1.0)\n",
        "\n",
        "        # 預處理圖像\n",
        "        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # 獲取圖像特徵\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_input)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算與地標提示的相似度\n",
        "            similarity = (100.0 * image_features @ self.landmark_text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "        # 找到最佳匹配\n",
        "        best_idx = similarity.argmax().item()\n",
        "        best_score = similarity[best_idx]\n",
        "\n",
        "        # top3 landmark\n",
        "        top_indices = similarity.argsort()[-3:][::-1]\n",
        "        top_landmarks = []\n",
        "\n",
        "        for idx in top_indices:\n",
        "            score = similarity[idx]\n",
        "            landmark_id = list(self.landmark_data.keys())[idx]\n",
        "            landmark_info = self.landmark_data[landmark_id]\n",
        "\n",
        "            landmark_result = {\n",
        "                \"landmark_id\": landmark_id,\n",
        "                \"landmark_name\": landmark_info[\"name\"],\n",
        "                \"location\": landmark_info[\"location\"],\n",
        "                \"confidence\": float(score)\n",
        "            }\n",
        "\n",
        "            # 添加額外可用信息\n",
        "            if \"year_built\" in landmark_info:\n",
        "                landmark_result[\"year_built\"] = landmark_info[\"year_built\"]\n",
        "            if \"architectural_style\" in landmark_info:\n",
        "                landmark_result[\"architectural_style\"] = landmark_info[\"architectural_style\"]\n",
        "            if \"significance\" in landmark_info:\n",
        "                landmark_result[\"significance\"] = landmark_info[\"significance\"]\n",
        "\n",
        "            top_landmarks.append(landmark_result)\n",
        "\n",
        "        # main result\n",
        "        result = {}\n",
        "        if best_score >= adjusted_threshold:\n",
        "            landmark_id = list(self.landmark_data.keys())[best_idx]\n",
        "            landmark_info = self.landmark_data[landmark_id]\n",
        "\n",
        "            # 應用地標類型特定閾值\n",
        "            landmark_type = self._determine_landmark_type(landmark_id)\n",
        "            type_multiplier = self.landmark_type_thresholds.get(landmark_type, 1.0) / 0.5\n",
        "            final_threshold = adjusted_threshold * type_multiplier\n",
        "\n",
        "            if best_score >= final_threshold:\n",
        "                result = {\n",
        "                    \"landmark_id\": landmark_id,\n",
        "                    \"landmark_name\": landmark_info[\"name\"],\n",
        "                    \"location\": landmark_info[\"location\"],\n",
        "                    \"confidence\": float(best_score),\n",
        "                    \"is_landmark\": True,\n",
        "                    \"landmark_type\": landmark_type,\n",
        "                    \"top_landmarks\": top_landmarks\n",
        "                }\n",
        "\n",
        "                # 添加額外可用信息\n",
        "                if \"year_built\" in landmark_info:\n",
        "                    result[\"year_built\"] = landmark_info[\"year_built\"]\n",
        "                if \"architectural_style\" in landmark_info:\n",
        "                    result[\"architectural_style\"] = landmark_info[\"architectural_style\"]\n",
        "                if \"significance\" in landmark_info:\n",
        "                    result[\"significance\"] = landmark_info[\"significance\"]\n",
        "            else:\n",
        "                result = {\n",
        "                    \"landmark_id\": None,\n",
        "                    \"landmark_name\": None,\n",
        "                    \"confidence\": float(best_score),\n",
        "                    \"is_landmark\": False,\n",
        "                    \"top_landmarks\": top_landmarks\n",
        "                }\n",
        "\n",
        "        # 如果請求詳細分析且是地標，進一步分析圖像區域\n",
        "        if detailed_analysis and result.get(\"is_landmark\", False):\n",
        "            # 創建不同區域進行更深入分析\n",
        "            width, height = image.size\n",
        "            regions = [\n",
        "                # 中心區域\n",
        "                [width * 0.25, height * 0.25, width * 0.75, height * 0.75],\n",
        "                # 左半部\n",
        "                [0, 0, width * 0.5, height],\n",
        "                # 右半部\n",
        "                [width * 0.5, 0, width, height],\n",
        "                # 上半部\n",
        "                [0, 0, width, height * 0.5],\n",
        "                # 下半部\n",
        "                [0, height * 0.5, width, height]\n",
        "            ]\n",
        "\n",
        "            region_results = []\n",
        "            for i, box in enumerate(regions):\n",
        "                region_result = self.classify_image_region(\n",
        "                    image,\n",
        "                    box,\n",
        "                    threshold=threshold * 0.9,\n",
        "                    detection_type=\"partial\"\n",
        "                )\n",
        "                if region_result[\"is_landmark\"]:\n",
        "                    region_result[\"region_name\"] = [\"center\", \"left\", \"right\", \"top\", \"bottom\"][i]\n",
        "                    region_results.append(region_result)\n",
        "\n",
        "            # 添加區域分析結果\n",
        "            if region_results:\n",
        "                result[\"region_analyses\"] = region_results\n",
        "\n",
        "        # 快取結果\n",
        "        self.results_cache[image_key] = result\n",
        "        self._manage_cache()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def enhanced_landmark_detection(self,\n",
        "                              image: Union[Image.Image, np.ndarray],\n",
        "                              threshold: float = 0.3) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Enhanced landmark detection using multiple analysis techniques.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "            threshold: Base confidence threshold\n",
        "\n",
        "        Returns:\n",
        "            Dict: Comprehensive landmark detection results\n",
        "        \"\"\"\n",
        "        # Ensure image is PIL format\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # Phase 1: Analyze viewpoint to adjust detection parameters\n",
        "        viewpoint_info = self._analyze_viewpoint(image)\n",
        "        viewpoint = viewpoint_info[\"dominant_viewpoint\"]\n",
        "\n",
        "        # Adjust threshold based on viewpoint\n",
        "        if viewpoint == \"distant\":\n",
        "            adjusted_threshold = threshold * 0.7  # Lower threshold for distant views\n",
        "        elif viewpoint == \"close_up\":\n",
        "            adjusted_threshold = threshold * 1.1  # Higher threshold for close-ups\n",
        "        else:\n",
        "            adjusted_threshold = threshold\n",
        "\n",
        "        # Phase 2: Perform multi-scale pyramid analysis\n",
        "        pyramid_results = self._perform_pyramid_analysis(image, levels=3, base_threshold=adjusted_threshold)\n",
        "\n",
        "        # Phase 3: Perform grid-based region analysis\n",
        "        grid_results = []\n",
        "        width, height = image.size\n",
        "\n",
        "        # Create adaptive grid based on viewpoint\n",
        "        if viewpoint == \"distant\":\n",
        "            grid_size = 3  # Coarser grid for distant views\n",
        "        elif viewpoint == \"close_up\":\n",
        "            grid_size = 5  # Finer grid for close-ups\n",
        "        else:\n",
        "            grid_size = 4  # Default grid size\n",
        "\n",
        "        # Generate grid regions\n",
        "        for i in range(grid_size):\n",
        "            for j in range(grid_size):\n",
        "                box = [\n",
        "                    width * (j/grid_size),\n",
        "                    height * (i/grid_size),\n",
        "                    width * ((j+1)/grid_size),\n",
        "                    height * ((i+1)/grid_size)\n",
        "                ]\n",
        "\n",
        "                # Apply feature enhancement\n",
        "                region_result = self.classify_image_region(\n",
        "                    image,\n",
        "                    box,\n",
        "                    threshold=adjusted_threshold,\n",
        "                    detection_type=\"auto\"\n",
        "                )\n",
        "\n",
        "                if region_result[\"is_landmark\"]:\n",
        "                    region_result[\"grid_position\"] = (i, j)\n",
        "                    grid_results.append(region_result)\n",
        "\n",
        "        # Phase 4: Cross-validate and combine results\n",
        "        all_detections = []\n",
        "\n",
        "        # Add pyramid results\n",
        "        if pyramid_results[\"is_landmark\"] and pyramid_results[\"best_result\"]:\n",
        "            all_detections.append({\n",
        "                \"source\": \"pyramid\",\n",
        "                \"landmark_id\": pyramid_results[\"best_result\"][\"landmark_id\"],\n",
        "                \"landmark_name\": pyramid_results[\"best_result\"][\"landmark_name\"],\n",
        "                \"confidence\": pyramid_results[\"best_result\"][\"confidence\"],\n",
        "                \"scale_factor\": pyramid_results[\"best_result\"].get(\"scale_factor\", 1.0)\n",
        "            })\n",
        "\n",
        "        # Add grid results\n",
        "        for result in grid_results:\n",
        "            all_detections.append({\n",
        "                \"source\": \"grid\",\n",
        "                \"landmark_id\": result[\"landmark_id\"],\n",
        "                \"landmark_name\": result[\"landmark_name\"],\n",
        "                \"confidence\": result[\"confidence\"],\n",
        "                \"grid_position\": result.get(\"grid_position\", (0, 0))\n",
        "            })\n",
        "\n",
        "        # Search entire image\n",
        "        full_image_result = self.search_entire_image(image, threshold=adjusted_threshold)\n",
        "        if full_image_result and full_image_result.get(\"is_landmark\", False):\n",
        "            all_detections.append({\n",
        "                \"source\": \"full_image\",\n",
        "                \"landmark_id\": full_image_result[\"landmark_id\"],\n",
        "                \"landmark_name\": full_image_result[\"landmark_name\"],\n",
        "                \"confidence\": full_image_result[\"confidence\"]\n",
        "            })\n",
        "\n",
        "        # Group by landmark_id and calculate aggregate confidence\n",
        "        landmark_groups = {}\n",
        "        for detection in all_detections:\n",
        "            landmark_id = detection[\"landmark_id\"]\n",
        "            if landmark_id not in landmark_groups:\n",
        "                landmark_groups[landmark_id] = {\n",
        "                    \"landmark_id\": landmark_id,\n",
        "                    \"landmark_name\": detection[\"landmark_name\"],\n",
        "                    \"detections\": [],\n",
        "                    \"sources\": set()\n",
        "                }\n",
        "\n",
        "            landmark_groups[landmark_id][\"detections\"].append(detection)\n",
        "            landmark_groups[landmark_id][\"sources\"].add(detection[\"source\"])\n",
        "\n",
        "        # Calculate aggregate confidence for each landmark\n",
        "        for landmark_id, group in landmark_groups.items():\n",
        "            detections = group[\"detections\"]\n",
        "\n",
        "            # Base confidence is the maximum confidence from any source\n",
        "            max_confidence = max(d[\"confidence\"] for d in detections)\n",
        "\n",
        "            # Bonus for detection from multiple sources\n",
        "            source_count = len(group[\"sources\"])\n",
        "            source_bonus = min(0.15, (source_count - 1) * 0.05)  # Up to 15% bonus\n",
        "\n",
        "            # Consistency bonus for multiple detections of the same landmark\n",
        "            detection_count = len(detections)\n",
        "            consistency_bonus = min(0.1, (detection_count - 1) * 0.02)  # Up to 10% bonus\n",
        "\n",
        "            # Calculate final confidence\n",
        "            aggregate_confidence = min(1.0, max_confidence + source_bonus + consistency_bonus)\n",
        "\n",
        "            group[\"confidence\"] = aggregate_confidence\n",
        "            group[\"detection_count\"] = detection_count\n",
        "            group[\"source_count\"] = source_count\n",
        "\n",
        "        # Sort landmarks by confidence\n",
        "        sorted_landmarks = sorted(\n",
        "            landmark_groups.values(),\n",
        "            key=lambda x: x[\"confidence\"],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"is_landmark_scene\": len(sorted_landmarks) > 0,\n",
        "            \"detected_landmarks\": sorted_landmarks,\n",
        "            \"viewpoint_info\": viewpoint_info,\n",
        "            \"primary_landmark\": sorted_landmarks[0] if sorted_landmarks else None\n",
        "        }\n",
        "\n",
        "    def _analyze_architectural_features(self, image):\n",
        "        \"\"\"\n",
        "        Analyzes the architectural features of a structure in the image without hardcoding specific landmarks.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "\n",
        "        Returns:\n",
        "            Dict: Architectural feature analysis results\n",
        "        \"\"\"\n",
        "        # Define universal architectural feature prompts that apply to all types of landmarks\n",
        "        architecture_prompts = {\n",
        "            \"tall_structure\": \"a tall vertical structure standing alone\",\n",
        "            \"tiered_building\": \"a building with multiple stacked tiers or segments\",\n",
        "            \"historical_structure\": \"a building with historical architectural elements\",\n",
        "            \"modern_design\": \"a modern structure with contemporary architectural design\",\n",
        "            \"segmented_exterior\": \"a structure with visible segmented or sectioned exterior\",\n",
        "            \"viewing_platform\": \"a tall structure with observation area at the top\",\n",
        "            \"time_display\": \"a structure with timepiece features\",\n",
        "            \"glass_facade\": \"a building with prominent glass exterior surfaces\",\n",
        "            \"memorial_structure\": \"a monument or memorial structure\",\n",
        "            \"ancient_construction\": \"ancient constructed elements or archaeological features\",\n",
        "            \"natural_landmark\": \"a natural geographic formation or landmark\",\n",
        "            \"slanted_design\": \"a structure with non-vertical or leaning profile\"\n",
        "        }\n",
        "\n",
        "        # Calculate similarity scores against universal architectural patterns\n",
        "        context_scores = self.calculate_similarity_scores(image, architecture_prompts)\n",
        "\n",
        "        # Determine most relevant architectural features\n",
        "        top_features = sorted(context_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "        # Calculate feature confidence\n",
        "        context_confidence = sum(score for _, score in top_features) / 3\n",
        "\n",
        "        # Determine primary architectural category based on top features\n",
        "        architectural_categories = {\n",
        "            \"tower\": [\"tall_structure\", \"viewing_platform\", \"time_display\"],\n",
        "            \"skyscraper\": [\"tall_structure\", \"modern_design\", \"glass_facade\"],\n",
        "            \"historical\": [\"historical_structure\", \"ancient_construction\", \"memorial_structure\"],\n",
        "            \"natural\": [\"natural_landmark\"],\n",
        "            \"distinctive\": [\"tiered_building\", \"segmented_exterior\", \"slanted_design\"]\n",
        "        }\n",
        "\n",
        "        # Score each category based on the top features\n",
        "        category_scores = {}\n",
        "        for category, features in architectural_categories.items():\n",
        "            category_score = 0\n",
        "            for feature, score in context_scores.items():\n",
        "                if feature in features:\n",
        "                    category_score += score\n",
        "            category_scores[category] = category_score\n",
        "\n",
        "        primary_category = max(category_scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        return {\n",
        "            \"architectural_features\": top_features,\n",
        "            \"context_confidence\": context_confidence,\n",
        "            \"primary_category\": primary_category,\n",
        "            \"category_scores\": category_scores\n",
        "        }\n",
        "\n",
        "    def intelligent_landmark_search(self,\n",
        "                                image: Union[Image.Image, np.ndarray],\n",
        "                                yolo_boxes: Optional[List[List[float]]] = None,\n",
        "                                base_threshold: float = 0.25) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        對圖像進行智能地標搜索，綜合整張圖像分析和區域分析\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            yolo_boxes: YOLO檢測到的邊界框 (可選)\n",
        "            base_threshold: 基礎置信度閾值\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含所有檢測結果的綜合分析\n",
        "        \"\"\"\n",
        "        # 確保圖像是PIL格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # No YOLO 框時，可以稍微降低閾值以提高召回率\n",
        "        actual_threshold = base_threshold * 0.85 if yolo_boxes is None or len(yolo_boxes) == 0 else base_threshold\n",
        "\n",
        "        # 首先對整張圖像進行分析\n",
        "        try:\n",
        "            full_image_result = self.search_entire_image(\n",
        "                image,\n",
        "                threshold=actual_threshold,\n",
        "                detailed_analysis=True  # 確保詳細分析開啟\n",
        "            )\n",
        "\n",
        "            # No YOLO 框，則進行多尺度分析以提高檢測機會\n",
        "            if (yolo_boxes is None or len(yolo_boxes) == 0) and (not full_image_result or not full_image_result.get(\"is_landmark\", False)):\n",
        "                print(\"No YOLO boxes provided, attempting multi-scale pyramid analysis\")\n",
        "                try:\n",
        "                    if hasattr(self, '_perform_pyramid_analysis'):\n",
        "                        pyramid_results = self._perform_pyramid_analysis(\n",
        "                            image,\n",
        "                            levels=4,  #\n",
        "                            base_threshold=actual_threshold,\n",
        "                            aspect_ratios=[1.0, 0.75, 1.5, 0.5, 2.0]\n",
        "                        )\n",
        "\n",
        "                        if pyramid_results and pyramid_results.get(\"is_landmark\", False) and pyramid_results.get(\"best_result\", {}).get(\"confidence\", 0) > actual_threshold:\n",
        "                            # 使用金字塔分析結果增強或替代全圖結果\n",
        "                            if not full_image_result or not full_image_result.get(\"is_landmark\", False):\n",
        "                                full_image_result = {\n",
        "                                    \"is_landmark\": True,\n",
        "                                    \"landmark_id\": pyramid_results[\"best_result\"][\"landmark_id\"],\n",
        "                                    \"landmark_name\": pyramid_results[\"best_result\"][\"landmark_name\"],\n",
        "                                    \"confidence\": pyramid_results[\"best_result\"][\"confidence\"],\n",
        "                                    \"location\": pyramid_results[\"best_result\"].get(\"location\", \"Unknown Location\")\n",
        "                                }\n",
        "                                print(f\"Pyramid analysis detected landmark: {pyramid_results['best_result']['landmark_name']} with confidence {pyramid_results['best_result']['confidence']:.3f}\")\n",
        "                    else:\n",
        "                        print(\"Pyramid analysis not available, skipping multi-scale detection\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in pyramid analysis: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in search_entire_image: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            full_image_result = None\n",
        "\n",
        "        # 初始化結果字典\n",
        "        result = {\n",
        "            \"full_image_analysis\": full_image_result if full_image_result else {},\n",
        "            \"is_landmark_scene\": False,  # 默認值\n",
        "            \"detected_landmarks\": []\n",
        "        }\n",
        "\n",
        "        # 上下文感知比較，處理接近的排名結果\n",
        "        if full_image_result and \"top_landmarks\" in full_image_result and len(full_image_result[\"top_landmarks\"]) >= 2:\n",
        "            top_landmarks = full_image_result[\"top_landmarks\"]\n",
        "\n",
        "            # 檢查前兩個結果是否非常接近（信心度差異小於 0.1）\n",
        "            if len(top_landmarks) >= 2 and abs(top_landmarks[0][\"confidence\"] - top_landmarks[1][\"confidence\"]) < 0.1:\n",
        "                # 對於接近的結果，使用通用建築特徵分析進行區分\n",
        "                try:\n",
        "                    # 分析建築特徵\n",
        "                    if hasattr(self, '_analyze_architectural_features'):\n",
        "                        architectural_analysis = self._analyze_architectural_features(image)\n",
        "                        top_features = architectural_analysis.get(\"architectural_features\", [])\n",
        "                        primary_category = architectural_analysis.get(\"primary_category\", \"\")\n",
        "\n",
        "                        # 根據建築特徵調整地標置信度\n",
        "                        for i, landmark in enumerate(top_landmarks[:2]):\n",
        "                            if i >= len(top_landmarks):\n",
        "                                continue\n",
        "\n",
        "                            landmark_id = landmark.get(\"landmark_id\", \"\").lower()\n",
        "                            confidence_boost = 0\n",
        "\n",
        "                            # 使用主要建築類別來調整置信度，使用通用條件而非特定地標名稱\n",
        "                            if primary_category == \"tower\" and any(term in landmark_id for term in [\"tower\", \"spire\", \"needle\"]):\n",
        "                                confidence_boost += 0.05\n",
        "                            elif primary_category == \"skyscraper\" and any(term in landmark_id for term in [\"building\", \"skyscraper\", \"tall\"]):\n",
        "                                confidence_boost += 0.05\n",
        "                            elif primary_category == \"historical\" and any(term in landmark_id for term in [\"monument\", \"castle\", \"palace\", \"temple\"]):\n",
        "                                confidence_boost += 0.05\n",
        "                            elif primary_category == \"distinctive\" and any(term in landmark_id for term in [\"unusual\", \"unique\", \"special\", \"famous\"]):\n",
        "                                confidence_boost += 0.05\n",
        "\n",
        "                            # 根據特定特徵進一步微調，使用通用特徵描述而非特定地標\n",
        "                            for feature, score in top_features:\n",
        "                                if feature == \"time_display\" and \"clock\" in landmark_id:\n",
        "                                    confidence_boost += 0.03\n",
        "                                elif feature == \"segmented_exterior\" and \"segmented\" in landmark_id:\n",
        "                                    confidence_boost += 0.03\n",
        "                                elif feature == \"slanted_design\" and \"leaning\" in landmark_id:\n",
        "                                    confidence_boost += 0.03\n",
        "\n",
        "                            # 應用信心度調整\n",
        "                            if confidence_boost > 0 and i < len(top_landmarks):\n",
        "                                top_landmarks[i][\"confidence\"] += confidence_boost\n",
        "                                print(f\"Boosted {landmark['landmark_name']} confidence by {confidence_boost:.2f} based on architectural features ({primary_category})\")\n",
        "\n",
        "                        # 重新排序\n",
        "                        top_landmarks.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
        "                        full_image_result[\"top_landmarks\"] = top_landmarks\n",
        "                        if top_landmarks:\n",
        "                            full_image_result[\"landmark_id\"] = top_landmarks[0][\"landmark_id\"]\n",
        "                            full_image_result[\"landmark_name\"] = top_landmarks[0][\"landmark_name\"]\n",
        "                            full_image_result[\"confidence\"] = top_landmarks[0][\"confidence\"]\n",
        "                            full_image_result[\"location\"] = top_landmarks[0].get(\"location\", \"Unknown Location\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in architectural feature analysis: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "\n",
        "        if full_image_result and full_image_result.get(\"is_landmark\", False):\n",
        "            result[\"is_landmark_scene\"] = True\n",
        "            landmark_id = full_image_result.get(\"landmark_id\", \"unknown\")\n",
        "\n",
        "            # extract landmark info\n",
        "            landmark_specific_info = self._extract_landmark_specific_info(landmark_id)\n",
        "\n",
        "            landmark_info = {\n",
        "                \"landmark_id\": landmark_id,\n",
        "                \"landmark_name\": full_image_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                \"confidence\": full_image_result.get(\"confidence\", 0.0),\n",
        "                \"location\": full_image_result.get(\"location\", \"Unknown Location\"),\n",
        "                \"region_type\": \"full_image\",\n",
        "                \"box\": [0, 0, getattr(image, 'width', 0), getattr(image, 'height', 0)]\n",
        "            }\n",
        "\n",
        "            # 整合地標特定info，確保正確的名稱被使用\n",
        "            landmark_info.update(landmark_specific_info)\n",
        "\n",
        "            # 如果特定信息中有更準確的地標名稱，使用它\n",
        "            if landmark_specific_info.get(\"landmark_name\"):\n",
        "                landmark_info[\"landmark_name\"] = landmark_specific_info[\"landmark_name\"]\n",
        "\n",
        "            result[\"detected_landmarks\"].append(landmark_info)\n",
        "\n",
        "            # 確保地標特定活動被正確設置為主要結果\n",
        "            if landmark_specific_info.get(\"has_specific_activities\", False):\n",
        "                result[\"primary_landmark_activities\"] = landmark_specific_info.get(\"landmark_specific_activities\", [])\n",
        "                print(f\"Set primary landmark activities: {len(result['primary_landmark_activities'])} activities for {landmark_info['landmark_name']}\")\n",
        "\n",
        "        # 如果提供了YOLO邊界框，分析這些區域\n",
        "        if yolo_boxes and len(yolo_boxes) > 0:\n",
        "            for box in yolo_boxes:\n",
        "                try:\n",
        "                    if hasattr(self, 'classify_image_region'):\n",
        "                        box_result = self.classify_image_region(\n",
        "                            image,\n",
        "                            box,\n",
        "                            threshold=base_threshold,\n",
        "                            detection_type=\"auto\"\n",
        "                        )\n",
        "\n",
        "                        # 如果檢測到地標\n",
        "                        if box_result and box_result.get(\"is_landmark\", False):\n",
        "                            # 檢查是否與已檢測的地標重複\n",
        "                            is_duplicate = False\n",
        "                            for existing in result[\"detected_landmarks\"]:\n",
        "                                if existing.get(\"landmark_id\") == box_result.get(\"landmark_id\"):\n",
        "                                    # 如果新的置信度更高，則更新\n",
        "                                    if box_result.get(\"confidence\", 0) > existing.get(\"confidence\", 0):\n",
        "                                        existing.update({\n",
        "                                            \"confidence\": box_result.get(\"confidence\", 0),\n",
        "                                            \"region_type\": \"yolo_box\",\n",
        "                                            \"box\": box\n",
        "                                        })\n",
        "                                    is_duplicate = True\n",
        "                                    break\n",
        "\n",
        "                            # 如果不是重複的，添加到列表\n",
        "                            if not is_duplicate:\n",
        "                                result[\"detected_landmarks\"].append({\n",
        "                                    \"landmark_id\": box_result.get(\"landmark_id\", \"unknown\"),\n",
        "                                    \"landmark_name\": box_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                    \"confidence\": box_result.get(\"confidence\", 0.0),\n",
        "                                    \"location\": box_result.get(\"location\", \"Unknown Location\"),\n",
        "                                    \"region_type\": \"yolo_box\",\n",
        "                                    \"box\": box\n",
        "                                })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in analyzing YOLO box: {e}\")\n",
        "                    continue\n",
        "\n",
        "        # 最後，執行額外的網格搜索以捕獲可能被遺漏的地標\n",
        "        # 但只有在尚未發現地標或僅發現低置信度地標時\n",
        "        should_do_grid_search = (\n",
        "            len(result[\"detected_landmarks\"]) == 0 or\n",
        "            max([landmark.get(\"confidence\", 0) for landmark in result[\"detected_landmarks\"]], default=0) < 0.5\n",
        "        )\n",
        "\n",
        "        if should_do_grid_search and hasattr(self, 'classify_image_region'):\n",
        "            try:\n",
        "                # 創建5x5網格\n",
        "                width, height = getattr(image, 'size', (getattr(image, 'width', 0), getattr(image, 'height', 0)))\n",
        "                if not isinstance(width, (int, float)) or width <= 0:\n",
        "                    width = getattr(image, 'width', 0)\n",
        "                if not isinstance(height, (int, float)) or height <= 0:\n",
        "                    height = getattr(image, 'height', 0)\n",
        "\n",
        "                if width > 0 and height > 0:\n",
        "                    grid_boxes = []\n",
        "                    for i in range(5):\n",
        "                        for j in range(5):\n",
        "                            grid_boxes.append([\n",
        "                                width * (j/5), height * (i/5),\n",
        "                                width * ((j+1)/5), height * ((i+1)/5)\n",
        "                            ])\n",
        "\n",
        "                    # 分析每個網格區域\n",
        "                    for box in grid_boxes:\n",
        "                        try:\n",
        "                            grid_result = self.classify_image_region(\n",
        "                                image,\n",
        "                                box,\n",
        "                                threshold=base_threshold * 0.9,  # 稍微降低網格搜索閾值\n",
        "                                detection_type=\"partial\"\n",
        "                            )\n",
        "\n",
        "                            # 如果檢測到地標\n",
        "                            if grid_result and grid_result.get(\"is_landmark\", False):\n",
        "                                # 檢查是否與已檢測的地標重複\n",
        "                                is_duplicate = False\n",
        "                                for existing in result[\"detected_landmarks\"]:\n",
        "                                    if existing.get(\"landmark_id\") == grid_result.get(\"landmark_id\"):\n",
        "                                        is_duplicate = True\n",
        "                                        break\n",
        "\n",
        "                                # 如果不是重複的，添加到列表\n",
        "                                if not is_duplicate:\n",
        "                                    result[\"detected_landmarks\"].append({\n",
        "                                        \"landmark_id\": grid_result.get(\"landmark_id\", \"unknown\"),\n",
        "                                        \"landmark_name\": grid_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                        \"confidence\": grid_result.get(\"confidence\", 0.0),\n",
        "                                        \"location\": grid_result.get(\"location\", \"Unknown Location\"),\n",
        "                                        \"region_type\": \"grid\",\n",
        "                                        \"box\": box\n",
        "                                    })\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error in analyzing grid region: {e}\")\n",
        "                            continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error in grid search: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        # 按置信度排序檢測結果\n",
        "        result[\"detected_landmarks\"].sort(key=lambda x: x.get(\"confidence\", 0), reverse=True)\n",
        "\n",
        "        # 更新整體場景類型判斷\n",
        "        if len(result[\"detected_landmarks\"]) > 0:\n",
        "            result[\"is_landmark_scene\"] = True\n",
        "            result[\"primary_landmark\"] = result[\"detected_landmarks\"][0]\n",
        "\n",
        "            # 添加 clip_analysis_on_full_image 結果，以便給 LLM 提供更多上下文\n",
        "            if full_image_result and \"clip_analysis\" in full_image_result:\n",
        "                result[\"clip_analysis_on_full_image\"] = full_image_result[\"clip_analysis\"]\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _extract_landmark_specific_info(self, landmark_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        提取特定地標的詳細信息，包括特色模板和活動建議\n",
        "\n",
        "        Args:\n",
        "            landmark_id: 地標ID\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標特定信息\n",
        "        \"\"\"\n",
        "        if not landmark_id or landmark_id == \"unknown\":\n",
        "            return {\"has_specific_activities\": False}\n",
        "\n",
        "        specific_info = {\"has_specific_activities\": False}\n",
        "\n",
        "        # 從 ALL_LANDMARKS 或 self.landmark_data 中提取基本信息\n",
        "        landmark_data_source = None\n",
        "\n",
        "        # 優先嘗試從類屬性獲取\n",
        "        if hasattr(self, 'landmark_data') and self.landmark_data and landmark_id in self.landmark_data:\n",
        "            landmark_data_source = self.landmark_data[landmark_id]\n",
        "            print(f\"Using landmark data from class attribute for {landmark_id}\")\n",
        "        else:\n",
        "            try:\n",
        "                if landmark_id in ALL_LANDMARKS:\n",
        "                    landmark_data_source = ALL_LANDMARKS[landmark_id]\n",
        "                    print(f\"Using landmark data from ALL_LANDMARKS for {landmark_id}\")\n",
        "            except ImportError:\n",
        "                print(\"Warning: Could not import ALL_LANDMARKS from landmark_data\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error accessing ALL_LANDMARKS: {e}\")\n",
        "\n",
        "        # 處理地標基本數據\n",
        "        if landmark_data_source:\n",
        "            # 提取正確的地標名稱\n",
        "            if \"name\" in landmark_data_source:\n",
        "                specific_info[\"landmark_name\"] = landmark_data_source[\"name\"]\n",
        "\n",
        "            # 提取所有可用的 prompts 作為特色模板\n",
        "            if \"prompts\" in landmark_data_source:\n",
        "                specific_info[\"feature_templates\"] = landmark_data_source[\"prompts\"][:5]\n",
        "                specific_info[\"primary_template\"] = landmark_data_source[\"prompts\"][0]\n",
        "\n",
        "            # 提取別名info\n",
        "            if \"aliases\" in landmark_data_source:\n",
        "                specific_info[\"aliases\"] = landmark_data_source[\"aliases\"]\n",
        "\n",
        "            # 提取位置信息\n",
        "            if \"location\" in landmark_data_source:\n",
        "                specific_info[\"location\"] = landmark_data_source[\"location\"]\n",
        "\n",
        "            # 提取其他相關信息\n",
        "            for key in [\"year_built\", \"architectural_style\", \"significance\", \"description\"]:\n",
        "                if key in landmark_data_source:\n",
        "                    specific_info[key] = landmark_data_source[key]\n",
        "\n",
        "        # 嘗試從 LANDMARK_ACTIVITIES 中提取活動建議\n",
        "        try:\n",
        "            if landmark_id in LANDMARK_ACTIVITIES:\n",
        "                activities = LANDMARK_ACTIVITIES[landmark_id]\n",
        "                specific_info[\"landmark_specific_activities\"] = activities\n",
        "                specific_info[\"has_specific_activities\"] = True\n",
        "                print(f\"Found {len(activities)} specific activities for landmark {landmark_id}\")\n",
        "            else:\n",
        "                print(f\"No specific activities found for landmark {landmark_id} in LANDMARK_ACTIVITIES\")\n",
        "                specific_info[\"has_specific_activities\"] = False\n",
        "        except ImportError:\n",
        "            print(\"Warning: Could not import LANDMARK_ACTIVITIES from landmark_activities\")\n",
        "            specific_info[\"has_specific_activities\"] = False\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading landmark activities for {landmark_id}: {e}\")\n",
        "            specific_info[\"has_specific_activities\"] = False\n",
        "\n",
        "        return specific_info\n",
        "\n",
        "    def _analyze_viewpoint(self, image: Union[Image.Image, np.ndarray]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Analyzes the image viewpoint to adjust detection parameters.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "\n",
        "        Returns:\n",
        "            Dict: Viewpoint analysis results\n",
        "        \"\"\"\n",
        "        viewpoint_prompts = {\n",
        "            \"aerial_view\": \"an aerial view from above looking down\",\n",
        "            \"street_level\": \"a street level view looking up at a tall structure\",\n",
        "            \"eye_level\": \"an eye-level horizontal view of a landmark\",\n",
        "            \"distant\": \"a distant view of a landmark on the horizon\",\n",
        "            \"close_up\": \"a close-up detailed view of architectural features\",\n",
        "            \"interior\": \"an interior view inside a structure\"\n",
        "        }\n",
        "\n",
        "        # Calculate similarity scores\n",
        "        viewpoint_scores = self.calculate_similarity_scores(image, viewpoint_prompts)\n",
        "\n",
        "        # Find dominant viewpoint\n",
        "        dominant_viewpoint = max(viewpoint_scores.items(), key=lambda x: x[1])\n",
        "\n",
        "        return {\n",
        "            \"viewpoint_scores\": viewpoint_scores,\n",
        "            \"dominant_viewpoint\": dominant_viewpoint[0],\n",
        "            \"confidence\": dominant_viewpoint[1]\n",
        "        }\n",
        "\n",
        "    def calculate_similarity_scores(self, image: Union[Image.Image, np.ndarray],\n",
        "                                prompts: Dict[str, str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        計算圖像與一組特定提示之間的相似度分數\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            prompts: 提示詞字典 {名稱: 提示文本}\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 每個提示的相似度分數\n",
        "        \"\"\"\n",
        "        # 確保圖像是PIL格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 預處理圖像\n",
        "        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # 獲取圖像特徵\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_input)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # 計算與每個提示的相似度\n",
        "        scores = {}\n",
        "        prompt_texts = list(prompts.values())\n",
        "        prompt_tokens = clip.tokenize(prompt_texts).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prompt_features = self.model.encode_text(prompt_tokens)\n",
        "            prompt_features = prompt_features / prompt_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # calculate similarity\n",
        "            similarity = (100.0 * image_features @ prompt_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "        # 填充結果字典\n",
        "        for i, (name, _) in enumerate(prompts.items()):\n",
        "            scores[name] = float(similarity[i])\n",
        "\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmj_nX2I0MDH"
      },
      "outputs": [],
      "source": [
        "# %%writefile scene_analyzer.py\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from spatial_analyzer import SpatialAnalyzer\n",
        "# from scene_description import SceneDescriptor\n",
        "# from enhance_scene_describer import EnhancedSceneDescriber\n",
        "# from clip_analyzer import CLIPAnalyzer\n",
        "# from landmark_activities import LANDMARK_ACTIVITIES\n",
        "# from clip_zero_shot_classifier import CLIPZeroShotClassifier\n",
        "# from llm_enhancer import LLMEnhancer\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from object_categories import OBJECT_CATEGORIES\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "\n",
        "\n",
        "class SceneAnalyzer:\n",
        "    \"\"\"\n",
        "    Core class for scene analysis and understanding based on object detection results.\n",
        "    Analyzes detected objects, their relationships, and infers the scene type.\n",
        "    \"\"\"\n",
        "    EVERYDAY_SCENE_TYPE_KEYS = [\n",
        "        \"general_indoor_space\", \"generic_street_view\",\n",
        "        \"desk_area_workspace\", \"outdoor_gathering_spot\",\n",
        "        \"kitchen_counter_or_utility_area\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, use_llm: bool = True, use_clip: bool = True, enable_landmark=True, llm_model_path: str = None):\n",
        "        \"\"\"\n",
        "        Initialize the scene analyzer with optional class name mappings.\n",
        "        Args:\n",
        "            class_names: Dictionary mapping class IDs to class names (optional)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.class_names = class_names\n",
        "\n",
        "            self.use_clip = use_clip\n",
        "            self.use_landmark_detection = enable_landmark\n",
        "            self.enable_landmark = enable_landmark\n",
        "\n",
        "            # 初始化基本屬性\n",
        "            self.LANDMARK_ACTIVITIES = {}\n",
        "            self.SCENE_TYPES = {}\n",
        "            self.OBJECT_CATEGORIES = {}\n",
        "\n",
        "            # 嘗試加載資料\n",
        "            try:\n",
        "                self.LANDMARK_ACTIVITIES = LANDMARK_ACTIVITIES\n",
        "                print(\"Loaded LANDMARK_ACTIVITIES successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Failed to load LANDMARK_ACTIVITIES: {e}\")\n",
        "\n",
        "            try:\n",
        "                self.SCENE_TYPES = SCENE_TYPES\n",
        "                print(\"Loaded SCENE_TYPES successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Failed to load SCENE_TYPES: {e}\")\n",
        "\n",
        "            try:\n",
        "                self.OBJECT_CATEGORIES = OBJECT_CATEGORIES\n",
        "                print(\"Loaded OBJECT_CATEGORIES successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Failed to load OBJECT_CATEGORIES: {e}\")\n",
        "\n",
        "            # 初始化其他組件\n",
        "            self.spatial_analyzer = None\n",
        "            self.descriptor = None\n",
        "            self.scene_describer = None\n",
        "\n",
        "            try:\n",
        "                self.spatial_analyzer = SpatialAnalyzer(class_names=class_names, object_categories=self.OBJECT_CATEGORIES)\n",
        "                print(\"Initialized SpatialAnalyzer successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error initializing SpatialAnalyzer: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "            try:\n",
        "                self.descriptor = SceneDescriptor(scene_types=self.SCENE_TYPES, object_categories=self.OBJECT_CATEGORIES)\n",
        "                print(\"Initialized SceneDescriptor successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error initializing SceneDescriptor: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "            try:\n",
        "                if self.spatial_analyzer:\n",
        "                    self.scene_describer = EnhancedSceneDescriber(scene_types=self.SCENE_TYPES, spatial_analyzer_instance=self.spatial_analyzer)\n",
        "                    print(\"Initialized EnhancedSceneDescriber successfully\")\n",
        "                else:\n",
        "                    print(\"Warning: Cannot initialize EnhancedSceneDescriber without SpatialAnalyzer\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error initializing EnhancedSceneDescriber: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "            # 初始化 CLIP 分析器\n",
        "            if self.use_clip:\n",
        "                try:\n",
        "                    self.clip_analyzer = CLIPAnalyzer()\n",
        "\n",
        "                    try:\n",
        "                        # 嘗試使用已加載的CLIP模型實例\n",
        "                        if hasattr(self.clip_analyzer, 'get_clip_instance'):\n",
        "                            model, preprocess, device = self.clip_analyzer.get_clip_instance()\n",
        "                            self.landmark_classifier = CLIPZeroShotClassifier(device=device)\n",
        "                            print(\"Initialized landmark classifier with shared CLIP model\")\n",
        "                        else:\n",
        "                            self.landmark_classifier = CLIPZeroShotClassifier()\n",
        "\n",
        "                        # 配置地標檢測器\n",
        "                        self.landmark_classifier.set_batch_size(8)  # 設置合適的批處理大小\n",
        "                        self.landmark_classifier.adjust_confidence_threshold(\"full_image\", 0.8)  # 整張圖像的閾值要求\n",
        "                        self.landmark_classifier.adjust_confidence_threshold(\"distant\", 0.65)  # 遠景地標的閾值要求\n",
        "\n",
        "                        self.use_landmark_detection = True\n",
        "                        print(\"Landmark detection enabled with optimized settings\")\n",
        "\n",
        "                    except (ImportError, Exception) as e:\n",
        "                        print(f\"Warning: Could not initialize landmark classifier: {e}\")\n",
        "                        self.use_landmark_detection = False\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not initialize CLIP analyzer: {e}\")\n",
        "                    print(\"Scene analysis will proceed without CLIP. Install CLIP with 'pip install clip' for enhanced scene understanding.\")\n",
        "                    self.use_clip = False\n",
        "\n",
        "            # 初始化LLM Model\n",
        "            self.use_llm = use_llm\n",
        "            if use_llm:\n",
        "                try:\n",
        "                    # from llm_enhancer import LLMEnhancer\n",
        "                    self.llm_enhancer = LLMEnhancer(model_path=llm_model_path)\n",
        "                    print(f\"LLM enhancer initialized successfully.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not initialize LLM enhancer: {e}\")\n",
        "                    print(\"Scene analysis will proceed without LLM. Make sure required packages are installed.\")\n",
        "                    self.use_llm = False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Critical error during SceneAnalyzer initialization: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "\n",
        "    def generate_scene_description(self,\n",
        "                             scene_type: str,\n",
        "                             detected_objects: List[Dict],\n",
        "                             confidence: float,\n",
        "                             lighting_info: Optional[Dict] = None,\n",
        "                             functional_zones: Optional[Dict] = None,\n",
        "                             enable_landmark: bool = True,\n",
        "                             scene_scores: Optional[Dict] = None,\n",
        "                             spatial_analysis: Optional[Dict] = None,\n",
        "                             image_dimensions: Optional[Tuple[int, int]] = None\n",
        "                             ):\n",
        "        \"\"\"\n",
        "        生成場景描述，並將所有必要的上下文傳遞給底層的描述器。\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            confidence: 場景分類置信度\n",
        "            lighting_info: 照明條件信息（可選）\n",
        "            functional_zones: 功能區域信息（可選）\n",
        "            enable_landmark: 是否啟用地標描述（可選）\n",
        "            scene_scores: 場景分數（可選）\n",
        "            spatial_analysis: 空間分析結果（可選）\n",
        "            image_dimensions: 圖像尺寸 (寬, 高)（可選）\n",
        "        Returns:\n",
        "            str: 生成的場景描述\n",
        "        \"\"\"\n",
        "\n",
        "        # 轉換 functional_zones 從 Dict 到 List[str]，並過濾技術術語\n",
        "        functional_zones_list = []\n",
        "        if functional_zones and isinstance(functional_zones, dict):\n",
        "            # 過濾掉技術術語，只保留有意義的描述\n",
        "            filtered_zones = {k: v for k, v in functional_zones.items()\n",
        "                            if not k.endswith('_zone') or k in ['dining_zone', 'seating_zone', 'work_zone']}\n",
        "            functional_zones_list = [v.get('description', k) for k, v in filtered_zones.items()\n",
        "                                if isinstance(v, dict) and v.get('description')]\n",
        "        elif functional_zones and isinstance(functional_zones, list):\n",
        "            # 過濾列表中的技術術語\n",
        "            functional_zones_list = [zone for zone in functional_zones\n",
        "                                if not zone.endswith('_zone') or 'area' in zone]\n",
        "\n",
        "        # 生成詳細的物體統計信息\n",
        "        object_statistics = {}\n",
        "        for obj in detected_objects:\n",
        "            class_name = obj.get(\"class_name\", \"unknown\")\n",
        "            if class_name not in object_statistics:\n",
        "                object_statistics[class_name] = {\n",
        "                    \"count\": 0,\n",
        "                    \"avg_confidence\": 0.0,\n",
        "                    \"max_confidence\": 0.0,\n",
        "                    \"instances\": []\n",
        "                }\n",
        "\n",
        "            stats = object_statistics[class_name]\n",
        "            stats[\"count\"] += 1\n",
        "            stats[\"instances\"].append(obj)\n",
        "            stats[\"max_confidence\"] = max(stats[\"max_confidence\"], obj.get(\"confidence\", 0.0))\n",
        "\n",
        "        # 計算平均信心度\n",
        "        for class_name, stats in object_statistics.items():\n",
        "            if stats[\"count\"] > 0:\n",
        "                total_conf = sum(inst.get(\"confidence\", 0.0) for inst in stats[\"instances\"])\n",
        "                stats[\"avg_confidence\"] = total_conf / stats[\"count\"]\n",
        "\n",
        "        return self.scene_describer.generate_description(\n",
        "            scene_type=scene_type,\n",
        "            detected_objects=detected_objects,\n",
        "            confidence=confidence,\n",
        "            lighting_info=lighting_info,\n",
        "            functional_zones=functional_zones_list,\n",
        "            enable_landmark=enable_landmark,\n",
        "            scene_scores=scene_scores,\n",
        "            spatial_analysis=spatial_analysis,\n",
        "            image_dimensions=image_dimensions,\n",
        "            object_statistics=object_statistics\n",
        "        )\n",
        "\n",
        "\n",
        "    def _define_image_regions(self):\n",
        "        \"\"\"Define regions of the image for spatial analysis (3x3 grid)\"\"\"\n",
        "        self.regions = {\n",
        "            \"top_left\": (0, 0, 1/3, 1/3),\n",
        "            \"top_center\": (1/3, 0, 2/3, 1/3),\n",
        "            \"top_right\": (2/3, 0, 1, 1/3),\n",
        "            \"middle_left\": (0, 1/3, 1/3, 2/3),\n",
        "            \"middle_center\": (1/3, 1/3, 2/3, 2/3),\n",
        "            \"middle_right\": (2/3, 1/3, 1, 2/3),\n",
        "            \"bottom_left\": (0, 2/3, 1/3, 1),\n",
        "            \"bottom_center\": (1/3, 2/3, 2/3, 1),\n",
        "            \"bottom_right\": (2/3, 2/3, 1, 1)\n",
        "        }\n",
        "\n",
        "    def _get_alternative_scene_type(self, landmark_scene_type, detected_objects, scene_scores):\n",
        "        \"\"\"\n",
        "        為地標場景類型選擇適合的替代類型\n",
        "\n",
        "        Args:\n",
        "            landmark_scene_type: 原始地標場景類型\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            scene_scores: 所有場景類型的分數\n",
        "\n",
        "        Returns:\n",
        "            str: 適合的替代場景類型\n",
        "        \"\"\"\n",
        "        # 1. 嘗試從現有場景分數中找出第二高的非地標場景\n",
        "        landmark_types = {\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"}\n",
        "        alternative_scores = {k: v for k, v in scene_scores.items() if k not in landmark_types and v > 0.2}\n",
        "\n",
        "        if alternative_scores:\n",
        "            # 返回分數最高的非地標場景類型\n",
        "            return max(alternative_scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # 2. 基於物體組合推斷場景類型\n",
        "        object_counts = {}\n",
        "        for obj in detected_objects:\n",
        "            class_name = obj.get(\"class_name\", \"\")\n",
        "            if class_name not in object_counts:\n",
        "                object_counts[class_name] = 0\n",
        "            object_counts[class_name] += 1\n",
        "\n",
        "        # 根據物體組合決定場景類型\n",
        "        if \"car\" in object_counts or \"truck\" in object_counts or \"bus\" in object_counts:\n",
        "            # 有車輛，可能是街道或交叉路口\n",
        "            if \"traffic light\" in object_counts or \"stop sign\" in object_counts:\n",
        "                return \"intersection\"\n",
        "            else:\n",
        "                return \"city_street\"\n",
        "\n",
        "        if \"building\" in object_counts and object_counts.get(\"person\", 0) > 0:\n",
        "            # 有建築物和人，可能是商業區\n",
        "            return \"commercial_district\"\n",
        "\n",
        "        if object_counts.get(\"person\", 0) > 3:\n",
        "            # 多個行人，可能是行人區\n",
        "            return \"pedestrian_area\"\n",
        "\n",
        "        if \"bench\" in object_counts or \"potted plant\" in object_counts:\n",
        "            # 有長椅或盆栽，可能是公園區域\n",
        "            return \"park_area\"\n",
        "\n",
        "        # 3. 根據原始地標場景類型選擇合適的替代場景\n",
        "        if landmark_scene_type == \"natural_landmark\":\n",
        "            return \"outdoor_natural_area\"\n",
        "        elif landmark_scene_type == \"historical_monument\":\n",
        "            return \"urban_architecture\"\n",
        "\n",
        "        # 默認回退到城市街道\n",
        "        return \"city_street\"\n",
        "\n",
        "    def analyze(self, detection_result: Any, lighting_info: Optional[Dict] = None, class_confidence_threshold: float = 0.25, scene_confidence_threshold: float = 0.6, enable_landmark=True, places365_info: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze detection results to determine scene type and provide understanding.\n",
        "        Args:\n",
        "            detection_result: Detection result from YOLOv8 or similar.\n",
        "            lighting_info: Optional lighting condition analysis results.\n",
        "            class_confidence_threshold: Minimum confidence to consider an object.\n",
        "            scene_confidence_threshold: Minimum confidence to determine a scene.\n",
        "            enable_landmark: Whether to enable landmark detection and recognition for this run.\n",
        "        Returns:\n",
        "            Dictionary with scene analysis results.\n",
        "        \"\"\"\n",
        "        current_run_enable_landmark = enable_landmark\n",
        "        print(f\"DIAGNOSTIC (SceneAnalyzer.analyze): Called with current_run_enable_landmark={current_run_enable_landmark}\")\n",
        "        print(f\"DEBUG: SceneAnalyzer received lighting_info type: {type(lighting_info)}\")\n",
        "        print(f\"DEBUG: SceneAnalyzer lighting_info source: {lighting_info.get('source', 'unknown') if isinstance(lighting_info, dict) else 'not_dict'}\")\n",
        "\n",
        "        # Log Places365 information if available\n",
        "        if places365_info:\n",
        "            print(f\"DIAGNOSTIC: Places365 info received - scene: {places365_info.get('scene_label', 'unknown')}, \"\n",
        "                f\"mapped: {places365_info.get('mapped_scene_type', 'unknown')}, \"\n",
        "                f\"confidence: {places365_info.get('confidence', 0.0):.3f}\")\n",
        "\n",
        "        # Sync enable_landmark status with child components for this analysis run\n",
        "        # Assuming these components exist and have an 'enable_landmark' attribute\n",
        "        for component_name in ['scene_describer', 'clip_analyzer', 'landmark_classifier']:\n",
        "            if hasattr(self, component_name):\n",
        "                component = getattr(self, component_name)\n",
        "                if component and hasattr(component, 'enable_landmark'):\n",
        "                    component.enable_landmark = current_run_enable_landmark\n",
        "\n",
        "        self.enable_landmark = current_run_enable_landmark # Instance's general state for this run\n",
        "        if hasattr(self, 'use_landmark_detection'):\n",
        "            self.use_landmark_detection = current_run_enable_landmark\n",
        "\n",
        "\n",
        "        original_image_pil = None\n",
        "        image_dims_val = None # Will be (width, height)\n",
        "\n",
        "        if detection_result is not None and hasattr(detection_result, 'orig_img') and detection_result.orig_img is not None:\n",
        "            if isinstance(detection_result.orig_img, np.ndarray):\n",
        "                try:\n",
        "                    img_array = detection_result.orig_img\n",
        "                    if img_array.ndim == 3 and img_array.shape[2] == 4: # RGBA\n",
        "                        img_array = img_array[:, :, :3] # Convert to RGB\n",
        "                    if img_array.ndim == 2 : # Grayscale\n",
        "                         original_image_pil = Image.fromarray(img_array).convert(\"RGB\")\n",
        "                    else: # Assuming RGB or BGR (PIL handles BGR->RGB on fromarray if mode not specified, but explicit is better if source is cv2 BGR)\n",
        "                         original_image_pil = Image.fromarray(img_array)\n",
        "\n",
        "                    if original_image_pil.mode == 'BGR': # Explicitly convert BGR from OpenCV to RGB for PIL\n",
        "                        original_image_pil = original_image_pil.convert('RGB')\n",
        "\n",
        "                    image_dims_val = (original_image_pil.width, original_image_pil.height)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error converting NumPy orig_img to PIL: {e}\")\n",
        "            elif hasattr(detection_result.orig_img, 'size') and callable(getattr(detection_result.orig_img, 'convert', None)):\n",
        "                original_image_pil = detection_result.orig_img.copy().convert(\"RGB\") # Ensure RGB\n",
        "                image_dims_val = original_image_pil.size\n",
        "            else:\n",
        "                print(f\"Warning: detection_result.orig_img (type: {type(detection_result.orig_img)}) is not a recognized NumPy array or PIL Image.\")\n",
        "        else:\n",
        "            print(\"Warning: detection_result.orig_img not available. Image-based analysis will be limited.\")\n",
        "\n",
        "        # Handling cases with no YOLO detections (or no boxes attribute)\n",
        "        no_yolo_detections = (detection_result is None or\n",
        "                            not hasattr(detection_result, 'boxes') or\n",
        "                            not hasattr(detection_result.boxes, 'xyxy') or\n",
        "                            len(detection_result.boxes.xyxy) == 0)\n",
        "\n",
        "        if no_yolo_detections:\n",
        "            tried_landmark_detection = False\n",
        "            landmark_detection_result = None\n",
        "\n",
        "            if original_image_pil and self.use_clip and current_run_enable_landmark:\n",
        "                if not hasattr(self, 'landmark_classifier') and hasattr(self, 'clip_analyzer'):\n",
        "                    try:\n",
        "                        if hasattr(self.clip_analyzer, 'get_clip_instance'):\n",
        "                            model, preprocess, device = self.clip_analyzer.get_clip_instance()\n",
        "                            self.landmark_classifier = CLIPZeroShotClassifier(device=device)\n",
        "                            print(\"Initialized landmark classifier with shared CLIP model\")\n",
        "                        else:\n",
        "                            self.landmark_classifier = CLIPZeroShotClassifier()\n",
        "                        print(\"Created landmark classifier on demand for no YOLO detection path\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Could not initialize landmark classifier: {e}\")\n",
        "\n",
        "                # 地標搜索\n",
        "                if hasattr(self, 'landmark_classifier'):\n",
        "                    try:\n",
        "                        tried_landmark_detection = True\n",
        "                        print(\"Attempting landmark detection with no YOLO boxes\")\n",
        "                        landmark_results_no_yolo = self.landmark_classifier.intelligent_landmark_search(\n",
        "                            original_image_pil, yolo_boxes=None, base_threshold=0.2  # 略微降低閾值，提高靈敏度\n",
        "                        )\n",
        "\n",
        "                        # 確保在無地標場景時返回有效結果\n",
        "                        if landmark_results_no_yolo is None:\n",
        "                            landmark_results_no_yolo = {\"is_landmark_scene\": False, \"detected_landmarks\": []}\n",
        "\n",
        "                        if landmark_results_no_yolo and landmark_results_no_yolo.get(\"is_landmark_scene\", False):\n",
        "                            primary_landmark_no_yolo = landmark_results_no_yolo.get(\"primary_landmark\")\n",
        "\n",
        "                            # 放寬閾值條件，以便捕獲更多潛在地標\n",
        "                            if primary_landmark_no_yolo and primary_landmark_no_yolo.get(\"confidence\", 0) > 0.25:  # 降低閾值\n",
        "                                landmark_detection_result = True\n",
        "                                detected_objects_from_landmarks_list = []\n",
        "                                w_img_no_yolo, h_img_no_yolo = image_dims_val if image_dims_val else (1,1)\n",
        "\n",
        "                                for lm_info_item in landmark_results_no_yolo.get(\"detected_landmarks\", []):\n",
        "                                    if lm_info_item.get(\"confidence\", 0) > 0.25:  # 降低閾值與上面保持一致\n",
        "                                        # 安全獲取 box 值，避免索引錯誤\n",
        "                                        box = lm_info_item.get(\"box\", [0, 0, w_img_no_yolo, h_img_no_yolo])\n",
        "                                        # 確保 box 包含至少 4 個元素\n",
        "                                        if len(box) < 4:\n",
        "                                            box = [0, 0, w_img_no_yolo, h_img_no_yolo]\n",
        "\n",
        "                                        # 計算中心點和標準化坐標\n",
        "                                        center_x, center_y = (box[0] + box[2]) / 2, (box[1] + box[3]) / 2\n",
        "                                        norm_cx = center_x / w_img_no_yolo if w_img_no_yolo > 0 else 0.5\n",
        "                                        norm_cy = center_y / h_img_no_yolo if h_img_no_yolo > 0 else 0.5\n",
        "\n",
        "                                        # 決定地標類型\n",
        "                                        landmark_type = \"architectural\"  # 預設類型\n",
        "                                        landmark_id = lm_info_item.get(\"landmark_id\", \"\")\n",
        "\n",
        "                                        if hasattr(self.landmark_classifier, '_determine_landmark_type') and landmark_id:\n",
        "                                            try:\n",
        "                                                landmark_type = self.landmark_classifier._determine_landmark_type(landmark_id)\n",
        "                                            except Exception as e:\n",
        "                                                print(f\"Error determining landmark type: {e}\")\n",
        "                                        else:\n",
        "                                            # 使用簡單的基於 ID 的啟發式方法推斷類型\n",
        "                                            landmark_id_lower = landmark_id.lower() if isinstance(landmark_id, str) else \"\"\n",
        "                                            if \"natural\" in landmark_id_lower or any(term in landmark_id_lower for term in [\"mountain\", \"waterfall\", \"canyon\", \"lake\"]):\n",
        "                                                landmark_type = \"natural\"\n",
        "                                            elif \"monument\" in landmark_id_lower or \"memorial\" in landmark_id_lower or \"historical\" in landmark_id_lower:\n",
        "                                                landmark_type = \"monument\"\n",
        "\n",
        "                                        # 決定區域位置\n",
        "                                        region = \"center\"  # 預設值\n",
        "                                        if hasattr(self, 'spatial_analyzer') and hasattr(self.spatial_analyzer, '_determine_region'):\n",
        "                                            try:\n",
        "                                                region = self.spatial_analyzer._determine_region(norm_cx, norm_cy)\n",
        "                                            except Exception as e:\n",
        "                                                print(f\"Error determining region: {e}\")\n",
        "\n",
        "                                        # 創建地標物體\n",
        "                                        landmark_obj = {\n",
        "                                            \"class_id\": lm_info_item.get(\"landmark_id\", f\"LM_{lm_info_item.get('landmark_name','unk')}\")[:15],\n",
        "                                            \"class_name\": lm_info_item.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                            \"confidence\": lm_info_item.get(\"confidence\", 0.0),\n",
        "                                            \"box\": box,\n",
        "                                            \"center\": (center_x, center_y),\n",
        "                                            \"normalized_center\": (norm_cx, norm_cy),\n",
        "                                            \"size\": (box[2] - box[0], box[3] - box[1]),\n",
        "                                            \"normalized_size\": (\n",
        "                                                (box[2] - box[0])/(w_img_no_yolo if w_img_no_yolo>0 else 1),\n",
        "                                                (box[3] - box[1])/(h_img_no_yolo if h_img_no_yolo>0 else 1)\n",
        "                                            ),\n",
        "                                            \"area\": (box[2] - box[0]) * (box[3] - box[1]),\n",
        "                                            \"normalized_area\": (\n",
        "                                                (box[2] - box[0]) * (box[3] - box[1])\n",
        "                                            ) / ((w_img_no_yolo*h_img_no_yolo) if w_img_no_yolo*h_img_no_yolo >0 else 1),\n",
        "                                            \"is_landmark\": True,\n",
        "                                            \"landmark_id\": landmark_id,\n",
        "                                            \"location\": lm_info_item.get(\"location\", \"Unknown Location\"),\n",
        "                                            \"region\": region,\n",
        "                                            \"year_built\": lm_info_item.get(\"year_built\", \"\"),\n",
        "                                            \"architectural_style\": lm_info_item.get(\"architectural_style\", \"\"),\n",
        "                                            \"significance\": lm_info_item.get(\"significance\", \"\"),\n",
        "                                            \"landmark_type\": landmark_type\n",
        "                                        }\n",
        "                                        detected_objects_from_landmarks_list.append(landmark_obj)\n",
        "\n",
        "                                if detected_objects_from_landmarks_list:\n",
        "                                    # 設定場景類型\n",
        "                                    best_scene_val_no_yolo = \"tourist_landmark\"  # 預設\n",
        "                                    if primary_landmark_no_yolo:\n",
        "                                        try:\n",
        "                                            lm_type_no_yolo = primary_landmark_no_yolo.get(\"landmark_type\", \"architectural\")\n",
        "                                            if lm_type_no_yolo and \"natural\" in lm_type_no_yolo.lower():\n",
        "                                                best_scene_val_no_yolo = \"natural_landmark\"\n",
        "                                            elif lm_type_no_yolo and (\"historical\" in lm_type_no_yolo.lower() or \"monument\" in lm_type_no_yolo.lower()):\n",
        "                                                best_scene_val_no_yolo = \"historical_monument\"\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Error determining scene type from landmark type: {e}\")\n",
        "\n",
        "                                    # 確保場景類型有效\n",
        "                                    if not hasattr(self, 'SCENE_TYPES') or best_scene_val_no_yolo not in self.SCENE_TYPES:\n",
        "                                        best_scene_val_no_yolo = \"tourist_landmark\"  # 預設場景類型\n",
        "\n",
        "                                    # 設定置信度\n",
        "                                    scene_confidence_no_yolo = primary_landmark_no_yolo.get(\"confidence\", 0.0) if primary_landmark_no_yolo else 0.0\n",
        "\n",
        "                                    # 分析空間區域\n",
        "                                    region_analysis_for_lm_desc = {}\n",
        "                                    if hasattr(self, 'spatial_analyzer') and hasattr(self.spatial_analyzer, '_analyze_regions'):\n",
        "                                        try:\n",
        "                                            region_analysis_for_lm_desc = self.spatial_analyzer._analyze_regions(detected_objects_from_landmarks_list)\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Error analyzing regions: {e}\")\n",
        "\n",
        "                                    # 獲取功能區\n",
        "                                    f_zones_no_yolo = {}\n",
        "                                    if hasattr(self, 'spatial_analyzer') and hasattr(self.spatial_analyzer, '_identify_landmark_zones'):\n",
        "                                        try:\n",
        "                                            f_zones_no_yolo = self.spatial_analyzer._identify_landmark_zones(detected_objects_from_landmarks_list)\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Error identifying landmark zones: {e}\")\n",
        "\n",
        "                                    # 生成場景描述\n",
        "                                    scene_desc_no_yolo = f\"A {best_scene_val_no_yolo} scene.\"  # 預設描述\n",
        "                                    if hasattr(self, 'scene_describer') and hasattr(self.scene_describer, 'generate_description'):\n",
        "                                        try:\n",
        "                                            scene_desc_no_yolo = self.scene_describer.generate_description(\n",
        "                                                scene_type=best_scene_val_no_yolo,\n",
        "                                                detected_objects=detected_objects_from_landmarks_list,\n",
        "                                                confidence=scene_confidence_no_yolo,\n",
        "                                                lighting_info=lighting_info,\n",
        "                                                functional_zones=list(f_zones_no_yolo.keys()) if f_zones_no_yolo else [],\n",
        "                                                enable_landmark=True,\n",
        "                                                scene_scores={best_scene_val_no_yolo: scene_confidence_no_yolo},\n",
        "                                                spatial_analysis=region_analysis_for_lm_desc,\n",
        "                                                image_dimensions=image_dims_val\n",
        "                                            )\n",
        "\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Error generating scene description: {e}\")\n",
        "\n",
        "\n",
        "                                    # 使用 LLM 增強描述\n",
        "                                    enhanced_desc_no_yolo = scene_desc_no_yolo\n",
        "                                    if self.use_llm and hasattr(self, 'llm_enhancer') and hasattr(self.llm_enhancer, 'enhance_description'):\n",
        "                                        try:\n",
        "                                            # 準備用於 LLM 增強器的數據\n",
        "                                            prominent_objects_detail = \"\"\n",
        "                                            if hasattr(self, 'scene_describer') and hasattr(self.scene_describer, '_format_object_list_for_description'):\n",
        "                                                try:\n",
        "                                                    prominent_objects_detail = self.scene_describer._format_object_list_for_description(\n",
        "                                                        detected_objects_from_landmarks_list[:min(1, len(detected_objects_from_landmarks_list))]\n",
        "                                                    )\n",
        "                                                except Exception as e:\n",
        "                                                    print(f\"Error formatting object list: {e}\")\n",
        "\n",
        "                                            scene_data_llm_no_yolo = {\n",
        "                                                \"original_description\": scene_desc_no_yolo,\n",
        "                                                \"scene_type\": best_scene_val_no_yolo,\n",
        "                                                \"scene_name\": self.SCENE_TYPES.get(best_scene_val_no_yolo, {}).get(\"name\", \"Landmark\")\n",
        "                                                    if hasattr(self, 'SCENE_TYPES') else \"Landmark\",\n",
        "                                                \"detected_objects\": detected_objects_from_landmarks_list,\n",
        "                                                \"object_list\": \"landmark\",\n",
        "                                                \"confidence\": scene_confidence_no_yolo,\n",
        "                                                \"lighting_info\": lighting_info,\n",
        "                                                \"functional_zones\": f_zones_no_yolo,\n",
        "                                                \"clip_analysis\": landmark_results_no_yolo.get(\"clip_analysis_on_full_image\", {}),\n",
        "                                                \"enable_landmark\": True,\n",
        "                                                \"image_width\": w_img_no_yolo,\n",
        "                                                \"image_height\": h_img_no_yolo,\n",
        "                                                \"prominent_objects_detail\": prominent_objects_detail\n",
        "                                            }\n",
        "                                            enhanced_desc_no_yolo = self.llm_enhancer.enhance_description(scene_data_llm_no_yolo)\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Error enhancing description with LLM: {e}\")\n",
        "                                            import traceback\n",
        "                                            traceback.print_exc()\n",
        "\n",
        "                                    # 計算可能的活動，優先使用地標特定活動\n",
        "                                    possible_activities = [\"Sightseeing\"]\n",
        "\n",
        "                                    # 檢查是否有主要地標活動從 CLIP 分析結果中獲取\n",
        "                                    primary_landmark_activities = landmark_results_no_yolo.get(\"primary_landmark_activities\", [])\n",
        "\n",
        "                                    if primary_landmark_activities:\n",
        "                                        print(f\"Using {len(primary_landmark_activities)} landmark-specific activities\")\n",
        "                                        possible_activities = primary_landmark_activities\n",
        "                                    else:\n",
        "                                        # 從檢測到的地標中提取特定活動\n",
        "                                        landmark_specific_activities = []\n",
        "                                        for lm_info_item in landmark_results_no_yolo.get(\"detected_landmarks\", []):\n",
        "                                            lm_id = lm_info_item.get(\"landmark_id\")\n",
        "                                            if lm_id and hasattr(self, 'LANDMARK_ACTIVITIES') and lm_id in self.LANDMARK_ACTIVITIES:\n",
        "                                                landmark_specific_activities.extend(self.LANDMARK_ACTIVITIES[lm_id])\n",
        "\n",
        "                                        if landmark_specific_activities:\n",
        "                                            possible_activities = list(set(landmark_specific_activities))  # 去重\n",
        "                                            print(f\"Extracted {len(possible_activities)} activities from landmark data\")\n",
        "                                        else:\n",
        "                                            # 回退到通用活動推斷\n",
        "                                            if hasattr(self, 'descriptor') and hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "                                                try:\n",
        "                                                    possible_activities = self.descriptor._infer_possible_activities(\n",
        "                                                        best_scene_val_no_yolo,\n",
        "                                                        detected_objects_from_landmarks_list,\n",
        "                                                        enable_landmark=True,\n",
        "                                                        scene_scores={best_scene_val_no_yolo: scene_confidence_no_yolo}\n",
        "                                                    )\n",
        "                                                except Exception as e:\n",
        "                                                    print(f\"Error inferring possible activities: {e}\")\n",
        "\n",
        "                                    # 準備最終結果\n",
        "                                    return {\n",
        "                                        \"scene_type\": best_scene_val_no_yolo,\n",
        "                                        \"scene_name\": self.SCENE_TYPES.get(best_scene_val_no_yolo, {}).get(\"name\", \"Landmark\")\n",
        "                                            if hasattr(self, 'SCENE_TYPES') else \"Landmark\",\n",
        "                                        \"confidence\": round(float(scene_confidence_no_yolo), 4),\n",
        "                                        \"description\": scene_desc_no_yolo,\n",
        "                                        \"enhanced_description\": enhanced_desc_no_yolo,\n",
        "                                        \"objects_present\": detected_objects_from_landmarks_list,\n",
        "                                        \"object_count\": len(detected_objects_from_landmarks_list),\n",
        "                                        \"regions\": region_analysis_for_lm_desc,\n",
        "                                        \"possible_activities\": possible_activities,\n",
        "                                        \"functional_zones\": f_zones_no_yolo,\n",
        "                                        \"detected_landmarks\": [lm for lm in detected_objects_from_landmarks_list if lm.get(\"is_landmark\", False)],\n",
        "                                        \"primary_landmark\": primary_landmark_no_yolo,\n",
        "                                        \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "                                    }\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error in landmark-only detection path (analyze method): {e}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "\n",
        "            # 如果地標檢測失敗或未嘗試，使用 CLIP 進行一般場景分析\n",
        "            if not landmark_detection_result and self.use_clip and original_image_pil:\n",
        "                try:\n",
        "                    clip_analysis_val_no_yolo = None\n",
        "                    if hasattr(self, 'clip_analyzer') and hasattr(self.clip_analyzer, 'analyze_image'):\n",
        "                        try:\n",
        "                            clip_analysis_val_no_yolo = self.clip_analyzer.analyze_image(\n",
        "                                original_image_pil,\n",
        "                                enable_landmark=current_run_enable_landmark\n",
        "                            )\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error in CLIP analysis: {e}\")\n",
        "\n",
        "                    scene_type_llm_no_yolo = \"llm_inferred_no_yolo\"\n",
        "                    confidence_llm_no_yolo = 0.0\n",
        "\n",
        "                    if clip_analysis_val_no_yolo and isinstance(clip_analysis_val_no_yolo, dict):\n",
        "                        top_scene = clip_analysis_val_no_yolo.get(\"top_scene\")\n",
        "                        if top_scene and isinstance(top_scene, tuple) and len(top_scene) >= 2:\n",
        "                            confidence_llm_no_yolo = top_scene[1]\n",
        "                            if isinstance(top_scene[0], str):\n",
        "                                scene_type_llm_no_yolo = top_scene[0]\n",
        "\n",
        "                    desc_llm_no_yolo = \"Primary object detection did not yield results. This description is based on overall image context.\"\n",
        "\n",
        "                    w_llm_no_yolo, h_llm_no_yolo = image_dims_val if image_dims_val else (1, 1)\n",
        "\n",
        "                    enhanced_desc_llm_no_yolo = desc_llm_no_yolo\n",
        "                    if self.use_llm and hasattr(self, 'llm_enhancer'):\n",
        "                        try:\n",
        "                            # 確保數據正確格式化\n",
        "                            clip_analysis_safe = {}\n",
        "                            if isinstance(clip_analysis_val_no_yolo, dict):\n",
        "                                clip_analysis_safe = clip_analysis_val_no_yolo\n",
        "\n",
        "                            scene_data_llm_no_yolo_enhance = {\n",
        "                                \"original_description\": desc_llm_no_yolo,\n",
        "                                \"scene_type\": scene_type_llm_no_yolo,\n",
        "                                \"scene_name\": \"Contextually Inferred (No Detections)\",\n",
        "                                \"detected_objects\": [],\n",
        "                                \"object_list\": \"general ambiance\",\n",
        "                                \"confidence\": confidence_llm_no_yolo,\n",
        "                                \"lighting_info\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0},\n",
        "                                \"clip_analysis\": clip_analysis_safe,\n",
        "                                \"enable_landmark\": current_run_enable_landmark,\n",
        "                                \"image_width\": w_llm_no_yolo,\n",
        "                                \"image_height\": h_llm_no_yolo,\n",
        "                                \"prominent_objects_detail\": \"the overall visual context\"\n",
        "                            }\n",
        "\n",
        "                            if hasattr(self.llm_enhancer, 'enhance_description'):\n",
        "                                try:\n",
        "                                    enhanced_desc_llm_no_yolo = self.llm_enhancer.enhance_description(scene_data_llm_no_yolo_enhance)\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Error in enhance_description: {e}\")\n",
        "\n",
        "                            if (not enhanced_desc_llm_no_yolo or len(enhanced_desc_llm_no_yolo.strip()) < 20) and hasattr(self.llm_enhancer, 'handle_no_detection'):\n",
        "                                try:\n",
        "                                    enhanced_desc_llm_no_yolo = self.llm_enhancer.handle_no_detection(clip_analysis_safe)\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Error in handle_no_detection: {e}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error preparing data for LLM enhancement: {e}\")\n",
        "                            import traceback\n",
        "                            traceback.print_exc()\n",
        "\n",
        "                    # 安全類型轉換\n",
        "                    try:\n",
        "                        confidence_float = float(confidence_llm_no_yolo)\n",
        "                    except (ValueError, TypeError):\n",
        "                        confidence_float = 0.0\n",
        "\n",
        "                    # 確保增強描述不為空\n",
        "                    if not enhanced_desc_llm_no_yolo or not isinstance(enhanced_desc_llm_no_yolo, str):\n",
        "                        enhanced_desc_llm_no_yolo = desc_llm_no_yolo\n",
        "\n",
        "                    # 返回結果\n",
        "                    return {\n",
        "                        \"scene_type\": scene_type_llm_no_yolo,\n",
        "                        \"confidence\": round(confidence_float, 4),\n",
        "                        \"description\": desc_llm_no_yolo,\n",
        "                        \"enhanced_description\": enhanced_desc_llm_no_yolo,\n",
        "                        \"objects_present\": [],\n",
        "                        \"object_count\": 0,\n",
        "                        \"regions\": {},\n",
        "                        \"possible_activities\": [],\n",
        "                        \"safety_concerns\": [],\n",
        "                        \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in CLIP no-detection fallback (analyze method): {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            # Check if Places365 provides useful scene information even without YOLO detections\n",
        "            fallback_scene_type = \"unknown\"\n",
        "            fallback_confidence = 0.0\n",
        "            fallback_description = \"No objects were detected in the image, and contextual analysis could not be performed or failed.\"\n",
        "\n",
        "            if places365_info and places365_info.get('confidence', 0) > 0.3:\n",
        "                fallback_scene_type = places365_info.get('mapped_scene_type', 'unknown')\n",
        "                fallback_confidence = places365_info.get('confidence', 0.0)\n",
        "                fallback_description = f\"Scene appears to be {places365_info.get('scene_label', 'an unidentified location')} based on overall visual context.\"\n",
        "\n",
        "            return {\n",
        "                \"scene_type\": fallback_scene_type,\n",
        "                \"confidence\": fallback_confidence,\n",
        "                \"description\": fallback_description,\n",
        "                \"enhanced_description\": \"The image analysis system could not detect any recognizable objects or landmarks in this image.\",\n",
        "                \"objects_present\": [],\n",
        "                \"object_count\": 0,\n",
        "                \"regions\": {},\n",
        "                \"possible_activities\": [],\n",
        "                \"safety_concerns\": [],\n",
        "                \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "            if self.use_llm and self.use_clip and original_image_pil:\n",
        "                try:\n",
        "                    clip_analysis_val_no_yolo = self.clip_analyzer.analyze_image(original_image_pil, enable_landmark=current_run_enable_landmark)\n",
        "                    scene_type_llm_no_yolo = \"llm_inferred_no_yolo\"\n",
        "                    confidence_llm_no_yolo = clip_analysis_val_no_yolo.get(\"top_scene\", (\"unknown\", 0.0))[1] if isinstance(clip_analysis_val_no_yolo, dict) else 0.0\n",
        "                    desc_llm_no_yolo = \"Primary object detection did not yield results. This description is based on overall image context.\"\n",
        "\n",
        "                    w_llm_no_yolo, h_llm_no_yolo = image_dims_val if image_dims_val else (1,1)\n",
        "                    scene_data_llm_no_yolo_enhance = {\n",
        "                        \"original_description\": desc_llm_no_yolo, \"scene_type\": scene_type_llm_no_yolo,\n",
        "                        \"scene_name\": \"Contextually Inferred (No Detections)\", \"detected_objects\": [], \"object_list\": \"general ambiance\",\n",
        "                        \"confidence\": confidence_llm_no_yolo, \"lighting_info\": lighting_info, \"clip_analysis\": clip_analysis_val_no_yolo,\n",
        "                        \"enable_landmark\": current_run_enable_landmark, \"image_width\": w_llm_no_yolo, \"image_height\": h_llm_no_yolo,\n",
        "                        \"prominent_objects_detail\": \"the overall visual context\"\n",
        "                    }\n",
        "                    enhanced_desc_llm_no_yolo = self.llm_enhancer.enhance_description(scene_data_llm_no_yolo_enhance) if hasattr(self, 'llm_enhancer') else desc_llm_no_yolo\n",
        "                    if hasattr(self, 'llm_enhancer') and hasattr(self.llm_enhancer, 'handle_no_detection') and (not enhanced_desc_llm_no_yolo or len(enhanced_desc_llm_no_yolo.strip()) < 20):\n",
        "                        enhanced_desc_llm_no_yolo = self.llm_enhancer.handle_no_detection(clip_analysis_val_no_yolo)\n",
        "\n",
        "                    return {\n",
        "                        \"scene_type\": scene_type_llm_no_yolo, \"confidence\": round(float(confidence_llm_no_yolo),4),\n",
        "                        \"description\": desc_llm_no_yolo, \"enhanced_description\": enhanced_desc_llm_no_yolo,\n",
        "                        \"objects_present\": [], \"object_count\": 0, \"regions\": {}, \"possible_activities\": [],\n",
        "                        \"safety_concerns\": [], \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in LLM/CLIP no-detection fallback (analyze method): {e}\")\n",
        "\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\", \"confidence\": 0.0,\n",
        "                \"description\": \"No objects were detected in the image, and contextual analysis could not be performed or failed.\",\n",
        "                \"objects_present\": [], \"object_count\": 0, \"regions\": {}, \"possible_activities\": [],\n",
        "                \"safety_concerns\": [], \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "        # Main processing flow if YOLO detections are present\n",
        "        if self.class_names is None and hasattr(detection_result, 'names'):\n",
        "            self.class_names = detection_result.names\n",
        "            if hasattr(self.spatial_analyzer, 'class_names'):\n",
        "                self.spatial_analyzer.class_names = self.class_names\n",
        "\n",
        "        detected_objects_main = self.spatial_analyzer._extract_detected_objects(\n",
        "            detection_result,\n",
        "            confidence_threshold=class_confidence_threshold\n",
        "        )\n",
        "\n",
        "        if not detected_objects_main:\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\", \"confidence\": 0.0,\n",
        "                \"description\": \"No objects detected with sufficient confidence by the primary vision system.\",\n",
        "                \"objects_present\": [], \"object_count\": 0, \"regions\": {}, \"possible_activities\": [],\n",
        "                \"safety_concerns\": [], \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "        # Spatial analysis done once on YOLO objects\n",
        "        region_analysis_val = self.spatial_analyzer._analyze_regions(detected_objects_main)\n",
        "\n",
        "        final_functional_zones = {}\n",
        "        final_activities = []\n",
        "        final_landmark_info = {}\n",
        "\n",
        "        tentative_best_scene = \"unknown\"\n",
        "        tentative_scene_confidence = 0.0\n",
        "\n",
        "        # Landmark Processing and Integration\n",
        "        landmark_objects_identified_clip = []\n",
        "        landmark_specific_activities = [] # NEW\n",
        "        if self.use_clip and current_run_enable_landmark and hasattr(self, 'process_unknown_objects') and hasattr(self, 'landmark_classifier'):\n",
        "\n",
        "            detected_objects_main_after_lm, landmark_objects_identified_clip = self.process_unknown_objects(\n",
        "                detection_result,\n",
        "                detected_objects_main\n",
        "            )\n",
        "            detected_objects_main = detected_objects_main_after_lm # Update main list\n",
        "\n",
        "            if landmark_objects_identified_clip:\n",
        "                primary_landmark_clip = max(landmark_objects_identified_clip, key=lambda x: x.get(\"confidence\", 0.0), default=None)\n",
        "                if primary_landmark_clip and primary_landmark_clip.get(\"confidence\", 0.0) > 0.35:\n",
        "                    lm_type_raw = \"architectural\" # Default\n",
        "                    if hasattr(self.landmark_classifier, '_determine_landmark_type') and primary_landmark_clip.get(\"landmark_id\"):\n",
        "                        lm_type_raw = self.landmark_classifier._determine_landmark_type(primary_landmark_clip.get(\"landmark_id\"))\n",
        "                    else:\n",
        "                         lm_type_raw = primary_landmark_clip.get(\"landmark_type\", \"architectural\")\n",
        "\n",
        "\n",
        "                    if lm_type_raw == \"natural\": tentative_best_scene = \"natural_landmark\"\n",
        "                    elif lm_type_raw == \"monument\": tentative_best_scene = \"historical_monument\"\n",
        "                    else: tentative_best_scene = \"tourist_landmark\"\n",
        "                    tentative_scene_confidence = primary_landmark_clip.get(\"confidence\", 0.0)\n",
        "\n",
        "                final_landmark_info = {\n",
        "                    \"detected_landmarks\": landmark_objects_identified_clip,\n",
        "                    \"primary_landmark\": primary_landmark_clip,\n",
        "                    \"detailed_landmarks\": landmark_objects_identified_clip\n",
        "                }\n",
        "\n",
        "                # 專門儲存地標特定活動的列表\n",
        "                landmark_specific_activities = []\n",
        "\n",
        "                # 優先收集來自識別地標的特定活動\n",
        "                for lm_obj in landmark_objects_identified_clip:\n",
        "                    lm_id = lm_obj.get(\"landmark_id\")\n",
        "                    if lm_id and lm_id in self.LANDMARK_ACTIVITIES:\n",
        "                        landmark_specific_activities.extend(self.LANDMARK_ACTIVITIES[lm_id])\n",
        "\n",
        "                # 將特定地標活動加入最終活動列表\n",
        "                if landmark_specific_activities:\n",
        "                    final_activities.extend(landmark_specific_activities)\n",
        "                    print(f\"Added {len(landmark_specific_activities)} landmark-specific activities for {', '.join([lm.get('landmark_name', 'unknown') for lm in landmark_objects_identified_clip if lm.get('is_landmark', False)])}\")\n",
        "\n",
        "                if hasattr(self.spatial_analyzer, '_identify_landmark_zones'):\n",
        "                    final_functional_zones.update(self.spatial_analyzer._identify_landmark_zones(landmark_objects_identified_clip))\n",
        "\n",
        "        if not current_run_enable_landmark:\n",
        "            detected_objects_main = [obj for obj in detected_objects_main if not obj.get(\"is_landmark\", False)]\n",
        "            final_landmark_info = {}\n",
        "\n",
        "        # --- Compute YOLO-based scene scores ---\n",
        "        # MODIFIED: Pass region_analysis_val as spatial_analysis_results\n",
        "        yolo_scene_scores_val = self._compute_scene_scores(detected_objects_main,\n",
        "                                                         spatial_analysis_results=region_analysis_val)\n",
        "\n",
        "        # --- CLIP Analysis for general scene scores ---\n",
        "        clip_scene_scores_val = {}\n",
        "        clip_analysis_results = None # To store the full dict from clip_analyzer\n",
        "        if self.use_clip and original_image_pil is not None:\n",
        "            try:\n",
        "                clip_analysis_results = self.clip_analyzer.analyze_image(\n",
        "                    original_image_pil,\n",
        "                    enable_landmark=current_run_enable_landmark,\n",
        "                    exclude_categories=[\"landmark\", \"tourist\", \"monument\", \"tower\", \"attraction\", \"scenic\", \"historical\", \"famous\"] if not current_run_enable_landmark else None\n",
        "                )\n",
        "                if isinstance(clip_analysis_results, dict): # Ensure it's a dict before get\n",
        "                    clip_scene_scores_val = clip_analysis_results.get(\"scene_scores\", {})\n",
        "                    # Filter again if landmarks are disabled\n",
        "                    if not current_run_enable_landmark:\n",
        "                        clip_scene_scores_val = {k: v for k, v in clip_scene_scores_val.items() if not any(kw in k.lower() for kw in [\"landmark\", \"monument\", \"tourist\"])}\n",
        "                        if \"cultural_analysis\" in clip_analysis_results: del clip_analysis_results[\"cultural_analysis\"]\n",
        "                        if \"top_scene\" in clip_analysis_results and any(term in clip_analysis_results.get(\"top_scene\",[\"unknown\",0.0])[0].lower() for term in [\"landmark\", \"monument\", \"tourist\"]):\n",
        "                            non_lm_cs = sorted([item for item in clip_scene_scores_val.items() if item[1] > 0], key=lambda x:x[1], reverse=True)\n",
        "                            clip_analysis_results[\"top_scene\"] = non_lm_cs[0] if non_lm_cs else (\"unknown\", 0.0)\n",
        "\n",
        "                    # (Keep your asian_commercial_street special handling here if needed)\n",
        "                    if not lighting_info and \"lighting_condition\" in clip_analysis_results: # If main lighting_info is still None\n",
        "                        lt, lc = clip_analysis_results.get(\"lighting_condition\", (\"unknown\", 0.0))\n",
        "                        lighting_info = {\"time_of_day\": lt, \"confidence\": lc, \"source\": \"CLIP_fallback\"}\n",
        "            except Exception as e:\n",
        "                print(f\"Error in main CLIP analysis for YOLO path (analyze method): {e}\")\n",
        "\n",
        "        # Calculate stats for _fuse_scene_scores (based on non-landmark YOLO objects)\n",
        "        yolo_only_objects_for_fuse_stats = [obj for obj in detected_objects_main if not obj.get(\"is_landmark\")]\n",
        "        num_yolo_detections_for_fuse = len(yolo_only_objects_for_fuse_stats)\n",
        "        avg_yolo_confidence_for_fuse = sum(obj.get('confidence', 0.0) for obj in yolo_only_objects_for_fuse_stats) / num_yolo_detections_for_fuse if num_yolo_detections_for_fuse > 0 else 0.0\n",
        "\n",
        "        print(f\"DEBUG: About to call _fuse_scene_scores with lighting_info: {lighting_info}\")\n",
        "        print(f\"DEBUG: Places365_info being passed to fuse: {places365_info}\")\n",
        "\n",
        "        scene_scores_fused = self._fuse_scene_scores(\n",
        "            yolo_scene_scores_val, clip_scene_scores_val,\n",
        "            num_yolo_detections=num_yolo_detections_for_fuse,\n",
        "            avg_yolo_confidence=avg_yolo_confidence_for_fuse,\n",
        "            lighting_info=lighting_info,\n",
        "            places365_info=places365_info\n",
        "        )\n",
        "\n",
        "        # Respect tentative scene from strong landmark detection during fusion adjustment\n",
        "        if tentative_best_scene != \"unknown\" and \"landmark\" in tentative_best_scene.lower() and tentative_scene_confidence > 0.5:\n",
        "             scene_scores_fused[tentative_best_scene] = max(scene_scores_fused.get(tentative_best_scene, 0.0), tentative_scene_confidence * 0.95)\n",
        "\n",
        "        # Final determination of scene type\n",
        "        final_best_scene, final_scene_confidence = self._determine_scene_type(scene_scores_fused)\n",
        "\n",
        "        if not current_run_enable_landmark and final_best_scene in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "            if hasattr(self, '_get_alternative_scene_type'):\n",
        "                alt_scene_type = self._get_alternative_scene_type(final_best_scene, detected_objects_main, scene_scores_fused)\n",
        "                final_best_scene = alt_scene_type\n",
        "                final_scene_confidence = scene_scores_fused.get(alt_scene_type, 0.6)\n",
        "            else:\n",
        "                final_best_scene = \"generic_street_view\"; final_scene_confidence = min(final_scene_confidence, 0.65)\n",
        "\n",
        "        # Generate final descriptive content (Activities, Safety, Zones)\n",
        "        # 如果有特定地標活動，限制通用活動的數量\n",
        "        generic_activities = []\n",
        "        if hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "            generic_activities = self.descriptor._infer_possible_activities(\n",
        "                final_best_scene, detected_objects_main,\n",
        "                enable_landmark=current_run_enable_landmark, scene_scores=scene_scores_fused\n",
        "            )\n",
        "\n",
        "        # 優先處理策略：使用特定地標活動，不足時才從通用活動補充\n",
        "        if landmark_specific_activities:\n",
        "            # 如果有特定活動，優先保留，去除與特定活動重複的通用活動\n",
        "            unique_generic_activities = [act for act in generic_activities if act not in landmark_specific_activities]\n",
        "\n",
        "            # 如果特定活動少於3個，從通用活動中補充\n",
        "            if len(landmark_specific_activities) < 3:\n",
        "                # 補充通用活動但總數不超過7個\n",
        "                supplement_count = min(3 - len(landmark_specific_activities), len(unique_generic_activities))\n",
        "                if supplement_count > 0:\n",
        "                    final_activities.extend(unique_generic_activities[:supplement_count])\n",
        "        else:\n",
        "            # 若無特定活動，則使用所有通用活動\n",
        "            final_activities.extend(generic_activities)\n",
        "\n",
        "        # 去重並排序，但確保特定地標活動保持在前面\n",
        "        final_activities_set = set(final_activities)\n",
        "        final_activities = []\n",
        "\n",
        "        # 先加入特定地標活動（按原順序）\n",
        "        for activity in landmark_specific_activities:\n",
        "            if activity in final_activities_set:\n",
        "                final_activities.append(activity)\n",
        "                final_activities_set.remove(activity)\n",
        "\n",
        "        # 再加入通用活動（按字母排序）\n",
        "        final_activities.extend(sorted(list(final_activities_set)))\n",
        "\n",
        "        final_safety_concerns = self.descriptor._identify_safety_concerns(detected_objects_main, final_best_scene) if hasattr(self.descriptor, '_identify_safety_concerns') else []\n",
        "\n",
        "        if hasattr(self.spatial_analyzer, '_identify_functional_zones'): # Update functional_zones\n",
        "            general_zones = self.spatial_analyzer._identify_functional_zones(detected_objects_main, final_best_scene)\n",
        "            for gz_key, gz_val in general_zones.items():\n",
        "                if gz_key not in final_functional_zones: final_functional_zones[gz_key] = gz_val\n",
        "\n",
        "        # Filter again if landmarks disabled for this run\n",
        "        if not current_run_enable_landmark:\n",
        "            final_functional_zones = {k: v for k, v in final_functional_zones.items() if not any(kw in k.lower() for kw in [\"landmark\", \"monument\", \"viewing\", \"tourist\"])}\n",
        "            current_activities_temp = [act for act in final_activities if not any(kw in act.lower() for kw in [\"sightsee\", \"photograph\", \"tour\", \"histor\", \"landmark\", \"monument\", \"cultur\"])]\n",
        "            final_activities = current_activities_temp\n",
        "            if not final_activities and hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "                 final_activities = self.descriptor._infer_possible_activities(\"generic_street_view\", detected_objects_main, enable_landmark=False)\n",
        "\n",
        "        # 創建淨化的光線資訊，避免不合理的時間描述\n",
        "        lighting_info_clean = None\n",
        "        if lighting_info:\n",
        "            lighting_info_clean = {\n",
        "                \"is_indoor\": lighting_info.get(\"is_indoor\"),\n",
        "                \"confidence\": lighting_info.get(\"confidence\", 0.0),\n",
        "                \"time_of_day\": lighting_info.get(\"time_of_day\", \"unknown\")  # 加入這行\n",
        "            }\n",
        "            # 如果 Places365 提供高信心度判斷，就用它的結果\n",
        "            if places365_info and places365_info.get('confidence', 0) >= 0.8:\n",
        "                lighting_info_clean[\"is_indoor\"] = places365_info.get('is_indoor')\n",
        "                lighting_info_clean[\"confidence\"] = places365_info.get('confidence')\n",
        "\n",
        "        base_scene_description = self.generate_scene_description(\n",
        "            scene_type=final_best_scene,\n",
        "            detected_objects=detected_objects_main,\n",
        "            confidence=final_scene_confidence,\n",
        "            lighting_info=lighting_info_clean,\n",
        "            functional_zones=final_functional_zones,\n",
        "            enable_landmark=current_run_enable_landmark,\n",
        "            scene_scores=scene_scores_fused,\n",
        "            spatial_analysis=region_analysis_val,\n",
        "            image_dimensions=image_dims_val\n",
        "        )\n",
        "\n",
        "        if not current_run_enable_landmark and hasattr(self, '_remove_landmark_references'):\n",
        "            base_scene_description = self._remove_landmark_references(base_scene_description)\n",
        "\n",
        "        # --- LLM Enhancement ---\n",
        "        enhanced_final_description = base_scene_description\n",
        "        llm_verification_output = None\n",
        "        if self.use_llm and hasattr(self, 'llm_enhancer'):\n",
        "            try:\n",
        "                obj_list_for_llm = \", \".join(sorted(list(set(\n",
        "                    obj[\"class_name\"] for obj in detected_objects_main\n",
        "                    if obj.get(\"confidence\", 0) > 0.4 and not obj.get(\"is_landmark\")\n",
        "                ))))\n",
        "                if not obj_list_for_llm and current_run_enable_landmark and final_landmark_info.get(\"primary_landmark\"):\n",
        "                    obj_list_for_llm = final_landmark_info[\"primary_landmark\"].get(\"class_name\", \"a prominent feature\")\n",
        "                elif not obj_list_for_llm: obj_list_for_llm = \"various visual elements\"\n",
        "\n",
        "                # 生成物體統計信息\n",
        "                object_statistics = {}\n",
        "                for obj in detected_objects_main:\n",
        "                    class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                    if class_name not in object_statistics:\n",
        "                        object_statistics[class_name] = {\n",
        "                            \"count\": 0,\n",
        "                            \"avg_confidence\": 0.0,\n",
        "                            \"max_confidence\": 0.0,\n",
        "                            \"instances\": []\n",
        "                        }\n",
        "\n",
        "                    stats = object_statistics[class_name]\n",
        "                    stats[\"count\"] += 1\n",
        "                    stats[\"instances\"].append(obj)\n",
        "                    stats[\"max_confidence\"] = max(stats[\"max_confidence\"], obj.get(\"confidence\", 0.0))\n",
        "\n",
        "                # 計算平均信心度\n",
        "                for class_name, stats in object_statistics.items():\n",
        "                    if stats[\"count\"] > 0:\n",
        "                        total_conf = sum(inst.get(\"confidence\", 0.0) for inst in stats[\"instances\"])\n",
        "                        stats[\"avg_confidence\"] = total_conf / stats[\"count\"]\n",
        "\n",
        "                llm_scene_data = {\n",
        "                    \"original_description\": base_scene_description, \"scene_type\": final_best_scene,\n",
        "                    \"scene_name\": self.SCENE_TYPES.get(final_best_scene, {}).get(\"name\", \"Unknown Scene\"),\n",
        "                    \"detected_objects\": detected_objects_main, \"object_list\": obj_list_for_llm,\n",
        "                    \"object_statistics\": object_statistics,  # 新增統計信息\n",
        "                    \"confidence\": final_scene_confidence, \"lighting_info\": lighting_info,\n",
        "                    \"functional_zones\": final_functional_zones, \"activities\": final_activities,\n",
        "                    \"safety_concerns\": final_safety_concerns,\n",
        "                    \"clip_analysis\": clip_analysis_results if isinstance(clip_analysis_results, dict) else None,\n",
        "                    \"enable_landmark\": current_run_enable_landmark,\n",
        "                    \"image_width\": image_dims_val[0] if image_dims_val else None,\n",
        "                    \"image_height\": image_dims_val[1] if image_dims_val else None,\n",
        "                    \"prominent_objects_detail\": self.scene_describer._format_object_list_for_description(\n",
        "                        self.scene_describer._get_prominent_objects(detected_objects_main, min_prominence_score=0.1, max_categories_to_return=3, max_total_objects=7)\n",
        "                    ) if hasattr(self.scene_describer, '_get_prominent_objects') and hasattr(self.scene_describer, '_format_object_list_for_description') else \"\"\n",
        "                }\n",
        "                if current_run_enable_landmark and final_landmark_info.get(\"primary_landmark\"):\n",
        "                    llm_scene_data[\"primary_landmark_info\"] = final_landmark_info[\"primary_landmark\"]\n",
        "\n",
        "                if self.use_clip and clip_analysis_results and isinstance(clip_analysis_results, dict) and \"top_scene\" in clip_analysis_results:\n",
        "                    clip_top_name = clip_analysis_results.get(\"top_scene\",[\"unknown\",0.0])[0]\n",
        "                    clip_top_conf = clip_analysis_results.get(\"top_scene\",[\"unknown\",0.0])[1]\n",
        "                    if clip_top_name != final_best_scene and clip_top_conf > 0.4 and final_scene_confidence > 0.4 and hasattr(self.llm_enhancer, 'verify_detection'):\n",
        "                        llm_verification_output = self.llm_enhancer.verify_detection(\n",
        "                            detected_objects_main, clip_analysis_results, final_best_scene,\n",
        "                            self.SCENE_TYPES.get(final_best_scene, {}).get(\"name\", \"Unknown\"), final_scene_confidence\n",
        "                        )\n",
        "                        if llm_verification_output : llm_scene_data[\"verification_result\"] = llm_verification_output.get(\"verification_text\", \"\")\n",
        "\n",
        "                enhanced_final_description = self.llm_enhancer.enhance_description(llm_scene_data)\n",
        "                if not current_run_enable_landmark and hasattr(self, '_remove_landmark_references'):\n",
        "                     enhanced_final_description = self._remove_landmark_references(enhanced_final_description)\n",
        "            except Exception as e:\n",
        "                print(f\"Error in LLM Enhancement in main flow (analyze method): {e}\")\n",
        "\n",
        "        # Construct final output dictionary\n",
        "        output_result = {\n",
        "            \"scene_type\": final_best_scene if final_scene_confidence >= scene_confidence_threshold else \"unknown\",\n",
        "            \"scene_name\": self.SCENE_TYPES.get(final_best_scene, {}).get(\"name\", \"Unknown Scene\") if final_scene_confidence >= scene_confidence_threshold else \"Unknown Scene\",\n",
        "            \"confidence\": round(float(final_scene_confidence), 4),\n",
        "            \"description\": base_scene_description,\n",
        "            \"enhanced_description\": enhanced_final_description,\n",
        "            \"objects_present\": [{\"class_id\": obj.get(\"class_id\", -1), \"class_name\": obj.get(\"class_name\", \"unknown\"), \"confidence\": round(float(obj.get(\"confidence\",0.0)), 4)} for obj in detected_objects_main],\n",
        "            \"object_count\": len(detected_objects_main),\n",
        "            \"regions\": region_analysis_val,\n",
        "            \"possible_activities\": final_activities,\n",
        "            \"safety_concerns\": final_safety_concerns,\n",
        "            \"functional_zones\": final_functional_zones,\n",
        "            \"alternative_scenes\": self.descriptor._get_alternative_scenes(scene_scores_fused, scene_confidence_threshold, top_k=2) if hasattr(self.descriptor, '_get_alternative_scenes') else [],\n",
        "            \"lighting_conditions\": lighting_info if lighting_info else {\"time_of_day\": \"unknown\", \"confidence\": 0.0, \"source\": \"default\"}\n",
        "        }\n",
        "\n",
        "        if current_run_enable_landmark and final_landmark_info and final_landmark_info.get(\"detected_landmarks\"):\n",
        "            output_result.update(final_landmark_info)\n",
        "            if final_best_scene in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                output_result[\"scene_source\"] = \"landmark_detection\"\n",
        "        elif not current_run_enable_landmark:\n",
        "             for key_rm in [\"detected_landmarks\", \"primary_landmark\", \"detailed_landmarks\", \"scene_source\"]:\n",
        "                if key_rm in output_result: del output_result[key_rm]\n",
        "\n",
        "        if llm_verification_output:\n",
        "            output_result[\"llm_verification\"] = llm_verification_output.get(\"verification_text\")\n",
        "            if llm_verification_output.get(\"has_errors\", False):\n",
        "                output_result[\"detection_warnings\"] = \"LLM detected potential issues with object recognition.\"\n",
        "\n",
        "        if clip_analysis_results and isinstance(clip_analysis_results, dict) and \"error\" not in clip_analysis_results:\n",
        "            top_scene_clip = clip_analysis_results.get(\"top_scene\", (\"unknown\", 0.0))\n",
        "            output_result[\"clip_analysis\"] = {\n",
        "                \"top_scene\": (top_scene_clip[0], round(float(top_scene_clip[1]), 4)),\n",
        "                \"cultural_analysis\": clip_analysis_results.get(\"cultural_analysis\", {}) if current_run_enable_landmark else {}\n",
        "            }\n",
        "\n",
        "        return output_result\n",
        "\n",
        "\n",
        "    def _get_object_spatial_cohesion_score(self, objects_for_scene: List[Dict], spatial_analysis_results: Optional[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        (This is a NEW helper function)\n",
        "        Calculates a score based on how spatially cohesive the key objects for a scene are.\n",
        "        A higher score means objects are more clustered in fewer regions.\n",
        "        This is a heuristic and can be refined.\n",
        "\n",
        "        Args:\n",
        "            objects_for_scene: List of detected objects (dictionaries with at least 'class_id')\n",
        "                               relevant to the current scene type being evaluated.\n",
        "            spatial_analysis_results: Output from SpatialAnalyzer._analyze_regions.\n",
        "                                      Expected format: {'objects_by_region': {'region_name': [{'class_id': id, ...}, ...]}}\n",
        "\n",
        "        Returns:\n",
        "            float: A cohesion score, typically a small bonus (e.g., 0.0 to 0.1).\n",
        "        \"\"\"\n",
        "        if not objects_for_scene or not spatial_analysis_results or \\\n",
        "           \"objects_by_region\" not in spatial_analysis_results or \\\n",
        "           not spatial_analysis_results[\"objects_by_region\"]:\n",
        "            return 0.0\n",
        "\n",
        "        # Get the set of class_ids for the key objects defining the current scene type\n",
        "        key_object_class_ids = {obj.get('class_id') for obj in objects_for_scene if obj.get('class_id') is not None}\n",
        "        if not key_object_class_ids:\n",
        "            return 0.0\n",
        "\n",
        "        # Find in which regions these key objects appear\n",
        "        regions_containing_key_objects = set()\n",
        "        # Count how many of the *instances* of key objects are found\n",
        "        # This helps differentiate a scene with 1 chair in 1 region vs 5 chairs spread over 5 regions\n",
        "        total_key_object_instances_found = 0\n",
        "\n",
        "        for region_name, objects_in_region_list in spatial_analysis_results[\"objects_by_region\"].items():\n",
        "            region_has_key_object = False\n",
        "            for obj_in_region in objects_in_region_list:\n",
        "                if obj_in_region.get('class_id') in key_object_class_ids:\n",
        "                    region_has_key_object = True\n",
        "                    total_key_object_instances_found += 1 # Count each instance\n",
        "            if region_has_key_object:\n",
        "                regions_containing_key_objects.add(region_name)\n",
        "\n",
        "        num_distinct_key_objects_in_scene = len(key_object_class_ids) # Number of *types* of key objects\n",
        "        num_instances_of_key_objects_passed = len(objects_for_scene) # Number of *instances* passed for this scene\n",
        "\n",
        "        if not regions_containing_key_objects or num_instances_of_key_objects_passed == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # A simple heuristic:\n",
        "        if len(regions_containing_key_objects) == 1 and total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.75:\n",
        "            return 0.10  # Strongest cohesion: most/all key object instances in a single region\n",
        "        elif len(regions_containing_key_objects) <= 2 and total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.60:\n",
        "            return 0.05  # Moderate cohesion: most/all key object instances in up to two regions\n",
        "        elif len(regions_containing_key_objects) <= 3 and total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.50:\n",
        "            return 0.02  # Weaker cohesion\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "    def _compute_scene_scores(self, detected_objects: List[Dict], spatial_analysis_results: Optional[Dict] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute confidence scores for each scene type based on detected objects.\n",
        "        Enhanced to better score everyday scenes and consider object richness and spatial cohesion.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects with their details (class_id, confidence, region, etc.).\n",
        "            spatial_analysis_results: Optional output from SpatialAnalyzer, specifically 'objects_by_region',\n",
        "                                      which is used by _get_object_spatial_cohesion_score.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping scene types to confidence scores.\n",
        "        \"\"\"\n",
        "        scene_scores = {}\n",
        "        if not detected_objects:\n",
        "            for scene_type_key in self.SCENE_TYPES:\n",
        "                scene_scores[scene_type_key] = 0.0\n",
        "            return scene_scores\n",
        "\n",
        "        # Prepare data from detected_objects\n",
        "        detected_class_ids_all = [obj[\"class_id\"] for obj in detected_objects]\n",
        "        detected_classes_set_all = set(detected_class_ids_all)\n",
        "        class_counts_all = {}\n",
        "        for obj in detected_objects:\n",
        "            class_id = obj[\"class_id\"]\n",
        "            class_counts_all[class_id] = class_counts_all.get(class_id, 0) + 1\n",
        "\n",
        "        # Evaluate each scene type defined in self.SCENE_TYPES\n",
        "        for scene_type, scene_def in self.SCENE_TYPES.items():\n",
        "            required_obj_ids_defined = set(scene_def.get(\"required_objects\", []))\n",
        "            optional_obj_ids_defined = set(scene_def.get(\"optional_objects\", []))\n",
        "            min_required_matches_needed = scene_def.get(\"minimum_required\", 0)\n",
        "\n",
        "            # Determine which actual detected objects are relevant for this scene_type\n",
        "            # These lists will store the actual detected object dicts, not just class_ids\n",
        "            actual_required_objects_found_list = []\n",
        "            for req_id in required_obj_ids_defined:\n",
        "                if req_id in detected_classes_set_all:\n",
        "                    # Find first instance of this required object to add to list (for cohesion check later)\n",
        "                    for dobj in detected_objects:\n",
        "                        if dobj['class_id'] == req_id:\n",
        "                            actual_required_objects_found_list.append(dobj)\n",
        "                            break\n",
        "\n",
        "            num_required_matches_found = len(actual_required_objects_found_list)\n",
        "\n",
        "            actual_optional_objects_found_list = []\n",
        "            for opt_id in optional_obj_ids_defined:\n",
        "                if opt_id in detected_classes_set_all:\n",
        "                    for dobj in detected_objects:\n",
        "                        if dobj['class_id'] == opt_id:\n",
        "                            actual_optional_objects_found_list.append(dobj)\n",
        "                            break\n",
        "\n",
        "            num_optional_matches_found = len(actual_optional_objects_found_list)\n",
        "\n",
        "            # --- Initial Score Calculation Weights ---\n",
        "            # Base score: 55% from required, 25% from optional, 10% richness, 10% cohesion (max)\n",
        "            required_weight = 0.55\n",
        "            optional_weight = 0.25\n",
        "            richness_bonus_max = 0.10\n",
        "            cohesion_bonus_max = 0.10 # Max bonus from _get_object_spatial_cohesion_score is 0.1\n",
        "\n",
        "            current_scene_score = 0.0\n",
        "            objects_to_check_for_cohesion = [] # For spatial cohesion scoring\n",
        "\n",
        "            # --- Check minimum_required condition & Calculate base score ---\n",
        "            if num_required_matches_found >= min_required_matches_needed:\n",
        "                if len(required_obj_ids_defined) > 0:\n",
        "                    required_ratio = num_required_matches_found / len(required_obj_ids_defined)\n",
        "                else: # No required objects defined, but min_required_matches_needed could be 0\n",
        "                    required_ratio = 1.0 if min_required_matches_needed == 0 else 0.0\n",
        "\n",
        "                current_scene_score = required_ratio * required_weight\n",
        "                objects_to_check_for_cohesion.extend(actual_required_objects_found_list)\n",
        "\n",
        "                # Add score from optional objects\n",
        "                if len(optional_obj_ids_defined) > 0:\n",
        "                    optional_ratio = num_optional_matches_found / len(optional_obj_ids_defined)\n",
        "                    current_scene_score += optional_ratio * optional_weight\n",
        "                objects_to_check_for_cohesion.extend(actual_optional_objects_found_list)\n",
        "\n",
        "            # Flexible handling for \"everyday scenes\" if strict minimum_required (based on 'required_objects') isn't met\n",
        "            elif scene_type in self.EVERYDAY_SCENE_TYPE_KEYS:\n",
        "                # If an everyday scene has many optional items, it might still be a weak candidate\n",
        "                # Check if a decent proportion of its 'optional_objects' are present\n",
        "                if len(optional_obj_ids_defined) > 0 and \\\n",
        "                   (num_optional_matches_found / len(optional_obj_ids_defined)) >= 0.25: # e.g., at least 25% of typical optional items\n",
        "                    # Base score more on optional fulfillment for these types\n",
        "                    current_scene_score = (num_optional_matches_found / len(optional_obj_ids_defined)) * (required_weight + optional_weight * 0.5) # Give some base\n",
        "                    objects_to_check_for_cohesion.extend(actual_optional_objects_found_list)\n",
        "                else:\n",
        "                    scene_scores[scene_type] = 0.0\n",
        "                    continue # Skip this scene type\n",
        "            else: # For non-everyday scenes, if minimum_required is not met, score is 0\n",
        "                scene_scores[scene_type] = 0.0\n",
        "                continue\n",
        "\n",
        "            # --- Bonus for object richness/variety ---\n",
        "            # Considers unique object *classes* found that are relevant to the scene definition\n",
        "            relevant_defined_class_ids = required_obj_ids_defined.union(optional_obj_ids_defined)\n",
        "            unique_relevant_detected_classes = relevant_defined_class_ids.intersection(detected_classes_set_all)\n",
        "\n",
        "            object_richness_score = 0.0\n",
        "            if len(relevant_defined_class_ids) > 0:\n",
        "                richness_ratio = len(unique_relevant_detected_classes) / len(relevant_defined_class_ids)\n",
        "                object_richness_score = min(richness_bonus_max, richness_ratio * 0.15) # Max 10% bonus from richness\n",
        "            current_scene_score += object_richness_score\n",
        "\n",
        "            # --- Bonus for spatial cohesion (if spatial_analysis_results are provided) ---\n",
        "            spatial_cohesion_bonus = 0.0\n",
        "            if spatial_analysis_results and objects_to_check_for_cohesion:\n",
        "                # Deduplicate objects_to_check_for_cohesion based on actual object instances (not just class_id)\n",
        "                # This can be done by converting list of dicts to list of tuples of items for hashing\n",
        "                # However, assuming _get_object_spatial_cohesion_score handles instances correctly.\n",
        "                # If objects_to_check_for_cohesion might have duplicate dict references for the SAME object,\n",
        "                # then a more robust deduplication on actual object references would be needed if not already handled.\n",
        "                # For now, assume it's a list of unique object *instances* found relevant to the scene.\n",
        "                spatial_cohesion_bonus = self._get_object_spatial_cohesion_score(\n",
        "                    objects_to_check_for_cohesion, # Pass the list of actual detected object dicts\n",
        "                    spatial_analysis_results\n",
        "                )\n",
        "            current_scene_score += spatial_cohesion_bonus # Max 0.1 from this bonus\n",
        "\n",
        "            # --- Bonus for multiple instances of key objects (original logic refined) ---\n",
        "            multiple_instance_bonus = 0.0\n",
        "            # For multiple instance bonus, focus on objects central to the scene's definition\n",
        "            key_objects_for_multi_instance_check = required_obj_ids_defined\n",
        "            if scene_type in self.EVERYDAY_SCENE_TYPE_KEYS and len(optional_obj_ids_defined) > 0:\n",
        "                # For everyday scenes, some optionals can also be key if they appear multiple times\n",
        "                # e.g., multiple chairs in a \"general_indoor_space\"\n",
        "                key_objects_for_multi_instance_check = key_objects_for_multi_instance_check.union(\n",
        "                    set(list(optional_obj_ids_defined)[:max(1, len(optional_obj_ids_defined)//2)]) # consider first half of optionals\n",
        "                )\n",
        "\n",
        "            for class_id_check in key_objects_for_multi_instance_check:\n",
        "                if class_id_check in detected_classes_set_all and class_counts_all.get(class_id_check, 0) > 1:\n",
        "                    multiple_instance_bonus += 0.025 # Slightly smaller bonus per type\n",
        "            current_scene_score += min(0.075, multiple_instance_bonus) # Max 7.5% bonus\n",
        "\n",
        "            # Apply scene-specific priority defined in SCENE_TYPES\n",
        "            if \"priority\" in scene_def:\n",
        "                current_scene_score *= scene_def[\"priority\"]\n",
        "\n",
        "            scene_scores[scene_type] = min(1.0, max(0.0, current_scene_score))\n",
        "\n",
        "        # If landmark detection is disabled via the instance attribute self.enable_landmark,\n",
        "        # ensure scores for landmark-specific scene types are zeroed out.\n",
        "        if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "            landmark_scene_types = [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]\n",
        "            for lm_scene_type in landmark_scene_types:\n",
        "                if lm_scene_type in scene_scores:\n",
        "                    scene_scores[lm_scene_type] = 0.0\n",
        "\n",
        "        return scene_scores\n",
        "\n",
        "    def _determine_scene_type(self, scene_scores: Dict[str, float]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        Determine the most likely scene type based on scores.\n",
        "        Args:\n",
        "            scene_scores: Dictionary mapping scene types to confidence scores\n",
        "        Returns:\n",
        "            Tuple of (best_scene_type, confidence)\n",
        "        \"\"\"\n",
        "        if not scene_scores:\n",
        "            return \"unknown\", 0.0\n",
        "\n",
        "        best_scene = max(scene_scores, key=scene_scores.get)\n",
        "        best_score = scene_scores[best_scene]\n",
        "        return best_scene, float(best_score)\n",
        "\n",
        "\n",
        "    def _fuse_scene_scores(self,\n",
        "                       yolo_scene_scores: Dict[str, float],\n",
        "                       clip_scene_scores: Dict[str, float],\n",
        "                       num_yolo_detections: int = 0,\n",
        "                       avg_yolo_confidence: float = 0.0,\n",
        "                       lighting_info: Optional[Dict] = None,\n",
        "                       places365_info: Optional[Dict] = None\n",
        "                      ) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Fuse scene scores from YOLO-based object detection, CLIP-based analysis, and Places365 scene classification.\n",
        "        Adjusts weights based on scene type, richness of YOLO detections, lighting information, and Places365 confidence.\n",
        "\n",
        "        Args:\n",
        "            yolo_scene_scores: Scene scores based on YOLO object detection.\n",
        "            clip_scene_scores: Scene scores based on CLIP analysis.\n",
        "            num_yolo_detections: Total number of non-landmark objects detected by YOLO with sufficient confidence.\n",
        "            avg_yolo_confidence: Average confidence of non-landmark objects detected by YOLO.\n",
        "            lighting_info: Optional lighting condition analysis results,\n",
        "                        expected to contain 'is_indoor' (bool) and 'confidence' (float).\n",
        "            places365_info: Optional Places365 scene classification results,\n",
        "                            expected to contain 'mapped_scene_type', 'confidence', and 'is_indoor'.\n",
        "\n",
        "        Returns:\n",
        "            Dict: Fused scene scores incorporating all three analysis sources.\n",
        "        \"\"\"\n",
        "        # Handle cases where one of the score dictionaries might be empty or all scores are effectively zero\n",
        "        # Extract and process Places365 scene scores\n",
        "        places365_scene_scores_map = {} # 修改變數名稱以避免與傳入的字典衝突\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.1:\n",
        "            mapped_scene_type = places365_info.get('mapped_scene_type', 'unknown')\n",
        "            places365_confidence = places365_info.get('confidence', 0.0)\n",
        "\n",
        "            if mapped_scene_type in self.SCENE_TYPES.keys():\n",
        "                places365_scene_scores_map[mapped_scene_type] = places365_confidence # 使用新的字典\n",
        "                print(f\"Places365 contributing: {mapped_scene_type} with confidence {places365_confidence:.3f}\")\n",
        "\n",
        "        yolo_has_meaningful_scores = bool(yolo_scene_scores and any(s > 1e-5 for s in yolo_scene_scores.values())) # 確保是布林值\n",
        "        clip_has_meaningful_scores = bool(clip_scene_scores and any(s > 1e-5 for s in clip_scene_scores.values())) # 確保是布林值\n",
        "        places365_has_meaningful_scores = bool(places365_scene_scores_map and any(s > 1e-5 for s in places365_scene_scores_map.values()))\n",
        "\n",
        "        meaningful_sources_count = sum([\n",
        "            yolo_has_meaningful_scores,\n",
        "            clip_has_meaningful_scores,\n",
        "            places365_has_meaningful_scores\n",
        "        ])\n",
        "\n",
        "\n",
        "        if meaningful_sources_count == 0:\n",
        "            return {st: 0.0 for st in self.SCENE_TYPES.keys()}\n",
        "        elif meaningful_sources_count == 1:\n",
        "            if yolo_has_meaningful_scores:\n",
        "                return {st: yolo_scene_scores.get(st, 0.0) for st in self.SCENE_TYPES.keys()}\n",
        "            elif clip_has_meaningful_scores:\n",
        "                return {st: clip_scene_scores.get(st, 0.0) for st in self.SCENE_TYPES.keys()}\n",
        "            elif places365_has_meaningful_scores:\n",
        "                return {st: places365_scene_scores_map.get(st, 0.0) for st in self.SCENE_TYPES.keys()}\n",
        "\n",
        "        fused_scores = {}\n",
        "        all_relevant_scene_types = set(self.SCENE_TYPES.keys())\n",
        "        all_possible_scene_types = all_relevant_scene_types.union(\n",
        "            set(yolo_scene_scores.keys()),\n",
        "            set(clip_scene_scores.keys()),\n",
        "            set(places365_scene_scores_map.keys())\n",
        "        )\n",
        "\n",
        "        # Base weights - adjusted to accommodate three sources\n",
        "        default_yolo_weight = 0.5\n",
        "        default_clip_weight = 0.3\n",
        "        default_places365_weight = 0.2\n",
        "\n",
        "        is_lighting_indoor = None\n",
        "        lighting_analysis_confidence = 0.0\n",
        "        if lighting_info and isinstance(lighting_info, dict):\n",
        "            is_lighting_indoor = lighting_info.get(\"is_indoor\")\n",
        "            lighting_analysis_confidence = lighting_info.get(\"confidence\", 0.0)\n",
        "\n",
        "        for scene_type in all_possible_scene_types:\n",
        "            yolo_score = yolo_scene_scores.get(scene_type, 0.0)\n",
        "            clip_score = clip_scene_scores.get(scene_type, 0.0)\n",
        "            places365_score = places365_scene_scores_map.get(scene_type, 0.0)\n",
        "\n",
        "            current_yolo_weight = default_yolo_weight\n",
        "            current_clip_weight = default_clip_weight\n",
        "            current_places365_weight = default_places365_weight\n",
        "\n",
        "            scene_definition = self.SCENE_TYPES.get(scene_type, {})\n",
        "\n",
        "            # Weight adjustment based on scene_type nature and YOLO richness\n",
        "            if scene_type in self.EVERYDAY_SCENE_TYPE_KEYS:\n",
        "                # Places365 excels at everyday scene classification\n",
        "                if num_yolo_detections >= 5 and avg_yolo_confidence >= 0.45: # Rich YOLO for everyday\n",
        "                    current_yolo_weight = 0.60\n",
        "                    current_clip_weight = 0.15\n",
        "                    current_places365_weight = 0.25\n",
        "                elif num_yolo_detections >= 3: # Moderate YOLO for everyday\n",
        "                    current_yolo_weight = 0.50\n",
        "                    current_clip_weight = 0.20\n",
        "                    current_places365_weight = 0.30\n",
        "                else: # Sparse YOLO for everyday, rely more on Places365\n",
        "                    current_yolo_weight = 0.35\n",
        "                    current_clip_weight = 0.25\n",
        "                    current_places365_weight = 0.40\n",
        "\n",
        "            # For scenes where CLIP's global understanding or specific training is often more valuable\n",
        "            elif any(keyword in scene_type.lower() for keyword in [\"asian\", \"cultural\", \"aerial\", \"landmark\", \"monument\", \"tourist\", \"natural_landmark\", \"historical_monument\"]):\n",
        "                current_yolo_weight = 0.25\n",
        "                current_clip_weight = 0.65\n",
        "                current_places365_weight = 0.10  # Lower weight for landmark scenes\n",
        "\n",
        "            # For specific indoor common scenes (non-landmark), object detection is key but Places365 provides strong scene context\n",
        "            elif any(keyword in scene_type.lower() for keyword in\n",
        "                    [\"room\", \"kitchen\", \"office\", \"bedroom\", \"desk_area\", \"indoor_space\",\n",
        "                    \"professional_kitchen\", \"cafe\", \"library\", \"gym\", \"retail_store\",\n",
        "                    \"supermarket\", \"classroom\", \"conference_room\", \"medical_facility\",\n",
        "                    \"educational_setting\", \"dining_area\"]):\n",
        "                current_yolo_weight = 0.55\n",
        "                current_clip_weight = 0.20\n",
        "                current_places365_weight = 0.25\n",
        "\n",
        "            # For specific outdoor common scenes (non-landmark) where objects are still important\n",
        "            elif any(keyword in scene_type.lower() for keyword in\n",
        "                    [\"parking_lot\", \"park_area\", \"beach\", \"harbor\", \"playground\", \"sports_field\", \"bus_stop\", \"train_station\", \"airport\"]):\n",
        "                current_yolo_weight = 0.50\n",
        "                current_clip_weight = 0.25\n",
        "                current_places365_weight = 0.25\n",
        "\n",
        "            # If landmark detection is globally disabled for this run\n",
        "            if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "                if any(keyword in scene_type.lower() for keyword in [\"landmark\", \"monument\", \"tourist\"]):\n",
        "                    yolo_score = 0.0 # Should already be 0 from _compute_scene_scores\n",
        "                    clip_score *= 0.05 # Heavily penalize\n",
        "                    places365_score *= 0.8 if scene_type not in self.EVERYDAY_SCENE_TYPE_KEYS else 1.0 # Slight penalty for landmark scenes\n",
        "                elif scene_type not in self.EVERYDAY_SCENE_TYPE_KEYS and \\\n",
        "                    not any(keyword in scene_type.lower() for keyword in [\"asian\", \"cultural\", \"aerial\"]):\n",
        "                    # Redistribute weights away from CLIP towards YOLO and Places365\n",
        "                    weight_boost = 0.05\n",
        "                    current_yolo_weight = min(0.9, current_yolo_weight + weight_boost)\n",
        "                    current_places365_weight = min(0.9, current_places365_weight + weight_boost)\n",
        "                    current_clip_weight = max(0.1, current_clip_weight - weight_boost * 2)\n",
        "\n",
        "            # Boost Places365 weight if it has high confidence for this specific scene type\n",
        "            if places365_score > 0.0 and places365_info: # 這裡的 places365_score 已經是從 map 中獲取\n",
        "                places365_original_confidence = places365_info.get('confidence', 0.0) # 獲取原始的 Places365 信心度\n",
        "                if places365_original_confidence > 0.7:\n",
        "                    boost_factor = min(0.2, (places365_original_confidence - 0.7) * 0.4)\n",
        "                    current_places365_weight += boost_factor\n",
        "                    total_other_weight = current_yolo_weight + current_clip_weight\n",
        "                    if total_other_weight > 0:\n",
        "                        reduction_factor = boost_factor / total_other_weight\n",
        "                        current_yolo_weight *= (1 - reduction_factor)\n",
        "                        current_clip_weight *= (1 - reduction_factor)\n",
        "\n",
        "            total_weight = current_yolo_weight + current_clip_weight + current_places365_weight\n",
        "            if total_weight > 0: # 避免除以零\n",
        "                current_yolo_weight /= total_weight\n",
        "                current_clip_weight /= total_weight\n",
        "                current_places365_weight /= total_weight\n",
        "            else:\n",
        "                current_yolo_weight = 1/3\n",
        "                current_clip_weight = 1/3\n",
        "                current_places365_weight = 1/3\n",
        "\n",
        "\n",
        "            fused_score = (yolo_score * current_yolo_weight) + (clip_score * current_clip_weight) + (places365_score * current_places365_weight)\n",
        "\n",
        "            places365_is_indoor = None\n",
        "            places365_confidence_for_indoor = 0.0\n",
        "            effective_is_indoor = is_lighting_indoor\n",
        "            effective_confidence = lighting_analysis_confidence\n",
        "\n",
        "            if places365_info and isinstance(places365_info, dict):\n",
        "                places365_is_indoor = places365_info.get('is_indoor')\n",
        "                places365_confidence_for_indoor = places365_info.get('confidence', 0.0)\n",
        "\n",
        "                # Places365 overrides lighting analysis when confidence is high\n",
        "                if places365_confidence_for_indoor >= 0.8 and places365_is_indoor is not None:\n",
        "                    effective_is_indoor = places365_is_indoor\n",
        "                    effective_confidence = places365_confidence_for_indoor\n",
        "\n",
        "                    # 只在特定場景類型首次處理時輸出調試資訊\n",
        "                    if scene_type == \"intersection\" or (scene_type in [\"urban_intersection\", \"street_view\"] and scene_type == sorted(all_possible_scene_types)[0]):\n",
        "                        print(f\"DEBUG: Using Places365 indoor/outdoor decision: {places365_is_indoor} (confidence: {places365_confidence_for_indoor:.3f}) over lighting analysis\")\n",
        "\n",
        "            if effective_is_indoor is not None and effective_confidence >= 0.65:\n",
        "                # Determine if the scene_type is inherently indoor or outdoor based on its definition\n",
        "                is_defined_as_indoor = \"indoor\" in scene_definition.get(\"description\", \"\").lower() or \\\n",
        "                                    any(kw in scene_type.lower() for kw in [\"room\", \"kitchen\", \"office\", \"indoor\", \"library\", \"cafe\", \"gym\"])\n",
        "                is_defined_as_outdoor = \"outdoor\" in scene_definition.get(\"description\", \"\").lower() or \\\n",
        "                                        any(kw in scene_type.lower() for kw in [\"street\", \"park\", \"aerial\", \"beach\", \"harbor\", \"intersection\", \"crosswalk\"])\n",
        "\n",
        "                lighting_adjustment_strength = 0.20 # Max adjustment factor (e.g., 20%)\n",
        "                # Scale adjustment by how confident the analysis is above the threshold\n",
        "                adjustment_scale = (effective_confidence - 0.65) / (1.0 - 0.65) # Scale from 0 to 1\n",
        "                adjustment = lighting_adjustment_strength * adjustment_scale\n",
        "                adjustment = min(lighting_adjustment_strength, max(0, adjustment)) # Clamp adjustment\n",
        "\n",
        "                if effective_is_indoor and is_defined_as_outdoor:\n",
        "                    fused_score *= (1.0 - adjustment)\n",
        "                elif not effective_is_indoor and is_defined_as_indoor:\n",
        "                    fused_score *= (1.0 - adjustment)\n",
        "                elif effective_is_indoor and is_defined_as_indoor:\n",
        "                    fused_score = min(1.0, fused_score * (1.0 + adjustment * 0.5))\n",
        "                elif not effective_is_indoor and is_defined_as_outdoor:\n",
        "                    fused_score = min(1.0, fused_score * (1.0 + adjustment * 0.5))\n",
        "\n",
        "            fused_scores[scene_type] = min(1.0, max(0.0, fused_score))\n",
        "\n",
        "        return fused_scores\n",
        "\n",
        "\n",
        "    def process_unknown_objects(self, detection_result, detected_objects):\n",
        "        \"\"\"\n",
        "        對YOLO未能識別或信心度低的物體進行地標檢測\n",
        "\n",
        "        Args:\n",
        "            detection_result: YOLO檢測結果\n",
        "            detected_objects: 已識別的物體列表\n",
        "\n",
        "        Returns:\n",
        "            tuple: (更新後的物體列表, 地標物體列表)\n",
        "        \"\"\"\n",
        "        if not getattr(self, 'enable_landmark', True) or not self.use_clip or not hasattr(self, 'use_landmark_detection') or not self.use_landmark_detection:\n",
        "            # 未啟用地標識別時，確保返回的物體列表中不包含任何地標物體\n",
        "            cleaned_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "            return cleaned_objects, []\n",
        "\n",
        "        try:\n",
        "            # 獲取原始圖像\n",
        "            original_image = None\n",
        "            if detection_result is not None and hasattr(detection_result, 'orig_img'):\n",
        "                original_image = detection_result.orig_img\n",
        "\n",
        "            # 檢查原始圖像是否存在\n",
        "            if original_image is None:\n",
        "                print(\"Warning: Original image not available for landmark detection\")\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 確保原始圖像為PIL格式或可轉換為PIL格式\n",
        "            if not isinstance(original_image, Image.Image):\n",
        "                if isinstance(original_image, np.ndarray):\n",
        "                    try:\n",
        "                        if original_image.ndim == 3 and original_image.shape[2] == 4:  # RGBA\n",
        "                            original_image = original_image[:, :, :3]  # 轉換為RGB\n",
        "                        if original_image.ndim == 2:  # 灰度圖\n",
        "                            original_image = Image.fromarray(original_image).convert(\"RGB\")\n",
        "                        else:  # 假設為RGB或BGR\n",
        "                            original_image = Image.fromarray(original_image)\n",
        "\n",
        "                        if hasattr(original_image, 'mode') and original_image.mode == 'BGR':  # 從OpenCV明確將BGR轉換為RGB\n",
        "                            original_image = original_image.convert('RGB')\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Error converting image for landmark detection: {e}\")\n",
        "                        return detected_objects, []\n",
        "                else:\n",
        "                    print(f\"Warning: Cannot process image of type {type(original_image)}\")\n",
        "                    return detected_objects, []\n",
        "\n",
        "            # 獲取圖像維度\n",
        "            if isinstance(original_image, np.ndarray):\n",
        "                h, w = original_image.shape[:2]\n",
        "            elif isinstance(original_image, Image.Image):\n",
        "                w, h = original_image.size\n",
        "            else:\n",
        "                print(f\"Warning: Unable to determine image dimensions for type {type(original_image)}\")\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 收集可能含有地標的區域\n",
        "            candidate_boxes = []\n",
        "            low_conf_boxes = []\n",
        "\n",
        "            # 即使沒有YOLO檢測到的物體，也嘗試進行更詳細的地標分析\n",
        "            if len(detected_objects) == 0:\n",
        "                # 創建一個包含整個圖像的框\n",
        "                full_image_box = [0, 0, w, h]\n",
        "                low_conf_boxes.append(full_image_box)\n",
        "                candidate_boxes.append((full_image_box, \"full_image\"))\n",
        "\n",
        "                # 加入網格分析以增加檢測成功率\n",
        "                grid_size = 2  # 2x2網格\n",
        "                for i in range(grid_size):\n",
        "                    for j in range(grid_size):\n",
        "                        # 創建網格框\n",
        "                        grid_box = [\n",
        "                            j * w / grid_size,\n",
        "                            i * h / grid_size,\n",
        "                            (j + 1) * w / grid_size,\n",
        "                            (i + 1) * h / grid_size\n",
        "                        ]\n",
        "                        low_conf_boxes.append(grid_box)\n",
        "                        candidate_boxes.append((grid_box, \"grid\"))\n",
        "\n",
        "                # 創建更大的中心框（覆蓋中心70%區域）\n",
        "                center_box = [\n",
        "                    w * 0.15, h * 0.15,\n",
        "                    w * 0.85, h * 0.85\n",
        "                ]\n",
        "                low_conf_boxes.append(center_box)\n",
        "                candidate_boxes.append((center_box, \"center\"))\n",
        "\n",
        "                print(\"No YOLO detections, attempting detailed landmark analysis with multiple regions\")\n",
        "            else:\n",
        "                try:\n",
        "                    # 獲取原始YOLO檢測結果中的低置信度物體\n",
        "                    if hasattr(detection_result, 'boxes') and hasattr(detection_result.boxes, 'xyxy') and hasattr(detection_result.boxes, 'conf') and hasattr(detection_result.boxes, 'cls'):\n",
        "                        all_boxes = detection_result.boxes.xyxy.cpu().numpy() if hasattr(detection_result.boxes.xyxy, 'cpu') else detection_result.boxes.xyxy\n",
        "                        all_confs = detection_result.boxes.conf.cpu().numpy() if hasattr(detection_result.boxes.conf, 'cpu') else detection_result.boxes.conf\n",
        "                        all_cls = detection_result.boxes.cls.cpu().numpy() if hasattr(detection_result.boxes.cls, 'cpu') else detection_result.boxes.cls\n",
        "\n",
        "                        # 收集低置信度區域和可能含有地標的區域（如建築物）\n",
        "                        for i, (box, conf, cls) in enumerate(zip(all_boxes, all_confs, all_cls)):\n",
        "                            is_low_conf = conf < 0.4 and conf > 0.1\n",
        "\n",
        "                            # 根據物體類別 ID 識別建築物 - 使用通用分類\n",
        "                            common_building_classes = [11, 12, 13, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]  # 常見建築類別 ID\n",
        "                            is_building = int(cls) in common_building_classes\n",
        "\n",
        "                            # 計算相對面積 - 大物體\n",
        "                            is_large_object = (box[2] - box[0]) * (box[3] - box[1]) > (0.1 * w * h)\n",
        "\n",
        "                            if is_low_conf or is_building:\n",
        "                                # 確保 box 是一個有效的數組或列表\n",
        "                                if isinstance(box, (list, tuple, np.ndarray)) and len(box) >= 4:\n",
        "                                    low_conf_boxes.append(box)\n",
        "                                    if is_large_object:\n",
        "                                        candidate_boxes.append((box, \"building\" if is_building else \"low_conf\"))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing YOLO detections: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            if not hasattr(self, 'landmark_classifier'):\n",
        "                if hasattr(self, 'clip_analyzer') and hasattr(self.clip_analyzer, 'get_clip_instance'):\n",
        "                    try:\n",
        "                        print(\"Initializing landmark classifier for process_unknown_objects\")\n",
        "                        model, preprocess, device = self.clip_analyzer.get_clip_instance()\n",
        "                        self.landmark_classifier = CLIPZeroShotClassifier(device=device)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error initializing landmark classifier: {e}\")\n",
        "                        return detected_objects, []\n",
        "                else:\n",
        "                    print(\"Warning: landmark_classifier not available and cannot be initialized\")\n",
        "                    return detected_objects, []\n",
        "\n",
        "            # 使用智能地標搜索\n",
        "            landmark_results = None\n",
        "            try:\n",
        "                # 確保有有效的框\n",
        "                if not low_conf_boxes:\n",
        "                    # 如果沒有低置信度框，添加全圖\n",
        "                    low_conf_boxes.append([0, 0, w, h])\n",
        "\n",
        "                landmark_results = self.landmark_classifier.intelligent_landmark_search(\n",
        "                    original_image,\n",
        "                    yolo_boxes=low_conf_boxes,\n",
        "                    base_threshold=0.25\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error in intelligent_landmark_search: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 處理識別結果\n",
        "            landmark_objects = []\n",
        "\n",
        "            # 如果有效的地標結果\n",
        "            if landmark_results and landmark_results.get(\"is_landmark_scene\", False):\n",
        "                for landmark_info in landmark_results.get(\"detected_landmarks\", []):\n",
        "                    try:\n",
        "                        # 使用 landmark_classifier 的閾值判斷\n",
        "                        base_threshold = 0.25  # 基礎閾值\n",
        "\n",
        "                        # 獲取地標類型並設定閾值\n",
        "                        landmark_type = \"architectural\"  # 預設類型\n",
        "                        type_threshold = 0.5  # 預設閾值\n",
        "\n",
        "                        # 優先使用 landmark_classifier\n",
        "                        if hasattr(self, 'landmark_classifier') and hasattr(self.landmark_classifier, '_determine_landmark_type'):\n",
        "                            landmark_type = self.landmark_classifier._determine_landmark_type(landmark_info.get(\"landmark_id\", \"\"))\n",
        "                            type_threshold = getattr(self.landmark_classifier, 'landmark_type_thresholds', {}).get(landmark_type, 0.5)\n",
        "                        # 否則使用本地方法\n",
        "                        elif hasattr(self, '_determine_landmark_type'):\n",
        "                            landmark_type = self._determine_landmark_type(landmark_info.get(\"landmark_id\", \"\"))\n",
        "                            # 依據地標類型調整閾值\n",
        "                            if landmark_type == \"skyscraper\":\n",
        "                                type_threshold = 0.4\n",
        "                            elif landmark_type == \"natural\":\n",
        "                                type_threshold = 0.6\n",
        "                        # 或者直接從地標 ID 推斷\n",
        "                        else:\n",
        "                            landmark_id = landmark_info.get(\"landmark_id\", \"\").lower()\n",
        "                            if any(term in landmark_id for term in [\"mountain\", \"canyon\", \"waterfall\", \"lake\", \"river\", \"natural\"]):\n",
        "                                landmark_type = \"natural\"\n",
        "                                type_threshold = 0.6\n",
        "                            elif any(term in landmark_id for term in [\"skyscraper\", \"building\", \"tower\", \"tall\"]):\n",
        "                                landmark_type = \"skyscraper\"\n",
        "                                type_threshold = 0.4\n",
        "                            elif any(term in landmark_id for term in [\"monument\", \"memorial\", \"statue\", \"historical\"]):\n",
        "                                landmark_type = \"monument\"\n",
        "                                type_threshold = 0.5\n",
        "\n",
        "                        effective_threshold = base_threshold * (type_threshold / 0.5)\n",
        "                        # 如果置信度足夠高\n",
        "                        if landmark_info.get(\"confidence\", 0) > effective_threshold:\n",
        "                            # 獲取邊界框\n",
        "                            if \"box\" in landmark_info:\n",
        "                                box = landmark_info[\"box\"]\n",
        "                            else:\n",
        "                                # 如果沒有邊界框，使用整個圖像的90%區域\n",
        "                                margin_x, margin_y = w * 0.05, h * 0.05\n",
        "                                box = [margin_x, margin_y, w - margin_x, h - margin_y]\n",
        "\n",
        "                            # 計算中心點和其他必要信息\n",
        "                            center_x = (box[0] + box[2]) / 2\n",
        "                            center_y = (box[1] + box[3]) / 2\n",
        "                            norm_center_x = center_x / w if w > 0 else 0.5\n",
        "                            norm_center_y = center_y / h if h > 0 else 0.5\n",
        "\n",
        "                            # 獲取區域位置\n",
        "                            region = \"center\"  # 預設\n",
        "                            if hasattr(self, 'spatial_analyzer') and hasattr(self.spatial_analyzer, '_determine_region'):\n",
        "                                try:\n",
        "                                    region = self.spatial_analyzer._determine_region(norm_center_x, norm_center_y)\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Error determining region: {e}\")\n",
        "\n",
        "                            # 創建地標物體\n",
        "                            landmark_obj = {\n",
        "                                \"class_id\": landmark_info.get(\"landmark_id\", \"\")[:15] if isinstance(landmark_info.get(\"landmark_id\", \"\"), str) else \"-100\",  # 截斷過長的 ID\n",
        "                                \"class_name\": landmark_info.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                \"confidence\": landmark_info.get(\"confidence\", 0.0),\n",
        "                                \"box\": box,\n",
        "                                \"center\": (center_x, center_y),\n",
        "                                \"normalized_center\": (norm_center_x, norm_center_y),\n",
        "                                \"size\": (box[2] - box[0], box[3] - box[1]),\n",
        "                                \"normalized_size\": (\n",
        "                                    (box[2] - box[0]) / w if w > 0 else 0,\n",
        "                                    (box[3] - box[1]) / h if h > 0 else 0\n",
        "                                ),\n",
        "                                \"area\": (box[2] - box[0]) * (box[3] - box[1]),\n",
        "                                \"normalized_area\": (\n",
        "                                    (box[2] - box[0]) * (box[3] - box[1]) / (w * h) if w * h > 0 else 0\n",
        "                                ),\n",
        "                                \"region\": region,\n",
        "                                \"is_landmark\": True,\n",
        "                                \"landmark_id\": landmark_info.get(\"landmark_id\", \"\"),\n",
        "                                \"location\": landmark_info.get(\"location\", \"Unknown Location\")\n",
        "                            }\n",
        "\n",
        "                            # 添加額外信息\n",
        "                            for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                                if key in landmark_info:\n",
        "                                    landmark_obj[key] = landmark_info[key]\n",
        "\n",
        "                            # 添加地標類型\n",
        "                            landmark_obj[\"landmark_type\"] = landmark_type\n",
        "\n",
        "                            # 添加到檢測物體列表\n",
        "                            detected_objects.append(landmark_obj)\n",
        "                            landmark_objects.append(landmark_obj)\n",
        "                            print(f\"Detected landmark: {landmark_info.get('landmark_name', 'Unknown')} with confidence {landmark_info.get('confidence', 0.0):.2f}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing landmark: {e}\")\n",
        "                        continue\n",
        "\n",
        "                return detected_objects, landmark_objects\n",
        "\n",
        "            return detected_objects, []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in landmark detection: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return detected_objects, []\n",
        "\n",
        "    def _remove_landmark_references(self, text):\n",
        "        \"\"\"\n",
        "        從文本中移除所有地標引用\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            str: 清除地標引用後的文本\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        import re\n",
        "\n",
        "        try:\n",
        "            # 動態收集所有地標名稱和位置\n",
        "            landmark_names = []\n",
        "            locations = []\n",
        "\n",
        "            for landmark_id, info in ALL_LANDMARKS.items():\n",
        "                # 收集地標名稱及其別名\n",
        "                landmark_names.append(info[\"name\"])\n",
        "                landmark_names.extend(info.get(\"aliases\", []))\n",
        "\n",
        "                # 收集地理位置\n",
        "                if \"location\" in info:\n",
        "                    location = info[\"location\"]\n",
        "                    locations.append(location)\n",
        "\n",
        "                    # 處理分離的城市和國家名稱\n",
        "                    parts = location.split(\",\")\n",
        "                    if len(parts) >= 1:\n",
        "                        locations.append(parts[0].strip())\n",
        "                    if len(parts) >= 2:\n",
        "                        locations.append(parts[1].strip())\n",
        "\n",
        "            # 使用正則表達式動態替換所有地標名稱\n",
        "            for name in landmark_names:\n",
        "                if name and len(name) > 2:  # 避免過短的名稱\n",
        "                    text = re.sub(r'\\b' + re.escape(name) + r'\\b', \"tall structure\", text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 動態替換所有位置引用\n",
        "            for location in locations:\n",
        "                if location and len(location) > 2:\n",
        "                    # 替換常見位置表述模式\n",
        "                    text = re.sub(r'in ' + re.escape(location), \"in the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'of ' + re.escape(location), \"of the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'\\b' + re.escape(location) + r'\\b', \"the urban area\", text, flags=re.IGNORECASE)\n",
        "\n",
        "        except ImportError:\n",
        "            # 通用地標描述模式\n",
        "            landmark_patterns = [\n",
        "                # 地標地點模式\n",
        "                (r'an iconic structure in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure'),\n",
        "                (r'a famous (monument|tower|landmark) in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure'),\n",
        "                (r'(the [A-Z][a-zA-Z\\s]+ Tower)', r'the tower'),\n",
        "                (r'(the [A-Z][a-zA-Z\\s]+ Building)', r'the building'),\n",
        "                (r'(the CN Tower)', r'the tower'),\n",
        "                (r'([A-Z][a-zA-Z\\s]+) Tower', r'tall structure'),\n",
        "\n",
        "                # 地標位置關係模式\n",
        "                (r'(centered|built|located|positioned) around the ([A-Z][a-zA-Z\\s]+? (Tower|Monument|Landmark))', r'located in this area'),\n",
        "\n",
        "                # 地標活動模式\n",
        "                (r'(sightseeing|guided tours|cultural tourism) (at|around|near) (this landmark|the [A-Z][a-zA-Z\\s]+)', r'\\1 in this area'),\n",
        "\n",
        "                # 一般性地標形容模式\n",
        "                (r'this (famous|iconic|historic|well-known) (landmark|monument|tower|structure)', r'this urban structure'),\n",
        "                (r'landmark scene', r'urban scene'),\n",
        "                (r'tourist destination', r'urban area'),\n",
        "                (r'tourist attraction', r'urban area')\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in landmark_patterns:\n",
        "                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVw5JMy6qhY3"
      },
      "outputs": [],
      "source": [
        "# %%writefile image_processor.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import uuid\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "# from detection_model import DetectionModel\n",
        "# from color_mapper import ColorMapper\n",
        "# from visualization_helper import VisualizationHelper\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from lighting_analyzer import LightingAnalyzer\n",
        "# from scene_analyzer import SceneAnalyzer\n",
        "# from places365_model import Places365Model\n",
        "\n",
        "class ImageProcessor:\n",
        "    \"\"\"\n",
        "    Class for handling image processing and object detection operations\n",
        "    Separates processing logic from UI components\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_llm=True, llm_model_path=None, enable_places365=True, places365_model_name='resnet50_places365'):\n",
        "        \"\"\"Initialize the image processor with required components\"\"\"\n",
        "        print(f\"Initializing ImageProcessor with use_llm={use_llm}, enable_places365={enable_places365}\")\n",
        "\n",
        "        try:\n",
        "            # Initialize basic components first\n",
        "            self.use_llm = use_llm\n",
        "            self.llm_model_path = llm_model_path\n",
        "            self.enable_places365 = enable_places365\n",
        "            self.model_instances = {}\n",
        "\n",
        "            # Initialize ColorMapper\n",
        "            self.color_mapper = ColorMapper()\n",
        "            print(\"ColorMapper initialized successfully\")\n",
        "\n",
        "            # Initialize LightingAnalyzer\n",
        "            self.lighting_analyzer = LightingAnalyzer()\n",
        "            print(\"LightingAnalyzer initialized successfully\")\n",
        "\n",
        "            # Initialize Places365 model if enabled\n",
        "            self.places365_model = None\n",
        "            if self.enable_places365:\n",
        "                try:\n",
        "                    self.places365_model = Places365Model(\n",
        "                        model_name=places365_model_name,\n",
        "                        device=None\n",
        "                    )\n",
        "                    print(f\"Places365 model initialized successfully with {places365_model_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Failed to initialize Places365 model: {e}\")\n",
        "                    print(\"Continuing without Places365 analysis\")\n",
        "                    self.enable_places365 = False\n",
        "                    self.places365_model = None\n",
        "\n",
        "            # Initialize SceneAnalyzer with error handling\n",
        "            self.scene_analyzer = None\n",
        "            self.class_names = None  # Will be set when first model is loaded\n",
        "\n",
        "            try:\n",
        "                # Initialize SceneAnalyzer without class_names (will be set later)\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=None,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=True,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "                print(\"SceneAnalyzer initialized successfully\")\n",
        "\n",
        "                # Verify critical components\n",
        "                if self.scene_analyzer is not None:\n",
        "                    print(f\"SceneAnalyzer status - spatial_analyzer: {hasattr(self.scene_analyzer, 'spatial_analyzer')}, \"\n",
        "                        f\"descriptor: {hasattr(self.scene_analyzer, 'descriptor')}, \"\n",
        "                        f\"scene_describer: {hasattr(self.scene_analyzer, 'scene_describer')}\")\n",
        "                else:\n",
        "                    print(\"WARNING: scene_analyzer is None after initialization\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error initializing SceneAnalyzer: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                self.scene_analyzer = None\n",
        "\n",
        "            print(\"ImageProcessor initialization completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Critical error during ImageProcessor initialization: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise RuntimeError(f\"Failed to initialize ImageProcessor: {str(e)}\")\n",
        "\n",
        "    def get_model_instance(self, model_name: str, confidence: float = 0.25, iou: float = 0.25) -> DetectionModel:\n",
        "        \"\"\"\n",
        "        Get or create a model instance based on model name\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the model to use\n",
        "            confidence: Confidence threshold for detection\n",
        "            iou: IoU threshold for non-maximum suppression\n",
        "\n",
        "        Returns:\n",
        "            DetectionModel instance\n",
        "        \"\"\"\n",
        "        if model_name not in self.model_instances:\n",
        "            print(f\"Creating new model instance for {model_name}\")\n",
        "            self.model_instances[model_name] = DetectionModel(\n",
        "                model_name=model_name,\n",
        "                confidence=confidence,\n",
        "                iou=iou\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Using existing model instance for {model_name}\")\n",
        "            self.model_instances[model_name].confidence = confidence\n",
        "\n",
        "        return self.model_instances[model_name]\n",
        "\n",
        "    def analyze_scene(self, detection_result: Any, lighting_info: Optional[Dict] = None, enable_landmark=True, places365_info=None) -> Dict:\n",
        "        \"\"\"\n",
        "        Perform scene analysis on detection results\n",
        "\n",
        "        Args:\n",
        "            detection_result: Object detection result from YOLOv8\n",
        "            lighting_info: Lighting condition analysis results (optional)\n",
        "            enable_landmark: Whether to enable landmark detection\n",
        "            places365_info: Places365 analysis results (optional)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing scene analysis results\n",
        "        \"\"\"\n",
        "        print(f\"DEBUG: analyze_scene received enable_landmark={enable_landmark}\")\n",
        "        try:\n",
        "            # Check if detection_result has valid names\n",
        "            class_names = getattr(detection_result, 'names', None) if detection_result else None\n",
        "\n",
        "            # Initialize or reinitialize scene analyzer if needed\n",
        "            if self.scene_analyzer is None:\n",
        "                print(\"Scene analyzer not initialized, creating new instance\")\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=class_names,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=enable_landmark,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "\n",
        "                if self.scene_analyzer is None:\n",
        "                    raise ValueError(\"Failed to create SceneAnalyzer instance\")\n",
        "            else:\n",
        "                # Update existing scene analyzer settings\n",
        "                self.scene_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # Update class names if available and different\n",
        "                if class_names and self.scene_analyzer.class_names != class_names:\n",
        "                    self.scene_analyzer.class_names = class_names\n",
        "                    if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                        self.scene_analyzer.spatial_analyzer.class_names = class_names\n",
        "\n",
        "                # Update landmark detection settings in child components\n",
        "                if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                    self.scene_analyzer.spatial_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "            # Perform scene analysis with lighting info and Places365 context\n",
        "            scene_analysis = self.scene_analyzer.analyze(\n",
        "                detection_result=detection_result,\n",
        "                lighting_info=lighting_info,\n",
        "                class_confidence_threshold=0.35,\n",
        "                scene_confidence_threshold=0.6,\n",
        "                enable_landmark=enable_landmark,\n",
        "                places365_info=places365_info\n",
        "            )\n",
        "\n",
        "            return scene_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in scene analysis: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Return a valid default result\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\",\n",
        "                \"confidence\": 0.0,\n",
        "                \"description\": f\"Error during scene analysis: {str(e)}\",\n",
        "                \"enhanced_description\": \"Scene analysis could not be completed due to an error.\",\n",
        "                \"objects_present\": [],\n",
        "                \"object_count\": 0,\n",
        "                \"regions\": {},\n",
        "                \"possible_activities\": [],\n",
        "                \"safety_concerns\": [],\n",
        "                \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "    def analyze_lighting_conditions(self, image, places365_info: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        分析光照條件並考慮 Places365 場景資訊。\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            places365_info: Places365 場景分析結果，用於覆蓋邏輯\n",
        "\n",
        "        Returns:\n",
        "            Dict: 光照分析結果\n",
        "        \"\"\"\n",
        "        return self.lighting_analyzer.analyze(image, places365_info=places365_info)\n",
        "\n",
        "    def analyze_places365_scene(self, image):\n",
        "        \"\"\"\n",
        "        Analyze scene using Places365 model.\n",
        "\n",
        "        Args:\n",
        "            image: Input image (PIL Image)\n",
        "\n",
        "        Returns:\n",
        "            Dict: Places365 analysis results or None if disabled/failed\n",
        "        \"\"\"\n",
        "        if not self.enable_places365 or self.places365_model is None:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    print(f\"Warning: Cannot process image of type {type(image)} for Places365\")\n",
        "                    return None\n",
        "\n",
        "            places365_result = self.places365_model.predict(image)\n",
        "\n",
        "            if places365_result and places365_result.get('confidence', 0) > 0.1:\n",
        "                print(f\"Places365 detected: {places365_result['scene_label']} \"\n",
        "                    f\"(mapped: {places365_result['mapped_scene_type']}) \"\n",
        "                    f\"confidence: {places365_result['confidence']:.3f}\")\n",
        "                return places365_result\n",
        "            else:\n",
        "                print(\"Places365 analysis failed or low confidence\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Places365 analysis: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_image(self, image: Any, model_name: str, confidence_threshold: float, filter_classes: Optional[List[int]] = None,  enable_landmark: bool = True) -> Tuple[Any, str, Dict]:\n",
        "        \"\"\"\n",
        "        Process an image for object detection and scene analysis.\n",
        "        Args:\n",
        "            image: Input image (numpy array or PIL Image).\n",
        "            model_name: Name of the model to use.\n",
        "            confidence_threshold: Confidence threshold for detection.\n",
        "            filter_classes: Optional list of classes to filter results.\n",
        "            enable_landmark: Whether to enable landmark detection for this run.\n",
        "        Returns:\n",
        "            Tuple of (result_image_pil, result_text, stats_data_with_scene_analysis).\n",
        "        \"\"\"\n",
        "        model_instance = self.get_model_instance(model_name, confidence_threshold)\n",
        "        if model_instance is None:\n",
        "            return None, f\"Failed to load model: {model_name}. Please check model configuration.\", {}\n",
        "\n",
        "        result = None\n",
        "        stats_data = {}\n",
        "        temp_path = None\n",
        "        pil_image_for_processing = None # Use this to store the consistently processed PIL image\n",
        "\n",
        "        try:\n",
        "            if isinstance(image, np.ndarray):\n",
        "                if image.ndim == 3 and image.shape[2] == 3: # RGB or BGR\n",
        "                    # Assuming BGR from OpenCV, convert to RGB for PIL standard\n",
        "                    image_rgb_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                    pil_image_for_processing = Image.fromarray(image_rgb_np)\n",
        "                elif image.ndim == 3 and image.shape[2] == 4: # RGBA or BGRA\n",
        "                    image_rgba_np = cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA) # Ensure RGBA\n",
        "                    pil_image_for_processing = Image.fromarray(image_rgba_np).convert(\"RGB\") # Convert to RGB\n",
        "                elif image.ndim == 2: # Grayscale\n",
        "                    pil_image_for_processing = Image.fromarray(image).convert(\"RGB\")\n",
        "                else:\n",
        "                    pil_image_for_processing = Image.fromarray(image) # Hope for the best\n",
        "            elif isinstance(image, Image.Image):\n",
        "                pil_image_for_processing = image.copy() # Use a copy\n",
        "            elif image is None:\n",
        "                return None, \"No image provided. Please upload an image.\", {}\n",
        "            else:\n",
        "                return None, f\"Unsupported image type: {type(image)}. Please provide a NumPy array or PIL Image.\", {}\n",
        "\n",
        "            if pil_image_for_processing.mode != \"RGB\": # Ensure final image is RGB\n",
        "                pil_image_for_processing = pil_image_for_processing.convert(\"RGB\")\n",
        "\n",
        "            # Add Places365 scene analysis parallel to lighting analysis\n",
        "            places365_info = self.analyze_places365_scene(pil_image_for_processing)\n",
        "\n",
        "            lighting_info = self.analyze_lighting_conditions(pil_image_for_processing, places365_info=places365_info)\n",
        "\n",
        "            temp_dir = tempfile.gettempdir()\n",
        "            temp_filename = f\"temp_{uuid.uuid4().hex}.jpg\"\n",
        "            temp_path = os.path.join(temp_dir, temp_filename)\n",
        "            pil_image_for_processing.save(temp_path, format=\"JPEG\")\n",
        "\n",
        "            result = model_instance.detect(temp_path)\n",
        "\n",
        "            if result is None or not hasattr(result, 'boxes'):\n",
        "                scene_analysis_no_yolo = self.analyze_scene(result, lighting_info, enable_landmark=enable_landmark, places365_info=places365_info)\n",
        "                desc_no_yolo = scene_analysis_no_yolo.get(\"enhanced_description\", scene_analysis_no_yolo.get(\"description\", \"Detection failed, scene context analysis attempted.\"))\n",
        "                stats_data[\"scene_analysis\"] = scene_analysis_no_yolo\n",
        "                if places365_info:\n",
        "                    stats_data[\"places365_analysis\"] = places365_info\n",
        "                return pil_image_for_processing, desc_no_yolo, stats_data\n",
        "\n",
        "            # 統計資訊\n",
        "            stats_data = EvaluationMetrics.calculate_basic_stats(result)\n",
        "            spatial_metrics = EvaluationMetrics.calculate_distance_metrics(result)\n",
        "            stats_data[\"spatial_metrics\"] = spatial_metrics\n",
        "            stats_data[\"lighting_conditions\"] = lighting_info\n",
        "            if places365_info:\n",
        "                stats_data[\"places365_analysis\"] = places365_info\n",
        "\n",
        "            if filter_classes and len(filter_classes) > 0:\n",
        "                classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "                confs = result.boxes.conf.cpu().numpy()\n",
        "                mask = np.isin(classes, filter_classes)\n",
        "                filtered_stats_data = {\n",
        "                    \"total_objects\": int(np.sum(mask)), \"class_statistics\": {},\n",
        "                    \"average_confidence\": float(np.mean(confs[mask])) if np.any(mask) else 0.0,\n",
        "                    \"spatial_metrics\": stats_data.get(\"spatial_metrics\",{}),\n",
        "                    \"lighting_conditions\": lighting_info\n",
        "                }\n",
        "                if places365_info:\n",
        "                    filtered_stats_data[\"places365_analysis\"] = places365_info\n",
        "                names = result.names\n",
        "                class_conf_sums = {}\n",
        "                for cls_id_int, conf_val in zip(classes[mask], confs[mask]):\n",
        "                    cls_name = names[cls_id_int]\n",
        "                    if cls_name not in filtered_stats_data[\"class_statistics\"]:\n",
        "                        filtered_stats_data[\"class_statistics\"][cls_name] = {\"count\": 0}\n",
        "                        class_conf_sums[cls_name] = 0.0\n",
        "                    filtered_stats_data[\"class_statistics\"][cls_name][\"count\"] += 1 # 累計統計資訊\n",
        "                    class_conf_sums[cls_name] += conf_val\n",
        "                for cls_name_stat, data_stat in filtered_stats_data[\"class_statistics\"].items():\n",
        "                    data_stat[\"average_confidence\"] = round(class_conf_sums[cls_name_stat] / data_stat[\"count\"] if data_stat[\"count\"] > 0 else 0.0, 4)\n",
        "                stats_data = filtered_stats_data\n",
        "\n",
        "            viz_data = EvaluationMetrics.generate_visualization_data(result, self.color_mapper.get_all_colors())\n",
        "\n",
        "            result_image_pil = VisualizationHelper.visualize_detection(\n",
        "                temp_path, result, color_mapper=self.color_mapper,\n",
        "                figsize=(12, 12), return_pil=True, filter_classes=filter_classes\n",
        "            )\n",
        "\n",
        "            result_text_summary = EvaluationMetrics.format_detection_summary(viz_data)\n",
        "\n",
        "            #  Pass the enable_landmark parameter from function signature\n",
        "            # Initialize or update scene analyzer if needed\n",
        "            if self.scene_analyzer is None:\n",
        "                print(\"Creating SceneAnalyzer in process_image\")\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=result.names if result else None,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=enable_landmark,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "\n",
        "                if self.scene_analyzer is None:\n",
        "                    print(\"ERROR: Failed to create SceneAnalyzer in process_image\")\n",
        "            else:\n",
        "                # Update existing scene analyzer with current settings\n",
        "                if result and hasattr(result, 'names'):\n",
        "                    self.scene_analyzer.class_names = result.names\n",
        "                    if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                        self.scene_analyzer.spatial_analyzer.class_names = result.names\n",
        "\n",
        "                self.scene_analyzer.enable_landmark = enable_landmark\n",
        "                if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                    self.scene_analyzer.spatial_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "            # Perform scene analysis using the existing analyze_scene method\n",
        "            scene_analysis_result = self.analyze_scene(\n",
        "                detection_result=result,\n",
        "                lighting_info=lighting_info,\n",
        "                enable_landmark=enable_landmark,\n",
        "                places365_info=places365_info\n",
        "            )\n",
        "\n",
        "            stats_data[\"scene_analysis\"] = scene_analysis_result\n",
        "\n",
        "            final_result_text = result_text_summary\n",
        "\n",
        "            # Use enable_landmark parameter for landmark block\n",
        "            if enable_landmark and \"detected_landmarks\" in scene_analysis_result:\n",
        "                landmarks_detected = scene_analysis_result.get(\"detected_landmarks\", [])\n",
        "                if not landmarks_detected and scene_analysis_result.get(\"primary_landmark\"):\n",
        "                    primary_lm = scene_analysis_result.get(\"primary_landmark\")\n",
        "                    if isinstance(primary_lm, dict): landmarks_detected = [primary_lm]\n",
        "\n",
        "                if landmarks_detected:\n",
        "                    final_result_text += \"\\n\\n--- Detected Landmarks ---\\n\"\n",
        "                    # Ensure drawing on the correct PIL image\n",
        "                    img_to_draw_on = result_image_pil.copy() # Draw on a copy\n",
        "                    img_for_drawing_cv2 = cv2.cvtColor(np.array(img_to_draw_on), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                    for landmark_item in landmarks_detected:\n",
        "                        if not isinstance(landmark_item, dict): continue\n",
        "\n",
        "                        # Use .get() for all potentially missing keys 比較保險\n",
        "                        landmark_name_disp = landmark_item.get(\"class_name\", landmark_item.get(\"name\", \"N/A\"))\n",
        "                        landmark_loc_disp = landmark_item.get(\"location\", \"N/A\")\n",
        "                        landmark_conf_disp = landmark_item.get(\"confidence\", 0.0)\n",
        "\n",
        "                        final_result_text += f\"• {landmark_name_disp} ({landmark_loc_disp}, confidence: {landmark_conf_disp:.2f})\\n\"\n",
        "\n",
        "                        if \"box\" in landmark_item:\n",
        "                            box = landmark_item[\"box\"]\n",
        "                            pt1 = (int(box[0]), int(box[1])); pt2 = (int(box[2]), int(box[3]))\n",
        "                            color_lm = (255, 0, 255); thickness_lm = 3 # Magenta BGR\n",
        "                            cv2.rectangle(img_for_drawing_cv2, pt1, pt2, color_lm, thickness_lm)\n",
        "\n",
        "                            label_lm = f\"{landmark_name_disp} ({landmark_conf_disp:.2f})\"\n",
        "                            font_scale_lm = 0.6; font_thickness_lm = 1\n",
        "                            (w_text, h_text), baseline = cv2.getTextSize(label_lm, cv2.FONT_HERSHEY_SIMPLEX, font_scale_lm, font_thickness_lm)\n",
        "\n",
        "                            # Label position logic (simplified from your extensive one for brevity)\n",
        "                            label_y_pos = pt1[1] - baseline - 3\n",
        "                            if label_y_pos < h_text : # If label goes above image, put it below box\n",
        "                                label_y_pos = pt2[1] + h_text + baseline + 3\n",
        "\n",
        "                            label_bg_pt1 = (pt1[0], label_y_pos - h_text - baseline)\n",
        "                            label_bg_pt2 = (pt1[0] + w_text, label_y_pos + baseline)\n",
        "\n",
        "                            cv2.rectangle(img_for_drawing_cv2, label_bg_pt1, label_bg_pt2, color_lm, -1)\n",
        "                            cv2.putText(img_for_drawing_cv2, label_lm, (pt1[0], label_y_pos),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, font_scale_lm, (255,255,255), font_thickness_lm, cv2.LINE_AA)\n",
        "\n",
        "                    result_image_pil = Image.fromarray(cv2.cvtColor(img_for_drawing_cv2, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            return result_image_pil, final_result_text, stats_data\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error in ImageProcessor.process_image: {str(e)}\"\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return pil_image_for_processing if pil_image_for_processing else None, error_message, {}\n",
        "        finally:\n",
        "            if temp_path and os.path.exists(temp_path):\n",
        "                try: os.remove(temp_path)\n",
        "                except Exception as e: print(f\"Warning: Cannot delete temp file {temp_path}: {str(e)}\")\n",
        "\n",
        "    def format_result_text(self, stats: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Format detection statistics into readable text with improved spacing\n",
        "\n",
        "        Args:\n",
        "            stats: Dictionary containing detection statistics\n",
        "\n",
        "        Returns:\n",
        "            Formatted text summary\n",
        "        \"\"\"\n",
        "        if not stats or \"total_objects\" not in stats:\n",
        "            return \"No objects detected.\"\n",
        "\n",
        "        # 減少不必要的空行\n",
        "        lines = [\n",
        "            f\"Detected {stats['total_objects']} objects.\",\n",
        "            f\"Average confidence: {stats.get('average_confidence', 0):.2f}\",\n",
        "            \"Objects by class:\"\n",
        "        ]\n",
        "\n",
        "        if \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            # 按計數排序類別\n",
        "            sorted_classes = sorted(\n",
        "                stats[\"class_statistics\"].items(),\n",
        "                key=lambda x: x[1][\"count\"],\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            for cls_name, cls_stats in sorted_classes:\n",
        "                count = cls_stats[\"count\"]\n",
        "                conf = cls_stats.get(\"average_confidence\", 0)\n",
        "\n",
        "                item_text = \"item\" if count == 1 else \"items\"\n",
        "                lines.append(f\"• {cls_name}: {count} {item_text} (avg conf: {conf:.2f})\")\n",
        "        else:\n",
        "            lines.append(\"No class information available.\")\n",
        "\n",
        "        # 添加空間資訊\n",
        "        if \"spatial_metrics\" in stats and \"spatial_distribution\" in stats[\"spatial_metrics\"]:\n",
        "            lines.append(\"Object Distribution:\")\n",
        "\n",
        "            dist = stats[\"spatial_metrics\"][\"spatial_distribution\"]\n",
        "            x_mean = dist.get(\"x_mean\", 0)\n",
        "            y_mean = dist.get(\"y_mean\", 0)\n",
        "\n",
        "            # 描述物體的大致位置\n",
        "            if x_mean < 0.33:\n",
        "                h_pos = \"on the left side\"\n",
        "            elif x_mean < 0.67:\n",
        "                h_pos = \"in the center\"\n",
        "            else:\n",
        "                h_pos = \"on the right side\"\n",
        "\n",
        "            if y_mean < 0.33:\n",
        "                v_pos = \"in the upper part\"\n",
        "            elif y_mean < 0.67:\n",
        "                v_pos = \"in the middle\"\n",
        "            else:\n",
        "                v_pos = \"in the lower part\"\n",
        "\n",
        "            lines.append(f\"• Most objects appear {h_pos} {v_pos} of the image\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def format_json_for_display(self, stats: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Format statistics JSON for better display\n",
        "\n",
        "        Args:\n",
        "            stats: Raw statistics dictionary\n",
        "\n",
        "        Returns:\n",
        "            Formatted statistics structure for display\n",
        "        \"\"\"\n",
        "        # Create a cleaner copy of the stats for display\n",
        "        display_stats = {}\n",
        "\n",
        "        # Add summary section\n",
        "        display_stats[\"summary\"] = {\n",
        "            \"total_objects\": stats.get(\"total_objects\", 0),\n",
        "            \"average_confidence\": round(stats.get(\"average_confidence\", 0), 3)\n",
        "        }\n",
        "\n",
        "        # Add class statistics in a more organized way\n",
        "        if \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            # Sort classes by count (descending)\n",
        "            sorted_classes = sorted(\n",
        "                stats[\"class_statistics\"].items(),\n",
        "                key=lambda x: x[1].get(\"count\", 0),\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            class_stats = {}\n",
        "            for cls_name, cls_data in sorted_classes:\n",
        "                class_stats[cls_name] = {\n",
        "                    \"count\": cls_data.get(\"count\", 0),\n",
        "                    \"average_confidence\": round(cls_data.get(\"average_confidence\", 0), 3)\n",
        "                }\n",
        "\n",
        "            display_stats[\"detected_objects\"] = class_stats\n",
        "\n",
        "        # Simplify spatial metrics\n",
        "        if \"spatial_metrics\" in stats:\n",
        "            spatial = stats[\"spatial_metrics\"]\n",
        "\n",
        "            # Simplify spatial distribution\n",
        "            if \"spatial_distribution\" in spatial:\n",
        "                dist = spatial[\"spatial_distribution\"]\n",
        "                display_stats[\"spatial\"] = {\n",
        "                    \"distribution\": {\n",
        "                        \"x_mean\": round(dist.get(\"x_mean\", 0), 3),\n",
        "                        \"y_mean\": round(dist.get(\"y_mean\", 0), 3),\n",
        "                        \"x_std\": round(dist.get(\"x_std\", 0), 3),\n",
        "                        \"y_std\": round(dist.get(\"y_std\", 0), 3)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            # Add simplified size information\n",
        "            if \"size_distribution\" in spatial:\n",
        "                size = spatial[\"size_distribution\"]\n",
        "                display_stats[\"spatial\"][\"size\"] = {\n",
        "                    \"mean_area\": round(size.get(\"mean_area\", 0), 3),\n",
        "                    \"min_area\": round(size.get(\"min_area\", 0), 3),\n",
        "                    \"max_area\": round(size.get(\"max_area\", 0), 3)\n",
        "                }\n",
        "\n",
        "        return display_stats\n",
        "\n",
        "    def prepare_visualization_data(self, stats: Dict, available_classes: Dict[int, str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Prepare data for visualization based on detection statistics\n",
        "\n",
        "        Args:\n",
        "            stats: Detection statistics\n",
        "            available_classes: Dictionary of available class IDs and names\n",
        "\n",
        "        Returns:\n",
        "            Visualization data dictionary\n",
        "        \"\"\"\n",
        "        if not stats or \"class_statistics\" not in stats or not stats[\"class_statistics\"]:\n",
        "            return {\"error\": \"No detection data available\"}\n",
        "\n",
        "        # Prepare visualization data\n",
        "        viz_data = {\n",
        "            \"total_objects\": stats.get(\"total_objects\", 0),\n",
        "            \"average_confidence\": stats.get(\"average_confidence\", 0),\n",
        "            \"class_data\": []\n",
        "        }\n",
        "\n",
        "        # Class data\n",
        "        for cls_name, cls_stats in stats.get(\"class_statistics\", {}).items():\n",
        "            # Search class ID\n",
        "            class_id = -1\n",
        "            for id, name in available_classes.items():\n",
        "                if name == cls_name:\n",
        "                    class_id = id\n",
        "                    break\n",
        "\n",
        "            cls_data = {\n",
        "                \"name\": cls_name,\n",
        "                \"class_id\": class_id,\n",
        "                \"count\": cls_stats.get(\"count\", 0),\n",
        "                \"average_confidence\": cls_stats.get(\"average_confidence\", 0),\n",
        "                \"color\": self.color_mapper.get_color(class_id if class_id >= 0 else cls_name)\n",
        "            }\n",
        "\n",
        "            viz_data[\"class_data\"].append(cls_data)\n",
        "\n",
        "        # Descending order\n",
        "        viz_data[\"class_data\"].sort(key=lambda x: x[\"count\"], reverse=True)\n",
        "\n",
        "        return viz_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGtfLV0N2g10"
      },
      "outputs": [],
      "source": [
        "# %%writefile video_processor.py\n",
        "import cv2\n",
        "import os\n",
        "import tempfile\n",
        "import uuid\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "# from image_processor import ImageProcessor\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from scene_analyzer import SceneAnalyzer\n",
        "# from detection_model import DetectionModel\n",
        "\n",
        "class VideoProcessor:\n",
        "    \"\"\"\n",
        "    Handles the processing of video files, including object detection\n",
        "    and scene analysis on selected frames.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_processor: ImageProcessor):\n",
        "        \"\"\"\n",
        "        Initializes the VideoProcessor.\n",
        "\n",
        "        Args:\n",
        "            image_processor (ImageProcessor): An initialized ImageProcessor instance.\n",
        "        \"\"\"\n",
        "        self.image_processor = image_processor\n",
        "\n",
        "    def process_video_file(self,\n",
        "                           video_path: str,\n",
        "                           model_name: str,\n",
        "                           confidence_threshold: float,\n",
        "                           process_interval: int = 5,\n",
        "                           scene_desc_interval_sec: int = 3) -> Tuple[Optional[str], str, Dict]:\n",
        "        \"\"\"\n",
        "        Processes an uploaded video file, performs detection and periodic scene analysis,\n",
        "        and returns the path to the annotated output video file along with a summary.\n",
        "\n",
        "        Args:\n",
        "            video_path (str): Path to the input video file.\n",
        "            model_name (str): Name of the YOLO model to use.\n",
        "            confidence_threshold (float): Confidence threshold for object detection.\n",
        "            process_interval (int): Process every Nth frame. Defaults to 5.\n",
        "            scene_desc_interval_sec (int): Update scene description every N seconds. Defaults to 3.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Optional[str], str, Dict]: (Path to output video or None, Summary text, Statistics dictionary)\n",
        "        \"\"\"\n",
        "        if not video_path or not os.path.exists(video_path):\n",
        "            print(f\"Error: Video file not found at {video_path}\")\n",
        "            return None, \"Error: Video file not found.\", {}\n",
        "\n",
        "        print(f\"Starting video processing for: {video_path}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            return None, \"Error opening video file.\", {}\n",
        "\n",
        "        # Get video properties\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        if fps <= 0: # Handle case where fps is not available or invalid\n",
        "             fps = 30 # Assume a default fps\n",
        "             print(f\"Warning: Could not get valid FPS for video. Assuming {fps} FPS.\")\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(f\"Video properties: {width}x{height} @ {fps:.2f} FPS, Total Frames: {total_frames_video}\")\n",
        "\n",
        "        # Calculate description update interval in frames\n",
        "        description_update_interval_frames = int(fps * scene_desc_interval_sec)\n",
        "        if description_update_interval_frames < 1:\n",
        "            description_update_interval_frames = int(fps) # Update at least once per second if interval is too short\n",
        "\n",
        "        object_trackers = {}  # 儲存ID與物體的映射\n",
        "        last_detected_objects = {}  # 儲存上一次檢測到的物體資訊\n",
        "        next_object_id = 0  # 下一個可用的物體ID\n",
        "        tracking_threshold = 0.6  # 相同物體的IoU\n",
        "        object_colors = {}  # 每個被追蹤的物體分配固定顏色\n",
        "\n",
        "        # Setup Output Video\n",
        "        output_filename = f\"processed_{uuid.uuid4().hex}_{os.path.basename(video_path)}\"\n",
        "        temp_dir = tempfile.gettempdir() # Use system's temp directory\n",
        "        output_path = os.path.join(temp_dir, output_filename)\n",
        "        # Ensure the output path has a compatible extension (like .mp4)\n",
        "        if not output_path.lower().endswith(('.mp4', '.avi', '.mov')):\n",
        "            output_path += \".mp4\"\n",
        "\n",
        "        # Use 'mp4v' for MP4, common and well-supported\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "        if not out.isOpened():\n",
        "            print(f\"Error: Could not open VideoWriter for path: {output_path}\")\n",
        "            cap.release()\n",
        "            return None, f\"Error creating output video file at {output_path}.\", {}\n",
        "        print(f\"Output video will be saved to: {output_path}\")\n",
        "\n",
        "        frame_count = 0\n",
        "        processed_frame_count = 0\n",
        "        all_stats = [] # Store stats for each processed frame\n",
        "        summary_lines = []\n",
        "        last_description = \"Analyzing scene...\" # Initial description\n",
        "        frame_since_last_desc = description_update_interval_frames # Trigger analysis on first processed frame\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break # End of video\n",
        "\n",
        "                frame_count += 1\n",
        "                frame_since_last_desc += 1\n",
        "                current_frame_annotated = False # Flag if this frame was processed and annotated\n",
        "\n",
        "                # Process frame based on interval\n",
        "                if frame_count % process_interval == 0:\n",
        "                    processed_frame_count += 1\n",
        "                    print(f\"Processing frame {frame_count}...\")\n",
        "                    current_frame_annotated = True\n",
        "\n",
        "                    # Use ImageProcessor for single-frame tasks\n",
        "                    # 1. Convert frame format BGR -> RGB -> PIL\n",
        "                    try:\n",
        "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                        pil_image = Image.fromarray(frame_rgb)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error converting frame {frame_count}: {e}\")\n",
        "                        continue # Skip this frame\n",
        "\n",
        "                    # 2. Get appropriate model instance\n",
        "                    # Confidence is passed from UI, model_name too\n",
        "                    model_instance = self.image_processor.get_model_instance(model_name, confidence_threshold)\n",
        "                    if not model_instance or not model_instance.is_model_loaded:\n",
        "                         print(f\"Error: Model {model_name} not loaded. Skipping frame {frame_count}.\")\n",
        "                         # Draw basic frame without annotation\n",
        "                         cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
        "                         cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "                         out.write(frame)\n",
        "                         continue\n",
        "\n",
        "\n",
        "                    # 3. Perform detection\n",
        "                    detection_result = model_instance.detect(pil_image) # Use PIL image\n",
        "\n",
        "                    current_description_for_frame = last_description # Default to last known description\n",
        "                    scene_analysis_result = None\n",
        "                    stats = {}\n",
        "\n",
        "                    if detection_result and hasattr(detection_result, 'boxes') and len(detection_result.boxes) > 0:\n",
        "                        # Ensure SceneAnalyzer is ready within ImageProcessor\n",
        "                        if not hasattr(self.image_processor, 'scene_analyzer') or self.image_processor.scene_analyzer is None:\n",
        "                             print(\"Initializing SceneAnalyzer...\")\n",
        "                             # Pass class names from the current detection result\n",
        "                             self.image_processor.scene_analyzer = SceneAnalyzer(class_names=detection_result.names)\n",
        "                        elif self.image_processor.scene_analyzer.class_names is None:\n",
        "                             # Update class names if they were missing\n",
        "                             self.image_processor.scene_analyzer.class_names = detection_result.names\n",
        "                             if hasattr(self.image_processor.scene_analyzer, 'spatial_analyzer'):\n",
        "                                 self.image_processor.scene_analyzer.spatial_analyzer.class_names = detection_result.names\n",
        "\n",
        "\n",
        "                        # 4. Perform Scene Analysis (periodically)\n",
        "                        if frame_since_last_desc >= description_update_interval_frames:\n",
        "                            print(f\"Analyzing scene at frame {frame_count} (threshold: {description_update_interval_frames} frames)...\")\n",
        "                            # Pass lighting_info=None for now, as it's disabled for performance\n",
        "                            scene_analysis_result = self.image_processor.analyze_scene(detection_result, lighting_info=None)\n",
        "                            current_description_for_frame = scene_analysis_result.get(\"description\", last_description)\n",
        "                            last_description = current_description_for_frame # Cache the new description\n",
        "                            frame_since_last_desc = 0 # Reset counter\n",
        "\n",
        "                        # 5. Calculate Statistics for this frame\n",
        "                        stats = EvaluationMetrics.calculate_basic_stats(detection_result)\n",
        "                        stats['frame_number'] = frame_count # Add frame number to stats\n",
        "                        all_stats.append(stats)\n",
        "\n",
        "                        # 6. Draw annotations\n",
        "                        names = detection_result.names\n",
        "                        boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
        "                        classes = detection_result.boxes.cls.cpu().numpy().astype(int)\n",
        "                        confs = detection_result.boxes.conf.cpu().numpy()\n",
        "\n",
        "                        def calculate_iou(box1, box2):\n",
        "                            \"\"\"Calculate Intersection IOU value\"\"\"\n",
        "                            x1_1, y1_1, x2_1, y2_1 = box1\n",
        "                            x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "                            xi1 = max(x1_1, x1_2)\n",
        "                            yi1 = max(y1_1, y1_2)\n",
        "                            xi2 = min(x2_1, x2_2)\n",
        "                            yi2 = min(y2_1, y2_2)\n",
        "\n",
        "                            inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "                            box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "                            box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "\n",
        "                            union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "                            return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "                        # 處理當前幀中的所有檢測\n",
        "                        current_detected_objects = {}\n",
        "\n",
        "                        for box, cls_id, conf in zip(boxes, classes, confs):\n",
        "                            x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                            # 查找最匹配的已追蹤物體\n",
        "                            best_match_id = None\n",
        "                            best_match_iou = 0\n",
        "\n",
        "                            for obj_id, (old_box, old_cls_id, _) in last_detected_objects.items():\n",
        "                                if old_cls_id == cls_id:  # 同一類別才比較\n",
        "                                    iou = calculate_iou(box, old_box)\n",
        "                                    if iou > tracking_threshold and iou > best_match_iou:\n",
        "                                        best_match_id = obj_id\n",
        "                                        best_match_iou = iou\n",
        "\n",
        "                            # 如果找到匹配，使用現有ID；否則分配新ID\n",
        "                            if best_match_id is not None:\n",
        "                                obj_id = best_match_id\n",
        "                            else:\n",
        "                                obj_id = next_object_id\n",
        "                                next_object_id += 1\n",
        "\n",
        "                                # 使用更明顯的顏色\n",
        "                                bright_colors = [\n",
        "                                    (0, 0, 255),    # red\n",
        "                                    (0, 255, 0),    # green\n",
        "                                    (255, 0, 0),    # blue\n",
        "                                    (0, 255, 255),  # yellow\n",
        "                                    (255, 0, 255),  # purple\n",
        "                                    (255, 128, 0),  # orange\n",
        "                                    (128, 0, 255)   # purple\n",
        "                                ]\n",
        "                                object_colors[obj_id] = bright_colors[obj_id % len(bright_colors)]\n",
        "\n",
        "                            # update tracking info\n",
        "                            current_detected_objects[obj_id] = (box, cls_id, conf)\n",
        "\n",
        "                            color = object_colors.get(obj_id, (0, 255, 0))  # default is green\n",
        "                            label = f\"{names.get(cls_id, 'Unknown')}-{obj_id}: {conf:.2f}\"\n",
        "\n",
        "                            # 平滑化邊界框：如果是已知物體，與上一幀位置平均\n",
        "                            if obj_id in last_detected_objects:\n",
        "                                old_box, _, _ = last_detected_objects[obj_id]\n",
        "                                old_x1, old_y1, old_x2, old_y2 = map(int, old_box)\n",
        "                                # 平滑係數\n",
        "                                alpha = 0.7  # current weight\n",
        "                                beta = 0.3   # history weight\n",
        "\n",
        "                                x1 = int(alpha * x1 + beta * old_x1)\n",
        "                                y1 = int(alpha * y1 + beta * old_y1)\n",
        "                                x2 = int(alpha * x2 + beta * old_x2)\n",
        "                                y2 = int(alpha * y2 + beta * old_y2)\n",
        "\n",
        "                            # draw box and label\n",
        "                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                            # add text\n",
        "                            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "                            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1 - 10), color, -1)\n",
        "                            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "                        # update tracking info\n",
        "                        last_detected_objects = current_detected_objects.copy()\n",
        "\n",
        "\n",
        "                    # Draw the current scene description on the frame\n",
        "                    cv2.putText(frame, f\"Scene: {current_description_for_frame[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA) # Black outline\n",
        "                    cv2.putText(frame, f\"Scene: {current_description_for_frame[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA) # White text\n",
        "\n",
        "                # Write the frame (annotated or original) to the output video\n",
        "                # Draw last known description if this frame wasn't processed\n",
        "                if not current_frame_annotated:\n",
        "                    cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
        "                    cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "                out.write(frame) # Write frame to output file\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during video processing loop for {video_path}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            summary_lines.append(f\"An error occurred during processing: {e}\")\n",
        "        finally:\n",
        "            # Release resources\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            print(f\"Video processing finished. Resources released. Output path: {output_path}\")\n",
        "            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "                print(f\"Error: Output video file was not created or is empty at {output_path}\")\n",
        "                summary_lines.append(\"Error: Failed to create output video.\")\n",
        "                output_path = None\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        summary_lines.insert(0, f\"Finished processing in {processing_time:.2f} seconds.\")\n",
        "        summary_lines.insert(1, f\"Processed {processed_frame_count} frames out of {frame_count} (interval: {process_interval} frames).\")\n",
        "        summary_lines.insert(2, f\"Scene description updated approximately every {scene_desc_interval_sec} seconds.\")\n",
        "\n",
        "        # Generate Aggregate Statistics\n",
        "        aggregated_stats = {\n",
        "            \"total_frames_read\": frame_count,\n",
        "            \"total_frames_processed\": processed_frame_count,\n",
        "            \"avg_objects_per_processed_frame\": 0, # Calculate below\n",
        "            \"cumulative_detections\": {}, # Total times each class was detected\n",
        "            \"max_concurrent_detections\": {} # Max count of each class in a single processed frame\n",
        "            }\n",
        "        object_cumulative_counts = {}\n",
        "        object_max_concurrent_counts = {} # Store the max count found for each object type\n",
        "        total_detected_in_processed = 0\n",
        "\n",
        "        # Iterate through stats collected from each processed frame\n",
        "        for frame_stats in all_stats:\n",
        "            total_objects_in_frame = frame_stats.get(\"total_objects\", 0)\n",
        "            total_detected_in_processed += total_objects_in_frame\n",
        "\n",
        "            # Iterate through object classes detected in this frame\n",
        "            for obj_name, obj_data in frame_stats.get(\"class_statistics\", {}).items():\n",
        "                count_in_frame = obj_data.get(\"count\", 0)\n",
        "\n",
        "                # Cumulative count\n",
        "                if obj_name not in object_cumulative_counts:\n",
        "                    object_cumulative_counts[obj_name] = 0\n",
        "                object_cumulative_counts[obj_name] += count_in_frame\n",
        "\n",
        "                # Max concurrent count\n",
        "                if obj_name not in object_max_concurrent_counts:\n",
        "                    object_max_concurrent_counts[obj_name] = 0\n",
        "                # Update the max count if the current frame's count is higher\n",
        "                object_max_concurrent_counts[obj_name] = max(object_max_concurrent_counts[obj_name], count_in_frame)\n",
        "\n",
        "        # Add sorted results to the final dictionary\n",
        "        aggregated_stats[\"cumulative_detections\"] = dict(sorted(object_cumulative_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "        aggregated_stats[\"max_concurrent_detections\"] = dict(sorted(object_max_concurrent_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "        # Calculate average objects per processed frame\n",
        "        if processed_frame_count > 0:\n",
        "             aggregated_stats[\"avg_objects_per_processed_frame\"] = round(total_detected_in_processed / processed_frame_count, 2)\n",
        "\n",
        "        summary_text = \"\\n\".join(summary_lines)\n",
        "        print(\"Generated Summary:\\n\", summary_text)\n",
        "        print(\"Aggregated Stats (Revised):\\n\", aggregated_stats) # Print the revised stats\n",
        "\n",
        "        # Return the potentially updated output_path\n",
        "        return output_path, summary_text, aggregated_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM2qYKBBjz--"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import torch\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "import logging\n",
        "\n",
        "class LLMEnhancer:\n",
        "    \"\"\"\n",
        "    負責使用LLM (Large Language Model) 增強場景理解和描述。\n",
        "    未來可以再整合Llama或其他LLM模型進行場景描述的生成和豐富化。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                model_path: Optional[str] = None,\n",
        "                tokenizer_path: Optional[str] = None,\n",
        "                device: Optional[str] = None,\n",
        "                max_length: int = 2048,\n",
        "                temperature: float = 0.3,\n",
        "                top_p: float = 0.85):\n",
        "        \"\"\"\n",
        "        初始化LLM增強器\n",
        "        Args:\n",
        "            model_path: LLM模型的路徑或HuggingFace log in，默認使用Llama 3.2\n",
        "            tokenizer_path: token處理器的路徑，通常與model_path相同\n",
        "            device: 設備檢查 ('cpu'或'cuda')\n",
        "            max_length: 生成文本的最大長度\n",
        "            temperature: 生成文本的溫度（較高比較有創意，較低會偏保守）\n",
        "            top_p: 生成文本時的核心採樣機率閾值\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(\"LLMEnhancer\")\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "        handler = logging.StreamHandler()\n",
        "        handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "        self.logger.addHandler(handler)\n",
        "\n",
        "        # 默認用 Llama3.2\n",
        "        self.model_path = model_path or \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "        self.tokenizer_path = tokenizer_path or self.model_path\n",
        "\n",
        "        # check device\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.logger.info(f\"Using device: {self.device}\")\n",
        "\n",
        "        # create parameters\n",
        "        self.max_length = max_length\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "\n",
        "        # 追蹤模型調用次數\n",
        "        self.call_count = 0\n",
        "\n",
        "        self._initialize_prompts()\n",
        "\n",
        "        # only if need to load the model\n",
        "        self._model_loaded = False\n",
        "\n",
        "        try:\n",
        "            self.hf_token = os.environ.get(\"HF_TOKEN\")\n",
        "            if self.hf_token:\n",
        "                self.logger.info(\"Logging in to Hugging Face with token\")\n",
        "                from huggingface_hub import login\n",
        "                login(token=self.hf_token)\n",
        "            else:\n",
        "                self.logger.warning(\"HF_TOKEN not found in environment variables. Access to gated models may be limited.\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error during Hugging Face login: {e}\")\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"只在首次需要時加載，使用 8 位量化以節省記憶體\"\"\"\n",
        "        if self._model_loaded:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Loading LLM model from {self.model_path} with 8-bit quantization\")\n",
        "            import torch\n",
        "            from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                free_in_GB = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "                print(f\"Total GPU memory: {free_in_GB:.2f} GB\")\n",
        "\n",
        "            # 設置 8 位元配置(節省記憶體空間)\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_8bit=True,\n",
        "                llm_int8_enable_fp32_cpu_offload=True\n",
        "            )\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.tokenizer_path,\n",
        "                padding_side=\"left\",\n",
        "                use_fast=False,\n",
        "                token=self.hf_token\n",
        "            )\n",
        "\n",
        "            # 特殊標記\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # 加載 8 位量化模型\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_path,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                low_cpu_mem_usage=True,\n",
        "                token=self.hf_token\n",
        "            )\n",
        "\n",
        "            self.logger.info(\"Model loaded successfully with 8-bit quantization\")\n",
        "            self._model_loaded = True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading LLM model: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def _initialize_prompts(self):\n",
        "        \"\"\"Return an optimized prompt template specifically for Zephyr model\"\"\"\n",
        "        # the critical prompt for the model\n",
        "        self.enhance_description_template = \"\"\"\n",
        "            <|system|>\n",
        "            You are an expert visual analyst. Your task is to improve the readability and fluency of scene descriptions using STRICT factual accuracy.\n",
        "            Your **top priority is to avoid hallucination** or fabrication. You are working in a computer vision pipeline using object detection (YOLO) and image embeddings. You MUST treat the input object list as a whitelist. Do not speculate beyond this list.\n",
        "            </|system|>\n",
        "            <|user|>\n",
        "            Rewrite the following scene description to be fluent and clear. DO NOT add any objects, events, or spatial relationships that are not explicitly present in the original or object list.\n",
        "            ORIGINAL:\n",
        "            {original_description}\n",
        "            CRITICAL RULES:\n",
        "            1. NEVER assume room type, object function, or scene purpose unless directly stated.\n",
        "            2. NEVER invent object types. You are limited to: {object_list}\n",
        "            3. NEVER speculate on object quantity. If the description says \"10 people\" , DO NOT say \"dozens\" or \"many\". Maintain the original quantity unless specified.\n",
        "            4. Use terms like \"in the scene\", \"visible in the background\", or \"positioned in the lower left\" instead of assuming direction or layout logic.\n",
        "            5. You MAY describe confirmed materials, colors, and composition style if visually obvious and non-speculative.\n",
        "            6. Write 2–4 complete, well-structured sentences with punctuation.\n",
        "            7. Final output MUST be a single fluent paragraph of 60–200 words (not longer).\n",
        "            8. Begin your response directly with the scene description. Do NOT include any introductory phrases, explanations, or formatting indicators.\n",
        "            9. Ensure grammatical completeness in all sentences. Each sentence must have a complete subject and predicate structure.\n",
        "            10. Vary sentence structures naturally while maintaining grammatical accuracy. Avoid incomplete phrases or dangling modifiers.\n",
        "            11. Limit repetition of descriptive verbs and spatial indicators to maintain text diversity and readability.\n",
        "            12. Create natural spatial flow by connecting object descriptions organically rather than listing positions mechanically.\n",
        "            13. Use transitional phrases to connect ideas smoothly, varying expression patterns throughout the description.\n",
        "            14. End with a conclusive observation about atmosphere, style, or overall impression rather than restating layout information.\n",
        "            15. When describing quantities or arrangements, use only information explicitly confirmed by the object detection system.\n",
        "            </|user|>\n",
        "            <|assistant|>\n",
        "            \"\"\"\n",
        "\n",
        "        # 錯誤檢測的prompt\n",
        "        self.verify_detection_template = \"\"\"\n",
        "            Task: You are an advanced vision system that verifies computer vision detections for accuracy.\n",
        "            Analyze the following detection results and identify any potential errors or inconsistencies:\n",
        "            SCENE TYPE: {scene_type}\n",
        "            SCENE NAME: {scene_name}\n",
        "            CONFIDENCE: {confidence:.2f}\n",
        "            DETECTED OBJECTS: {detected_objects}\n",
        "            CLIP ANALYSIS RESULTS:\n",
        "            {clip_analysis}\n",
        "            Possible Errors to Check:\n",
        "            1. Objects misidentified (e.g., architectural elements labeled as vehicles)\n",
        "            2. Cultural elements misunderstood (e.g., Asian temple structures labeled as boats)\n",
        "            3. Objects that seem out of place for this type of scene\n",
        "            4. Inconsistencies between different detection systems\n",
        "            If you find potential errors, list them clearly with explanations. If the detections seem reasonable, state that they appear accurate.\n",
        "            Verification Results:\n",
        "            \"\"\"\n",
        "\n",
        "        # 無檢測處理的prompt\n",
        "        self.no_detection_template = \"\"\"\n",
        "            Task: You are an advanced scene understanding system analyzing an image where standard object detection failed to identify specific objects.\n",
        "            Based on advanced image embeddings (CLIP analysis), we have the following information:\n",
        "            MOST LIKELY SCENE: {top_scene} (confidence: {top_confidence:.2f})\n",
        "            VIEWPOINT: {viewpoint}\n",
        "            LIGHTING: {lighting_condition}\n",
        "            CULTURAL ANALYSIS: {cultural_analysis}\n",
        "            Create a detailed description of what might be in this scene, considering:\n",
        "            1. The most likely type of location or setting\n",
        "            2. Possible architectural or natural elements present\n",
        "            3. The lighting and atmosphere\n",
        "            4. Potential cultural or regional characteristics\n",
        "            Your description should be natural, flowing, and offer insights into what the image likely contains despite the lack of specific object detection.\n",
        "            Scene Description:\n",
        "            \"\"\"\n",
        "\n",
        "    def _clean_llama_response(self, response: str) -> str:\n",
        "        \"\"\"處理 Llama 模型特有的輸出格式問題\"\"\"\n",
        "        # 首先應用通用清理\n",
        "        response = self._clean_model_response(response)\n",
        "\n",
        "        # 移除 Llama 常見的前綴短語\n",
        "        prefixes_to_remove = [\n",
        "            \"Here's the enhanced description:\",\n",
        "            \"Enhanced description:\",\n",
        "            \"Here is the enhanced scene description:\",\n",
        "            \"I've enhanced the description while preserving all factual details:\"\n",
        "        ]\n",
        "\n",
        "        for prefix in prefixes_to_remove:\n",
        "            if response.lower().startswith(prefix.lower()):\n",
        "                response = response[len(prefix):].strip()\n",
        "\n",
        "        # 移除可能的後綴說明\n",
        "        suffixes_to_remove = [\n",
        "            \"I've maintained all the key factual elements\",\n",
        "            \"I've preserved all the factual details\",\n",
        "            \"All factual elements have been maintained\"\n",
        "        ]\n",
        "\n",
        "        for suffix in suffixes_to_remove:\n",
        "            if response.lower().endswith(suffix.lower()):\n",
        "                response = response[:response.rfind(suffix)].strip()\n",
        "\n",
        "        return response\n",
        "\n",
        "    # For Future Usage\n",
        "    def _detect_scene_type(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        Detect scene type based on object distribution and patterns\n",
        "        \"\"\"\n",
        "        # Default scene type\n",
        "        scene_type = \"intersection\"\n",
        "\n",
        "        # Count objects by class\n",
        "        object_counts = {}\n",
        "        for obj in detected_objects:\n",
        "            class_name = obj.get(\"class_name\", \"\")\n",
        "            if class_name not in object_counts:\n",
        "                object_counts[class_name] = 0\n",
        "            object_counts[class_name] += 1\n",
        "\n",
        "        # 辨識人\n",
        "        people_count = object_counts.get(\"person\", 0)\n",
        "\n",
        "        # 交通工具的\n",
        "        car_count = object_counts.get(\"car\", 0)\n",
        "        bus_count = object_counts.get(\"bus\", 0)\n",
        "        truck_count = object_counts.get(\"truck\", 0)\n",
        "        total_vehicles = car_count + bus_count + truck_count\n",
        "\n",
        "        # Simple scene type detection logic\n",
        "        if people_count > 8 and total_vehicles < 2:\n",
        "            scene_type = \"pedestrian_crossing\"\n",
        "        elif people_count > 5 and total_vehicles > 2:\n",
        "            scene_type = \"busy_intersection\"\n",
        "        elif people_count < 3 and total_vehicles > 3:\n",
        "            scene_type = \"traffic_junction\"\n",
        "\n",
        "        return scene_type\n",
        "\n",
        "    def _clean_scene_type(self, scene_type: str) -> str:\n",
        "        \"\"\"清理場景類型，使其更適合用於提示詞\"\"\"\n",
        "        if not scene_type:\n",
        "            return \"scene\"\n",
        "\n",
        "        # replace underline to space or sometime capital letter\n",
        "        if '_' in scene_type:\n",
        "            return ' '.join(word.capitalize() for word in scene_type.split('_'))\n",
        "\n",
        "        return scene_type\n",
        "\n",
        "    def _clean_model_response(self, response: str) -> str:\n",
        "        \"\"\"清理模型回應以移除常見的標記和前綴\"\"\"\n",
        "        # 移除任何可能殘留的系統樣式標記\n",
        "        response = re.sub(r'<\\|.*?\\|>', '', response)\n",
        "\n",
        "        # 移除任何 \"This european_plaza\" 或類似前綴\n",
        "        response = re.sub(r'^This [a-z_]+\\s+', '', response)\n",
        "\n",
        "        # 確保響應以大寫字母開頭\n",
        "        if response and not response[0].isupper():\n",
        "            response = response[0].upper() + response[1:]\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "    def reset_context(self):\n",
        "        \"\"\"在處理新圖像前重置模型上下文\"\"\"\n",
        "        if self._model_loaded:\n",
        "            # 清除 GPU 緩存\n",
        "            torch.cuda.empty_cache()\n",
        "            self.logger.info(\"Model context reset\")\n",
        "        else:\n",
        "            self.logger.info(\"Model not loaded, no context to reset\")\n",
        "\n",
        "    def _remove_introduction_sentences(self, response: str) -> str:\n",
        "        \"\"\"remove introduction sentences\"\"\"\n",
        "        # 識別常見的介紹性模式\n",
        "        intro_patterns = [\n",
        "            r'^Here is the (?:rewritten|enhanced) .*?description:',\n",
        "            r'^The (?:rewritten|enhanced) description:',\n",
        "            r'^Here\\'s the (?:rewritten|enhanced) description of .*?:'\n",
        "        ]\n",
        "\n",
        "        for pattern in intro_patterns:\n",
        "            if re.match(pattern, response, re.IGNORECASE):\n",
        "                # 找到冒號後的內容\n",
        "                parts = re.split(r':', response, 1)\n",
        "                if len(parts) > 1:\n",
        "                    return parts[1].strip()\n",
        "\n",
        "        return response\n",
        "\n",
        "    def enhance_description(self, scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"場景描述增強器，處理各種場景類型並保留視角與光照資訊，並作為總窗口可運用於其他class\"\"\"\n",
        "        try:\n",
        "            # 重置上下文\n",
        "            self.reset_context()\n",
        "\n",
        "            # 確保模型已加載\n",
        "            if not self._model_loaded:\n",
        "                self._load_model()\n",
        "\n",
        "            # extract original description\n",
        "            original_desc = scene_data.get(\"original_description\", \"\")\n",
        "            if not original_desc:\n",
        "                return \"No original description provided.\"\n",
        "\n",
        "            # get scene type 並標準化\n",
        "            scene_type = scene_data.get(\"scene_type\", \"unknown scene\")\n",
        "            scene_type = self._clean_scene_type(scene_type)\n",
        "\n",
        "            # 提取檢測到的物件並過濾低信心度物件\n",
        "            detected_objects = scene_data.get(\"detected_objects\", [])\n",
        "            filtered_objects = []\n",
        "\n",
        "            # 高信心度閾值，嚴格過濾物件\n",
        "            high_confidence_threshold = 0.65\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                confidence = obj.get(\"confidence\", 0)\n",
        "                class_name = obj.get(\"class_name\", \"\")\n",
        "\n",
        "                # 為特殊類別設置更高閾值\n",
        "                special_classes = [\"airplane\", \"helicopter\", \"boat\"]\n",
        "                if class_name in special_classes:\n",
        "                    if confidence < 0.75:  # 為這些類別設置更高閾值\n",
        "                        continue\n",
        "\n",
        "                # 只保留高信心度物件\n",
        "                if confidence >= high_confidence_threshold:\n",
        "                    filtered_objects.append(obj)\n",
        "\n",
        "            # 優先使用傳入的物體統計信息，如果不存在則計算\n",
        "            object_statistics = scene_data.get(\"object_statistics\", {})\n",
        "            object_counts = {}\n",
        "\n",
        "            if object_statistics:\n",
        "                # 使用預計算的統計資訊，確保數量準確\n",
        "                for class_name, stats in object_statistics.items():\n",
        "                    if stats.get(\"count\", 0) > 0 and stats.get(\"avg_confidence\", 0) >= high_confidence_threshold:\n",
        "                        object_counts[class_name] = stats[\"count\"]\n",
        "            else:\n",
        "                # 回退到原有的計算方式\n",
        "                for obj in filtered_objects:\n",
        "                    class_name = obj.get(\"class_name\", \"\")\n",
        "                    if class_name not in object_counts:\n",
        "                        object_counts[class_name] = 0\n",
        "                    object_counts[class_name] += 1\n",
        "\n",
        "            # 將物件格式化為更精確的描述\n",
        "            high_confidence_objects = \", \".join([\n",
        "                f\"{count} {obj}{'s' if count > 1 else ''}\"\n",
        "                for obj, count in object_counts.items()\n",
        "            ])\n",
        "\n",
        "            # 如果沒有高信心度物件，回退到使用原始描述中的關鍵詞\n",
        "            if not high_confidence_objects:\n",
        "                # 從原始描述中提取物件提及\n",
        "                object_keywords = self._extract_objects_from_description(original_desc)\n",
        "                high_confidence_objects = \", \".join(object_keywords) if object_keywords else \"objects visible in the scene\"\n",
        "\n",
        "            # 保留原始描述中的關鍵視角信息\n",
        "            perspective = self._extract_perspective_from_description(original_desc)\n",
        "\n",
        "            # 提取光照資訊\n",
        "            lighting_description = \"unknown lighting\"\n",
        "            if \"lighting_info\" in scene_data:\n",
        "                lighting_info = scene_data.get(\"lighting_info\", {})\n",
        "                time_of_day = lighting_info.get(\"time_of_day\", \"unknown\")\n",
        "                is_indoor = lighting_info.get(\"is_indoor\", False)\n",
        "                lighting_description = f\"{'indoor' if is_indoor else 'outdoor'} {time_of_day} lighting\"\n",
        "\n",
        "            # 創建prompt，整合所有關鍵資訊\n",
        "            prompt = self.enhance_description_template.format(\n",
        "                scene_type=scene_type,\n",
        "                object_list=high_confidence_objects,\n",
        "                original_description=original_desc,\n",
        "                perspective=perspective,\n",
        "                lighting_description=lighting_description\n",
        "            )\n",
        "\n",
        "            # 生成增強描述\n",
        "            self.logger.info(\"Generating LLM response...\")\n",
        "            response = self._generate_llm_response(prompt)\n",
        "\n",
        "            # 檢查回應完整性的更嚴格標準\n",
        "            is_landmark_only = (\n",
        "                    scene_data.get(\"scene_type\") in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"] and\n",
        "                    (not scene_data.get(\"detected_objects\") or len(scene_data.get(\"detected_objects\", [])) <= 1)\n",
        "                )\n",
        "\n",
        "            # 如果是只有地標的情況，調整相關邏輯\n",
        "            if is_landmark_only:\n",
        "                # 確保原始描述不為空\n",
        "                original_desc = scene_data.get(\"original_description\", \"\")\n",
        "                if not original_desc or len(original_desc.strip()) < 10:\n",
        "                    # 從場景類型和地標信息生成基本描述\n",
        "                    scene_type = scene_data.get(\"scene_type\", \"unknown\")\n",
        "                    scene_name = scene_data.get(\"scene_name\", \"Unknown\")\n",
        "                    if \"primary_landmark\" in scene_data:\n",
        "                        landmark_name = scene_data[\"primary_landmark\"].get(\"name\", \"unnamed landmark\")\n",
        "                        original_desc = f\"A {scene_type.replace('_', ' ')} scene featuring {landmark_name}.\"\n",
        "                    else:\n",
        "                        original_desc = f\"A {scene_type.replace('_', ' ')} scene.\"\n",
        "\n",
        "                    # 更新場景數據\n",
        "                    scene_data[\"original_description\"] = original_desc\n",
        "\n",
        "            # 檢查回應完整性的更嚴格標準 (保持不變)\n",
        "            is_incomplete = (\n",
        "                len(response) < 100 or  # too short\n",
        "                (len(response) < 200 and \".\" not in response[-30:]) or  # 結尾沒有適當的標點符號\n",
        "                any(response.endswith(phrase) for phrase in [\"in the\", \"with the\", \"and the\"])  # 以不完整短語結尾\n",
        "            )\n",
        "\n",
        "            max_retries = 3\n",
        "            attempts = 0\n",
        "            while attempts < max_retries and is_incomplete:\n",
        "                self.logger.warning(f\"Generated incomplete response, retrying... Attempt {attempts+1}/{max_retries}\")\n",
        "                # 重新生成\n",
        "                response = self._generate_llm_response(prompt)\n",
        "                attempts += 1\n",
        "\n",
        "                # 重新檢查完整性\n",
        "                is_incomplete = (len(response) < 100 or\n",
        "                                (len(response) < 200 and \".\" not in response[-30:]) or\n",
        "                                any(response.endswith(phrase) for phrase in [\"in the\", \"with the\", \"and the\"]))\n",
        "\n",
        "            if not response or len(response.strip()) < 10:\n",
        "                self.logger.warning(\"Generated response was empty or too short, returning original description\")\n",
        "                return original_desc\n",
        "\n",
        "            # 使用與模型相符的清理方法\n",
        "            if \"llama\" in self.model_path.lower():\n",
        "                result = self._clean_llama_response(response)\n",
        "            else:\n",
        "                result = self._clean_model_response(response)\n",
        "\n",
        "            # 移除介紹性type句子\n",
        "            result = self._remove_introduction_sentences(result)\n",
        "\n",
        "            # 移除explanation\n",
        "            result = self._remove_explanatory_notes(result)\n",
        "\n",
        "            # fact check\n",
        "            result = self._verify_factual_accuracy(original_desc, result, high_confidence_objects)\n",
        "\n",
        "            # 確保場景類型和視角一致性\n",
        "            result = self._ensure_scene_type_consistency(result, scene_type, original_desc)\n",
        "            if perspective and perspective.lower() not in result.lower():\n",
        "                result = f\"{perspective}, {result[0].lower()}{result[1:]}\"\n",
        "\n",
        "            final_result = str(result)\n",
        "            if not final_result or len(final_result.strip()) < 20:\n",
        "                self.logger.warning(f\"WARNING: LLM enhanced description is empty or too short!\")\n",
        "                self.logger.info(f\"Original description: {original_desc[:50]}...\")\n",
        "                self.logger.info(f\"Input data: scene_type={scene_data.get('scene_type')}, objects={len(scene_data.get('detected_objects', []))}\")\n",
        "            else:\n",
        "                self.logger.info(f\"LLM enhanced description generated successfully ({len(final_result)} chars)\")\n",
        "\n",
        "            return final_result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Enhancement failed: {str(e)}\")\n",
        "            import traceback\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return original_desc  # 發生任何錯誤時返回原始描述\n",
        "\n",
        "    def _verify_factual_accuracy(self, original: str, generated: str, object_list: str) -> str:\n",
        "        \"\"\"驗證生成的描述不包含原始描述或物體列表中沒有的信息，並檢測重複用詞問題\"\"\"\n",
        "\n",
        "        # 將原始描述和物體列表合併為授權詞彙源\n",
        "        authorized_content = original.lower() + \" \" + object_list.lower()\n",
        "\n",
        "        # 提取生成描述中具有實質意義的名詞\n",
        "        # 創建常見地點、文化和地域詞彙的列表\n",
        "        location_terms = [\"plaza\", \"square\", \"market\", \"mall\", \"avenue\", \"boulevard\"]\n",
        "        cultural_terms = [\"european\", \"asian\", \"american\", \"african\", \"western\", \"eastern\"]\n",
        "\n",
        "        # 檢查生成文本中的每個詞\n",
        "        for term in location_terms + cultural_terms:\n",
        "            # 僅當該詞出現在生成文本但不在授權內容中時進行替換\n",
        "            if term in generated.lower() and term not in authorized_content:\n",
        "                # 根據詞語類型選擇適當的替換詞\n",
        "                if term in location_terms:\n",
        "                    replacement = \"area\"\n",
        "                else:\n",
        "                    replacement = \"scene\"\n",
        "\n",
        "                # 使用正則表達式進行完整詞匹配替換\n",
        "                pattern = re.compile(r'\\b' + term + r'\\b', re.IGNORECASE)\n",
        "                generated = pattern.sub(replacement, generated)\n",
        "\n",
        "        # 檢查描述性詞彙重複問題\n",
        "        repetitive_patterns = [\n",
        "            (r'\\b(visible)\\b.*?\\b(visible)\\b', 'Multiple uses of \"visible\" detected'),\n",
        "            (r'\\b(positioned)\\b.*?\\b(positioned)\\b', 'Multiple uses of \"positioned\" detected'),\n",
        "            (r'\\b(located)\\b.*?\\b(located)\\b', 'Multiple uses of \"located\" detected'),\n",
        "            (r'\\b(situated)\\b.*?\\b(situated)\\b', 'Multiple uses of \"situated\" detected'),\n",
        "            (r'\\b(appears)\\b.*?\\b(appears)\\b', 'Multiple uses of \"appears\" detected'),\n",
        "            (r'\\b(features)\\b.*?\\b(features)\\b', 'Multiple uses of \"features\" detected'),\n",
        "            (r'\\bThis\\s+(\\w+)\\s+.*?\\bThis\\s+\\1\\b', 'Repetitive sentence structure detected')\n",
        "        ]\n",
        "\n",
        "        # 定義替換詞典，提供多樣化的表達方式\n",
        "        replacement_dict = {\n",
        "            'visible': ['present', 'evident', 'apparent', 'observable'],\n",
        "            'positioned': ['arranged', 'placed', 'set', 'organized'],\n",
        "            'located': ['found', 'placed', 'situated', 'established'],\n",
        "            'situated': ['placed', 'positioned', 'arranged', 'set'],\n",
        "            'appears': ['seems', 'looks', 'presents', 'exhibits'],\n",
        "            'features': ['includes', 'contains', 'displays', 'showcases']\n",
        "        }\n",
        "\n",
        "        for pattern, issue in repetitive_patterns:\n",
        "            matches = list(re.finditer(pattern, generated, re.IGNORECASE | re.DOTALL))\n",
        "            if matches:\n",
        "                self.logger.warning(f\"Text quality issue detected: {issue}\")\n",
        "\n",
        "                # 針對特定重複詞彙進行替換\n",
        "                for word in replacement_dict.keys():\n",
        "                    if word in issue.lower():\n",
        "                        word_pattern = re.compile(r'\\b' + word + r'\\b', re.IGNORECASE)\n",
        "                        word_matches = list(word_pattern.finditer(generated))\n",
        "\n",
        "                        # 保留第一次出現，替換後續出現\n",
        "                        for i, match in enumerate(word_matches[1:], 1):\n",
        "                            if i <= len(replacement_dict[word]):\n",
        "                                replacement = replacement_dict[word][(i-1) % len(replacement_dict[word])]\n",
        "\n",
        "                                # 保持原始大小寫格式\n",
        "                                if match.group().isupper():\n",
        "                                    replacement = replacement.upper()\n",
        "                                elif match.group().istitle():\n",
        "                                    replacement = replacement.capitalize()\n",
        "\n",
        "                                # 執行替換\n",
        "                                generated = generated[:match.start()] + replacement + generated[match.end():]\n",
        "                                # 重新計算後續匹配位置\n",
        "                                word_matches = list(word_pattern.finditer(generated))\n",
        "                        break\n",
        "\n",
        "        return generated\n",
        "\n",
        "\n",
        "    def verify_detection(self,\n",
        "                       detected_objects: List[Dict],\n",
        "                       clip_analysis: Dict[str, Any],\n",
        "                       scene_type: str,\n",
        "                       scene_name: str,\n",
        "                       confidence: float) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        驗證並可能修正YOLO的檢測結果\n",
        "        Args:\n",
        "            detected_objects: YOLO檢測到的物體列表\n",
        "            clip_analysis: CLIP分析結果\n",
        "            scene_type: 識別的場景類型\n",
        "            scene_name: 場景名稱\n",
        "            confidence: 場景分類的信心度\n",
        "        Returns:\n",
        "            Dict: 包含驗證結果和建議的字典\n",
        "        \"\"\"\n",
        "        # 確保模型已加載\n",
        "        self._load_model()\n",
        "\n",
        "        # 格式化數據\n",
        "        objects_str = self._format_objects_for_prompt(detected_objects)\n",
        "        clip_str = self._format_clip_results(clip_analysis)\n",
        "\n",
        "        # 構建提示\n",
        "        prompt = self.verify_detection_template.format(\n",
        "            scene_type=scene_type,\n",
        "            scene_name=scene_name,\n",
        "            confidence=confidence,\n",
        "            detected_objects=objects_str,\n",
        "            clip_analysis=clip_str\n",
        "        )\n",
        "\n",
        "        # 調用LLM進行驗證\n",
        "        verification_result = self._generate_llm_response(prompt)\n",
        "\n",
        "        # 解析驗證結果\n",
        "        result = {\n",
        "            \"verification_text\": verification_result,\n",
        "            \"has_errors\": \"appear accurate\" not in verification_result.lower(),\n",
        "            \"corrected_objects\": None\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _remove_explanatory_notes(self, response: str) -> str:\n",
        "        \"\"\"移除解釋性注釋、說明和其他非描述性內容\"\"\"\n",
        "\n",
        "        # 識別常見的注釋和解釋模式\n",
        "        note_patterns = [\n",
        "            r'(?:^|\\n)Note:.*?(?:\\n|$)',\n",
        "            r'(?:^|\\n)I have (?:followed|adhered to|ensured).*?(?:\\n|$)',\n",
        "            r'(?:^|\\n)This description (?:follows|adheres to|maintains).*?(?:\\n|$)',\n",
        "            r'(?:^|\\n)The enhanced description (?:maintains|preserves).*?(?:\\n|$)'\n",
        "        ]\n",
        "\n",
        "        # 尋找第一段完整的描述內容\n",
        "        paragraphs = [p.strip() for p in response.split('\\n\\n') if p.strip()]\n",
        "\n",
        "        # 如果只有一個段落，檢查並清理它\n",
        "        if len(paragraphs) == 1:\n",
        "            for pattern in note_patterns:\n",
        "                paragraphs[0] = re.sub(pattern, '', paragraphs[0], flags=re.IGNORECASE)\n",
        "            return paragraphs[0].strip()\n",
        "\n",
        "        # 如果有多個段落，識別並移除注釋段落\n",
        "        content_paragraphs = []\n",
        "        for paragraph in paragraphs:\n",
        "            is_note = False\n",
        "            for pattern in note_patterns:\n",
        "                if re.search(pattern, paragraph, flags=re.IGNORECASE):\n",
        "                    is_note = True\n",
        "                    break\n",
        "\n",
        "            # 檢查段落是否以常見的注釋詞開頭\n",
        "            if paragraph.lower().startswith(('note:', 'please note:', 'remember:')):\n",
        "                is_note = True\n",
        "\n",
        "            if not is_note:\n",
        "                content_paragraphs.append(paragraph)\n",
        "\n",
        "        # 返回清理後的內容\n",
        "        return '\\n\\n'.join(content_paragraphs).strip()\n",
        "\n",
        "    def handle_no_detection(self, clip_analysis: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        處理YOLO未檢測到物體的情況\n",
        "        Args:\n",
        "            clip_analysis: CLIP分析結果\n",
        "        Returns:\n",
        "            str: 生成的場景描述\n",
        "        \"\"\"\n",
        "        # 確保模型已加載\n",
        "        self._load_model()\n",
        "\n",
        "        # 提取CLIP結果\n",
        "        top_scene, top_confidence = clip_analysis.get(\"top_scene\", (\"unknown\", 0))\n",
        "        viewpoint = clip_analysis.get(\"viewpoint\", (\"standard\", 0))[0]\n",
        "        lighting = clip_analysis.get(\"lighting_condition\", (\"unknown\", 0))[0]\n",
        "\n",
        "        # 格式化文化分析\n",
        "        cultural_str = self._format_cultural_analysis(clip_analysis.get(\"cultural_analysis\", {}))\n",
        "\n",
        "        # 構建提示\n",
        "        prompt = self.no_detection_template.format(\n",
        "            top_scene=top_scene,\n",
        "            top_confidence=top_confidence,\n",
        "            viewpoint=viewpoint,\n",
        "            lighting_condition=lighting,\n",
        "            cultural_analysis=cultural_str\n",
        "        )\n",
        "\n",
        "        # 調用LLM生成描述\n",
        "        description = self._generate_llm_response(prompt)\n",
        "\n",
        "        # 優化輸出\n",
        "        return self._clean_llm_response(description)\n",
        "\n",
        "    def _clean_input_text(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        對輸入文本進行通用的格式清理，處理常見的格式問題。\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "        Returns:\n",
        "            清理後的文本\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # 清理格式的問題\n",
        "        # 1. 處理連續標點符號問題\n",
        "        text = re.sub(r'([.,;:!?])\\1+', r'\\1', text)\n",
        "\n",
        "        # 2. 修復不完整句子的標點（如 \"Something,\" 後沒有繼續接續下去）\n",
        "        text = re.sub(r',\\s*$', '.', text)\n",
        "\n",
        "        # 3. 修復如 \"word.\" 後未加空格即接下一句的問題\n",
        "        text = re.sub(r'([.!?])([A-Z])', r'\\1 \\2', text)\n",
        "\n",
        "        # 4. 移除多餘空格\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # 5. 確保句子正確結束（句尾加句號）\n",
        "        if text and not text[-1] in '.!?':\n",
        "            text += '.'\n",
        "\n",
        "        return text\n",
        "\n",
        "    def _fact_check_description(self, original_desc: str, enhanced_desc: str, scene_type: str, detected_objects: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        驗證並可能修正增強後的描述，確保有保持事實準確性。\n",
        "        Args:\n",
        "            original_desc: 原始場景描述\n",
        "            enhanced_desc: 增強後的描述待驗證\n",
        "            scene_type: 場景類型\n",
        "            detected_objects: 檢測到的物體名稱列表\n",
        "        Returns:\n",
        "            經過事實檢查的描述\n",
        "        \"\"\"\n",
        "        # 如果增強描述為空或太短，返回原始描述\n",
        "        if not enhanced_desc or len(enhanced_desc) < 30:\n",
        "            return original_desc\n",
        "\n",
        "        # 1. 檢查數值一致性（如人數、物體數量等）\n",
        "        # 從原始描述中提取數字和相關名詞\n",
        "        number_patterns = [\n",
        "            (r'(\\d+)\\s+(people|person|pedestrians|individuals)', r'\\1', r'\\2'), # 人數\n",
        "            (r'(\\d+)\\s+(cars|vehicles|automobiles)', r'\\1', r'\\2'),            # 車輛數\n",
        "            (r'(\\d+)\\s+(buildings|structures)', r'\\1', r'\\2')                  # 建築數\n",
        "        ]\n",
        "\n",
        "        # 檢查原始描述中的每個數字\n",
        "        for pattern, num_group, word_group in number_patterns:\n",
        "            original_matches = re.finditer(pattern, original_desc, re.IGNORECASE)\n",
        "            for match in original_matches:\n",
        "                number = match.group(1)\n",
        "                noun = match.group(2)\n",
        "\n",
        "                # 檢查增強描述中是否保留了這個數字\n",
        "                # 創建一個更通用的模式來檢查增強描述中是否包含此數字和對象類別\n",
        "                enhanced_pattern = r'(\\d+)\\s+(' + re.escape(noun) + r'|' + re.escape(noun.rstrip('s')) + r'|' + re.escape(noun + 's') + r')'\n",
        "                enhanced_matches = list(re.finditer(enhanced_pattern, enhanced_desc, re.IGNORECASE))\n",
        "\n",
        "                if not enhanced_matches:\n",
        "                    # 數字+名詞未在增強描述中找到\n",
        "                    plural_form = noun if noun.endswith('s') or number == '1' else noun + 's'\n",
        "                    if enhanced_desc.startswith(\"This\") or enhanced_desc.startswith(\"The\"):\n",
        "                        enhanced_desc = enhanced_desc.replace(\"This \", f\"This scene with {number} {plural_form} \", 1)\n",
        "                        enhanced_desc = enhanced_desc.replace(\"The \", f\"The scene with {number} {plural_form} \", 1)\n",
        "                    else:\n",
        "                        enhanced_desc = f\"The scene includes {number} {plural_form}. \" + enhanced_desc\n",
        "                elif enhanced_matches and match.group(1) != number:\n",
        "                    # 存在但數字不一致，就要更正數字\n",
        "                    for ematch in enhanced_matches:\n",
        "                        wrong_number = ematch.group(1)\n",
        "                        enhanced_desc = enhanced_desc.replace(f\"{wrong_number} {ematch.group(2)}\", f\"{number} {ematch.group(2)}\")\n",
        "\n",
        "        # 2. 檢查視角的一致性\n",
        "        perspective_terms = {\n",
        "            \"aerial\": [\"aerial\", \"bird's-eye\", \"overhead\", \"top-down\", \"above\", \"looking down\"],\n",
        "            \"ground\": [\"street-level\", \"ground level\", \"eye-level\", \"standing\"],\n",
        "            \"indoor\": [\"inside\", \"interior\", \"indoor\", \"within\"],\n",
        "            \"close-up\": [\"close-up\", \"detailed view\", \"close shot\"]\n",
        "        }\n",
        "\n",
        "        # 確定原始視角\n",
        "        original_perspective = None\n",
        "        for persp, terms in perspective_terms.items():\n",
        "            if any(term in original_desc.lower() for term in terms):\n",
        "                original_perspective = persp\n",
        "                break\n",
        "\n",
        "        # 檢查是否保留了視角方面\n",
        "        if original_perspective:\n",
        "            enhanced_has_perspective = any(term in enhanced_desc.lower() for term in perspective_terms[original_perspective])\n",
        "\n",
        "            if not enhanced_has_perspective:\n",
        "                # 添加之前缺的視角方面\n",
        "                perspective_prefixes = {\n",
        "                    \"aerial\": \"From an aerial perspective, \",\n",
        "                    \"ground\": \"From street level, \",\n",
        "                    \"indoor\": \"In this indoor setting, \",\n",
        "                    \"close-up\": \"In this close-up view, \"\n",
        "                }\n",
        "\n",
        "                prefix = perspective_prefixes.get(original_perspective, \"\")\n",
        "                if prefix:\n",
        "                    if enhanced_desc[0].isupper():\n",
        "                        enhanced_desc = prefix + enhanced_desc[0].lower() + enhanced_desc[1:]\n",
        "                    else:\n",
        "                        enhanced_desc = prefix + enhanced_desc\n",
        "\n",
        "        # 3. 檢查場景類型一致性\n",
        "        if scene_type and scene_type.lower() != \"unknown\" and scene_type.lower() not in enhanced_desc.lower():\n",
        "            # 添加場景類型\n",
        "            if enhanced_desc.startswith(\"This \") or enhanced_desc.startswith(\"The \"):\n",
        "                # 避免產生 \"This scene\" 和 \"This intersection\" 的重複\n",
        "                if \"scene\" in enhanced_desc[:15].lower():\n",
        "                    fixed_type = scene_type.lower()\n",
        "                    enhanced_desc = enhanced_desc.replace(\"scene\", fixed_type, 1)\n",
        "                else:\n",
        "                    enhanced_desc = enhanced_desc.replace(\"This \", f\"This {scene_type} \", 1)\n",
        "                    enhanced_desc = enhanced_desc.replace(\"The \", f\"The {scene_type} \", 1)\n",
        "            else:\n",
        "                enhanced_desc = f\"This {scene_type} \" + enhanced_desc\n",
        "\n",
        "        # 4. 確保文字長度適當，這邊的限制要與prompt相同,否則會產生矛盾\n",
        "        words = enhanced_desc.split()\n",
        "        if len(words) > 200:\n",
        "            # 找尋接近字數限制的句子結束處\n",
        "            truncated = ' '.join(words[:200])\n",
        "            last_period = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('?'))\n",
        "\n",
        "            if last_period > 0:\n",
        "                enhanced_desc = truncated[:last_period+1]\n",
        "            else:\n",
        "                enhanced_desc = truncated + '.'\n",
        "\n",
        "        return enhanced_desc\n",
        "\n",
        "    def _extract_perspective_from_description(self, description: str) -> str:\n",
        "        \"\"\"從原始描述中提取視角/透視信息\"\"\"\n",
        "        perspective_terms = {\n",
        "            \"aerial\": [\"aerial perspective\", \"aerial view\", \"bird's-eye view\", \"overhead view\", \"from above\"],\n",
        "            \"ground\": [\"ground level\", \"eye level\", \"street level\"],\n",
        "            \"indoor\": [\"indoor setting\", \"inside\", \"interior\"]\n",
        "        }\n",
        "\n",
        "        for persp_type, terms in perspective_terms.items():\n",
        "            for term in terms:\n",
        "                if term.lower() in description.lower():\n",
        "                    return term\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def _extract_objects_from_description(self, description: str) -> List[str]:\n",
        "        \"\"\"從原始描述中提取物件提及\"\"\"\n",
        "        # 常見物件正則表達式模式\n",
        "        object_patterns = [\n",
        "            r'(\\d+)\\s+(people|persons|pedestrians|individuals)',\n",
        "            r'(\\d+)\\s+(cars|vehicles|automobiles)',\n",
        "            r'(\\d+)\\s+(buildings|structures)',\n",
        "            r'(\\d+)\\s+(plants|potted plants|flowers)',\n",
        "            r'(\\d+)\\s+(beds|furniture|tables|chairs)'\n",
        "        ]\n",
        "\n",
        "        extracted_objects = []\n",
        "\n",
        "        for pattern in object_patterns:\n",
        "            matches = re.finditer(pattern, description, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                number = match.group(1)\n",
        "                object_type = match.group(2)\n",
        "                extracted_objects.append(f\"{number} {object_type}\")\n",
        "\n",
        "        return extracted_objects\n",
        "\n",
        "    def _ensure_scene_type_consistency(self, description: str, scene_type: str, original_desc: str) -> str:\n",
        "        \"\"\"確保描述中的場景類型與指定的場景類型一致\"\"\"\n",
        "        # 禁止使用的錯誤場景詞列表\n",
        "        prohibited_scene_words = [\"plaza\", \"square\", \"european\", \"asian\", \"american\"]\n",
        "\n",
        "        # 檢查是否包含禁止的場景詞\n",
        "        for word in prohibited_scene_words:\n",
        "            if word in description.lower() and word not in original_desc.lower() and word not in scene_type.lower():\n",
        "                # 替換錯誤場景詞為正確場景類型\n",
        "                pattern = re.compile(r'\\b' + word + r'\\b', re.IGNORECASE)\n",
        "                description = pattern.sub(scene_type, description)\n",
        "\n",
        "        # 確保場景類型在描述中被提及\n",
        "        if scene_type.lower() not in description.lower():\n",
        "            # 尋找通用場景詞並替換\n",
        "            for general_term in [\"scene\", \"area\", \"place\", \"location\"]:\n",
        "                if general_term in description.lower():\n",
        "                    pattern = re.compile(r'\\b' + general_term + r'\\b', re.IGNORECASE)\n",
        "                    description = pattern.sub(scene_type, description, count=1)\n",
        "                    break\n",
        "            else:\n",
        "                # 如果沒有找到通用詞，在開頭添加場景類型\n",
        "                if description.startswith(\"The \"):\n",
        "                    description = description.replace(\"The \", f\"The {scene_type} \", 1)\n",
        "                elif description.startswith(\"This \"):\n",
        "                    description = description.replace(\"This \", f\"This {scene_type} \", 1)\n",
        "                else:\n",
        "                    description = f\"This {scene_type} \" + description\n",
        "\n",
        "        return description\n",
        "\n",
        "    def _generate_llm_response(self, prompt: str) -> str:\n",
        "        \"\"\"生成 LLM 的回應\"\"\"\n",
        "        self._load_model()\n",
        "\n",
        "        try:\n",
        "            self.call_count += 1\n",
        "            self.logger.info(f\"LLM call #{self.call_count}\")\n",
        "\n",
        "            # 清除 GPU 緩存\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # 設置固定種子以提高一致性\n",
        "            torch.manual_seed(42)\n",
        "\n",
        "            # 準備輸入\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=self.max_length).to(self.device)\n",
        "\n",
        "            # 根據模型類型調整參數\n",
        "            generation_params = {\n",
        "                \"max_new_tokens\": 120,\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id,\n",
        "                \"attention_mask\": inputs.attention_mask,\n",
        "                \"use_cache\": True,\n",
        "            }\n",
        "\n",
        "            # 為 Llama 模型設置特定參數\n",
        "            if \"llama\" in self.model_path.lower():\n",
        "                generation_params.update({\n",
        "                    \"temperature\": 0.35,        # 不要太高, 否則模型可能會太有主觀意見\n",
        "                    \"max_new_tokens\": 600,\n",
        "                    \"do_sample\": True,\n",
        "                    \"top_p\": 0.75,\n",
        "                    \"repetition_penalty\": 1.5,  # 重複的懲罰權重,可避免掉重複字\n",
        "                    \"num_beams\": 5 ,\n",
        "                    \"length_penalty\": 1,\n",
        "                    \"no_repeat_ngram_size\": 3\n",
        "                })\n",
        "\n",
        "            else:\n",
        "                # 如果用其他模型的參數\n",
        "                generation_params.update({\n",
        "                    \"temperature\": 0.6,\n",
        "                    \"max_new_tokens\": 300,\n",
        "                    \"top_p\": 0.9,\n",
        "                    \"do_sample\": True,\n",
        "                    \"num_beams\": 1,\n",
        "                    \"repetition_penalty\": 1.05\n",
        "                })\n",
        "\n",
        "            # 生成回應\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(inputs.input_ids, **generation_params)\n",
        "\n",
        "            # 解碼完整輸出\n",
        "            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # 提取生成的響應部分\n",
        "            assistant_tag = \"<|assistant|>\"\n",
        "            if assistant_tag in full_response:\n",
        "                response = full_response.split(assistant_tag)[-1].strip()\n",
        "\n",
        "                # 檢查是否有未閉合的 <|assistant|>\n",
        "                user_tag = \"<|user|>\"\n",
        "                if user_tag in response:\n",
        "                    response = response.split(user_tag)[0].strip()\n",
        "            else:\n",
        "                # 移除輸入提示\n",
        "                input_text = self.tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\n",
        "                response = full_response\n",
        "                if response.startswith(input_text):\n",
        "                    response = response[len(input_text):].strip()\n",
        "\n",
        "            # 確保不返回空的回應\n",
        "            if not response or len(response.strip()) < 10:\n",
        "                self.logger.warning(\"response is too short or empty\")\n",
        "                return \"No detailed description could be generated.\"\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"生成 LLM 響應時出錯: {str(e)}\")\n",
        "            import traceback\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return \"Unable to generate enhanced description.\"\n",
        "\n",
        "    def _clean_llm_response(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean the LLM response to ensure the output contains only clean descriptive text.\n",
        "        Sometimes it will not only display the description but display tags, notes...etc\n",
        "        Args:\n",
        "            response: Original response from the LLM\n",
        "        Returns:\n",
        "            Cleaned description text\n",
        "        \"\"\"\n",
        "        if not response:\n",
        "            return \"\"\n",
        "\n",
        "        # Save original response as backup\n",
        "        original_response = response\n",
        "\n",
        "        # 1. Extract content between markers (if present)\n",
        "        output_start = response.find(\"[OUTPUT_START]\")\n",
        "        output_end = response.find(\"[OUTPUT_END]\")\n",
        "        if output_start != -1 and output_end != -1 and output_end > output_start:\n",
        "            response = response[output_start + len(\"[OUTPUT_START]\"):output_end].strip()\n",
        "\n",
        "        # 2. Remove all remaining section markers and instructions\n",
        "        section_markers = [\n",
        "            r'\\[.*?\\]',                      # [any text]\n",
        "            r'OUTPUT_START\\s*:|OUTPUT_END\\s*:',  # OUTPUT_START: or OUTPUT_END:\n",
        "            r'ENHANCED DESCRIPTION\\s*:',      # ENHANCED DESCRIPTION:\n",
        "            r'Scene Type\\s*:.*?(?=\\n|$)',    # Scene Type: text\n",
        "            r'Original Description\\s*:.*?(?=\\n|$)', # Original Description: text\n",
        "            r'GOOD\\s*:|BAD\\s*:',             # GOOD: or BAD:\n",
        "            r'PROBLEM\\s*:.*?(?=\\n|$)',       # PROBLEM: text\n",
        "            r'</?\\|(?:assistant|system|user)\\|>',  # Dialog markers\n",
        "            r'\\(Note:.*?\\)',                 # Notes in parentheses\n",
        "            r'\\(.*?I\\'ve.*?\\)',              # Common explanatory content\n",
        "            r'\\(.*?as per your request.*?\\)' # References to instructions\n",
        "        ]\n",
        "\n",
        "        for marker in section_markers:\n",
        "            response = re.sub(marker, '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        # 2.5. Deal with Here is...\n",
        "        intro_prefixes = [\n",
        "            r'^Here\\s+is\\s+(?:a\\s+|the\\s+)?(?:rewritten\\s+|enhanced\\s+)?scene\\s+description.*?:\\s*',\n",
        "            r'^The\\s+(?:rewritten\\s+|enhanced\\s+)?(?:scene\\s+)?description\\s+is.*?:\\s*',\n",
        "            r'^Here\\'s\\s+(?:a\\s+|the\\s+)?(?:rewritten\\s+|enhanced\\s+)?description.*?:\\s*'\n",
        "        ]\n",
        "\n",
        "        for prefix_pattern in intro_prefixes:\n",
        "            response = re.sub(prefix_pattern, '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        # 3. Remove common prefixes and suffixes\n",
        "        prefixes_to_remove = [\n",
        "            \"Enhanced Description:\",\n",
        "            \"Scene Description:\",\n",
        "            \"Description:\",\n",
        "            \"Here is the enhanced description:\",\n",
        "            \"Here's the enhanced description:\",\n",
        "            \"Here is a rewritten scene description that adheres to the provided critical rules:\",\n",
        "            \"Here is the rewritten scene description:\",\n",
        "            \"Here's a rewritten scene description:\",\n",
        "            \"The rewritten scene description is as follows:\"\n",
        "        ]\n",
        "\n",
        "        for prefix in prefixes_to_remove:\n",
        "            if response.lower().startswith(prefix.lower()):\n",
        "                response = response[len(prefix):].strip()\n",
        "\n",
        "        # 4. Remove any Context tags or text containing Context\n",
        "        response = re.sub(r'<\\s*Context:.*?>', '', response)\n",
        "        response = re.sub(r'Context:.*?(?=\\n|$)', '', response)\n",
        "        response = re.sub(r'Note:.*?(?=\\n|$)', '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        # 5. Clean improper scene type references\n",
        "        scene_type_pattern = r'This ([a-zA-Z_]+) (features|shows|displays|contains)'\n",
        "        match = re.search(scene_type_pattern, response)\n",
        "        if match and '_' in match.group(1):\n",
        "            fixed_text = f\"This scene {match.group(2)}\"\n",
        "            response = re.sub(scene_type_pattern, fixed_text, response)\n",
        "\n",
        "        # 6. Reduce dash usage for more natural punctuation\n",
        "        response = re.sub(r'—', ', ', response)\n",
        "        response = re.sub(r' - ', ', ', response)\n",
        "\n",
        "        # 7. Remove excess whitespace and line breaks\n",
        "        response = response.replace('\\r', ' ')\n",
        "        response = re.sub(r'\\n+', ' ', response)  # 將所有換行符替換為空格\n",
        "        response = re.sub(r'\\s{2,}', ' ', response)  # 將多個空格替換為單個空格\n",
        "\n",
        "        # 8. Remove Markdown formatting\n",
        "        response = re.sub(r'\\*\\*|\\*|__|\\|', '', response)  # Remove Markdown indicators\n",
        "\n",
        "        # 9. Detect and remove sentence duplicates\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', response)\n",
        "        unique_sentences = []\n",
        "        seen_content = set()\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Skip empty sentences\n",
        "            if not sentence.strip():\n",
        "                continue\n",
        "\n",
        "            # Create simplified version for comparison (lowercase, no punctuation)\n",
        "            simplified = re.sub(r'[^\\w\\s]', '', sentence.lower())\n",
        "            simplified = ' '.join(simplified.split())  # Standardize whitespace\n",
        "\n",
        "            # Check if we've seen a similar sentence\n",
        "            is_duplicate = False\n",
        "            for existing in seen_content:\n",
        "                if len(simplified) > 10 and (existing in simplified or simplified in existing):\n",
        "                    is_duplicate = True\n",
        "                    break\n",
        "\n",
        "            if not is_duplicate and simplified:\n",
        "                unique_sentences.append(sentence)\n",
        "                seen_content.add(simplified)\n",
        "\n",
        "        # Recombine unique sentences\n",
        "        response = ' '.join(unique_sentences)\n",
        "\n",
        "        # 9.5. Advanced repetition detection and replacement\n",
        "        repetitive_descriptors = ['visible', 'positioned', 'located', 'situated', 'appears', 'features', 'shows', 'displays']\n",
        "        word_usage_count = {}\n",
        "\n",
        "        # Count occurrences of each repetitive descriptor\n",
        "        for word in repetitive_descriptors:\n",
        "            count = len(re.findall(r'\\b' + word + r'\\b', response, re.IGNORECASE))\n",
        "            if count > 1:\n",
        "                word_usage_count[word] = count\n",
        "\n",
        "        # Replace excessive repetitions with varied alternatives\n",
        "        replacement_alternatives = {\n",
        "            'visible': ['present', 'evident', 'apparent', 'observable'],\n",
        "            'positioned': ['arranged', 'placed', 'set', 'organized'],\n",
        "            'located': ['found', 'placed', 'situated', 'established'],\n",
        "            'situated': ['placed', 'positioned', 'arranged', 'set'],\n",
        "            'appears': ['seems', 'looks', 'presents', 'exhibits'],\n",
        "            'features': ['includes', 'contains', 'displays', 'showcases'],\n",
        "            'shows': ['reveals', 'presents', 'exhibits', 'demonstrates'],\n",
        "            'displays': ['presents', 'exhibits', 'shows', 'reveals']\n",
        "        }\n",
        "\n",
        "        for word, count in word_usage_count.items():\n",
        "            if count > 1 and word in replacement_alternatives:\n",
        "                # Find all occurrences\n",
        "                pattern = re.compile(r'\\b' + word + r'\\b', re.IGNORECASE)\n",
        "                matches = list(pattern.finditer(response))\n",
        "\n",
        "                # Replace subsequent occurrences (keep first one)\n",
        "                for i, match in enumerate(matches[1:], 1):\n",
        "                    if i <= len(replacement_alternatives[word]):\n",
        "                        replacement = replacement_alternatives[word][(i-1) % len(replacement_alternatives[word])]\n",
        "                        # Maintain original case pattern\n",
        "                        if match.group().isupper():\n",
        "                            replacement = replacement.upper()\n",
        "                        elif match.group().istitle():\n",
        "                            replacement = replacement.capitalize()\n",
        "\n",
        "                        response = response[:match.start()] + replacement + response[match.end():]\n",
        "                        # Update remaining matches positions\n",
        "                        offset = len(replacement) - len(match.group())\n",
        "                        matches = list(pattern.finditer(response))\n",
        "\n",
        "        # 10. Ensure word count is within limits (50-150 words)\n",
        "        words = response.split()\n",
        "        if len(words) > 200:\n",
        "            # Find sentence ending near the word limit\n",
        "            truncated = ' '.join(words[:200])\n",
        "            last_period = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('?'))\n",
        "\n",
        "            if last_period > 0:\n",
        "                response = truncated[:last_period+1]\n",
        "            else:\n",
        "                response = truncated + \".\"\n",
        "\n",
        "        # 11. Check sentence completeness\n",
        "        if response and not response.strip()[-1] in ['.', '!', '?']:\n",
        "            # Find the last preposition or conjunction\n",
        "            common_prepositions = [\"into\", \"onto\", \"about\", \"above\", \"across\", \"after\", \"along\", \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"between\", \"beyond\", \"by\", \"down\", \"during\", \"except\", \"for\", \"from\", \"in\", \"inside\", \"near\", \"of\", \"off\", \"on\", \"over\", \"through\", \"to\", \"toward\", \"under\", \"up\", \"upon\", \"with\", \"within\"]\n",
        "\n",
        "            # Check if ending with preposition or conjunction\n",
        "            last_word = response.strip().split()[-1].lower() if response.strip().split() else \"\"\n",
        "            if last_word in common_prepositions or last_word in [\"and\", \"or\", \"but\"]:\n",
        "                # Find the last complete sentence\n",
        "                last_period = max(response.rfind('.'), response.rfind('!'), response.rfind('?'))\n",
        "                if last_period > 0:\n",
        "                    response = response[:last_period+1]\n",
        "                else:\n",
        "                    # If no complete sentence found, modify the ending\n",
        "                    words = response.strip().split()\n",
        "                    if words:\n",
        "                        # Remove the last preposition or conjunction\n",
        "                        response = \" \".join(words[:-1]) + \".\"\n",
        "\n",
        "        # 12. Grammar completeness check\n",
        "        incomplete_patterns = [\n",
        "            r'\\b(fine|the)\\s+(the\\s+)?(?:urban|area|scene)\\b(?!\\s+\\w)',  # 檢測不完整的片語\n",
        "            r'\\b(and|or|but|with|from|in|at|on)\\s*[.!?]',              # 介詞後直接結束\n",
        "            r'\\b\\w+\\s+\\1\\b'  # 重複詞語檢測\n",
        "        ]\n",
        "\n",
        "        for pattern in incomplete_patterns:\n",
        "            if re.search(pattern, response, re.IGNORECASE):\n",
        "                # 移除有問題的片段或進行修正\n",
        "                response = re.sub(pattern, '', response, flags=re.IGNORECASE)\n",
        "                response = re.sub(r'\\s{2,}', ' ', response)  # 清理多餘空格\n",
        "\n",
        "        # 13. Ensure haven't over-filtered\n",
        "        if not response or len(response) < 40:\n",
        "            # Try to get the first meaningful paragraph from the original response\n",
        "            paragraphs = [p for p in original_response.split('\\n\\n') if p.strip()]\n",
        "            if paragraphs:\n",
        "                # Choose the longest paragraph as it's most likely the actual description\n",
        "                best_para = max(paragraphs, key=len)\n",
        "                # Clean it using a subset of the above rules\n",
        "                best_para = re.sub(r'\\[.*?\\]', '', best_para)  # Remove [SECTION] markers\n",
        "                best_para = re.sub(r'\\s{2,}', ' ', best_para).strip()  # Clean whitespace\n",
        "\n",
        "                if len(best_para) >= 40:\n",
        "                    return best_para\n",
        "\n",
        "            # If still no good content, return a simple message\n",
        "            return \"Unable to generate a valid enhanced description.\"\n",
        "\n",
        "        # 14. Final cleaning - catch any missed special cases\n",
        "        response = re.sub(r'</?\\|.*?\\|>', '', response)  # Any remaining tags\n",
        "        response = re.sub(r'\\(.*?\\)', '', response)  # Any remaining parenthetical content\n",
        "        response = re.sub(r'Note:.*?(?=\\n|$)', '', response, flags=re.IGNORECASE)  # Any remaining notes\n",
        "\n",
        "        # Ensure proper spacing after punctuation\n",
        "        response = re.sub(r'([.!?])([A-Z])', r'\\1 \\2', response)\n",
        "\n",
        "        # Ensure first letter is capitalized\n",
        "        if response and response[0].islower():\n",
        "            response = response[0].upper() + response[1:]\n",
        "\n",
        "        # 15. 統一格式 - 確保輸出始終是單一段落\n",
        "        response = re.sub(r'\\s*\\n\\s*', ' ', response)  # 將所有換行符替換為空格\n",
        "        response = ' '.join(response.split())\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "    def _format_objects_for_prompt(self, objects: List[Dict]) -> str:\n",
        "        \"\"\"格式化物體列表以用於提示\"\"\"\n",
        "        if not objects:\n",
        "            return \"No objects detected\"\n",
        "\n",
        "        formatted = []\n",
        "        for obj in objects:\n",
        "            formatted.append(f\"{obj['class_name']} (confidence: {obj['confidence']:.2f})\")\n",
        "\n",
        "        return \"\\n- \" + \"\\n- \".join(formatted)\n",
        "\n",
        "\n",
        "    def _format_clip_results(self, clip_analysis: Dict) -> str:\n",
        "        \"\"\"格式化CLIP分析結果以用於提示\"\"\"\n",
        "        if not clip_analysis or \"error\" in clip_analysis:\n",
        "            return \"No CLIP analysis available\"\n",
        "\n",
        "        parts = [\"CLIP Analysis Results:\"]\n",
        "\n",
        "        # 加上頂級場景\n",
        "        top_scene, confidence = clip_analysis.get(\"top_scene\", (\"unknown\", 0))\n",
        "        parts.append(f\"- Most likely scene: {top_scene} (confidence: {confidence:.2f})\")\n",
        "\n",
        "        # 加上視角\n",
        "        viewpoint, vp_conf = clip_analysis.get(\"viewpoint\", (\"standard\", 0))\n",
        "        parts.append(f\"- Camera viewpoint: {viewpoint} (confidence: {vp_conf:.2f})\")\n",
        "\n",
        "        # 加上物體組合\n",
        "        if \"object_combinations\" in clip_analysis:\n",
        "            combos = []\n",
        "            for combo, score in clip_analysis[\"object_combinations\"][:3]:\n",
        "                combos.append(f\"{combo} ({score:.2f})\")\n",
        "            parts.append(f\"- Object combinations: {', '.join(combos)}\")\n",
        "\n",
        "        # 加上文化分析\n",
        "        if \"cultural_analysis\" in clip_analysis:\n",
        "            parts.append(\"- Cultural analysis:\")\n",
        "            for culture_type, data in clip_analysis[\"cultural_analysis\"].items():\n",
        "                best_desc = data.get(\"best_description\", \"\")\n",
        "                desc_conf = data.get(\"confidence\", 0)\n",
        "                parts.append(f\"  * {culture_type}: {best_desc} ({desc_conf:.2f})\")\n",
        "\n",
        "        return \"\\n\".join(parts)\n",
        "\n",
        "    def _format_cultural_analysis(self, cultural_analysis: Dict) -> str:\n",
        "        \"\"\"格式化文化分析結果\"\"\"\n",
        "        if not cultural_analysis:\n",
        "            return \"No specific cultural elements detected\"\n",
        "\n",
        "        parts = []\n",
        "        for culture_type, data in cultural_analysis.items():\n",
        "            best_desc = data.get(\"best_description\", \"\")\n",
        "            desc_conf = data.get(\"confidence\", 0)\n",
        "            parts.append(f\"{culture_type}: {best_desc} (confidence: {desc_conf:.2f})\")\n",
        "\n",
        "        return \"\\n\".join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc279edc479540b7a21bd0d2fac5346f",
            "21aa051411894333addde7063e59d8e3",
            "9d4790cee279417fbb42983389f07268",
            "03f5c1dc292a4db0810d07280c1925bc",
            "75bba9bc06024df5913a7f1c49c9b902",
            "a90548f9a10b4292be1d17f4044a5d38",
            "fa4ff948d1214548b8ca917e05aae008",
            "20f50fe1899b4ccc9a2affc05d4861b1",
            "7540db0f4a9d43d5b3dc2fdfb8fa0442",
            "20fa2a57873e4ad582c453ff869f468b",
            "6cde27c9220e40e1a8a06271246ba4a5",
            "36440f03db3f483da100311ad7512ca9",
            "bcb446c3bc6c42b2bf0b514d3eaa75c1",
            "56e6fc8a666b4f248a1356754fbd731d",
            "54daf70413414ee78027eb49a9a61c91",
            "4924f7025fd24500b05a32c264933a5d",
            "4fbc5bea58f844e293c76ca218445d22",
            "d07da533ae36416589fc189972337062",
            "666cfc635eac476ebea70f13d2e5ee00",
            "d18b00f9f5da4652930390f9e37a0434",
            "ac162f9528f4458cb37a5ac64c7ccc68",
            "a8d03ea7afe4451ea64d3fd9115bded3",
            "760ceceeb80640cea853cdaf71db7e70",
            "e9351cd13b3d4d2faf0b4335d7cc5642",
            "46135514d1434ae8b7b63fa15c5f8e46",
            "1e43670477024ba39e29a512489ee0ff",
            "077768d6a9d9433cbc190b544ed2f95c",
            "bb50c52afa814a97adfa303032982c4e",
            "3b538d70083c4ea796543b994546b544",
            "3e27287cc9834ff0ab130eeac56c870e",
            "daee5ceeb0dd4a3c94e115092632a741",
            "6dcd42eaedc24838a94c3e5637e2de7f",
            "f3af0e6428d84f34b9f202d5893e93e7",
            "2ffa644344a24dca802bbe084e7893d2",
            "15c1086566d4418e805145453c776bf9",
            "9aac29b2414748a8a42d7f565934aef9",
            "2a0de34ef5664a37a076d07a1702072b",
            "d10d1cbc20124781bdaab6a1612612fb",
            "b95e2875d5b74496938e8dd86cd64753",
            "b46f7b644c73497d9d343451f0984b4d",
            "1dad548aae954f4e967b0039bcb00415",
            "b1054eafba0c457da893864af0708529",
            "c060aa54bfe94d9b8d6705fed947a558",
            "777913992879487fa0d8b736f29aa896",
            "da7aa83bbef64df0bec0eb4063370510",
            "46ca7ab9f1f74317b3c4ff50e840b31e",
            "a081f7c2aa1a41c297c8f9fe52664522",
            "7bbac2aa84b8474e8b564e3db036e87a",
            "d23f0ece6ea2430e9cd3f7674165b79f",
            "c3ca559d95bc4943b1ff7afcd8c397fd",
            "1a2260ffa9954056bfe8799df2ee85ed",
            "53ee77b9fc9043078e4def2be0ee4f32",
            "49a623e832444bf695cffe6badd18ef8",
            "84a89bd4883e4a57af2576b797489bd2",
            "e420097050b24730a392a4b0f1b931f0",
            "9a922dabd66d4852b9efb2ee8ca20c2d",
            "163533ea1fbc435a97e7657983ef4a67",
            "fbc8486b1eaa4090aa37e72eb7098d3d",
            "59e674851ef44e8c92369447181025a5",
            "1b0cd2c0629049fe95a88cf7991a0819",
            "c5306481c5f34d458d9bdc11bdde5dc4",
            "6d3df1b8ba1f4ef6b9a13d93896650aa",
            "8d175024d6d740b9b7a07e8987f57d9f",
            "44101bd468ab472e93e950f297ccd105",
            "9db570cdd4f743438141c1c9a2a48fb5",
            "00487bf4c9324cd587824764d4586eb2",
            "195a823cf7eb4d0e9a87d440dce64a33",
            "5cfded6f513c4ce090e014caf7e10611",
            "e775f3b04f484693ac25979a07bed69c",
            "c7202ffc711f4b279168666796d49a30",
            "b80d8a8560ec4b3dbd1c3a56d6badec0",
            "31e0afe748d24afca536db1c320a2e55",
            "a454d744823c49908489fa37dcf41a60",
            "8f7c417af8724fc78e790e07b044a3f1",
            "1ae810f77e4b4232a94cc12321ace4ee",
            "4b134c5f101a46d4bb391353010ea0d6",
            "e99e8c4be12140a28c0af2477672f7ed",
            "fa1034426f1146329719e1ca85f3f8b2",
            "e0c75bd63f5244b296bfe691d99f6069",
            "2f9d4c27cc5f4832bb5ff3eb2f52a4d5",
            "d2aed8c7bf3a41898c428818b54fe767",
            "7d88f24e26bb46aca9f0aaadc455bda1",
            "793029ea7566487f945ef9ddd28fff7a",
            "80bc2e6dc7934e1d86ecbcef545714f6",
            "cd259340fbe24b9aa1e2ed50824aada9",
            "4ed020cf9b594b8fb19637d1e405d34c",
            "207b2a43865d42ecb1cfc7a37ce728f1",
            "6d34ea4a4fef49ba90bd8de03efa24f2",
            "d247d75143f04de19cc11670984426d7",
            "efe78ecd2226491b9f5e281036057790",
            "8e84fb80b6094cbe86f6b678a5c8af7d",
            "468db119f1034e30928876703afe8a70",
            "c886c911cefe4310b8e83bc0205baeec",
            "88aabf8f024d41e0ad87c858af1bcca3",
            "86b0789e28654ded804c10c036301741",
            "0c99b9a0d9da4b1d889458a63bc9d49a",
            "c6cdfc2ba4d34f83a35f9931853be02c",
            "4399644dbcd04180aed88006665cb918",
            "554cfacaaded4a8eac8ef752ec023fc6",
            "990a191b31324ab3a0b176ac2b709698",
            "0b4a4c8d234f48cdb7b540d2e105bc74",
            "c85e0a23e6c349d08aa489d6e416326f",
            "f72735bf8c2e41f1939a48a4ce738fc1",
            "c66ead96e3e4481c815b77d928230de4",
            "98c8e50df2bc454888376fd95dacf1ee",
            "b527be0b34344f3fab2580e3631aa0b3",
            "306026f826d540c4aab96909317bd7b9",
            "213c4da087ba4a889b9177c1fcdcf696",
            "000221dc3f72487d8a43cd615875583d",
            "5cfd8e649df24d74830a3eb19686324f"
          ]
        },
        "id": "XoMFwi652rCU",
        "outputId": "8c508a8c-baec-4bb2-a946-a7b58cdeebd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to initialize ImageProcessor with LLM support...\n",
            "Initializing ImageProcessor with use_llm=True, enable_places365=True\n",
            "ColorMapper initialized successfully\n",
            "LightingAnalyzer initialized successfully\n",
            "Places365 model initialized successfully with resnet50_places365\n",
            "Loaded LANDMARK_ACTIVITIES successfully\n",
            "Loaded SCENE_TYPES successfully\n",
            "Loaded OBJECT_CATEGORIES successfully\n",
            "Initialized SpatialAnalyzer successfully\n",
            "Initialized SceneDescriptor successfully\n",
            "Initialized EnhancedSceneDescriber successfully\n",
            "Loading CLIP model ViT-L/14 on cuda...\n",
            "CLIP model loaded successfully.\n",
            "CLIP text_features_cache prepared.\n",
            "Initializing CLIP Zero-Shot Landmark Classifier (ViT-L/14) on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-26 13:58:16,634 - LLMEnhancer - INFO - Using device: cuda\n",
            "2025-05-26 13:58:16,634 - LLMEnhancer - INFO - Using device: cuda\n",
            "INFO:LLMEnhancer:Using device: cuda\n",
            "2025-05-26 13:58:16,636 - LLMEnhancer - WARNING - HF_TOKEN not found in environment variables. Access to gated models may be limited.\n",
            "2025-05-26 13:58:16,636 - LLMEnhancer - WARNING - HF_TOKEN not found in environment variables. Access to gated models may be limited.\n",
            "WARNING:LLMEnhancer:HF_TOKEN not found in environment variables. Access to gated models may be limited.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded CLIP model\n",
            "Loaded 114 landmark prompts for classification\n",
            "Initialized landmark classifier with shared CLIP model\n",
            "Batch size set to 8\n",
            "Adjusted confidence threshold multiplier for full_image to 0.8\n",
            "Adjusted confidence threshold multiplier for distant to 0.65\n",
            "Landmark detection enabled with optimized settings\n",
            "LLM enhancer initialized successfully.\n",
            "SceneAnalyzer initialized successfully\n",
            "SceneAnalyzer status - spatial_analyzer: True, descriptor: True, scene_describer: True\n",
            "ImageProcessor initialization completed successfully\n",
            "ImageProcessor initialized successfully with LLM\n",
            "scene_analyzer initialized: <class '__main__.SceneAnalyzer'>\n",
            "scene_analyzer.use_llm available: True\n",
            "VideoProcessor initialized successfully\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://50b7419ba537d603ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://50b7419ba537d603ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIAGNOSTIC: Image upload handled with enable_landmark=True, use_llm=True\n",
            "Processing image with model: yolov8m.pt, confidence: 0.25, use_llm: True, enable_landmark: True\n",
            "Updated existing scene_analyzer use_llm setting to: True\n",
            "Updated all landmark detection settings to: True\n",
            "DEBUG: app.py 傳遞 enable_landmark=True 到 process_image\n",
            "Creating new model instance for yolov8m.pt\n",
            "Loading model: yolov8m.pt\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 330MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded model: yolov8m.pt\n",
            "Number of classes the model can recognize: 80\n",
            "Places365 detected: palace (mapped: historical_monument) confidence: 0.626\n",
            "DEBUG_OVERRIDE: Pre-override -> is_indoor: True (type: <class 'numpy.bool'>), p365_conf: 0.6263149380683899, p365_raw_is_indoor: False\n",
            "DEBUG_OVERRIDE: Override condition p365_conf >= 0.8 MET. p365_is_indoor_decision: False (type: <class 'bool'>)\n",
            "DEBUG_OVERRIDE: Path for p365_is_indoor_decision == False taken. Original is_indoor: True\n",
            "INFO: Places365 FORCED OUTDOOR override applied. New is_indoor: False\n",
            "DEBUG_OVERRIDE: Returning from _analyze_indoor_outdoor -> is_indoor: False (type: <class 'bool'>), final_indoor_score: -8.0, indoor_probability: 0.02\n",
            "\n",
            "image 1/1 /tmp/temp_2715fb89bf954ab0b22b7fd71a15971b.jpg: 640x512 (no detections), 74.9ms\n",
            "Speed: 5.4ms preprocess, 74.9ms inference, 69.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "DEBUG: analyze_scene 接收到 enable_landmark=True\n",
            "DIAGNOSTIC (SceneAnalyzer.analyze): Called with current_run_enable_landmark=True\n",
            "DEBUG: SceneAnalyzer received lighting_info type: <class 'dict'>\n",
            "DEBUG: SceneAnalyzer lighting_info source: unknown\n",
            "DIAGNOSTIC: Places365 info received - scene: palace, mapped: historical_monument, confidence: 0.626\n",
            "Attempting landmark detection with no YOLO boxes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-f795261a62ed>:289: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 2712027 negative Z values that have been clipped to zero\n",
            "  enhanced_img = color.lab2rgb(lab) * 255.0\n",
            "<ipython-input-32-f795261a62ed>:289: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 4030923 negative Z values that have been clipped to zero\n",
            "  enhanced_img = color.lab2rgb(lab) * 255.0\n",
            "<ipython-input-32-f795261a62ed>:289: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 3676445 negative Z values that have been clipped to zero\n",
            "  enhanced_img = color.lab2rgb(lab) * 255.0\n",
            "<ipython-input-32-f795261a62ed>:289: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 6850496 negative Z values that have been clipped to zero\n",
            "  enhanced_img = color.lab2rgb(lab) * 255.0\n",
            "<ipython-input-32-f795261a62ed>:289: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 841632 negative Z values that have been clipped to zero\n",
            "  enhanced_img = color.lab2rgb(lab) * 255.0\n",
            "2025-05-26 14:01:25,708 - LLMEnhancer - INFO - Model not loaded, no context to reset\n",
            "2025-05-26 14:01:25,708 - LLMEnhancer - INFO - Model not loaded, no context to reset\n",
            "INFO:LLMEnhancer:Model not loaded, no context to reset\n",
            "2025-05-26 14:01:25,710 - LLMEnhancer - INFO - Loading LLM model from meta-llama/Llama-3.2-3B-Instruct with 8-bit quantization\n",
            "2025-05-26 14:01:25,710 - LLMEnhancer - INFO - Loading LLM model from meta-llama/Llama-3.2-3B-Instruct with 8-bit quantization\n",
            "INFO:LLMEnhancer:Loading LLM model from meta-llama/Llama-3.2-3B-Instruct with 8-bit quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using landmark data from class attribute for louvre_museum\n",
            "Found 6 specific activities for landmark louvre_museum\n",
            "Set primary landmark activities: 6 activities for Louvre Museum\n",
            "Total GPU memory: 14.74 GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc279edc479540b7a21bd0d2fac5346f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36440f03db3f483da100311ad7512ca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "760ceceeb80640cea853cdaf71db7e70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ffa644344a24dca802bbe084e7893d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da7aa83bbef64df0bec0eb4063370510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a922dabd66d4852b9efb2ee8ca20c2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "195a823cf7eb4d0e9a87d440dce64a33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa1034426f1146329719e1ca85f3f8b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d247d75143f04de19cc11670984426d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "990a191b31324ab3a0b176ac2b709698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-26 14:03:23,322 - LLMEnhancer - INFO - Model loaded successfully with 8-bit quantization\n",
            "2025-05-26 14:03:23,322 - LLMEnhancer - INFO - Model loaded successfully with 8-bit quantization\n",
            "INFO:LLMEnhancer:Model loaded successfully with 8-bit quantization\n",
            "2025-05-26 14:03:23,329 - LLMEnhancer - INFO - Generating LLM response...\n",
            "2025-05-26 14:03:23,329 - LLMEnhancer - INFO - Generating LLM response...\n",
            "INFO:LLMEnhancer:Generating LLM response...\n",
            "2025-05-26 14:03:23,330 - LLMEnhancer - INFO - LLM call #1\n",
            "2025-05-26 14:03:23,330 - LLMEnhancer - INFO - LLM call #1\n",
            "INFO:LLMEnhancer:LLM call #1\n",
            "2025-05-26 14:03:41,114 - LLMEnhancer - WARNING - Text quality issue detected: Multiple uses of \"visible\" detected\n",
            "2025-05-26 14:03:41,114 - LLMEnhancer - WARNING - Text quality issue detected: Multiple uses of \"visible\" detected\n",
            "WARNING:LLMEnhancer:Text quality issue detected: Multiple uses of \"visible\" detected\n",
            "2025-05-26 14:03:41,121 - LLMEnhancer - INFO - LLM enhanced description generated successfully (571 chars)\n",
            "2025-05-26 14:03:41,121 - LLMEnhancer - INFO - LLM enhanced description generated successfully (571 chars)\n",
            "INFO:LLMEnhancer:LLM enhanced description generated successfully (571 chars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 6 landmark-specific activities\n",
            "Processing scene_analysis: dict_keys(['scene_type', 'scene_name', 'confidence', 'description', 'enhanced_description', 'objects_present', 'object_count', 'regions', 'possible_activities', 'functional_zones', 'detected_landmarks', 'primary_landmark', 'lighting_conditions'])\n",
            "Original scene description (first 50 chars): A tourist landmark scene centered around Louvre Mu...\n",
            "Cleaned scene description (first 50 chars): A tourist landmark scene centered around Louvre Mu...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://50b7419ba537d603ea.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# %%writefile app.py\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import uuid\n",
        "# import spaces\n",
        "\n",
        "# from detection_model import DetectionModel\n",
        "# from color_mapper import ColorMapper\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from style import Style\n",
        "# from image_processor import ImageProcessor\n",
        "# from video_processor import VideoProcessor\n",
        "# from llm_enhancer import LLMEnhancer\n",
        "\n",
        "# Initialize Processors with LLM support\n",
        "image_processor = None\n",
        "video_processor = None\n",
        "\n",
        "def initialize_processors():\n",
        "    global image_processor, video_processor\n",
        "\n",
        "    try:\n",
        "        print(\"Attempting to initialize ImageProcessor with LLM support...\")\n",
        "        image_processor = ImageProcessor(use_llm=True, llm_model_path=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "        print(\"ImageProcessor initialized successfully with LLM\")\n",
        "\n",
        "        # 添加診斷檢查\n",
        "        if hasattr(image_processor, 'scene_analyzer'):\n",
        "            if image_processor.scene_analyzer is not None:\n",
        "                print(f\"scene_analyzer initialized: {type(image_processor.scene_analyzer)}\")\n",
        "                if hasattr(image_processor.scene_analyzer, 'use_llm'):\n",
        "                    print(f\"scene_analyzer.use_llm available: {image_processor.scene_analyzer.use_llm}\")\n",
        "            else:\n",
        "                print(\"WARNING: scene_analyzer is None after initialization\")\n",
        "        else:\n",
        "            print(\"WARNING: scene_analyzer attribute not found in image_processor\")\n",
        "\n",
        "        video_processor = VideoProcessor(image_processor)\n",
        "        print(\"VideoProcessor initialized successfully\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing processors with LLM: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Create fallback processor without LLM\n",
        "        try:\n",
        "            print(\"Attempting fallback initialization without LLM...\")\n",
        "            image_processor = ImageProcessor(use_llm=False, enable_places365=False)\n",
        "            video_processor = VideoProcessor(image_processor)\n",
        "            print(\"Fallback processors initialized successfully without LLM and Places365\")\n",
        "            return True\n",
        "\n",
        "        except Exception as fallback_error:\n",
        "            print(f\"Fatal error: Cannot initialize processors: {fallback_error}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            image_processor = None\n",
        "            video_processor = None\n",
        "            return False\n",
        "\n",
        "# Initialize processors\n",
        "initialization_success = initialize_processors()\n",
        "if not initialization_success:\n",
        "    print(\"WARNING: Failed to initialize processors. Application may not function correctly.\")\n",
        "\n",
        "# Helper Function\n",
        "def get_all_classes():\n",
        "    \"\"\"Gets all available COCO classes.\"\"\"\n",
        "    # Try to get from a loaded model first\n",
        "    if image_processor and image_processor.model_instances:\n",
        "         for model_instance in image_processor.model_instances.values():\n",
        "              if model_instance and model_instance.is_model_loaded:\n",
        "                   try:\n",
        "                        # Ensure class_names is a dict {id: name}\n",
        "                        if isinstance(model_instance.class_names, dict):\n",
        "                             return sorted([(int(idx), name) for idx, name in model_instance.class_names.items()])\n",
        "                   except Exception as e:\n",
        "                        print(f\"Error getting class names from model: {e}\")\n",
        "\n",
        "    # Fallback to standard COCO (ensure keys are ints)\n",
        "    default_classes = {\n",
        "        0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',\n",
        "        6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',\n",
        "        11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',\n",
        "        16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear',\n",
        "        22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',\n",
        "        27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard',\n",
        "        32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',\n",
        "        36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',\n",
        "        40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',\n",
        "        46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',\n",
        "        51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair',\n",
        "        57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet',\n",
        "        62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard',\n",
        "        67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink',\n",
        "        72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors',\n",
        "        77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
        "    }\n",
        "    return sorted(default_classes.items())\n",
        "\n",
        "# @spaces.GPU\n",
        "def handle_image_upload(image, model_name, confidence_threshold, filter_classes=None, use_llm=True, enable_landmark=True):\n",
        "    \"\"\"Processes a single uploaded image.\"\"\"\n",
        "    # Enhanced safety check for image_processor\n",
        "    if image_processor is None:\n",
        "        error_msg = \"Image processor is not initialized. Please restart the application or check system dependencies.\"\n",
        "        print(f\"ERROR: {error_msg}\")\n",
        "\n",
        "        # Create error plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.text(0.5, 0.5, \"Initialization Error\\nProcessor Not Available\",\n",
        "                color=\"red\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        return (None, error_msg, {}, fig, f\"<div style='color: red; font-weight: bold;'>Error: {error_msg}</div>\",\n",
        "                \"<div style='color: red;'>Error: System not initialized</div>\",\n",
        "                [[\"System Error\"]], [[\"System Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "    # Additional safety check for processor attributes\n",
        "    if not hasattr(image_processor, 'use_llm'):\n",
        "        error_msg = \"Image processor is corrupted. Missing required attributes.\"\n",
        "        print(f\"ERROR: {error_msg}\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.text(0.5, 0.5, \"Processor Error\\nCorrupted State\",\n",
        "                color=\"red\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        return (None, error_msg, {}, fig, f\"<div style='color: red; font-weight: bold;'>Error: {error_msg}</div>\",\n",
        "                \"<div style='color: red;'>Error: Processor corrupted</div>\",\n",
        "                [[\"Processor Error\"]], [[\"Processor Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "    print(f\"DIAGNOSTIC: Image upload handled with enable_landmark={enable_landmark}, use_llm={use_llm}\")\n",
        "    print(f\"Processing image with model: {model_name}, confidence: {confidence_threshold}, use_llm: {use_llm}, enable_landmark: {enable_landmark}\")\n",
        "    try:\n",
        "        image_processor.use_llm = use_llm\n",
        "\n",
        "        # 確保 scene_analyzer 不是 None\n",
        "        if hasattr(image_processor, 'scene_analyzer') and image_processor.scene_analyzer is not None:\n",
        "            if hasattr(image_processor.scene_analyzer, 'use_llm'):\n",
        "                image_processor.scene_analyzer.use_llm = use_llm\n",
        "                print(f\"Updated existing scene_analyzer use_llm setting to: {use_llm}\")\n",
        "\n",
        "            # 檢查並設置 landmark detection\n",
        "            if hasattr(image_processor.scene_analyzer, 'use_landmark_detection'):\n",
        "                # 設置所有相關標記\n",
        "                image_processor.scene_analyzer.use_landmark_detection = enable_landmark\n",
        "                image_processor.scene_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 確保處理器也設置了這選項\n",
        "                image_processor.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置更深層次的組件\n",
        "                if hasattr(image_processor.scene_analyzer, 'scene_describer') and image_processor.scene_analyzer.scene_describer is not None:\n",
        "                    image_processor.scene_analyzer.scene_describer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置CLIP分析器上的標記\n",
        "                if hasattr(image_processor.scene_analyzer, 'clip_analyzer') and image_processor.scene_analyzer.clip_analyzer is not None:\n",
        "                    if hasattr(image_processor.scene_analyzer.clip_analyzer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.clip_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置LLM增強器\n",
        "                if hasattr(image_processor.scene_analyzer, 'llm_enhancer') and image_processor.scene_analyzer.llm_enhancer is not None:\n",
        "                    if hasattr(image_processor.scene_analyzer.llm_enhancer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.llm_enhancer.enable_landmark = enable_landmark\n",
        "                        print(f\"Updated LLM enhancer enable_landmark to: {enable_landmark}\")\n",
        "\n",
        "                print(f\"Updated all landmark detection settings to: {enable_landmark}\")\n",
        "        else:\n",
        "            print(\"WARNING: scene_analyzer is None or not available\")\n",
        "            if hasattr(image_processor, 'enable_landmark'):\n",
        "                image_processor.enable_landmark = enable_landmark\n",
        "\n",
        "                # 設置更深層次的組別\n",
        "                if hasattr(image_processor.scene_analyzer, 'scene_describer'):\n",
        "                    image_processor.scene_analyzer.scene_describer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 設置CLIP分析器上的標記\n",
        "                if hasattr(image_processor.scene_analyzer, 'clip_analyzer'):\n",
        "                    if hasattr(image_processor.scene_analyzer.clip_analyzer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.clip_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 如果有LLM增強器，也設置它\n",
        "                if hasattr(image_processor.scene_analyzer, 'llm_enhancer'):\n",
        "                    image_processor.scene_analyzer.llm_enhancer.enable_landmark = enable_landmark\n",
        "                    print(f\"Updated LLM enhancer enable_landmark to: {enable_landmark}\")\n",
        "\n",
        "                print(f\"Updated all landmark detection settings to: {enable_landmark}\")\n",
        "\n",
        "        class_ids_to_filter = None\n",
        "        if filter_classes:\n",
        "            class_ids_to_filter = []\n",
        "            available_classes_dict = dict(get_all_classes())\n",
        "            name_to_id = {name: id for id, name in available_classes_dict.items()}\n",
        "            for class_str in filter_classes:\n",
        "                class_name_or_id = class_str.split(\":\")[0].strip()\n",
        "                class_id = -1\n",
        "                try:\n",
        "                    class_id = int(class_name_or_id)\n",
        "                    if class_id not in available_classes_dict:\n",
        "                        class_id = -1\n",
        "                except ValueError:\n",
        "                    if class_name_or_id in name_to_id:\n",
        "                        class_id = name_to_id[class_name_or_id]\n",
        "                    elif class_str in name_to_id: # Check full string \"id: name\"\n",
        "                        class_id = name_to_id[class_str]\n",
        "\n",
        "                if class_id != -1:\n",
        "                    class_ids_to_filter.append(class_id)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not parse class filter: {class_str}\")\n",
        "            print(f\"Filtering image results for class IDs: {class_ids_to_filter}\")\n",
        "\n",
        "        # Call the existing image processing logic\n",
        "        print(f\"DEBUG: app.py 傳遞 enable_landmark={enable_landmark} 到 process_image\")\n",
        "        result_image, result_text, stats = image_processor.process_image(\n",
        "            image,\n",
        "            model_name,\n",
        "            confidence_threshold,\n",
        "            class_ids_to_filter,\n",
        "            enable_landmark\n",
        "        )\n",
        "\n",
        "        # Format stats for JSON display\n",
        "        formatted_stats = image_processor.format_json_for_display(stats)\n",
        "\n",
        "        # Prepare visualization data for the plot\n",
        "        plot_figure = None\n",
        "        if stats and \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            available_classes_dict = dict(get_all_classes())\n",
        "            viz_data = image_processor.prepare_visualization_data(stats, available_classes_dict)\n",
        "            if \"error\" not in viz_data:\n",
        "                 plot_figure = EvaluationMetrics.create_enhanced_stats_plot(viz_data)\n",
        "            else:\n",
        "                 fig, ax = plt.subplots(figsize=(8, 6))\n",
        "                 ax.text(0.5, 0.5, viz_data[\"error\"], ha='center', va='center', fontsize=12)\n",
        "                 ax.axis('off')\n",
        "                 plot_figure = fig\n",
        "        else:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            ax.text(0.5, 0.5, \"No detection data for plot\", ha='center', va='center', fontsize=12)\n",
        "            ax.axis('off')\n",
        "            plot_figure = fig\n",
        "\n",
        "        # Extract scene analysis info\n",
        "        scene_analysis = stats.get(\"scene_analysis\", {})\n",
        "        scene_desc = scene_analysis.get(\"description\", \"Scene analysis requires detected objects.\")\n",
        "        # Ensure scene_desc is a string before adding HTML\n",
        "        if not isinstance(scene_desc, str):\n",
        "            scene_desc = str(scene_desc)\n",
        "\n",
        "        def clean_description(desc):\n",
        "            if not desc:\n",
        "                return \"\"\n",
        "\n",
        "            # 先過濾問答格式\n",
        "            if \"Questions:\" in desc:\n",
        "                desc = desc.split(\"Questions:\")[0].strip()\n",
        "            if \"Answers:\" in desc:\n",
        "                desc = desc.split(\"Answers:\")[0].strip()\n",
        "\n",
        "            # 然後按行過濾代碼和其他非敘述內容\n",
        "            lines = desc.split('\\n')\n",
        "            clean_lines = []\n",
        "            skip_block = False\n",
        "\n",
        "            for line in lines:\n",
        "                # 檢測問題格式\n",
        "                if re.match(r'^\\d+\\.\\s+(What|How|Why|When|Where|Who|The)', line):\n",
        "                    continue\n",
        "\n",
        "                # 檢查需要跳過的行\n",
        "                if line.strip().startswith(':param') or line.strip().startswith('\"\"\"'):\n",
        "                    continue\n",
        "                if line.strip().startswith(\"Exercise\") or \"class SceneDescriptionSystem\" in line:\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "                if ('def generate_scene_description' in line or\n",
        "                    'def enhance_scene_descriptions' in line or\n",
        "                    'def __init__' in line):\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "                if line.strip().startswith('#TEST'):\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "\n",
        "                if skip_block and line.strip() == \"\":\n",
        "                    skip_block = False\n",
        "\n",
        "                # 如果不需要跳過\n",
        "                if not skip_block:\n",
        "                    clean_lines.append(line)\n",
        "\n",
        "            cleaned_text = '\\n'.join(clean_lines)\n",
        "\n",
        "            # 如果清理後為空，返回原始描述的第一段作為保險\n",
        "            if not cleaned_text.strip():\n",
        "                paragraphs = [p.strip() for p in desc.split('\\n\\n') if p.strip()]\n",
        "                if paragraphs:\n",
        "                    return paragraphs[0]\n",
        "                return desc\n",
        "\n",
        "            return cleaned_text\n",
        "\n",
        "        # 獲取和處理場景描述\n",
        "        scene_analysis = stats.get(\"scene_analysis\", {})\n",
        "        print(\"Processing scene_analysis:\", scene_analysis.keys())\n",
        "\n",
        "        # 獲取原始描述\n",
        "        scene_desc = scene_analysis.get(\"description\", \"Scene analysis requires detected objects.\")\n",
        "        if not isinstance(scene_desc, str):\n",
        "            scene_desc = str(scene_desc)\n",
        "\n",
        "        print(f\"Original scene description (first 50 chars): {scene_desc[:50]}...\")\n",
        "\n",
        "        # determine original description\n",
        "        clean_scene_desc = clean_description(scene_desc)\n",
        "        print(f\"Cleaned scene description (first 50 chars): {clean_scene_desc[:50]}...\")\n",
        "\n",
        "        if not clean_scene_desc.strip():\n",
        "            clean_scene_desc = scene_desc\n",
        "\n",
        "        scene_desc_html = f\"<div>{clean_scene_desc}</div>\"\n",
        "\n",
        "        # 獲取LLM增強描述並且確保設置默認值為空字符串而非 None，不然會有None type Error\n",
        "        enhanced_description = scene_analysis.get(\"enhanced_description\", \"\")\n",
        "        if enhanced_description is None:\n",
        "            enhanced_description = \"\"\n",
        "\n",
        "        if not enhanced_description or not enhanced_description.strip():\n",
        "            print(\"WARNING: LLM enhanced description is empty!\")\n",
        "\n",
        "        # bedge & label\n",
        "        llm_badge = \"\"\n",
        "        description_to_show = \"\"\n",
        "\n",
        "        # 在 Original Scene Analysis 折疊區顯示原始的描述\n",
        "        if use_llm and enhanced_description:\n",
        "            llm_badge = '<span style=\"display:inline-block; margin-left:8px; padding:3px 10px; border-radius:12px; background: linear-gradient(90deg, #38b2ac, #4299e1); color:white; font-size:0.7rem; font-weight:bold; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); border: 1px solid rgba(255, 255, 255, 0.2);\">LLM Enhanced</span>'\n",
        "            description_to_show = enhanced_description\n",
        "\n",
        "        else:\n",
        "            llm_badge = '<span style=\"display:inline-block; margin-left:8px; padding:3px 10px; border-radius:12px; background-color:#718096; color:white; font-size:0.7rem; font-weight:bold;\">Basic</span>'\n",
        "            description_to_show = clean_scene_desc\n",
        "\n",
        "        # 使用LLM敘述時會有徽章標籤在標題上\n",
        "        scene_description_html = f'''\n",
        "        <div>\n",
        "            <div class=\"section-heading\" style=\"font-size:1.2rem; margin-top:15px;\">Scene Description {llm_badge}\n",
        "                <span style=\"font-size:0.8rem; color:#666; font-weight:normal; display:block; margin-top:2px;\">\n",
        "                    {('(Enhanced by AI language model)' if use_llm and enhanced_description else '(Based on object detection)')}\n",
        "                </span>\n",
        "            </div>\n",
        "            <div style=\"padding:15px; background-color:#ffffff; border-radius:8px; border:1px solid #e2e8f0; margin-bottom:20px; box-shadow:0 1px 3px rgba(0,0,0,0.05);\">\n",
        "                {description_to_show}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # 原始描述只在使用 LLM 且有增強描述時在折疊區顯示\n",
        "        original_desc_visibility = \"block\" if use_llm and enhanced_description else \"none\"\n",
        "        original_desc_html = f'''\n",
        "        <div id=\"original_scene_analysis_accordion\" style=\"display: {original_desc_visibility};\">\n",
        "            <div style=\"padding:15px; background-color:#f0f0f0; border-radius:8px; border:1px solid #e2e8f0;\">\n",
        "                {clean_scene_desc}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # Prepare activities list\n",
        "        activities_list = scene_analysis.get(\"possible_activities\", [])\n",
        "        if not activities_list:\n",
        "            activities_list_data = [[\"No specific activities inferred\"]] # Data for Dataframe\n",
        "        else:\n",
        "            activities_list_data = [[activity] for activity in activities_list]\n",
        "\n",
        "        # Prepare safety concerns list\n",
        "        safety_concerns_list = scene_analysis.get(\"safety_concerns\", [])\n",
        "        if not safety_concerns_list:\n",
        "            safety_data = [[\"No safety concerns detected\"]] # Data for Dataframe\n",
        "        else:\n",
        "            safety_data = [[concern] for concern in safety_concerns_list]\n",
        "\n",
        "        zones = scene_analysis.get(\"functional_zones\", {})\n",
        "        lighting = scene_analysis.get(\"lighting_conditions\", {\"time_of_day\": \"unknown\", \"confidence\": 0})\n",
        "\n",
        "        # 如果描述為空，記錄警告\n",
        "        if not clean_scene_desc.strip():\n",
        "            print(\"WARNING: Scene description is empty after cleaning!\")\n",
        "        if not enhanced_description.strip():\n",
        "            print(\"WARNING: LLM enhanced description is empty!\")\n",
        "\n",
        "        return (result_image, result_text, formatted_stats, plot_figure,\n",
        "            scene_description_html, original_desc_html,\n",
        "            activities_list_data, safety_data, zones, lighting)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in handle_image_upload: {e}\")\n",
        "        import traceback\n",
        "        error_msg = f\"Error processing image: {str(e)}\\n{traceback.format_exc()}\"\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.text(0.5, 0.5, \"Processing Error\", color=\"red\", ha=\"center\", va=\"center\")\n",
        "        ax.axis('off')\n",
        "        # Ensure return structure matches outputs even on error\n",
        "        return (None, error_msg, {}, fig, f\"<div>Error: {str(e)}</div>\", \"Error\",\n",
        "            [[\"Error\"]], [[\"Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "def download_video_from_url(video_url, max_duration_minutes=10):\n",
        "    \"\"\"\n",
        "    Downloads a video from a YouTube URL and returns the local path to the downloaded file.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): URL of the YouTube video to download\n",
        "        max_duration_minutes (int): Maximum allowed video duration in minutes\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Path to the downloaded video file or None, Error message or None)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a temporary directory to store the video\n",
        "        temp_dir = tempfile.gettempdir()\n",
        "        output_filename = f\"downloaded_{uuid.uuid4().hex}.mp4\"\n",
        "        output_path = os.path.join(temp_dir, output_filename)\n",
        "\n",
        "        # Check if it's a YouTube URL\n",
        "        if \"youtube.com\" in video_url or \"youtu.be\" in video_url:\n",
        "            # Import yt-dlp here to avoid dependency if not needed\n",
        "            import yt_dlp\n",
        "\n",
        "            # Setup yt-dlp options\n",
        "            ydl_opts = {\n",
        "                'format': 'best[ext=mp4]/best',  # Best quality MP4 or best available format\n",
        "                'outtmpl': output_path,\n",
        "                'noplaylist': True,\n",
        "                'quiet': False,  # Set to True to reduce output\n",
        "                'no_warnings': False,\n",
        "            }\n",
        "\n",
        "            # First extract info to check duration\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                print(f\"Extracting info from YouTube URL: {video_url}\")\n",
        "                info_dict = ydl.extract_info(video_url, download=False)\n",
        "\n",
        "                # Check if video exists\n",
        "                if not info_dict:\n",
        "                    return None, \"Could not retrieve video information. Please check the URL.\"\n",
        "\n",
        "                video_title = info_dict.get('title', 'Unknown Title')\n",
        "                duration = info_dict.get('duration', 0)\n",
        "\n",
        "                print(f\"Video title: {video_title}\")\n",
        "                print(f\"Video duration: {duration} seconds\")\n",
        "\n",
        "                # Check video duration\n",
        "                if duration > max_duration_minutes * 60:\n",
        "                    return None, f\"Video is too long ({duration} seconds). Maximum duration is {max_duration_minutes} minutes.\"\n",
        "\n",
        "                # Download the video\n",
        "                print(f\"Downloading YouTube video: {video_title}\")\n",
        "                ydl.download([video_url])\n",
        "\n",
        "            # Verify the file exists and has content\n",
        "            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "                return None, \"Download failed: Empty or missing file.\"\n",
        "\n",
        "            print(f\"Successfully downloaded video to: {output_path}\")\n",
        "            return output_path, None\n",
        "        else:\n",
        "            return None, \"Only YouTube URLs are supported at this time. Please enter a valid YouTube URL.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"Error downloading video: {e}\\n{error_details}\")\n",
        "        return None, f\"Error downloading video: {str(e)}\"\n",
        "\n",
        "\n",
        "# @spaces.GPU\n",
        "def handle_video_upload(video_input, video_url, input_type, model_name, confidence_threshold, process_interval):\n",
        "    \"\"\"Handles video upload or URL input and calls the VideoProcessor.\"\"\"\n",
        "\n",
        "    print(f\"Received video request: input_type={input_type}\")\n",
        "    video_path = None\n",
        "\n",
        "    # Handle based on input type\n",
        "    if input_type == \"upload\" and video_input:\n",
        "        print(f\"Processing uploaded video file\")\n",
        "        video_path = video_input\n",
        "    elif input_type == \"url\" and video_url:\n",
        "        print(f\"Processing video from URL: {video_url}\")\n",
        "        # Download video from URL\n",
        "        video_path, error_message = download_video_from_url(video_url)\n",
        "        if error_message:\n",
        "            error_html = f\"<div class='video-summary-content-wrapper'><pre>{error_message}</pre></div>\"\n",
        "            return None, error_html, {\"error\": error_message}\n",
        "    else:\n",
        "        print(\"No valid video input provided.\")\n",
        "        return None, \"<div class='video-summary-content-wrapper'><pre>Please upload a video file or provide a valid video URL.</pre></div>\", {}\n",
        "\n",
        "    print(f\"Starting video processing with: model={model_name}, confidence={confidence_threshold}, interval={process_interval}\")\n",
        "    try:\n",
        "        # Call the VideoProcessor method\n",
        "        output_video_path, summary_text, stats_dict = video_processor.process_video_file(\n",
        "            video_path=video_path,\n",
        "            model_name=model_name,\n",
        "            confidence_threshold=confidence_threshold,\n",
        "            process_interval=int(process_interval) # Ensure interval is int\n",
        "        )\n",
        "        print(f\"Video processing function returned: path={output_video_path}, summary length={len(summary_text)}\")\n",
        "\n",
        "        # Wrap processing summary in HTML tags for consistent styling with scene understanding page\n",
        "        summary_html = f\"<div class='video-summary-content-wrapper'><pre>{summary_text}</pre></div>\"\n",
        "\n",
        "        # Format statistics for better display\n",
        "        formatted_stats = {}\n",
        "        if stats_dict and isinstance(stats_dict, dict):\n",
        "            formatted_stats = stats_dict\n",
        "\n",
        "        return output_video_path, summary_html, formatted_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in handle_video_upload: {e}\")\n",
        "        import traceback\n",
        "        error_msg = f\"Error processing video: {str(e)}\\n{traceback.format_exc()}\"\n",
        "        error_html = f\"<div class='video-summary-content-wrapper'><pre>{error_msg}</pre></div>\"\n",
        "        return None, error_html, {\"error\": str(e)}\n",
        "\n",
        "\n",
        "# Create Gradio Interface\n",
        "def create_interface():\n",
        "    \"\"\"Creates the Gradio interface with Tabs.\"\"\"\n",
        "    css = Style.get_css()\n",
        "    available_models = DetectionModel.get_available_models()\n",
        "    model_choices = [model[\"model_file\"] for model in available_models]\n",
        "    class_choices_formatted = [f\"{id}: {name}\" for id, name in get_all_classes()] # Use formatted choices\n",
        "\n",
        "    with gr.Blocks(css=css, theme=gr.themes.Soft(primary_hue=\"teal\", secondary_hue=\"blue\")) as demo:\n",
        "\n",
        "        # Header\n",
        "        with gr.Group(elem_classes=\"app-header\"):\n",
        "              gr.HTML(\"\"\"\n",
        "                    <div style=\"text-align: center; width: 100%; padding: 2rem 0 3rem 0; background: linear-gradient(135deg, #f0f9ff, #e1f5fe);\">\n",
        "                        <h1 style=\"font-size: 3.5rem; margin-bottom: 0.5rem; background: linear-gradient(90deg, #38b2ac, #4299e1); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-weight: bold; font-family: 'Arial', sans-serif;\">VisionScout</h1>\n",
        "                        <h2 style=\"color: #4A5568; font-size: 1.2rem; font-weight: 400; margin-top: 0.5rem; margin-bottom: 1.5rem; font-family: 'Arial', sans-serif;\">Object Detection and Scene Understanding</h2>\n",
        "                        <div style=\"display: flex; justify-content: center; gap: 10px; margin: 0.5rem 0;\"><div style=\"height: 3px; width: 80px; background: linear-gradient(90deg, #38b2ac, #4299e1);\"></div></div>\n",
        "                        <div style=\"display: flex; justify-content: center; gap: 25px; margin-top: 1.5rem;\">\n",
        "                            <div style=\"padding: 8px 15px; border-radius: 20px; background: rgba(66, 153, 225, 0.15); color: #2b6cb0; font-weight: 500; font-size: 0.9rem;\"><span style=\"margin-right: 6px;\">🖼️</span> Image Analysis</div>\n",
        "                            <div style=\"padding: 8px 15px; border-radius: 20px; background: rgba(56, 178, 172, 0.15); color: #2b6cb0; font-weight: 500; font-size: 0.9rem;\"><span style=\"margin-right: 6px;\">🎬</span> Video Analysis</div>\n",
        "                        </div>\n",
        "                         <div style=\"margin-top: 20px; padding: 10px 15px; background-color: rgba(255, 248, 230, 0.9); border-left: 3px solid #f6ad55; border-radius: 6px; max-width: 600px; margin-left: auto; margin-right: auto; text-align: left;\">\n",
        "                             <p style=\"margin: 0; font-size: 0.9rem; color: #805ad5; font-weight: 500;\">\n",
        "                                 <span style=\"margin-right: 5px;\">📱</span> iPhone users: HEIC images may not be supported.\n",
        "                                 <a href=\"https://cloudconvert.com/heic-to-jpg\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">Convert HEIC to JPG</a> before uploading if needed.\n",
        "                             </p>\n",
        "                         </div>\n",
        "                    </div>\n",
        "                \"\"\")\n",
        "\n",
        "        # Main Content with Tabs\n",
        "        with gr.Tabs(elem_classes=\"tabs\"):\n",
        "\n",
        "            # Tab 1: Image Processing\n",
        "            with gr.Tab(\"Image Processing\"):\n",
        "                current_image_model = gr.State(\"yolov8m.pt\") # State for image model selection\n",
        "                with gr.Row(equal_height=False): # Allow columns to have different heights\n",
        "                    # Left Column: Image Input & Controls\n",
        "                    with gr.Column(scale=4, elem_classes=\"input-panel\"):\n",
        "                        with gr.Group():\n",
        "                            gr.HTML('<div class=\"section-heading\">Upload Image</div>')\n",
        "                            image_input = gr.Image(type=\"pil\", label=\"Upload an image\", elem_classes=\"upload-box\")\n",
        "\n",
        "                            with gr.Accordion(\"Image Analysis Settings\", open=False):\n",
        "                                image_model_dropdown = gr.Dropdown(\n",
        "                                    choices=model_choices,\n",
        "                                    value=\"yolov8m.pt\", # Default for images\n",
        "                                    label=\"Select Model\",\n",
        "                                    info=\"Choose speed vs. accuracy (n=fast, m=balanced, x=accurate)\"\n",
        "                                )\n",
        "                                # Display model info\n",
        "                                image_model_info = gr.Markdown(DetectionModel.get_model_description(\"yolov8m.pt\"))\n",
        "\n",
        "                                image_confidence = gr.Slider(\n",
        "                                    minimum=0.1, maximum=0.9, value=0.25, step=0.05,\n",
        "                                    label=\"Confidence Threshold\",\n",
        "                                    info=\"Minimum confidence for displaying a detected object\"\n",
        "                                )\n",
        "\n",
        "                                use_llm = gr.Checkbox(\n",
        "                                    label=\"Use LLM for enhanced scene descriptions\",\n",
        "                                    value=True,\n",
        "                                    info=\"Provides more detailed and natural language descriptions (may increase processing time)\"\n",
        "                                )\n",
        "\n",
        "                                use_landmark_detection = gr.Checkbox(\n",
        "                                    label=\"Use CLIP for Landmark Detection\",\n",
        "                                    value=False,\n",
        "                                    info=\"Detect famous landmarks, monuments, and tourist attractions that standard object detection cannot recognize (increases processing time)\"\n",
        "                                )\n",
        "\n",
        "                                with gr.Accordion(\"Filter Classes\", open=False):\n",
        "                                     gr.HTML('<div class=\"section-heading\" style=\"font-size: 1rem;\">Common Categories</div>')\n",
        "                                     with gr.Row():\n",
        "                                         people_btn = gr.Button(\"People\", size=\"sm\")\n",
        "                                         vehicles_btn = gr.Button(\"Vehicles\", size=\"sm\")\n",
        "                                         animals_btn = gr.Button(\"Animals\", size=\"sm\")\n",
        "                                         objects_btn = gr.Button(\"Common Objects\", size=\"sm\")\n",
        "                                     image_class_filter = gr.Dropdown(\n",
        "                                         choices=class_choices_formatted, # Use formatted choices\n",
        "                                         multiselect=True,\n",
        "                                         label=\"Select Classes to Display\",\n",
        "                                         info=\"Leave empty to show all detected objects\"\n",
        "                                     )\n",
        "\n",
        "                        image_detect_btn = gr.Button(\"Analyze Image\", variant=\"primary\", elem_classes=\"detect-btn\")\n",
        "\n",
        "                        with gr.Group(elem_classes=\"how-to-use\"):\n",
        "                             gr.HTML('<div class=\"section-heading\">How to Use (Image)</div>')\n",
        "                             gr.Markdown(\"\"\"\n",
        "                                1. Upload an image or use the camera\n",
        "                                2. *(Optional)* Adjust settings like confidence threshold or model size (n, m = balanced, x = accurate)\n",
        "                                3. In **Analysis Settings**, you can:\n",
        "                                    * Uncheck **Use LLM** to skip enhanced descriptions (faster)\n",
        "                                    * Check **Use CLIP for Landmark Detection** to identify famous landmarks like museums, monuments, and tourist attractions *(may take longer)*\n",
        "                                    * Filter object classes to focus on specific types of objects *(optional)*\n",
        "                                4. Click **Analyze Image** button\n",
        "\n",
        "                                **💡 Tip:** For landmark recognition (e.g. Louvre Museum), make sure to enable **CLIP for Landmark Detection** in the settings above.\n",
        "                                \"\"\")\n",
        "\n",
        "\n",
        "                        # Image Examples\n",
        "                        gr.Examples(\n",
        "                            examples=[\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_01.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_02.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_04.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_05.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/landmark_Louvre_01.jpg\",\n",
        "                                ],\n",
        "                            inputs=image_input,\n",
        "                            label=\"Example Images\"\n",
        "                         )\n",
        "\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div style=\"text-align: center; margin-top: 8px; padding: 6px; background-color: #f8f9fa; border-radius: 4px; border: 1px solid #e2e8f0;\">\n",
        "                                <p style=\"font-size: 12px; color: #718096; margin: 0;\">\n",
        "                                    📷 Sample images sourced from <a href=\"https://unsplash.com\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">Unsplash</a>\n",
        "                                </p>\n",
        "                            </div>\n",
        "                        \"\"\")\n",
        "\n",
        "                    # Right Column: Image Results\n",
        "                    with gr.Column(scale=6, elem_classes=\"output-panel\"):\n",
        "                        with gr.Tabs(elem_classes=\"tabs\"):\n",
        "                            with gr.Tab(\"Detection Result\"):\n",
        "                                image_result_image = gr.Image(type=\"pil\", label=\"Detection Result\")\n",
        "                                gr.HTML('<div class=\"section-heading\">Detection Details</div>')\n",
        "                                image_result_text = gr.Textbox(label=None, lines=10, elem_id=\"detection-details\", container=False)\n",
        "\n",
        "                            with gr.Tab(\"Scene Understanding\"):\n",
        "                                gr.HTML('<div class=\"section-heading\">Scene Analysis</div>')\n",
        "                                gr.HTML(\"\"\"\n",
        "                                    <details class=\"info-details\" style=\"margin: 5px 0 15px 0;\">\n",
        "                                        <summary style=\"padding: 8px; background-color: #f0f7ff; border-radius: 6px; border-left: 3px solid #4299e1; font-weight: bold; cursor: pointer; color: #2b6cb0;\">\n",
        "                                            🔍 The AI Vision Scout Report: Click for important notes about this analysis\n",
        "                                        </summary>\n",
        "                                        <div style=\"margin-top: 8px; padding: 10px; background-color: #f8f9fa; border-radius: 6px; border: 1px solid #e2e8f0;\">\n",
        "                                            <p style=\"font-size: 13px; color: #718096; margin: 0;\">\n",
        "                                                <b>About this analysis:</b> This analysis is the model's best guess based on visible objects.\n",
        "                                                Like human scouts, it sometimes gets lost or sees things that aren't there (but don't we all?).\n",
        "                                                Consider this an educated opinion rather than absolute truth. For critical applications, always verify with human eyes! 🧐\n",
        "                                            </p>\n",
        "                                        </div>\n",
        "                                    </details>\n",
        "                                \"\"\")\n",
        "\n",
        "                                gr.HTML('''\n",
        "                                    <div style=\"margin-top: 5px; padding: 6px 10px; background-color: #f0f9ff; border-radius: 4px; border-left: 3px solid #63b3ed; font-size: 12px; margin-bottom: 10px;\">\n",
        "                                        <p style=\"margin: 0; color: #4a5568;\">\n",
        "                                            <b>Note:</b> AI descriptions may vary slightly with each generation, reflecting the creative nature of AI. This is similar to how a person might use different words each time they describe the same image. Processing time may be longer during first use or when analyzing complex scenes, as the LLM enhancement requires additional computational resources.\n",
        "                                        </p>\n",
        "                                    </div>\n",
        "                                    ''')\n",
        "                                image_scene_description_html = gr.HTML(label=None, elem_id=\"scene_analysis_description_text\")\n",
        "\n",
        "                                # 使用LLM增強敘述時也會顯示原本敘述內容\n",
        "                                with gr.Accordion(\"Original Scene Analysis\", open=False, elem_id=\"original_scene_analysis_accordion\"):\n",
        "                                    image_llm_description = gr.HTML(label=None, elem_id=\"original_scene_description_text\")\n",
        "\n",
        "                                with gr.Row():\n",
        "                                     with gr.Column(scale=1):\n",
        "                                         gr.HTML('<div class=\"section-heading\" style=\"font-size:1rem; text-align:left;\">Possible Activities</div>')\n",
        "                                         image_activities_list = gr.Dataframe(headers=[\"Activity\"], datatype=[\"str\"], row_count=5, col_count=1, wrap=True)\n",
        "\n",
        "                                     with gr.Column(scale=1):\n",
        "                                         gr.HTML('<div class=\"section-heading\" style=\"font-size:1rem; text-align:left;\">Safety Concerns</div>')\n",
        "                                         image_safety_list = gr.Dataframe(headers=[\"Concern\"], datatype=[\"str\"], row_count=5, col_count=1, wrap=True)\n",
        "\n",
        "                                gr.HTML('<div class=\"section-heading\">Functional Zones</div>')\n",
        "                                image_zones_json = gr.JSON(label=None, elem_classes=\"json-box\")\n",
        "\n",
        "                                gr.HTML('<div class=\"section-heading\">Lighting Conditions</div>')\n",
        "                                image_lighting_info = gr.JSON(label=None, elem_classes=\"json-box\")\n",
        "\n",
        "                            with gr.Tab(\"Statistics\"):\n",
        "                                with gr.Row():\n",
        "                                    with gr.Column(scale=3, elem_classes=\"plot-column\"):\n",
        "                                        gr.HTML('<div class=\"section-heading\">Object Distribution</div>')\n",
        "                                        image_plot_output = gr.Plot(label=None, elem_classes=\"large-plot-container\")\n",
        "                                    with gr.Column(scale=2, elem_classes=\"stats-column\"):\n",
        "                                        gr.HTML('<div class=\"section-heading\">Detection Statistics</div>')\n",
        "                                        image_stats_json = gr.JSON(label=None, elem_classes=\"enhanced-json-display\")\n",
        "\n",
        "            # Tab 2: Video Processing\n",
        "            with gr.Tab(\"Video Processing\"):\n",
        "                with gr.Row(equal_height=False):\n",
        "                    # Left Column: Video Input & Controls\n",
        "                    with gr.Column(scale=4, elem_classes=\"input-panel\"):\n",
        "                        with gr.Group():\n",
        "                            gr.HTML('<div class=\"section-heading\">Video Input</div>')\n",
        "\n",
        "                            # Add input type selection\n",
        "                            video_input_type = gr.Radio(\n",
        "                                [\"upload\", \"url\"],\n",
        "                                label=\"Input Method\",\n",
        "                                value=\"upload\",\n",
        "                                info=\"Choose how to provide the video\"\n",
        "                            )\n",
        "\n",
        "                            # File upload (will be shown/hidden based on selection)\n",
        "                            with gr.Group(elem_id=\"upload-video-group\"):\n",
        "                                video_input = gr.Video(\n",
        "                                    label=\"Upload a video file (MP4, AVI, MOV)\",\n",
        "                                    sources=[\"upload\"],\n",
        "                                    visible=True\n",
        "                                )\n",
        "\n",
        "                            # URL input (will be shown/hidden based on selection)\n",
        "                            with gr.Group(elem_id=\"url-video-group\"):\n",
        "                                video_url_input = gr.Textbox(\n",
        "                                    label=\"Enter video URL (YouTube or direct video link)\",\n",
        "                                    placeholder=\"https://www.youtube.com/watch?v=...\",\n",
        "                                    visible=False,\n",
        "                                    elem_classes=\"custom-video-url-input\"\n",
        "                                )\n",
        "                                gr.HTML(\"\"\"\n",
        "                                    <div style=\"padding: 8px; margin-top: 5px; background-color: #fff8f8; border-radius: 4px; border-left: 3px solid #f87171; font-size: 12px;\">\n",
        "                                        <p style=\"margin: 0; color: #4b5563;\">\n",
        "                                            Note: Currently only YouTube URLs are supported. Maximum video duration is 10 minutes. Due to YouTube's anti-bot protection, some videos may not be downloadable. For protected videos, please upload a local video file instead.\n",
        "                                        </p>\n",
        "                                    </div>\n",
        "                                \"\"\")\n",
        "\n",
        "                            with gr.Accordion(\"Video Analysis Settings\", open=True):\n",
        "                                video_model_dropdown = gr.Dropdown(\n",
        "                                    choices=model_choices,\n",
        "                                    value=\"yolov8n.pt\", # Default 'n' for video\n",
        "                                    label=\"Select Model (Video)\",\n",
        "                                    info=\"Faster models (like 'n') are recommended\"\n",
        "                                )\n",
        "                                video_confidence = gr.Slider(\n",
        "                                    minimum=0.1, maximum=0.9, value=0.4, step=0.05,\n",
        "                                    label=\"Confidence Threshold (Video)\"\n",
        "                                )\n",
        "                                video_process_interval = gr.Slider(\n",
        "                                    minimum=1, maximum=60, value=10, step=1, # Allow up to 60 frame interval\n",
        "                                    label=\"Processing Interval (Frames)\",\n",
        "                                    info=\"Analyze every Nth frame (higher value = faster)\"\n",
        "                                )\n",
        "                        video_process_btn = gr.Button(\"Process Video\", variant=\"primary\", elem_classes=\"detect-btn\")\n",
        "\n",
        "                        with gr.Group(elem_classes=\"how-to-use\"):\n",
        "                            gr.HTML('<div class=\"section-heading\">How to Use (Video)</div>')\n",
        "                            gr.Markdown(\"\"\"\n",
        "                            1. Choose your input method: Upload a file or enter a URL.\n",
        "                            2. Adjust settings if needed (using a faster model and larger interval is recommended for longer videos).\n",
        "                            3. Click \"Process Video\". **Processing can take a significant amount of time.**\n",
        "                            4. The annotated video and summary will appear on the right when finished.\n",
        "                            \"\"\")\n",
        "\n",
        "                        # Add video examples\n",
        "                        gr.HTML('<div class=\"section-heading\">Example Videos</div>')\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div style=\"padding: 10px; background-color: #f0f7ff; border-radius: 6px; margin-bottom: 15px;\">\n",
        "                                <p style=\"font-size: 14px; color: #4A5568; margin: 0;\">\n",
        "                                    Upload any video containing objects that YOLO can detect. For testing, find sample videos\n",
        "                                    <a href=\"https://www.pexels.com/search/videos/street/\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">here</a>.\n",
        "                                </p>\n",
        "                            </div>\n",
        "                        \"\"\")\n",
        "\n",
        "                    # Right Column: Video Results\n",
        "                    with gr.Column(scale=6, elem_classes=\"output-panel video-result-panel\"):\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div class=\"section-heading\">Video Result</div>\n",
        "                            <details class=\"info-details\" style=\"margin: 5px 0 15px 0;\">\n",
        "                                <summary style=\"padding: 8px; background-color: #f0f7ff; border-radius: 6px; border-left: 3px solid #4299e1; font-weight: bold; cursor: pointer; color: #2b6cb0;\">\n",
        "                                    🎬 Video Processing Notes\n",
        "                                </summary>\n",
        "                                <div style=\"margin-top: 8px; padding: 10px; background-color: #f8f9fa; border-radius: 6px; border: 1px solid #e2e8f0;\">\n",
        "                                    <p style=\"font-size: 13px; color: #718096; margin: 0;\">\n",
        "                                        The processed video includes bounding boxes around detected objects. For longer videos,\n",
        "                                        consider using a faster model (like YOLOv8n) and a higher frame interval to reduce processing time.\n",
        "                                    </p>\n",
        "                                </div>\n",
        "                            </details>\n",
        "                        \"\"\")\n",
        "                        video_output = gr.Video(label=\"Processed Video\", elem_classes=\"video-output-container\") # Output for the processed video file\n",
        "\n",
        "                        gr.HTML('<div class=\"section-heading\">Processing Summary</div>')\n",
        "                        # 使用HTML顯示影片的摘要\n",
        "                        video_summary_text = gr.HTML(\n",
        "                            label=None,\n",
        "                            elem_id=\"video-summary-html-output\"\n",
        "                        )\n",
        "\n",
        "                        gr.HTML('<div class=\"section-heading\">Aggregated Statistics</div>')\n",
        "                        video_stats_json = gr.JSON(label=None, elem_classes=\"video-stats-display\") # Display statistics\n",
        "\n",
        "        # Event Listeners\n",
        "        # Image Model Change Handler\n",
        "        image_model_dropdown.change(\n",
        "            fn=lambda model: (model, DetectionModel.get_model_description(model)),\n",
        "            inputs=[image_model_dropdown],\n",
        "            outputs=[current_image_model, image_model_info] # Update state and description\n",
        "        )\n",
        "\n",
        "        # Image Filter Buttons\n",
        "        available_classes_list = get_all_classes() # Get list of (id, name)\n",
        "        people_classes_ids = [0]\n",
        "        vehicles_classes_ids = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "        animals_classes_ids = list(range(14, 24))\n",
        "        common_objects_ids = [39, 41, 42, 43, 44, 45, 56, 57, 60, 62, 63, 67, 73] # Bottle, cup, fork, knife, spoon, bowl, chair, couch, table, tv, laptop, phone, book\n",
        "\n",
        "        people_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in people_classes_ids], outputs=image_class_filter)\n",
        "        vehicles_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in vehicles_classes_ids], outputs=image_class_filter)\n",
        "        animals_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in animals_classes_ids], outputs=image_class_filter)\n",
        "        objects_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in common_objects_ids], outputs=image_class_filter)\n",
        "\n",
        "        video_input_type.change(\n",
        "            fn=lambda input_type: [\n",
        "                # Show/hide file upload\n",
        "                gr.update(visible=(input_type == \"upload\")),\n",
        "                # Show/hide URL input\n",
        "                gr.update(visible=(input_type == \"url\"))\n",
        "            ],\n",
        "            inputs=[video_input_type],\n",
        "            outputs=[video_input, video_url_input]\n",
        "        )\n",
        "\n",
        "        image_detect_btn.click(\n",
        "            fn=handle_image_upload,\n",
        "            inputs=[image_input, image_model_dropdown, image_confidence, image_class_filter, use_llm, use_landmark_detection ],\n",
        "            outputs=[\n",
        "                image_result_image, image_result_text, image_stats_json, image_plot_output,\n",
        "                image_scene_description_html, image_llm_description, image_activities_list, image_safety_list, image_zones_json,\n",
        "                image_lighting_info\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        video_process_btn.click(\n",
        "            fn=handle_video_upload,\n",
        "            inputs=[\n",
        "                video_input,\n",
        "                video_url_input,\n",
        "                video_input_type,\n",
        "                video_model_dropdown,\n",
        "                video_confidence,\n",
        "                video_process_interval\n",
        "            ],\n",
        "            outputs=[video_output, video_summary_text, video_stats_json]\n",
        "        )\n",
        "\n",
        "        # Footer\n",
        "        gr.HTML(\"\"\"\n",
        "            <div class=\"footer\" style=\"padding: 25px 0; text-align: center; background: linear-gradient(to right, #f5f9fc, #e1f5fe); border-top: 1px solid #e2e8f0; margin-top: 30px;\">\n",
        "                <div style=\"margin-bottom: 15px;\">\n",
        "                    <p style=\"font-size: 14px; color: #4A5568; margin: 5px 0;\">Powered by YOLOv8, CLIP, Places365, Meta Llama3.2 and Ultralytics • Created with Gradio</p>\n",
        "                </div>\n",
        "                <div style=\"display: flex; align-items: center; justify-content: center; gap: 20px; margin-top: 15px;\">\n",
        "                    <p style=\"font-family: 'Arial', sans-serif; font-size: 14px; font-weight: 500; letter-spacing: 2px; background: linear-gradient(90deg, #38b2ac, #4299e1); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin: 0; text-transform: uppercase; display: inline-block;\">EXPLORE THE CODE →</p>\n",
        "                    <a href=\"https://github.com/Eric-Chung-0511/Learning-Record/tree/main/Data%20Science%20Projects/VisionScout\" target=\"_blank\" style=\"text-decoration: none;\">\n",
        "                        <img src=\"https://img.shields.io/badge/GitHub-VisionScout-4299e1?logo=github&style=for-the-badge\">\n",
        "                    </a>\n",
        "                </div>\n",
        "            </div>\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_interface = create_interface()\n",
        "\n",
        "    demo_interface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikiFwTh3WG75"
      },
      "outputs": [],
      "source": [
        "# %%writefile requirements.txt\n",
        "# torch>=2.0.0\n",
        "# torchvision>=0.15.0\n",
        "# ultralytics>=8.0.0\n",
        "# opencv-python>=4.7.0\n",
        "# pillow>=9.4.0\n",
        "# numpy>=1.23.5\n",
        "# matplotlib>=3.7.0\n",
        "# gradio>=3.32.0\n",
        "# git+https://github.com/openai/CLIP.git\n",
        "# yt-dlp>=2023.3.4\n",
        "# requests>=2.28.1\n",
        "# transformers\n",
        "# accelerate\n",
        "# bitsandbytes\n",
        "# sentencepiece\n",
        "# huggingface_hub>=0.19.0\n",
        "# urllib3>=1.26.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8l2_CT9W2Vl"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.download('detection_model.py')\n",
        "# files.download('color_mapper.py')\n",
        "# files.download('visualization_helper.py')\n",
        "# files.download('evaluation_metrics.py')\n",
        "# files.download('style.py')\n",
        "# files.download('scene_type.py')\n",
        "# files.download('confifence_templates.py')\n",
        "# files.download('scene_detail_templates.py')\n",
        "# files.download('object_template_fillers.py')\n",
        "# files.download('safety_templates.py')\n",
        "# files.download('activity_templates.py')\n",
        "# files.download('object_categories.py')\n",
        "# files.download('lighting_conditions.py')\n",
        "# files.download('viewpoint_templates.py')\n",
        "# files.download('cultural_templates.py')\n",
        "# files.download('spatial_analyzer.py')\n",
        "# files.download('enhance_scene_describer.py')\n",
        "# files.download('lighting_analyzer.py')\n",
        "# files.download('scene_description.py')\n",
        "# files.download('clip_prompts.py')\n",
        "# files.download('clip_analyzer.py')\n",
        "# files.download('scene_analyzer.py')\n",
        "# files.download('image_processor.py')\n",
        "# files.download('video_processor.py')\n",
        "# files.download('llm_enhancer.py')\n",
        "# files.download('app.py')\n",
        "\n",
        "# files.download('requirements.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVswpsr-Wfr8"
      },
      "outputs": [],
      "source": [
        "#    # Set up example images\n",
        "# examples=[\n",
        "#             \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_01.jpg\",\n",
        "#             \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_02.jpg\",\n",
        "#             \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_02.jpg\",\n",
        "#             \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_04.jpg\"\n",
        "#             ],"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc279edc479540b7a21bd0d2fac5346f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21aa051411894333addde7063e59d8e3",
              "IPY_MODEL_9d4790cee279417fbb42983389f07268",
              "IPY_MODEL_03f5c1dc292a4db0810d07280c1925bc"
            ],
            "layout": "IPY_MODEL_75bba9bc06024df5913a7f1c49c9b902"
          }
        },
        "21aa051411894333addde7063e59d8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90548f9a10b4292be1d17f4044a5d38",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4ff948d1214548b8ca917e05aae008",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9d4790cee279417fbb42983389f07268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f50fe1899b4ccc9a2affc05d4861b1",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7540db0f4a9d43d5b3dc2fdfb8fa0442",
            "value": 54528
          }
        },
        "03f5c1dc292a4db0810d07280c1925bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20fa2a57873e4ad582c453ff869f468b",
            "placeholder": "​",
            "style": "IPY_MODEL_6cde27c9220e40e1a8a06271246ba4a5",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 3.59MB/s]"
          }
        },
        "75bba9bc06024df5913a7f1c49c9b902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90548f9a10b4292be1d17f4044a5d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4ff948d1214548b8ca917e05aae008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f50fe1899b4ccc9a2affc05d4861b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7540db0f4a9d43d5b3dc2fdfb8fa0442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20fa2a57873e4ad582c453ff869f468b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cde27c9220e40e1a8a06271246ba4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36440f03db3f483da100311ad7512ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcb446c3bc6c42b2bf0b514d3eaa75c1",
              "IPY_MODEL_56e6fc8a666b4f248a1356754fbd731d",
              "IPY_MODEL_54daf70413414ee78027eb49a9a61c91"
            ],
            "layout": "IPY_MODEL_4924f7025fd24500b05a32c264933a5d"
          }
        },
        "bcb446c3bc6c42b2bf0b514d3eaa75c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fbc5bea58f844e293c76ca218445d22",
            "placeholder": "​",
            "style": "IPY_MODEL_d07da533ae36416589fc189972337062",
            "value": "tokenizer.json: 100%"
          }
        },
        "56e6fc8a666b4f248a1356754fbd731d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666cfc635eac476ebea70f13d2e5ee00",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d18b00f9f5da4652930390f9e37a0434",
            "value": 9085657
          }
        },
        "54daf70413414ee78027eb49a9a61c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac162f9528f4458cb37a5ac64c7ccc68",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d03ea7afe4451ea64d3fd9115bded3",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 21.0MB/s]"
          }
        },
        "4924f7025fd24500b05a32c264933a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fbc5bea58f844e293c76ca218445d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07da533ae36416589fc189972337062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "666cfc635eac476ebea70f13d2e5ee00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18b00f9f5da4652930390f9e37a0434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac162f9528f4458cb37a5ac64c7ccc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d03ea7afe4451ea64d3fd9115bded3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "760ceceeb80640cea853cdaf71db7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9351cd13b3d4d2faf0b4335d7cc5642",
              "IPY_MODEL_46135514d1434ae8b7b63fa15c5f8e46",
              "IPY_MODEL_1e43670477024ba39e29a512489ee0ff"
            ],
            "layout": "IPY_MODEL_077768d6a9d9433cbc190b544ed2f95c"
          }
        },
        "e9351cd13b3d4d2faf0b4335d7cc5642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb50c52afa814a97adfa303032982c4e",
            "placeholder": "​",
            "style": "IPY_MODEL_3b538d70083c4ea796543b994546b544",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "46135514d1434ae8b7b63fa15c5f8e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e27287cc9834ff0ab130eeac56c870e",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daee5ceeb0dd4a3c94e115092632a741",
            "value": 296
          }
        },
        "1e43670477024ba39e29a512489ee0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dcd42eaedc24838a94c3e5637e2de7f",
            "placeholder": "​",
            "style": "IPY_MODEL_f3af0e6428d84f34b9f202d5893e93e7",
            "value": " 296/296 [00:00&lt;00:00, 33.1kB/s]"
          }
        },
        "077768d6a9d9433cbc190b544ed2f95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb50c52afa814a97adfa303032982c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b538d70083c4ea796543b994546b544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e27287cc9834ff0ab130eeac56c870e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daee5ceeb0dd4a3c94e115092632a741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dcd42eaedc24838a94c3e5637e2de7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3af0e6428d84f34b9f202d5893e93e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ffa644344a24dca802bbe084e7893d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15c1086566d4418e805145453c776bf9",
              "IPY_MODEL_9aac29b2414748a8a42d7f565934aef9",
              "IPY_MODEL_2a0de34ef5664a37a076d07a1702072b"
            ],
            "layout": "IPY_MODEL_d10d1cbc20124781bdaab6a1612612fb"
          }
        },
        "15c1086566d4418e805145453c776bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95e2875d5b74496938e8dd86cd64753",
            "placeholder": "​",
            "style": "IPY_MODEL_b46f7b644c73497d9d343451f0984b4d",
            "value": "config.json: 100%"
          }
        },
        "9aac29b2414748a8a42d7f565934aef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dad548aae954f4e967b0039bcb00415",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1054eafba0c457da893864af0708529",
            "value": 878
          }
        },
        "2a0de34ef5664a37a076d07a1702072b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c060aa54bfe94d9b8d6705fed947a558",
            "placeholder": "​",
            "style": "IPY_MODEL_777913992879487fa0d8b736f29aa896",
            "value": " 878/878 [00:00&lt;00:00, 97.5kB/s]"
          }
        },
        "d10d1cbc20124781bdaab6a1612612fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95e2875d5b74496938e8dd86cd64753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b46f7b644c73497d9d343451f0984b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dad548aae954f4e967b0039bcb00415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1054eafba0c457da893864af0708529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c060aa54bfe94d9b8d6705fed947a558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777913992879487fa0d8b736f29aa896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da7aa83bbef64df0bec0eb4063370510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ca7ab9f1f74317b3c4ff50e840b31e",
              "IPY_MODEL_a081f7c2aa1a41c297c8f9fe52664522",
              "IPY_MODEL_7bbac2aa84b8474e8b564e3db036e87a"
            ],
            "layout": "IPY_MODEL_d23f0ece6ea2430e9cd3f7674165b79f"
          }
        },
        "46ca7ab9f1f74317b3c4ff50e840b31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ca559d95bc4943b1ff7afcd8c397fd",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2260ffa9954056bfe8799df2ee85ed",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "a081f7c2aa1a41c297c8f9fe52664522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ee77b9fc9043078e4def2be0ee4f32",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49a623e832444bf695cffe6badd18ef8",
            "value": 20919
          }
        },
        "7bbac2aa84b8474e8b564e3db036e87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a89bd4883e4a57af2576b797489bd2",
            "placeholder": "​",
            "style": "IPY_MODEL_e420097050b24730a392a4b0f1b931f0",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 2.12MB/s]"
          }
        },
        "d23f0ece6ea2430e9cd3f7674165b79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ca559d95bc4943b1ff7afcd8c397fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2260ffa9954056bfe8799df2ee85ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ee77b9fc9043078e4def2be0ee4f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a623e832444bf695cffe6badd18ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84a89bd4883e4a57af2576b797489bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e420097050b24730a392a4b0f1b931f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a922dabd66d4852b9efb2ee8ca20c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_163533ea1fbc435a97e7657983ef4a67",
              "IPY_MODEL_fbc8486b1eaa4090aa37e72eb7098d3d",
              "IPY_MODEL_59e674851ef44e8c92369447181025a5"
            ],
            "layout": "IPY_MODEL_1b0cd2c0629049fe95a88cf7991a0819"
          }
        },
        "163533ea1fbc435a97e7657983ef4a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5306481c5f34d458d9bdc11bdde5dc4",
            "placeholder": "​",
            "style": "IPY_MODEL_6d3df1b8ba1f4ef6b9a13d93896650aa",
            "value": "Fetching 2 files: 100%"
          }
        },
        "fbc8486b1eaa4090aa37e72eb7098d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d175024d6d740b9b7a07e8987f57d9f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44101bd468ab472e93e950f297ccd105",
            "value": 2
          }
        },
        "59e674851ef44e8c92369447181025a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db570cdd4f743438141c1c9a2a48fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_00487bf4c9324cd587824764d4586eb2",
            "value": " 2/2 [01:10&lt;00:00, 70.61s/it]"
          }
        },
        "1b0cd2c0629049fe95a88cf7991a0819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5306481c5f34d458d9bdc11bdde5dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d3df1b8ba1f4ef6b9a13d93896650aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d175024d6d740b9b7a07e8987f57d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44101bd468ab472e93e950f297ccd105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9db570cdd4f743438141c1c9a2a48fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00487bf4c9324cd587824764d4586eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195a823cf7eb4d0e9a87d440dce64a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cfded6f513c4ce090e014caf7e10611",
              "IPY_MODEL_e775f3b04f484693ac25979a07bed69c",
              "IPY_MODEL_c7202ffc711f4b279168666796d49a30"
            ],
            "layout": "IPY_MODEL_b80d8a8560ec4b3dbd1c3a56d6badec0"
          }
        },
        "5cfded6f513c4ce090e014caf7e10611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e0afe748d24afca536db1c320a2e55",
            "placeholder": "​",
            "style": "IPY_MODEL_a454d744823c49908489fa37dcf41a60",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "e775f3b04f484693ac25979a07bed69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7c417af8724fc78e790e07b044a3f1",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ae810f77e4b4232a94cc12321ace4ee",
            "value": 4965799096
          }
        },
        "c7202ffc711f4b279168666796d49a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b134c5f101a46d4bb391353010ea0d6",
            "placeholder": "​",
            "style": "IPY_MODEL_e99e8c4be12140a28c0af2477672f7ed",
            "value": " 4.97G/4.97G [01:10&lt;00:00, 42.5MB/s]"
          }
        },
        "b80d8a8560ec4b3dbd1c3a56d6badec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e0afe748d24afca536db1c320a2e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a454d744823c49908489fa37dcf41a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f7c417af8724fc78e790e07b044a3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae810f77e4b4232a94cc12321ace4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b134c5f101a46d4bb391353010ea0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99e8c4be12140a28c0af2477672f7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa1034426f1146329719e1ca85f3f8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c75bd63f5244b296bfe691d99f6069",
              "IPY_MODEL_2f9d4c27cc5f4832bb5ff3eb2f52a4d5",
              "IPY_MODEL_d2aed8c7bf3a41898c428818b54fe767"
            ],
            "layout": "IPY_MODEL_7d88f24e26bb46aca9f0aaadc455bda1"
          }
        },
        "e0c75bd63f5244b296bfe691d99f6069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793029ea7566487f945ef9ddd28fff7a",
            "placeholder": "​",
            "style": "IPY_MODEL_80bc2e6dc7934e1d86ecbcef545714f6",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "2f9d4c27cc5f4832bb5ff3eb2f52a4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd259340fbe24b9aa1e2ed50824aada9",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ed020cf9b594b8fb19637d1e405d34c",
            "value": 1459729952
          }
        },
        "d2aed8c7bf3a41898c428818b54fe767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207b2a43865d42ecb1cfc7a37ce728f1",
            "placeholder": "​",
            "style": "IPY_MODEL_6d34ea4a4fef49ba90bd8de03efa24f2",
            "value": " 1.46G/1.46G [00:15&lt;00:00, 137MB/s]"
          }
        },
        "7d88f24e26bb46aca9f0aaadc455bda1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793029ea7566487f945ef9ddd28fff7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80bc2e6dc7934e1d86ecbcef545714f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd259340fbe24b9aa1e2ed50824aada9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed020cf9b594b8fb19637d1e405d34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "207b2a43865d42ecb1cfc7a37ce728f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d34ea4a4fef49ba90bd8de03efa24f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d247d75143f04de19cc11670984426d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe78ecd2226491b9f5e281036057790",
              "IPY_MODEL_8e84fb80b6094cbe86f6b678a5c8af7d",
              "IPY_MODEL_468db119f1034e30928876703afe8a70"
            ],
            "layout": "IPY_MODEL_c886c911cefe4310b8e83bc0205baeec"
          }
        },
        "efe78ecd2226491b9f5e281036057790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88aabf8f024d41e0ad87c858af1bcca3",
            "placeholder": "​",
            "style": "IPY_MODEL_86b0789e28654ded804c10c036301741",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8e84fb80b6094cbe86f6b678a5c8af7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c99b9a0d9da4b1d889458a63bc9d49a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6cdfc2ba4d34f83a35f9931853be02c",
            "value": 2
          }
        },
        "468db119f1034e30928876703afe8a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4399644dbcd04180aed88006665cb918",
            "placeholder": "​",
            "style": "IPY_MODEL_554cfacaaded4a8eac8ef752ec023fc6",
            "value": " 2/2 [00:32&lt;00:00, 14.67s/it]"
          }
        },
        "c886c911cefe4310b8e83bc0205baeec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88aabf8f024d41e0ad87c858af1bcca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b0789e28654ded804c10c036301741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c99b9a0d9da4b1d889458a63bc9d49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cdfc2ba4d34f83a35f9931853be02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4399644dbcd04180aed88006665cb918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554cfacaaded4a8eac8ef752ec023fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990a191b31324ab3a0b176ac2b709698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b4a4c8d234f48cdb7b540d2e105bc74",
              "IPY_MODEL_c85e0a23e6c349d08aa489d6e416326f",
              "IPY_MODEL_f72735bf8c2e41f1939a48a4ce738fc1"
            ],
            "layout": "IPY_MODEL_c66ead96e3e4481c815b77d928230de4"
          }
        },
        "0b4a4c8d234f48cdb7b540d2e105bc74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c8e50df2bc454888376fd95dacf1ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b527be0b34344f3fab2580e3631aa0b3",
            "value": "generation_config.json: 100%"
          }
        },
        "c85e0a23e6c349d08aa489d6e416326f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306026f826d540c4aab96909317bd7b9",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_213c4da087ba4a889b9177c1fcdcf696",
            "value": 189
          }
        },
        "f72735bf8c2e41f1939a48a4ce738fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000221dc3f72487d8a43cd615875583d",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfd8e649df24d74830a3eb19686324f",
            "value": " 189/189 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "c66ead96e3e4481c815b77d928230de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c8e50df2bc454888376fd95dacf1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b527be0b34344f3fab2580e3631aa0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306026f826d540c4aab96909317bd7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213c4da087ba4a889b9177c1fcdcf696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "000221dc3f72487d8a43cd615875583d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfd8e649df24d74830a3eb19686324f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}