{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eric-Chung-0511/Learning-Record/blob/main/Data%20Science%20Projects/VisionScout/(GitHub_Refactoring_YOLO_CLIP_Llama_Places365)_Vision_Scout_Model_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZc4F5T9e9t-"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = userdata.get(\"HF_TOKEN\")  # 已新增至Secret\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVpfCYfq0HUe",
        "outputId": "1319db79-91ef-4e89-9236-2e5161fe3d75",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio)\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.32.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.32.0 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.3\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxiomUThoEN",
        "outputId": "0820fb46-e8da-4cd3-a6a9-a2a1489e0943",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.5.22-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Downloading yt_dlp-2025.5.22-py3-none-any.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m182.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.5.22\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0477JcxwzrHV",
        "outputId": "f6751876-e08d-4caa-d711-0e13302b3996",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-cuy9m3y5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-cuy9m3y5\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting clip\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=7112e297563f331b123469914ebcd239760cc3a78cefc21fff223e9a89b97ee2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-157vdzhe/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch clip git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCodZ3KyPKQ",
        "outputId": "7f46f692-e873-4251-b06e-edae324f22d3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.3.128\n",
            "  Downloading ultralytics-8.3.128-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.128) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.3.128)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.128) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.128) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.128) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.128) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.128) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.128) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.128) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.128) (3.0.2)\n",
            "Downloading ultralytics-8.3.128-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.128 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.3.128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5Wbwj0j1FQ",
        "outputId": "ef62f26d-d1c7-4a66-f132-89b5eb594151",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, bitsandbytes\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.2\n",
            "    Uninstalling transformers-4.52.2:\n",
            "      Successfully uninstalled transformers-4.52.2\n",
            "Successfully installed bitsandbytes-0.46.0 transformers-4.52.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers accelerate bitsandbytes sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te0fPfkgvPKa",
        "outputId": "3ecfe05b-6779-4016-8871-83de17e2f763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-wICk4sFeRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7487798f-51ce-4c31-8a16-a7ad2d8a736b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing detection_model.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile detection_model.py\n",
        "from ultralytics import YOLO\n",
        "from typing import Any, List, Dict, Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class DetectionModel:\n",
        "    \"\"\"Core detection model class for object detection using YOLOv8\"\"\"\n",
        "\n",
        "    # Model information dictionary\n",
        "    MODEL_INFO = {\n",
        "        \"yolov8n.pt\": {\n",
        "            \"name\": \"YOLOv8n (Nano)\",\n",
        "            \"description\": \"Fastest model with smallest size (3.2M parameters). Best for speed-critical applications.\",\n",
        "            \"size_mb\": 6,\n",
        "            \"inference_speed\": \"Very Fast\"\n",
        "        },\n",
        "        \"yolov8m.pt\": {\n",
        "            \"name\": \"YOLOv8m (Medium)\",\n",
        "            \"description\": \"Balanced model with good accuracy-speed tradeoff (25.9M parameters). Recommended for general use.\",\n",
        "            \"size_mb\": 25,\n",
        "            \"inference_speed\": \"Medium\"\n",
        "        },\n",
        "        \"yolov8x.pt\": {\n",
        "            \"name\": \"YOLOv8x (XLarge)\",\n",
        "            \"description\": \"Most accurate but slower model (68.2M parameters). Best for accuracy-critical applications.\",\n",
        "            \"size_mb\": 68,\n",
        "            \"inference_speed\": \"Slower\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def __init__(self, model_name: str = 'yolov8m.pt', confidence: float = 0.25, iou: float = 0.25):\n",
        "        \"\"\"\n",
        "        Initialize the detection model\n",
        "\n",
        "        Args:\n",
        "            model_name: Model name or path, default is yolov8m.pt\n",
        "            confidence: Confidence threshold, default is 0.25\n",
        "            iou: IoU threshold for non-maximum suppression, default is 0.45\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.confidence = confidence\n",
        "        self.iou = iou\n",
        "        self.model = None\n",
        "        self.class_names = {}\n",
        "        self.is_model_loaded = False\n",
        "\n",
        "        # Load model on initialization\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the YOLO model\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading model: {self.model_name}\")\n",
        "            self.model = YOLO(self.model_name)\n",
        "            self.class_names = self.model.names\n",
        "            self.is_model_loaded = True\n",
        "            print(f\"Successfully loaded model: {self.model_name}\")\n",
        "            print(f\"Number of classes the model can recognize: {len(self.class_names)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred when loading the model: {e}\")\n",
        "            self.is_model_loaded = False\n",
        "\n",
        "    def change_model(self, new_model_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        Change the currently loaded model\n",
        "\n",
        "        Args:\n",
        "            new_model_name: Name of the new model to load\n",
        "\n",
        "        Returns:\n",
        "            bool: True if model changed successfully, False otherwise\n",
        "        \"\"\"\n",
        "        if self.model_name == new_model_name and self.is_model_loaded:\n",
        "            print(f\"Model {new_model_name} is already loaded\")\n",
        "            return True\n",
        "\n",
        "        print(f\"Changing model from {self.model_name} to {new_model_name}\")\n",
        "\n",
        "        # Unload current model to free memory\n",
        "        if self.model is not None:\n",
        "            del self.model\n",
        "            self.model = None\n",
        "\n",
        "            # Clean GPU memory if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Update model name and load new model\n",
        "        self.model_name = new_model_name\n",
        "        self._load_model()\n",
        "\n",
        "        return self.is_model_loaded\n",
        "\n",
        "    def reload_model(self):\n",
        "        \"\"\"Reload the model (useful for changing model or after error)\"\"\"\n",
        "        if self.model is not None:\n",
        "            del self.model\n",
        "            self.model = None\n",
        "\n",
        "            # Clean GPU memory if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        self._load_model()\n",
        "\n",
        "    def detect(self, image_input: Any) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Perform object detection on a single image\n",
        "\n",
        "        Args:\n",
        "            image_input: Image path (str), PIL Image, or numpy array\n",
        "\n",
        "        Returns:\n",
        "            Detection result object or None if error occurred\n",
        "        \"\"\"\n",
        "        if self.model is None or not self.is_model_loaded:\n",
        "            print(\"Model not found or not loaded. Attempting to reload...\")\n",
        "            self._load_model()\n",
        "            if self.model is None or not self.is_model_loaded:\n",
        "                print(\"Failed to load model. Cannot perform detection.\")\n",
        "                return None\n",
        "\n",
        "        try:\n",
        "            results = self.model(image_input, conf=self.confidence, iou=self.iou)\n",
        "            return results[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred during detection: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_class_names(self, class_id: int) -> str:\n",
        "        \"\"\"Get class name for a given class ID\"\"\"\n",
        "        return self.class_names.get(class_id, \"Unknown Class\")\n",
        "\n",
        "    def get_supported_classes(self) -> Dict[int, str]:\n",
        "        \"\"\"Get all supported classes as a dictionary of {id: class_name}\"\"\"\n",
        "        return self.class_names\n",
        "\n",
        "    @classmethod\n",
        "    def get_available_models(cls) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get list of available models with their information\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries containing model information\n",
        "        \"\"\"\n",
        "        models = []\n",
        "        for model_file, info in cls.MODEL_INFO.items():\n",
        "            models.append({\n",
        "                \"model_file\": model_file,\n",
        "                \"name\": info[\"name\"],\n",
        "                \"description\": info[\"description\"],\n",
        "                \"size_mb\": info[\"size_mb\"],\n",
        "                \"inference_speed\": info[\"inference_speed\"]\n",
        "            })\n",
        "        return models\n",
        "\n",
        "    @classmethod\n",
        "    def get_model_description(cls, model_name: str) -> str:\n",
        "        \"\"\"Get description for a specific model\"\"\"\n",
        "        if model_name in cls.MODEL_INFO:\n",
        "            info = cls.MODEL_INFO[model_name]\n",
        "            return f\"{info['name']}: {info['description']} (Size: ~{info['size_mb']}MB, Speed: {info['inference_speed']})\"\n",
        "        return \"Model information not available\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BApUce5S87og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c822a37-c71d-4ed9-e859-0f0a0cbcfc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing color_mapper.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile color_mapper.py\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Union, Any\n",
        "\n",
        "class ColorMapper:\n",
        "    \"\"\"\n",
        "    A class for consistent color mapping of object detection classes\n",
        "    Provides color schemes for visualization in both RGB and hex formats\n",
        "    \"\"\"\n",
        "\n",
        "    # Class categories for better organization\n",
        "    CATEGORIES = {\n",
        "        \"person\": [0],\n",
        "        \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "        \"traffic\": [9, 10, 11, 12],\n",
        "        \"animals\": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
        "        \"outdoor\": [13, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
        "        \"sports\": [34, 35, 36, 37, 38],\n",
        "        \"kitchen\": [39, 40, 41, 42, 43, 44, 45],\n",
        "        \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "        \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "        \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "        \"household\": [71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
        "    }\n",
        "\n",
        "    # Base colors for each category (in HSV for easier variation)\n",
        "    # HSV:  Hue, Saturation, Value\n",
        "    CATEGORY_COLORS = {\n",
        "        \"person\": (0, 0.8, 0.9),       # Red\n",
        "        \"vehicles\": (210, 0.8, 0.9),   # Blue\n",
        "        \"traffic\": (45, 0.8, 0.9),     # Orange\n",
        "        \"animals\": (120, 0.7, 0.8),    # Green\n",
        "        \"outdoor\": (180, 0.7, 0.9),    # Cyan\n",
        "        \"sports\": (270, 0.7, 0.8),     # Purple\n",
        "        \"kitchen\": (30, 0.7, 0.9),     # Light Orange\n",
        "        \"food\": (330, 0.7, 0.85),      # Pink\n",
        "        \"furniture\": (150, 0.5, 0.85), # Light Green\n",
        "        \"electronics\": (240, 0.6, 0.9), # Light Blue\n",
        "        \"household\": (60, 0.6, 0.9)    # Yellow\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the ColorMapper with COCO class mappings\"\"\"\n",
        "        self.class_names = self._get_coco_classes()\n",
        "        self.color_map = self._generate_color_map()\n",
        "\n",
        "    def _get_coco_classes(self) -> Dict[int, str]:\n",
        "        \"\"\"Get the standard COCO class names with their IDs\"\"\"\n",
        "        return {\n",
        "            0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',\n",
        "            5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
        "            10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
        "            14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
        "            20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',\n",
        "            25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',\n",
        "            30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat',\n",
        "            35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket',\n",
        "            39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife',\n",
        "            44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich',\n",
        "            49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',\n",
        "            54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',\n",
        "            59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop',\n",
        "            64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave',\n",
        "            69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book',\n",
        "            74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier',\n",
        "            79: 'toothbrush'\n",
        "        }\n",
        "\n",
        "    def _hsv_to_rgb(self, h: float, s: float, v: float) -> Tuple[int, int, int]:\n",
        "        \"\"\"\n",
        "        Convert HSV color to RGB\n",
        "\n",
        "        Args:\n",
        "            h: Hue (0-360)\n",
        "            s: Saturation (0-1)\n",
        "            v: Value (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (R, G, B) values (0-255)\n",
        "        \"\"\"\n",
        "        h = h / 60\n",
        "        i = int(h)\n",
        "        f = h - i\n",
        "        p = v * (1 - s)\n",
        "        q = v * (1 - s * f)\n",
        "        t = v * (1 - s * (1 - f))\n",
        "\n",
        "        if i == 0:\n",
        "            r, g, b = v, t, p\n",
        "        elif i == 1:\n",
        "            r, g, b = q, v, p\n",
        "        elif i == 2:\n",
        "            r, g, b = p, v, t\n",
        "        elif i == 3:\n",
        "            r, g, b = p, q, v\n",
        "        elif i == 4:\n",
        "            r, g, b = t, p, v\n",
        "        else:\n",
        "            r, g, b = v, p, q\n",
        "\n",
        "        return (int(r * 255), int(g * 255), int(b * 255))\n",
        "\n",
        "    def _rgb_to_hex(self, rgb: Tuple[int, int, int]) -> str:\n",
        "        \"\"\"\n",
        "        Convert RGB color to hex color code\n",
        "\n",
        "        Args:\n",
        "            rgb: Tuple of (R, G, B) values (0-255)\n",
        "\n",
        "        Returns:\n",
        "            Hex color code (e.g. '#FF0000')\n",
        "        \"\"\"\n",
        "        return f'#{rgb[0]:02x}{rgb[1]:02x}{rgb[2]:02x}'\n",
        "\n",
        "    def _find_category(self, class_id: int) -> str:\n",
        "        \"\"\"\n",
        "        Find the category for a given class ID\n",
        "\n",
        "        Args:\n",
        "            class_id: Class ID (0-79)\n",
        "\n",
        "        Returns:\n",
        "            Category name\n",
        "        \"\"\"\n",
        "        for category, ids in self.CATEGORIES.items():\n",
        "            if class_id in ids:\n",
        "                return category\n",
        "        return \"other\"  # Fallback\n",
        "\n",
        "    def _generate_color_map(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate a color map for all 80 COCO classes\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping class IDs and names to color values\n",
        "        \"\"\"\n",
        "        color_map = {\n",
        "            'by_id': {},      # Map class ID to RGB and hex\n",
        "            'by_name': {},    # Map class name to RGB and hex\n",
        "            'categories': {}  # Map category to base color\n",
        "        }\n",
        "\n",
        "        # Generate colors for categories\n",
        "        for category, hsv in self.CATEGORY_COLORS.items():\n",
        "            rgb = self._hsv_to_rgb(hsv[0], hsv[1], hsv[2])\n",
        "            hex_color = self._rgb_to_hex(rgb)\n",
        "            color_map['categories'][category] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color\n",
        "            }\n",
        "\n",
        "        # Generate variations for each class within a category\n",
        "        for class_id, class_name in self.class_names.items():\n",
        "            category = self._find_category(class_id)\n",
        "            base_hsv = self.CATEGORY_COLORS.get(category, (0, 0, 0.8))  # Default gray\n",
        "\n",
        "            # Slightly vary the hue and saturation within the category\n",
        "            ids_in_category = self.CATEGORIES.get(category, [])\n",
        "            if ids_in_category:\n",
        "                position = ids_in_category.index(class_id) if class_id in ids_in_category else 0\n",
        "                variation = position / max(1, len(ids_in_category) - 1)  # 0 to 1\n",
        "\n",
        "                # Vary hue slightly (±15°) and saturation\n",
        "                h_offset = 30 * variation - 15  # -15 to +15\n",
        "                s_offset = 0.2 * variation  # 0 to 0.2\n",
        "\n",
        "                h = (base_hsv[0] + h_offset) % 360\n",
        "                s = min(1.0, base_hsv[1] + s_offset)\n",
        "                v = base_hsv[2]\n",
        "            else:\n",
        "                h, s, v = base_hsv\n",
        "\n",
        "            rgb = self._hsv_to_rgb(h, s, v)\n",
        "            hex_color = self._rgb_to_hex(rgb)\n",
        "\n",
        "            # Store in both mappings\n",
        "            color_map['by_id'][class_id] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color,\n",
        "                'category': category\n",
        "            }\n",
        "\n",
        "            color_map['by_name'][class_name] = {\n",
        "                'rgb': rgb,\n",
        "                'hex': hex_color,\n",
        "                'category': category\n",
        "            }\n",
        "\n",
        "        return color_map\n",
        "\n",
        "    def get_color(self, class_identifier: Union[int, str], format: str = 'hex') -> Any:\n",
        "        \"\"\"\n",
        "        Get color for a specific class\n",
        "\n",
        "        Args:\n",
        "            class_identifier: Class ID (int) or name (str)\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Color in requested format\n",
        "        \"\"\"\n",
        "        # Determine if identifier is an ID or name\n",
        "        if isinstance(class_identifier, int):\n",
        "            color_info = self.color_map['by_id'].get(class_identifier)\n",
        "        else:\n",
        "            color_info = self.color_map['by_name'].get(class_identifier)\n",
        "\n",
        "        if not color_info:\n",
        "            # Fallback color if not found\n",
        "            return '#CCCCCC' if format == 'hex' else (204, 204, 204)\n",
        "\n",
        "        if format == 'hex':\n",
        "            return color_info['hex']\n",
        "        elif format == 'rgb':\n",
        "            return color_info['rgb']\n",
        "        elif format == 'bgr':\n",
        "            # Convert RGB to BGR for OpenCV\n",
        "            r, g, b = color_info['rgb']\n",
        "            return (b, g, r)\n",
        "        else:\n",
        "            return color_info['rgb']\n",
        "\n",
        "    def get_all_colors(self, format: str = 'hex') -> Dict:\n",
        "        \"\"\"\n",
        "        Get all colors in the specified format\n",
        "\n",
        "        Args:\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping class names to colors\n",
        "        \"\"\"\n",
        "        result = {}\n",
        "        for class_id, class_name in self.class_names.items():\n",
        "            result[class_name] = self.get_color(class_id, format)\n",
        "        return result\n",
        "\n",
        "    def get_category_colors(self, format: str = 'hex') -> Dict:\n",
        "        \"\"\"\n",
        "        Get base colors for each category\n",
        "\n",
        "        Args:\n",
        "            format: Color format ('hex', 'rgb', or 'bgr')\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping categories to colors\n",
        "        \"\"\"\n",
        "        result = {}\n",
        "        for category, color_info in self.color_map['categories'].items():\n",
        "            if format == 'hex':\n",
        "                result[category] = color_info['hex']\n",
        "            elif format == 'bgr':\n",
        "                r, g, b = color_info['rgb']\n",
        "                result[category] = (b, g, r)\n",
        "            else:\n",
        "                result[category] = color_info['rgb']\n",
        "        return result\n",
        "\n",
        "    def get_category_for_class(self, class_identifier: Union[int, str]) -> str:\n",
        "        \"\"\"\n",
        "        Get the category for a specific class\n",
        "\n",
        "        Args:\n",
        "            class_identifier: Class ID (int) or name (str)\n",
        "\n",
        "        Returns:\n",
        "            Category name\n",
        "        \"\"\"\n",
        "        if isinstance(class_identifier, int):\n",
        "            return self.color_map['by_id'].get(class_identifier, {}).get('category', 'other')\n",
        "        else:\n",
        "            return self.color_map['by_name'].get(class_identifier, {}).get('category', 'other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZMzmZVD-r6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329d1f48-9592-4f31-cc9d-a4dd1b891033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing visualization_helper.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile visualization_helper.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "from typing import Any, List, Dict, Tuple, Optional\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "class VisualizationHelper:\n",
        "    \"\"\"Helper class for visualizing detection results\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_detection(image: Any, result: Any, color_mapper: Optional[Any] = None,\n",
        "                            figsize: Tuple[int, int] = (12, 12),\n",
        "                            return_pil: bool = False,\n",
        "                            filter_classes: Optional[List[int]] = None) -> Optional[Image.Image]:\n",
        "        \"\"\"\n",
        "        Visualize detection results on a single image\n",
        "        Args:\n",
        "            image: Image path or numpy array\n",
        "            result: Detection result object\n",
        "            color_mapper: ColorMapper instance for consistent colors\n",
        "            figsize: Figure size\n",
        "            return_pil: If True, returns a PIL Image object\n",
        "\n",
        "        Returns:\n",
        "            PIL Image if return_pil is True, otherwise displays the plot\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            print('No data for visualization')\n",
        "            return None\n",
        "\n",
        "        # Read image if path is provided\n",
        "        if isinstance(image, str):\n",
        "            img = cv2.imread(image)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            img = image\n",
        "            if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "                # Check if BGR format (OpenCV) and convert to RGB if needed\n",
        "                if isinstance(img, np.ndarray):\n",
        "                    # Assuming BGR format from OpenCV\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # Get bounding boxes, classes and confidences\n",
        "        boxes = result.boxes.xyxy.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy()\n",
        "        confs = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Get class names\n",
        "        names = result.names\n",
        "\n",
        "        # Create a default color mapper if none is provided\n",
        "        if color_mapper is None:\n",
        "            # For backward compatibility, fallback to a simple color function\n",
        "            from matplotlib import colormaps\n",
        "            cmap = colormaps['tab10']\n",
        "            def get_color(class_id):\n",
        "                return cmap(class_id % 10)\n",
        "        else:\n",
        "            # Use the provided color mapper\n",
        "            def get_color(class_id):\n",
        "                hex_color = color_mapper.get_color(class_id)\n",
        "                # Convert hex to RGB float values for matplotlib\n",
        "                hex_color = hex_color.lstrip('#')\n",
        "                return tuple(int(hex_color[i:i+2], 16) / 255 for i in (0, 2, 4)) + (1.0,)\n",
        "\n",
        "        # Draw detection results\n",
        "        for box, cls, conf in zip(boxes, classes, confs):\n",
        "            x1, y1, x2, y2 = box\n",
        "            cls_id = int(cls)\n",
        "\n",
        "            if filter_classes and cls_id not in filter_classes:\n",
        "                continue\n",
        "\n",
        "            cls_name = names[cls_id]\n",
        "\n",
        "            # Get color for this class\n",
        "            box_color = get_color(cls_id)\n",
        "\n",
        "            box_width = x2 - x1\n",
        "            box_height = y2 - y1\n",
        "            box_area = box_width * box_height\n",
        "\n",
        "            # 根據框大小調整字體大小，但有限制\n",
        "            adaptive_fontsize = max(10, min(14, int(10 + box_area / 10000)))\n",
        "\n",
        "\n",
        "            ax.text(x1, y1 - 8, f'{cls_name}: {conf:.2f}',\n",
        "                    color='white', fontsize=adaptive_fontsize, fontweight=\"bold\",\n",
        "                    bbox=dict(facecolor=box_color[:3], alpha=0.85, pad=3, boxstyle=\"round,pad=0.3\"),\n",
        "                    path_effects=[path_effects.withStroke(linewidth=1.5, foreground=\"black\")])\n",
        "\n",
        "            # Add bounding box\n",
        "            ax.add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                    fill=False, edgecolor=box_color[:3], linewidth=2))\n",
        "\n",
        "        ax.axis('off')\n",
        "        # ax.set_title('Detection Result')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if return_pil:\n",
        "            # Convert plot to PIL Image\n",
        "            buf = io.BytesIO()\n",
        "            fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
        "            buf.seek(0)\n",
        "            pil_img = Image.open(buf)\n",
        "            plt.close(fig)\n",
        "            return pil_img\n",
        "        else:\n",
        "            plt.show()\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def create_summary(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Create a summary of detection results\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with detection summary statistics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get classes and confidences\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "        names = result.names\n",
        "\n",
        "        # Count detections by class\n",
        "        class_counts = {}\n",
        "        for cls, conf in zip(classes, confidences):\n",
        "            cls_name = names[int(cls)]\n",
        "            if cls_name not in class_counts:\n",
        "                class_counts[cls_name] = {\"count\": 0, \"confidences\": []}\n",
        "\n",
        "            class_counts[cls_name][\"count\"] += 1\n",
        "            class_counts[cls_name][\"confidences\"].append(float(conf))\n",
        "\n",
        "        # Calculate average confidence for each class\n",
        "        for cls_name, stats in class_counts.items():\n",
        "            if stats[\"confidences\"]:\n",
        "                stats[\"average_confidence\"] = float(np.mean(stats[\"confidences\"]))\n",
        "                stats.pop(\"confidences\")  # Remove detailed confidences list to keep summary concise\n",
        "\n",
        "        # Prepare summary\n",
        "        summary = {\n",
        "            \"total_objects\": len(classes),\n",
        "            \"class_counts\": class_counts,\n",
        "            \"unique_classes\": len(class_counts)\n",
        "        }\n",
        "\n",
        "        return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxZyG9wX80Og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4782be6-0979-4247-b39f-a77bd66451cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluation_metrics.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile evaluation_metrics.py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"Class for computing detection metrics, generating statistics and visualization data\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_basic_stats(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate basic statistics for a single detection result\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with basic statistics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get classes and confidences\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "        names = result.names\n",
        "\n",
        "        # Count by class\n",
        "        class_counts = {}\n",
        "        for cls, conf in zip(classes, confidences):\n",
        "            cls_name = names[int(cls)]\n",
        "            if cls_name not in class_counts:\n",
        "                class_counts[cls_name] = {\"count\": 0, \"total_confidence\": 0, \"confidences\": []}\n",
        "\n",
        "            class_counts[cls_name][\"count\"] += 1\n",
        "            class_counts[cls_name][\"total_confidence\"] += float(conf)\n",
        "            class_counts[cls_name][\"confidences\"].append(float(conf))\n",
        "\n",
        "        # Calculate average confidence\n",
        "        for cls_name, stats in class_counts.items():\n",
        "            if stats[\"count\"] > 0:\n",
        "                stats[\"average_confidence\"] = stats[\"total_confidence\"] / stats[\"count\"]\n",
        "                stats[\"confidence_std\"] = float(np.std(stats[\"confidences\"])) if len(stats[\"confidences\"]) > 1 else 0\n",
        "                stats.pop(\"total_confidence\")  # Remove intermediate calculation\n",
        "\n",
        "        # Prepare summary\n",
        "        stats = {\n",
        "            \"total_objects\": len(classes),\n",
        "            \"class_statistics\": class_counts,\n",
        "            \"average_confidence\": float(np.mean(confidences)) if len(confidences) > 0 else 0\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_visualization_data(result: Any, class_colors: Dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate structured data suitable for visualization\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "            class_colors: Dictionary mapping class names to color codes (optional)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with visualization-ready data\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        # Get basic stats first\n",
        "        stats = EvaluationMetrics.calculate_basic_stats(result)\n",
        "\n",
        "        # Create visualization-specific data structure\n",
        "        viz_data = {\n",
        "            \"total_objects\": stats[\"total_objects\"],\n",
        "            \"average_confidence\": stats[\"average_confidence\"],\n",
        "            \"class_data\": []\n",
        "        }\n",
        "\n",
        "        # Sort classes by count (descending)\n",
        "        sorted_classes = sorted(\n",
        "            stats[\"class_statistics\"].items(),\n",
        "            key=lambda x: x[1][\"count\"],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Create class-specific visualization data\n",
        "        for cls_name, cls_stats in sorted_classes:\n",
        "            class_id = -1\n",
        "            # Find the class ID based on the name\n",
        "            for idx, name in result.names.items():\n",
        "                if name == cls_name:\n",
        "                    class_id = idx\n",
        "                    break\n",
        "\n",
        "            cls_data = {\n",
        "                \"name\": cls_name,\n",
        "                \"class_id\": class_id,\n",
        "                \"count\": cls_stats[\"count\"],\n",
        "                \"average_confidence\": cls_stats.get(\"average_confidence\", 0),\n",
        "                \"confidence_std\": cls_stats.get(\"confidence_std\", 0),\n",
        "                \"color\": class_colors.get(cls_name, \"#CCCCCC\") if class_colors else \"#CCCCCC\"\n",
        "            }\n",
        "\n",
        "            viz_data[\"class_data\"].append(cls_data)\n",
        "\n",
        "        return viz_data\n",
        "\n",
        "    @staticmethod\n",
        "    def create_stats_plot(viz_data: Dict, figsize: Tuple[int, int] = (10, 7), max_classes: int = 30) -> plt.Figure:\n",
        "        \"\"\"\n",
        "        Create a horizontal bar chart showing detection statistics\n",
        "\n",
        "        Args:\n",
        "            viz_data: Visualization data generated by generate_visualization_data\n",
        "            figsize: Figure size (width, height) in inches\n",
        "            max_classes: Maximum number of classes to display\n",
        "\n",
        "        Returns:\n",
        "            Matplotlib figure object\n",
        "        \"\"\"\n",
        "        # Use the enhanced version\n",
        "        return EvaluationMetrics.create_enhanced_stats_plot(viz_data, figsize, max_classes)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_enhanced_stats_plot(viz_data: Dict, figsize: Tuple[int, int] = (10, 7), max_classes: int = 30) -> plt.Figure:\n",
        "        \"\"\"\n",
        "        Create an enhanced horizontal bar chart with larger fonts and better styling\n",
        "\n",
        "        Args:\n",
        "            viz_data: Visualization data dictionary\n",
        "            figsize: Figure size (width, height) in inches\n",
        "            max_classes: Maximum number of classes to display\n",
        "\n",
        "        Returns:\n",
        "            Matplotlib figure with enhanced styling\n",
        "        \"\"\"\n",
        "        if \"error\" in viz_data:\n",
        "            # Create empty plot if error\n",
        "            fig, ax = plt.subplots(figsize=figsize)\n",
        "            ax.text(0.5, 0.5, viz_data[\"error\"],\n",
        "                    ha='center', va='center', fontsize=14)\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "\n",
        "        if \"class_data\" not in viz_data or not viz_data[\"class_data\"]:\n",
        "            # Create empty plot if no data\n",
        "            fig, ax = plt.subplots(figsize=figsize)\n",
        "            ax.text(0.5, 0.5, \"No detection data available\",\n",
        "                    ha='center', va='center', fontsize=14)\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.set_ylim(0, 1)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "\n",
        "        # Limit to max_classes\n",
        "        class_data = viz_data[\"class_data\"][:max_classes]\n",
        "\n",
        "        # Extract data for plotting\n",
        "        class_names = [item[\"name\"] for item in class_data]\n",
        "        counts = [item[\"count\"] for item in class_data]\n",
        "        colors = [item[\"color\"] for item in class_data]\n",
        "\n",
        "        # Create figure and horizontal bar chart with improved styling\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "        # Set background color to white\n",
        "        fig.patch.set_facecolor('white')\n",
        "        ax.set_facecolor('white')\n",
        "\n",
        "        y_pos = np.arange(len(class_names))\n",
        "\n",
        "        # Create horizontal bars with class-specific colors\n",
        "        bars = ax.barh(y_pos, counts, color=colors, alpha=0.8, height=0.6)\n",
        "\n",
        "        # Add count values at end of each bar with larger font\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            conf = class_data[i][\"average_confidence\"]\n",
        "            ax.text(width + 0.3, bar.get_y() + bar.get_height()/2,\n",
        "                    f\"{width:.0f} (conf: {conf:.2f})\",\n",
        "                    va='center', fontsize=12)\n",
        "\n",
        "        # Customize axis and labels with larger fonts\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(class_names, fontsize=14)\n",
        "        ax.invert_yaxis()  # Labels read top-to-bottom\n",
        "        ax.set_xlabel('Count', fontsize=14)\n",
        "        ax.set_title(f'Objects Detected: {viz_data[\"total_objects\"]} Total',\n",
        "                    fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Add grid for better readability\n",
        "        ax.set_axisbelow(True)\n",
        "        ax.grid(axis='x', linestyle='--', alpha=0.7, color='#E5E7EB')\n",
        "\n",
        "        # Increase tick label font size\n",
        "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "        # Add detection summary as a text box with improved styling\n",
        "        summary_text = (\n",
        "            f\"Total Objects: {viz_data['total_objects']}\\n\"\n",
        "            f\"Average Confidence: {viz_data['average_confidence']:.2f}\\n\"\n",
        "            f\"Unique Classes: {len(viz_data['class_data'])}\"\n",
        "        )\n",
        "        plt.figtext(0.02, 0.02, summary_text, fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.5',\n",
        "                            edgecolor='#E5E7EB'))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    @staticmethod\n",
        "    def format_detection_summary(viz_data: Dict) -> str:\n",
        "        if \"error\" in viz_data:\n",
        "            return viz_data[\"error\"]\n",
        "\n",
        "        if \"total_objects\" not in viz_data:\n",
        "            return \"No detection data available.\"\n",
        "\n",
        "        total_objects = viz_data[\"total_objects\"]\n",
        "        avg_confidence = viz_data[\"average_confidence\"]\n",
        "\n",
        "        lines = [\n",
        "            f\"Detected {total_objects} objects.\",\n",
        "            f\"Average confidence: {avg_confidence:.2f}\",\n",
        "            \"Objects by class:\"\n",
        "        ]\n",
        "\n",
        "        if \"class_data\" in viz_data and viz_data[\"class_data\"]:\n",
        "            for item in viz_data[\"class_data\"]:\n",
        "                count = item['count']\n",
        "                item_text = \"item\" if count == 1 else \"items\"\n",
        "                lines.append(f\"• {item['name']}: {count} {item_text} (Confidence: {item['average_confidence']:.2f})\")\n",
        "        else:\n",
        "            lines.append(\"No class information available.\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_distance_metrics(result: Any) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate distance-related metrics for detected objects\n",
        "\n",
        "        Args:\n",
        "            result: Detection result object\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with distance metrics\n",
        "        \"\"\"\n",
        "        if result is None:\n",
        "            return {\"error\": \"No detection result provided\"}\n",
        "\n",
        "        boxes = result.boxes.xyxy.cpu().numpy()\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        names = result.names\n",
        "\n",
        "        # Initialize metrics\n",
        "        metrics = {\n",
        "            \"proximity\": {},  # Classes that appear close to each other\n",
        "            \"spatial_distribution\": {},  # Distribution across the image\n",
        "            \"size_distribution\": {}  # Size distribution of objects\n",
        "        }\n",
        "\n",
        "        # Calculate image dimensions (assuming normalized coordinates or extract from result)\n",
        "        img_width, img_height = 1, 1\n",
        "        if hasattr(result, \"orig_shape\"):\n",
        "            img_height, img_width = result.orig_shape[:2]\n",
        "\n",
        "        # Calculate bounding box areas and centers\n",
        "        areas = []\n",
        "        centers = []\n",
        "        class_names = []\n",
        "\n",
        "        for box, cls in zip(boxes, classes):\n",
        "            x1, y1, x2, y2 = box\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            area = width * height\n",
        "            center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "            areas.append(area)\n",
        "            centers.append((center_x, center_y))\n",
        "            class_names.append(names[int(cls)])\n",
        "\n",
        "        # Calculate spatial distribution\n",
        "        if centers:\n",
        "            x_coords = [c[0] for c in centers]\n",
        "            y_coords = [c[1] for c in centers]\n",
        "\n",
        "            metrics[\"spatial_distribution\"] = {\n",
        "                \"x_mean\": float(np.mean(x_coords)) / img_width,\n",
        "                \"y_mean\": float(np.mean(y_coords)) / img_height,\n",
        "                \"x_std\": float(np.std(x_coords)) / img_width,\n",
        "                \"y_std\": float(np.std(y_coords)) / img_height\n",
        "            }\n",
        "\n",
        "        # Calculate size distribution\n",
        "        if areas:\n",
        "            metrics[\"size_distribution\"] = {\n",
        "                \"mean_area\": float(np.mean(areas)) / (img_width * img_height),\n",
        "                \"std_area\": float(np.std(areas)) / (img_width * img_height),\n",
        "                \"min_area\": float(np.min(areas)) / (img_width * img_height),\n",
        "                \"max_area\": float(np.max(areas)) / (img_width * img_height)\n",
        "            }\n",
        "\n",
        "        # Calculate proximity between different classes\n",
        "        class_centers = {}\n",
        "        for cls_name, center in zip(class_names, centers):\n",
        "            if cls_name not in class_centers:\n",
        "                class_centers[cls_name] = []\n",
        "            class_centers[cls_name].append(center)\n",
        "\n",
        "        # Find classes that appear close to each other\n",
        "        proximity_pairs = []\n",
        "        for i, cls1 in enumerate(class_centers.keys()):\n",
        "            for j, cls2 in enumerate(class_centers.keys()):\n",
        "                if i >= j:  # Avoid duplicate pairs and self-comparison\n",
        "                    continue\n",
        "\n",
        "                # Calculate minimum distance between any two objects of these classes\n",
        "                min_distance = float('inf')\n",
        "                for center1 in class_centers[cls1]:\n",
        "                    for center2 in class_centers[cls2]:\n",
        "                        dist = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
        "                        min_distance = min(min_distance, dist)\n",
        "\n",
        "                # Normalize by image diagonal\n",
        "                img_diagonal = np.sqrt(img_width**2 + img_height**2)\n",
        "                norm_distance = min_distance / img_diagonal\n",
        "\n",
        "                proximity_pairs.append({\n",
        "                    \"class1\": cls1,\n",
        "                    \"class2\": cls2,\n",
        "                    \"distance\": float(norm_distance)\n",
        "                })\n",
        "\n",
        "        # Sort by distance and keep the closest pairs\n",
        "        proximity_pairs.sort(key=lambda x: x[\"distance\"])\n",
        "        metrics[\"proximity\"] = proximity_pairs[:5]  # Keep top 5 closest pairs\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHIMZpcZwWGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b471792b-0364-45f3-bce4-fcc153ca87c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing style.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile style.py\n",
        "\n",
        "class Style:\n",
        "\n",
        "    @staticmethod\n",
        "    def get_css():\n",
        "\n",
        "        css = \"\"\"\n",
        "        /* Base styles and typography */\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            background: linear-gradient(135deg, #f0f9ff, #e1f5fe);\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            min-height: 100vh;\n",
        "        }\n",
        "\n",
        "        /* Typography improvements */\n",
        "        h1, h2, h3, h4, h5, h6, p, span, div, label, button {\n",
        "            font-family: Arial, sans-serif;\n",
        "        }\n",
        "\n",
        "        /* Container styling */\n",
        "        .gradio-container {\n",
        "            max-width: 1200px !important;\n",
        "            margin: auto !important;\n",
        "            padding: 1rem;\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* Header area styling with gradient background */\n",
        "        .app-header {\n",
        "            text-align: center;\n",
        "            margin-bottom: 2rem;\n",
        "            background: linear-gradient(135deg, #f8f9fa, #e9ecef);\n",
        "            padding: 1.5rem;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        .app-title {\n",
        "            color: #2D3748;\n",
        "            font-size: 2.5rem;\n",
        "            margin-bottom: 0.5rem;\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "\n",
        "        .app-subtitle {\n",
        "            color: #4A5568;\n",
        "            font-size: 1.2rem;\n",
        "            font-weight: normal;\n",
        "            margin-top: 0.25rem;\n",
        "        }\n",
        "\n",
        "        .app-divider {\n",
        "            width: 80px;\n",
        "            height: 3px;\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1);\n",
        "            margin: 1rem auto;\n",
        "        }\n",
        "\n",
        "        /* Panel styling - gradient background */\n",
        "        .input-panel, .output-panel {\n",
        "            background: white;\n",
        "            border-radius: 10px;\n",
        "            padding: 1.5rem;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\n",
        "            margin: 0 auto 1rem auto;\n",
        "        }\n",
        "\n",
        "        /* 修改輸出面板確保內容能夠完整顯示 */\n",
        "        .output-panel {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            width: 100%;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 確保輸出面板內的元素寬度可以適應面板 */\n",
        "        .output-panel > * {\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* How-to-use section with gradient background */\n",
        "        .how-to-use {\n",
        "            background: linear-gradient(135deg, #f8fafc, #e8f4fd);\n",
        "            border-radius: 10px;\n",
        "            padding: 1.5rem;\n",
        "            margin-top: 1rem;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "            color: #2d3748;\n",
        "        }\n",
        "\n",
        "        /* Detection button styling */\n",
        "        .detect-btn {\n",
        "            background: linear-gradient(90deg, #38b2ac, #4299e1) !important;\n",
        "            color: white !important;\n",
        "            border: none !important;\n",
        "            border-radius: 8px !important;\n",
        "            transition: transform 0.3s, box-shadow 0.3s !important;\n",
        "            font-weight: bold !important;\n",
        "            letter-spacing: 0.5px !important;\n",
        "            padding: 0.75rem 1.5rem !important;\n",
        "            width: 100%;\n",
        "            margin: 1rem auto !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "        }\n",
        "\n",
        "        .detect-btn:hover {\n",
        "            transform: translateY(-2px) !important;\n",
        "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        .detect-btn:active {\n",
        "            transform: translateY(1px) !important;\n",
        "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        /* JSON display improvements */\n",
        "        .json-display {\n",
        "            width: 98% !important;\n",
        "            margin: 0.5rem auto 1.5rem auto !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            background-color: white !important;\n",
        "            border: 1px solid #E2E8F0 !important;\n",
        "            box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.05) !important;\n",
        "        }\n",
        "\n",
        "        .json-key {\n",
        "            color: #e53e3e;\n",
        "        }\n",
        "\n",
        "        .json-value {\n",
        "            color: #2b6cb0;\n",
        "        }\n",
        "\n",
        "        .json-string {\n",
        "            color: #38a169;\n",
        "        }\n",
        "\n",
        "        /* Chart/plot styling improvements */\n",
        "        .plot-container {\n",
        "            background: white;\n",
        "            border-radius: 8px;\n",
        "            padding: 0.5rem;\n",
        "            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);\n",
        "        }\n",
        "\n",
        "        /* Larger font for plots */\n",
        "        .plot-container text {\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "        }\n",
        "\n",
        "        /* Title styling for charts */\n",
        "        .plot-title {\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 16px !important;\n",
        "            font-weight: bold !important;\n",
        "        }\n",
        "\n",
        "        /* Tab styling with subtle gradient */\n",
        "        .tabs {\n",
        "            width: 100%;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "        }\n",
        "\n",
        "        .tabs > div:first-child {\n",
        "            background: linear-gradient(to right, #f8fafc, #e8f4fd) !important;\n",
        "            border-radius: 8px 8px 0 0;\n",
        "        }\n",
        "\n",
        "        /* Tab content styling - 確保內容區域有足夠寬度 */\n",
        "        .tab-content {\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* Footer styling with gradient background */\n",
        "        .footer {\n",
        "            text-align: center;\n",
        "            margin-top: 2rem;\n",
        "            font-size: 0.9rem;\n",
        "            color: #4A5568;\n",
        "            padding: 1rem;\n",
        "            background: linear-gradient(135deg, #f8f9fa, #e1effe);\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* Ensure centering works for all elements */\n",
        "        .container, .gr-container, .gr-row, .gr-col {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            width: 100%;\n",
        "        }\n",
        "\n",
        "        /* 統一文本框樣式，確保寬度一致 */\n",
        "        .gr-textbox, .gr-textarea, .gr-text-input {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 確保文本區域可以適應容器寬度 */\n",
        "        textarea.gr-textarea, .gr-textbox textarea, .gr-text-input textarea {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 16px !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            line-height: 1.6 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            word-break: normal !important;\n",
        "        }\n",
        "\n",
        "        /* 特別針對場景描述文本框樣式增強 */\n",
        "        #scene-description-text, #detection-details {\n",
        "            width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 16px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            border-radius: 8px !important;\n",
        "            min-height: 250px !important;\n",
        "            overflow-y: auto !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            background-color: white !important;\n",
        "            display: block !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 針對場景描述容器的樣式 */\n",
        "        .scene-description-container {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* Scene Understanding Tab 特定樣式 */\n",
        "        .scene-understanding-tab .result-details-box {\n",
        "            display: flex !important;\n",
        "            flex-direction: column !important;\n",
        "            align-items: stretch !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 場景分析描述區域樣式 */\n",
        "        .scene-description-box {\n",
        "            background-color: #f8f9fa !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 15px !important;\n",
        "            margin: 10px 0 20px 0 !important;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            line-height: 1.7 !important;\n",
        "            color: #2D3748 !important;\n",
        "            font-size: 16px !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        #scene_analysis_description_text {\n",
        "            background-color: #f0f0f0 !important; /* 淺灰色背景 */\n",
        "            padding: 15px !important;             /* 內邊距，讓文字和邊框有點空間 */\n",
        "            border-radius: 8px !important;        /* 圓角 */\n",
        "            margin: 10px 0 20px 0 !important;     /* 其他元素的間距，特別是上下的part */\n",
        "            display: block !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        #scene_analysis_description_text p {\n",
        "            margin: 0 !important;\n",
        "            color: #2D3748 !important; /* 確保文字顏色 */\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            font-size: 16px !important; /* 你可以調整文字大小 */\n",
        "            line-height: 1.7 !important;\n",
        "        }\n",
        "\n",
        "        /* 結果容器樣式 */\n",
        "        .result-container {\n",
        "            width: 100% !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #E2E8F0 !important;\n",
        "            margin-bottom: 1.5rem !important;\n",
        "            background-color: #F8FAFC !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 結果文本框的樣式 */\n",
        "        .wide-result-text {\n",
        "            width: 100% !important;\n",
        "            min-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        /* 片段標題樣式 */\n",
        "        .section-heading {\n",
        "            font-size: 1.25rem !important;\n",
        "            font-weight: 600 !important;\n",
        "            color: #2D3748 !important;\n",
        "            margin: 1rem auto !important;\n",
        "            padding: 0.75rem 1rem !important;\n",
        "            background: linear-gradient(to right, #e6f3fc, #f0f9ff) !important;\n",
        "            border-radius: 8px !important;\n",
        "            width: 98% !important;\n",
        "            display: inline-block !important;\n",
        "            box-sizing: border-box !important;\n",
        "            text-align: center !important;\n",
        "            overflow: visible !important;\n",
        "            line-height: 1.5 !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "        }\n",
        "\n",
        "        /* JSON 顯示區域樣式 */\n",
        "        .json-box {\n",
        "            width: 100% !important;\n",
        "            min-height: 200px !important;\n",
        "            overflow-y: auto !important;\n",
        "            background: white !important;\n",
        "            padding: 1rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 欄佈局調整 */\n",
        "        .plot-column, .stats-column {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            padding: 1rem;\n",
        "            box-sizing: border-box !important;\n",
        "            width: 100% !important;\n",
        "        }\n",
        "\n",
        "        /* statistics plot */\n",
        "        .large-plot-container {\n",
        "            width: 100% !important;\n",
        "            min-height: 400px !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 增強 JSON 顯示 */\n",
        "        .enhanced-json-display {\n",
        "            background: white !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 1rem !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            width: 100% !important;\n",
        "            min-height: 300px !important;\n",
        "            max-height: 500px !important;\n",
        "            overflow-y: auto !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* 確保全寬元素真正占滿整個寬度 */\n",
        "        .full-width-element {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "        }\n",
        "\n",
        "        /* Video summary HTML 容器與內容樣式 */\n",
        "        #video-summary-html-output {\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            padding: 0 !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        .video-summary-content-wrapper {\n",
        "            width: 100% !important;\n",
        "            padding: 16px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            border-radius: 8px !important;\n",
        "            min-height: 250px !important;\n",
        "            max-height: 600px !important;\n",
        "            overflow-y: auto !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            background-color: white !important;\n",
        "            display: block !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            margin: 0 !important;\n",
        "        }\n",
        "\n",
        "        .video-summary-content-wrapper pre {\n",
        "            white-space: pre-wrap !important;\n",
        "            word-wrap: break-word !important;\n",
        "            margin: 0 !important;\n",
        "            padding: 0 !important;\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            line-height: 1.8 !important;\n",
        "            color: #2D3748 !important;\n",
        "        }\n",
        "\n",
        "        /* 視頻結果面板相關樣式 */\n",
        "        .video-result-panel {\n",
        "            padding: 1rem !important;\n",
        "            background: white !important;\n",
        "            border-radius: 10px !important;\n",
        "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08) !important;\n",
        "        }\n",
        "\n",
        "        .video-output-container {\n",
        "            width: 100% !important;\n",
        "            margin-bottom: 1.5rem !important;\n",
        "            border-radius: 8px !important;\n",
        "            overflow: hidden !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "        }\n",
        "\n",
        "        /* 視頻統計資料顯示增強 */\n",
        "        .video-stats-display {\n",
        "            background: white !important;\n",
        "            border-radius: 8px !important;\n",
        "            padding: 1rem !important;\n",
        "            box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.1) !important;\n",
        "            width: 100% !important;\n",
        "            min-height: 200px !important;\n",
        "            max-height: 400px !important;\n",
        "            overflow-y: auto !important;\n",
        "            font-family: monospace !important;\n",
        "            box-sizing: border-box !important;\n",
        "            color: #2D3748 !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input {\n",
        "            width: 100% !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input textarea {\n",
        "            width: 100% !important;\n",
        "            min-height: 120px !important;\n",
        "            padding: 15px !important;\n",
        "            font-size: 16px !important;\n",
        "            line-height: 1.6 !important;\n",
        "            background-color: #F7FAFC !important;\n",
        "            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;\n",
        "            border: 2px solid #CBD5E0 !important;\n",
        "            border-radius: 8px !important;\n",
        "        }\n",
        "\n",
        "        .custom-video-url-input textarea:focus {\n",
        "            border-color: #4299E1 !important;\n",
        "            box-shadow: 0 0 0 3px rgba(66, 153, 225, 0.2) !important;\n",
        "        }\n",
        "\n",
        "        /* 輸入框容器100%寬度 */\n",
        "        .custom-video-url-input > div {\n",
        "            width: 100% !important;\n",
        "            max-width: 100% !important;\n",
        "        }\n",
        "\n",
        "        /* LLM 增強描述樣式 */\n",
        "        #llm_enhanced_description_text {\n",
        "            padding: 15px !important;\n",
        "            background-color: #ffffff !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "            margin-bottom: 20px !important;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.05) !important;\n",
        "            font-family: Arial, sans-serif !important;\n",
        "            line-height: 1.7 !important;\n",
        "            color: #2D3748 !important;\n",
        "            font-size: 16px !important;\n",
        "            width: 100% !important;\n",
        "            box-sizing: border-box !important;\n",
        "            min-height: 200px !important;\n",
        "        }\n",
        "\n",
        "        /* 原始描述折疊區域樣式 */\n",
        "        #original_scene_analysis_accordion {\n",
        "            margin-top: 10px !important;\n",
        "            margin-bottom: 20px !important;\n",
        "            background-color: #f8f9fa !important;\n",
        "            border-radius: 8px !important;\n",
        "            border: 1px solid #e2e8f0 !important;\n",
        "        }\n",
        "\n",
        "        /* 確保折疊區域內容與頁面樣式協調 */\n",
        "        #original_scene_analysis_accordion > div:nth-child(2) {\n",
        "            padding: 15px !important;\n",
        "        }\n",
        "\n",
        "        /* 動畫效果, 增加互動感 */\n",
        "        @keyframes fadeIn {\n",
        "            from { opacity: 0; }\n",
        "            to { opacity: 1; }\n",
        "        }\n",
        "\n",
        "        .video-result-panel > * {\n",
        "            animation: fadeIn 0.5s ease-in-out;\n",
        "        }\n",
        "\n",
        "        /* 響應式調整 */\n",
        "        @media (max-width: 768px) {\n",
        "            .app-title {\n",
        "                font-size: 2rem;\n",
        "            }\n",
        "\n",
        "            .app-subtitle {\n",
        "                font-size: 1rem;\n",
        "            }\n",
        "\n",
        "            .gradio-container {\n",
        "                padding: 0.5rem;\n",
        "            }\n",
        "\n",
        "            /* 在小螢幕上調整文本區域的高度 */\n",
        "            #scene-description-text, #detection-details {\n",
        "                min-height: 150px !important;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        \"\"\"\n",
        "        return css"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBOELeMbrVBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2186c396-7bcd-4ccf-f9fd-cb283597b336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_type.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile scene_type.py\n",
        "\n",
        "SCENE_TYPES = {\n",
        "    \"living_room\": {\n",
        "        \"name\": \"Living Room\",\n",
        "        \"required_objects\": [57, 62],  # couch, tv\n",
        "        \"optional_objects\": [56, 60, 73, 75],  # chair, dining table, book, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A living room area with furniture for relaxation and entertainment\"\n",
        "    },\n",
        "    \"bedroom\": {\n",
        "        \"name\": \"Bedroom\",\n",
        "        \"required_objects\": [59],  # bed\n",
        "        \"optional_objects\": [56, 60, 73, 74, 75],  # chair, dining table, book, clock, vase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A bedroom with sleeping furniture\"\n",
        "    },\n",
        "    \"dining_area\": {\n",
        "        \"name\": \"Dining Area\",\n",
        "        \"required_objects\": [60],  # dining table\n",
        "        \"optional_objects\": [56, 39, 41, 42, 43, 44, 45],  # chair, bottle, cup, fork, knife, spoon, bowl\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A dining area for meals\"\n",
        "    },\n",
        "    \"kitchen\": {\n",
        "        \"name\": \"Kitchen\",\n",
        "        \"required_objects\": [72, 68, 69, 71],  # refrigerator, microwave, oven, sink\n",
        "        \"optional_objects\": [39, 41, 42, 43, 44, 45],  # bottle, cup, fork, knife, spoon, bowl\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A kitchen area for food preparation\"\n",
        "    },\n",
        "    \"office_workspace\": {\n",
        "        \"name\": \"Office Workspace\",\n",
        "        \"required_objects\": [56, 63, 66, 64, 73],  # chair, laptop, keyboard, mouse, book\n",
        "        \"optional_objects\": [60, 74, 75, 67],  # dining table, clock, vase, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A workspace with computer equipment for office work\"\n",
        "    },\n",
        "    \"meeting_room\": {\n",
        "        \"name\": \"Meeting Room\",\n",
        "        \"required_objects\": [56, 60],  # chair, dining table\n",
        "        \"optional_objects\": [63, 62, 67],  # laptop, tv, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A room set up for meetings with multiple seating\"\n",
        "    },\n",
        "    \"city_street\": {\n",
        "        \"name\": \"City Street\",\n",
        "        \"required_objects\": [0, 1, 2, 3, 5, 7, 9],  # person, bicycle, car, motorcycle, bus, truck, traffic light\n",
        "        \"optional_objects\": [10, 11, 12, 24, 25, 26, 28],  # fire hydrant, stop sign, parking meter, backpack, umbrella, handbag, suitcase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A city street with traffic and pedestrians\"\n",
        "    },\n",
        "    \"parking_lot\": {\n",
        "        \"name\": \"Parking Lot\",\n",
        "        \"required_objects\": [2, 3, 5, 7],  # car, motorcycle, bus, truck\n",
        "        \"optional_objects\": [0, 11, 12],  # person, stop sign, parking meter\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A parking area with multiple vehicles\"\n",
        "    },\n",
        "    \"park_area\": {\n",
        "        \"name\": \"Park or Recreation Area\",\n",
        "        \"required_objects\": [0, 13],  # person, bench\n",
        "        \"optional_objects\": [1, 14, 16, 25, 33],  # bicycle, bird, dog, umbrella, kite\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An outdoor recreational area for leisure activities\"\n",
        "    },\n",
        "    \"retail_store\": {\n",
        "        \"name\": \"Retail Store\",\n",
        "        \"required_objects\": [0, 24, 26, 28],  # person, backpack, handbag, suitcase\n",
        "        \"optional_objects\": [39, 45, 67],  # bottle, bowl, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A retail environment with shoppers and merchandise\"\n",
        "    },\n",
        "    \"supermarket\": {\n",
        "        \"name\": \"Supermarket\",\n",
        "        \"required_objects\": [0, 24, 39, 46, 47, 49],  # person, backpack, bottle, banana, apple, orange\n",
        "        \"optional_objects\": [26, 37, 45, 48, 51, 52, 53, 54, 55],  # handbag, surfboard, bowl, sandwich, carrot, hot dog, pizza, donut, cake\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A supermarket with food items and shoppers\"\n",
        "    },\n",
        "    \"classroom\": {\n",
        "        \"name\": \"Classroom\",\n",
        "        \"required_objects\": [56, 60, 73],  # chair, dining table, book\n",
        "        \"optional_objects\": [63, 66, 67],  # laptop, keyboard, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A classroom environment set up for educational activities\"\n",
        "    },\n",
        "    \"conference_room\": {\n",
        "        \"name\": \"Conference Room\",\n",
        "        \"required_objects\": [56, 60, 63],  # chair, dining table, laptop\n",
        "        \"optional_objects\": [62, 67, 73],  # tv, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A conference room designed for meetings and presentations\"\n",
        "    },\n",
        "    \"cafe\": {\n",
        "        \"name\": \"Cafe\",\n",
        "        \"required_objects\": [56, 60, 41],  # chair, dining table, cup\n",
        "        \"optional_objects\": [39, 40, 63, 67, 73],  # bottle, wine glass, laptop, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A cafe setting with seating and beverages\"\n",
        "    },\n",
        "    \"library\": {\n",
        "        \"name\": \"Library\",\n",
        "        \"required_objects\": [56, 60, 73],  # chair, dining table, book\n",
        "        \"optional_objects\": [63, 67, 75],  # laptop, cell phone, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A library with books and reading areas\"\n",
        "    },\n",
        "    \"gym\": {\n",
        "        \"name\": \"Gym\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [24, 25, 28, 38],  # backpack, umbrella, suitcase, tennis racket\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A gym or fitness area for physical activities\"\n",
        "    },\n",
        "    \"beach\": {\n",
        "        \"name\": \"Beach\",\n",
        "        \"required_objects\": [0, 25, 29, 33, 37],  # person, umbrella, frisbee, kite, surfboard\n",
        "        \"optional_objects\": [1, 24, 26, 38],  # bicycle, backpack, handbag, tennis racket\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A beach area with people and recreational items\"\n",
        "    },\n",
        "    \"restaurant\": {\n",
        "        \"name\": \"Restaurant\",\n",
        "        \"required_objects\": [56, 60, 41, 42, 43, 44, 45],  # chair, dining table, cup, fork, knife, spoon, bowl\n",
        "        \"optional_objects\": [39, 40, 48, 49, 50, 51, 52, 53, 54, 55],  # bottle, wine glass, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake\n",
        "        \"minimum_required\": 3,\n",
        "        \"description\": \"A restaurant setting for dining with tables and eating utensils\"\n",
        "    },\n",
        "    \"train_station\": {\n",
        "        \"name\": \"Train Station\",\n",
        "        \"required_objects\": [0, 6],  # person, train\n",
        "        \"optional_objects\": [1, 2, 24, 28, 67],  # bicycle, car, backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A train station with train and passengers\"\n",
        "    },\n",
        "    \"airport\": {\n",
        "        \"name\": \"Airport\",\n",
        "        \"required_objects\": [0, 4, 28],  # person, airplane, suitcase\n",
        "        \"optional_objects\": [24, 25, 26, 67],  # backpack, umbrella, handbag, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An airport with planes and travelers carrying luggage\"\n",
        "    },\n",
        "      \"upscale_dining\": {\n",
        "        \"name\": \"Upscale Dining Area\",\n",
        "        \"required_objects\": [56, 60, 40, 41],  # chair, dining table, wine glass, cup\n",
        "        \"optional_objects\": [39, 42, 43, 44, 45, 62, 75],  # bottle, fork, knife, spoon, bowl, tv, vase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An elegantly designed dining space with refined furniture and decorative elements\"\n",
        "    },\n",
        "    \"asian_commercial_street\": {\n",
        "        \"name\": \"Asian Commercial Street\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 2, 3, 24, 25, 26, 28],  # bicycle, car, motorcycle, backpack, umbrella, handbag, suitcase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A bustling commercial street with shops, signage, and pedestrians in an Asian urban setting\"\n",
        "    },\n",
        "    \"financial_district\": {\n",
        "        \"name\": \"Financial District\",\n",
        "        \"required_objects\": [2, 5, 7, 9],  # car, bus, truck, traffic light\n",
        "        \"optional_objects\": [0, 1, 3, 8],  # person, bicycle, motorcycle, boat\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A major thoroughfare in a business district with high-rise buildings and traffic\"\n",
        "    },\n",
        "    \"urban_intersection\": {\n",
        "        \"name\": \"Urban Intersection\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A busy urban crossroad with pedestrian crossings and multiple traffic flows\"\n",
        "    },\n",
        "    \"transit_hub\": {\n",
        "        \"name\": \"Transit Hub\",\n",
        "        \"required_objects\": [0, 5, 6, 7],  # person, bus, train, truck\n",
        "        \"optional_objects\": [1, 2, 3, 9, 24, 28],  # bicycle, car, motorcycle, traffic light, backpack, suitcase\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A transportation center where multiple modes of transit converge\"\n",
        "    },\n",
        "    \"shopping_district\": {\n",
        "        \"name\": \"Shopping District\",\n",
        "        \"required_objects\": [0, 24, 26],  # person, backpack, handbag\n",
        "        \"optional_objects\": [1, 2, 3, 25, 27, 28, 39, 67],  # bicycle, car, motorcycle, umbrella, tie, suitcase, bottle, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A retail-focused area with shops, pedestrians, and commercial activity\"\n",
        "    },\n",
        "     \"bus_stop\": {\n",
        "        \"name\": \"Bus Stop\",\n",
        "        \"required_objects\": [0, 5],  # person, bus\n",
        "        \"optional_objects\": [1, 2, 7, 24],  # bicycle, car, truck, backpack\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A roadside bus stop with waiting passengers and buses\"\n",
        "    },\n",
        "    \"bus_station\": {\n",
        "        \"name\": \"Bus Station\",\n",
        "        \"required_objects\": [0, 5, 7],  # person, bus, truck\n",
        "        \"optional_objects\": [24, 28, 67],  # backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A bus terminal with multiple buses and travelers\"\n",
        "    },\n",
        "    \"zoo\": {\n",
        "        \"name\": \"Zoo\",\n",
        "        \"required_objects\": [20, 22, 23],  # elephant, zebra, giraffe\n",
        "        \"optional_objects\": [0, 14, 16],  # person, bird, dog\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A zoo environment featuring large animal exhibits and visitors\"\n",
        "    },\n",
        "    \"harbor\": {\n",
        "        \"name\": \"Harbor\",\n",
        "        \"required_objects\": [8],  # boat\n",
        "        \"optional_objects\": [0, 2, 3, 39],  # person, car, motorcycle, bottle\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A harbor area with boats docked and surrounding traffic\"\n",
        "    },\n",
        "    \"playground\": {\n",
        "        \"name\": \"Playground\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [33, 24, 1],  # kite, backpack, bicycle\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An outdoor playground with people playing sports and games\"\n",
        "    },\n",
        "    \"sports_field\": {\n",
        "        \"name\": \"Sports Field\",\n",
        "        \"required_objects\": [32],  # sports ball\n",
        "        \"optional_objects\": [38, 34, 35],  # tennis racket, baseball bat, baseball glove\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A sports field set up for various ball games\"\n",
        "    },\n",
        "     \"narrow_commercial_alley\": {\n",
        "        \"name\": \"Narrow Commercial Alley\",\n",
        "        \"required_objects\": [0, 3],  # person, motorcycle\n",
        "        \"optional_objects\": [2, 7, 24, 26],  # car, truck, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A tight urban alley lined with shops, with pedestrians and light vehicles\"\n",
        "    },\n",
        "    \"daytime_shopping_street\": {\n",
        "        \"name\": \"Daytime Shopping Street\",\n",
        "        \"required_objects\": [0, 2],  # person, car\n",
        "        \"optional_objects\": [1, 3, 24, 26],  # bicycle, motorcycle, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A busy pedestrian street during daytime, featuring shops, vehicles, and shoppers\"\n",
        "    },\n",
        "    \"urban_pedestrian_crossing\": {\n",
        "        \"name\": \"Urban Pedestrian Crossing\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [2, 3, 5],  # car, motorcycle, bus\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A city street crossing with pedestrians and traffic signals\"\n",
        "    },\n",
        "    \"aerial_view_intersection\": {\n",
        "    \"name\": \"Aerial View Intersection\",\n",
        "    \"required_objects\": [0, 9],  # person, traffic light\n",
        "    \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "    \"minimum_required\": 1,\n",
        "    \"description\": \"An intersection viewed from above, showing crossing patterns and pedestrian movement\"\n",
        "    },\n",
        "    \"aerial_view_commercial_area\": {\n",
        "        \"name\": \"Aerial View Commercial Area\",\n",
        "        \"required_objects\": [0, 2],  # person, car\n",
        "        \"optional_objects\": [1, 3, 5, 7, 24, 26],  # bicycle, motorcycle, bus, truck, backpack, handbag\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A commercial or shopping area viewed from above showing pedestrians and urban layout\"\n",
        "    },\n",
        "    \"aerial_view_plaza\": {\n",
        "        \"name\": \"Aerial View Plaza\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [1, 2, 24, 25, 26],  # bicycle, car, backpack, umbrella, handbag\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An urban plaza or public square viewed from above with pedestrian activity\"\n",
        "    },\n",
        "\n",
        "    # specific cultural item\n",
        "    \"asian_night_market\": {\n",
        "        \"name\": \"Asian Night Market\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 3, 24, 26, 39, 41],  # bicycle, motorcycle, backpack, handbag, bottle, cup\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A vibrant night market scene typical in Asian cities with food stalls and crowds\"\n",
        "    },\n",
        "    \"asian_temple_area\": {\n",
        "        \"name\": \"Asian Temple Area\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 25, 26, 67, 75],  # backpack, umbrella, handbag, cell phone, vase\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A traditional Asian temple complex with visitors and cultural elements\"\n",
        "    },\n",
        "\n",
        "    # specific time item\n",
        "    \"nighttime_street\": {\n",
        "        \"name\": \"Nighttime Street\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7, 67],  # bicycle, car, motorcycle, bus, truck, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An urban street at night with artificial lighting and nighttime activity\"\n",
        "    },\n",
        "    \"nighttime_commercial_district\": {\n",
        "        \"name\": \"Nighttime Commercial District\",\n",
        "        \"required_objects\": [0, 67],  # person, cell phone\n",
        "        \"optional_objects\": [1, 2, 3, 24, 26],  # bicycle, car, motorcycle, backpack, handbag\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A commercial district illuminated at night with neon signs and evening activity\"\n",
        "    },\n",
        "\n",
        "    # mixture enviroment item\n",
        "    \"indoor_outdoor_cafe\": {\n",
        "        \"name\": \"Indoor-Outdoor Cafe\",\n",
        "        \"required_objects\": [56, 60, 41],  # chair, dining table, cup\n",
        "        \"optional_objects\": [39, 40, 63, 67, 73],  # bottle, wine glass, laptop, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A cafe setting with both indoor elements and outdoor patio or sidewalk seating\"\n",
        "    },\n",
        "    \"transit_station_platform\": {\n",
        "        \"name\": \"Transit Station Platform\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [5, 6, 7, 24, 28, 67],  # bus, train, truck, backpack, suitcase, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A transit platform with waiting passengers and arriving/departing vehicles\"\n",
        "    },\n",
        "    \"sports_stadium\": {\n",
        "        \"name\": \"Sports Stadium\",\n",
        "        \"required_objects\": [0, 32],  # person, sports ball\n",
        "        \"optional_objects\": [24, 38, 39, 41, 67],  # backpack, tennis racket, bottle, cup, cell phone\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A sports stadium or arena with spectators and athletic activities\"\n",
        "    },\n",
        "    \"construction_site\": {\n",
        "        \"name\": \"Construction Site\",\n",
        "        \"required_objects\": [0, 7],  # person, truck\n",
        "        \"optional_objects\": [2, 3, 11, 76, 77, 78],  # car, motorcycle, fire hydrant, scissors, teddy bear, hair drier\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"A construction site with workers, equipment, and building materials\"\n",
        "    },\n",
        "    \"medical_facility\": {\n",
        "        \"name\": \"Medical Facility\",\n",
        "        \"required_objects\": [0, 56, 60],  # person, chair, dining table\n",
        "        \"optional_objects\": [63, 64, 66, 67, 73],  # laptop, mouse, keyboard, cell phone, book\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"A medical facility such as hospital, clinic or doctor's office with medical staff and patients\"\n",
        "    },\n",
        "    \"educational_setting\": {\n",
        "        \"name\": \"Educational Setting\",\n",
        "        \"required_objects\": [0, 56, 60, 73],  # person, chair, dining table, book\n",
        "        \"optional_objects\": [63, 64, 66, 67, 74],  # laptop, mouse, keyboard, cell phone, clock\n",
        "        \"minimum_required\": 2,\n",
        "        \"description\": \"An educational environment such as classroom, lecture hall or study area\"\n",
        "    },\n",
        "    \"aerial_view_intersection\": {\n",
        "        \"name\": \"Aerial View Intersection\",\n",
        "        \"required_objects\": [0, 9],  # person, traffic light\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7],  # bicycle, car, motorcycle, bus, truck\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An intersection viewed from above, showing crossing patterns and pedestrian movement\",\n",
        "        \"viewpoint_indicator\": \"aerial\", # view side\n",
        "        \"key_features\": [\"crosswalk_pattern\", \"pedestrian_flow\", \"intersection_layout\"],  # key feature\n",
        "        \"detection_priority\": 10  # priority\n",
        "    },\n",
        "    \"perpendicular_crosswalk_intersection\": {\n",
        "        \"name\": \"Perpendicular Crosswalk Intersection\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [1, 2, 3, 5, 7, 9],  # bicycle, car, motorcycle, bus, truck, traffic light\n",
        "        \"minimum_required\": 1,\n",
        "        \"description\": \"An intersection with perpendicular crosswalks where pedestrians cross in multiple directions\",\n",
        "        \"viewpoint_indicator\": \"aerial\",\n",
        "        \"key_features\": [\"perpendicular_crosswalks\", \"pedestrian_crossing\", \"multi_directional_movement\"],\n",
        "        \"pattern_detection\": True, # specific pattern\n",
        "        \"detection_priority\": 15  #\n",
        "    },\n",
        "    \"beach_water_recreation\": {\n",
        "    \"name\": \"Beach/Water Recreation Area\",\n",
        "    \"required_objects\": [0, 37],  # person, surfboard\n",
        "    \"optional_objects\": [25, 33, 1, 8, 29, 24, 26, 39, 41],  # umbrella, kite, bicycle, boat, frisbee, backpack, handbag, bottle, cup\n",
        "    \"minimum_required\": 2,\n",
        "    \"description\": \"A beach or water recreation area with water sports equipment and beach accessories\"\n",
        "    },\n",
        "    \"sports_venue\": {\n",
        "    \"name\": \"Sports Venue\",\n",
        "    \"required_objects\": [0, 32],  # person, sports ball\n",
        "    \"optional_objects\": [34, 35, 38, 25, 24, 26, 39, 41],  # baseball bat, baseball glove, tennis racket, umbrella, backpack, handbag, bottle, cup\n",
        "    \"minimum_required\": 2,\n",
        "    \"description\": \"A professional sports venue with specialized sports equipment and spectator areas\"\n",
        "    },\n",
        "    \"professional_kitchen\": {\n",
        "    \"name\": \"Professional Kitchen\",\n",
        "    \"required_objects\": [43, 44, 45],  # knife, spoon, bowl\n",
        "    \"optional_objects\": [42, 39, 41, 68, 69, 71, 72, 0],  # fork, bottle, cup, microwave, oven, sink, refrigerator, person\n",
        "    \"minimum_required\": 3,\n",
        "    \"description\": \"A commercial kitchen with professional cooking equipment and food preparation areas\"\n",
        "    },\n",
        "    \"tourist_landmark\": {\n",
        "        \"name\": \"Tourist Landmark\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,  # 可能沒有人，但仍然是地標\n",
        "        \"description\": \"A location featuring a famous landmark with tourist activity\",\n",
        "        \"priority\": 1.2  # 提高優先級\n",
        "    },\n",
        "    \"natural_landmark\": {\n",
        "        \"name\": \"Natural Landmark\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,\n",
        "        \"description\": \"A natural landmark site with scenic views\",\n",
        "        \"priority\": 1.2\n",
        "    },\n",
        "    \"historical_monument\": {\n",
        "        \"name\": \"Historical Monument\",\n",
        "        \"required_objects\": [0],  # person\n",
        "        \"optional_objects\": [24, 26, 67],  # backpack, handbag, cell phone\n",
        "        \"minimum_required\": 0,\n",
        "        \"description\": \"A historical monument or heritage site\",\n",
        "        \"priority\": 1.2\n",
        "    },\n",
        "    \"general_indoor_space\": {\n",
        "        \"name\": \"General Indoor Space\",\n",
        "        \"required_objects\": [], # No strict required objects, depends on combination\n",
        "        \"optional_objects\": [\n",
        "            56, # chair\n",
        "            57, # couch\n",
        "            58, # potted plant\n",
        "            59, # bed\n",
        "            60, # dining table\n",
        "            61, # toilet\n",
        "            62, # tv\n",
        "            63, # laptop\n",
        "            66, # keyboard\n",
        "            67, # cell phone\n",
        "            73, # book\n",
        "            74, # clock\n",
        "            75, # vase\n",
        "            39, # bottle\n",
        "            41, # cup\n",
        "        ],\n",
        "        \"minimum_required\": 2, # Needs at least a few common indoor items\n",
        "        \"description\": \"An indoor area with various common household or functional items.\",\n",
        "        \"priority\": 0.8 # Lower priority than more specific scenes\n",
        "    },\n",
        "    \"generic_street_view\": {\n",
        "        \"name\": \"Generic Street View\",\n",
        "        \"required_objects\": [], # More about the combination\n",
        "        \"optional_objects\": [\n",
        "            0,  # person\n",
        "            1,  # bicycle\n",
        "            2,  # car\n",
        "            3,  # motorcycle\n",
        "            5,  # bus\n",
        "            7,  # truck\n",
        "            9,  # traffic light\n",
        "            10, # fire hydrant\n",
        "            11, # stop sign\n",
        "            13, # bench\n",
        "            # Consider adding building if YOLO detects it (not a standard COCO class for YOLOv8, but some custom models might)\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., a car and a person, or multiple vehicles\n",
        "        \"description\": \"An outdoor street view, likely in an urban or suburban setting, with vehicles and/or pedestrians.\",\n",
        "        \"priority\": 0.85\n",
        "    },\n",
        "    \"desk_area_workspace\": {\n",
        "        \"name\": \"Desk Area / Workspace\",\n",
        "        \"required_objects\": [\n",
        "            63, # laptop or 62 (tv as monitor) or 66 (keyboard)\n",
        "        ],\n",
        "        \"optional_objects\": [\n",
        "            56, # chair\n",
        "            60, # dining table (often used as a desk)\n",
        "            64, # mouse\n",
        "            66, # keyboard\n",
        "            73, # book\n",
        "            41, # cup\n",
        "            67, # cell phone\n",
        "            74, # clock\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., laptop and chair, or table and keyboard\n",
        "        \"description\": \"A workspace or desk area, typically featuring a computer and related accessories.\",\n",
        "        \"priority\": 0.9\n",
        "    },\n",
        "    \"outdoor_gathering_spot\": {\n",
        "        \"name\": \"Outdoor Gathering Spot\",\n",
        "        \"required_objects\": [\n",
        "            0,  # person\n",
        "        ],\n",
        "        \"optional_objects\": [\n",
        "            13, # bench\n",
        "            32, # sports ball\n",
        "            24, # backpack\n",
        "            25, # umbrella\n",
        "            29, # frisbee\n",
        "            33, # kite\n",
        "            58, # potted plant (if in a more structured park area)\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., person and bench, or multiple people\n",
        "        \"description\": \"An outdoor area where people might gather for leisure or activity.\",\n",
        "        \"priority\": 0.8\n",
        "    },\n",
        "    \"kitchen_counter_or_utility_area\": {\n",
        "        \"name\": \"Kitchen Counter or Utility Area\",\n",
        "        \"required_objects\": [],\n",
        "        \"optional_objects\": [\n",
        "            39, # bottle\n",
        "            41, # cup\n",
        "            44, # spoon\n",
        "            45, # bowl\n",
        "            68, # microwave\n",
        "            69, # oven\n",
        "            70, # toaster\n",
        "            71, # sink\n",
        "            72, # refrigerator\n",
        "        ],\n",
        "        \"minimum_required\": 2, # e.g., sink and microwave, or refrigerator and bottles\n",
        "        \"description\": \"An area likely used for food preparation or kitchen utilities.\",\n",
        "        \"priority\": 0.9\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDHYIPUCXGMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5304b139-33c3-4b6b-eb51-b72956df55bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing confidence_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile confidence_templates.py\n",
        "\n",
        "CONFIDENCE_TEMPLATES = {\n",
        "    \"high\": \"{description} {details}\",\n",
        "    \"medium\": \"This appears to be {description} {details}\",\n",
        "    \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUwQa_4KqHbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae954ef-dce9-4cb0-f3f1-d748466b0de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_detail_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile scene_detail_templates.py\n",
        "\n",
        "SCENE_DETAIL_TEMPLATES = {\n",
        "            \"living_room\": [\n",
        "                \"The space is arranged for relaxation with {furniture}.\",\n",
        "                \"There is {electronics} for entertainment.\",\n",
        "                \"The room has a seating area with {seating}.\"\n",
        "            ],\n",
        "            \"bedroom\": [\n",
        "                \"The room contains {bed_type} in the {bed_location}.\",\n",
        "                \"This sleeping area has {bed_description}.\",\n",
        "                \"A personal space with {bed_type} and {extras}.\"\n",
        "            ],\n",
        "            \"dining_area\": [\n",
        "                \"A space set up for meals with {table_setup}.\",\n",
        "                \"The dining area contains {table_description}.\",\n",
        "                \"A place for eating with {dining_items}.\"\n",
        "            ],\n",
        "            \"kitchen\": [\n",
        "                \"A food preparation area with {appliances}.\",\n",
        "                \"The kitchen contains {kitchen_items}.\",\n",
        "                \"A cooking space equipped with {cooking_equipment}.\"\n",
        "            ],\n",
        "            \"office_workspace\": [\n",
        "                \"A work environment with {office_equipment}.\",\n",
        "                \"A space designed for productivity with {desk_setup}.\",\n",
        "                \"A workspace containing {computer_equipment}.\"\n",
        "            ],\n",
        "            \"city_street\": [\n",
        "                \"An urban thoroughfare with {traffic_description}.\",\n",
        "                \"A street scene with {people_and_vehicles}.\",\n",
        "                \"A city path with {street_elements}.\"\n",
        "            ],\n",
        "            \"park_area\": [\n",
        "                \"An outdoor recreational space with {park_features}.\",\n",
        "                \"A leisure area featuring {outdoor_elements}.\",\n",
        "                \"A public outdoor space with {park_description}.\"\n",
        "            ],\n",
        "            \"retail_store\": [\n",
        "                \"A shopping environment with {store_elements}.\",\n",
        "                \"A commercial space where {shopping_activity}.\",\n",
        "                \"A retail area containing {store_items}.\"\n",
        "            ],\n",
        "            \"upscale_dining\": [\n",
        "            \"The space features {furniture} with {design_elements} for an elegant dining experience.\",\n",
        "            \"This sophisticated dining area includes {lighting} illuminating {table_setup}.\",\n",
        "            \"A stylish dining environment with {seating} arranged around {table_description}.\"\n",
        "            ],\n",
        "            \"asian_commercial_street\": [\n",
        "                \"A vibrant street lined with {storefront_features} and filled with {pedestrian_flow}.\",\n",
        "                \"This urban commercial area displays {asian_elements} with {cultural_elements}.\",\n",
        "                \"A lively shopping street characterized by {signage} and busy with {street_activities}.\"\n",
        "            ],\n",
        "            \"financial_district\": [\n",
        "                \"A canyon of {buildings} with {traffic_elements} moving through the urban landscape.\",\n",
        "                \"This business district features {skyscrapers} along {road_features}.\",\n",
        "                \"A downtown corridor with {architectural_elements} framing views of {city_landmarks}.\"\n",
        "            ],\n",
        "            \"urban_intersection\": [\n",
        "                \"A busy crossroad with {crossing_pattern} where {pedestrian_behavior} is observed.\",\n",
        "                \"This urban junction features {pedestrian_density} navigating the {traffic_pattern}.\",\n",
        "                \"A well-marked intersection designed for {pedestrian_flow} across multiple directions.\"\n",
        "            ],\n",
        "            \"transit_hub\": [\n",
        "                \"A transportation nexus where {transit_vehicles} arrive and depart amid {passenger_activity}.\",\n",
        "                \"This transit center accommodates {transportation_modes} with facilities for {passenger_needs}.\",\n",
        "                \"A busy transport hub featuring {transit_infrastructure} and areas for {passenger_movement}.\"\n",
        "            ],\n",
        "            \"shopping_district\": [\n",
        "                \"A commercial zone filled with {retail_elements} and {shopping_activity}.\",\n",
        "                \"This shopping area features {store_types} along {walkway_features}.\",\n",
        "                \"A retail district characterized by {commercial_signage} and {consumer_behavior}.\"\n",
        "            ],\n",
        "            \"bus_stop\": [\n",
        "                \"Passengers waiting at a roadside stop served by {transit_vehicles}.\",\n",
        "                \"A designated bus stop with shelters and {passenger_activity}.\",\n",
        "                \"Commuters boarding or alighting from {transit_vehicles} at the curb.\"\n",
        "            ],\n",
        "            \"bus_station\": [\n",
        "                \"Multiple buses parked in a terminal where {passenger_activity}.\",\n",
        "                \"A busy station hub featuring {transit_vehicles} and traveler luggage.\",\n",
        "                \"A transit center with waiting areas and various {transportation_modes}.\"\n",
        "            ],\n",
        "            \"zoo\": [\n",
        "                \"Enclosures showcasing elephants, zebras, and giraffes with visitors observing.\",\n",
        "                \"A wildlife exhibit area where families watch animal displays.\",\n",
        "                \"A recreational space featuring large animal exhibits and strolling guests.\"\n",
        "            ],\n",
        "            \"harbor\": [\n",
        "                \"Boats docked along the waterfront with nearby vehicular traffic.\",\n",
        "                \"A maritime area where vessels anchor beside roads busy with cars and motorcycles.\",\n",
        "                \"A coastal dock featuring moored boats and passing traffic elements.\"\n",
        "            ],\n",
        "            \"playground\": [\n",
        "                \"An open play area equipped with balls and recreational structures.\",\n",
        "                \"People engaging in games and sports in a communal space.\",\n",
        "                \"A leisure area featuring playground equipment and active participants.\"\n",
        "            ],\n",
        "            \"sports_field\": [\n",
        "                \"An athletic field marked for various ball games and matches.\",\n",
        "                \"Players using equipment like bats, gloves, and rackets on a grassy pitch.\",\n",
        "                \"A designated sports area with goalposts or markings for competitive play.\"\n",
        "            ],\n",
        "            \"narrow_commercial_alley\": [\n",
        "                \"A tight alley lined with {storefront_features} and light vehicles.\",\n",
        "                \"Pedestrians navigate a confined lane flanked by shops and {street_activities}.\",\n",
        "                \"An urban passage featuring {storefront_features} with {people_and_vehicles}.\"\n",
        "            ],\n",
        "            \"daytime_shopping_street\": [\n",
        "                \"A bustling street during daytime with {storefront_features} and {pedestrian_flow}.\",\n",
        "                \"Shoppers and vehicles move along a retail strip marked by {signage}.\",\n",
        "                \"An open commercial avenue filled with {people_and_vehicles} amid shops.\"\n",
        "            ],\n",
        "            \"urban_pedestrian_crossing\": [\n",
        "                \"A marked crosswalk with {crossing_pattern} under {lighting_modifier} sky.\",\n",
        "                \"Pedestrians use designated crossing with {traffic_pattern} at the intersection.\",\n",
        "                \"People waiting at a signal-controlled crossing next to {street_elements}.\"\n",
        "            ],\n",
        "            \"aerial_view_intersection\": [\n",
        "                \"The crossing pattern shows {crossing_pattern} with {pedestrian_flow} across multiple directions.\",\n",
        "                \"From above, this intersection reveals {traffic_pattern} with {pedestrian_density} navigating through defined paths.\",\n",
        "                \"This bird's-eye view shows {street_elements} converging at a junction where {pedestrian_behavior} is visible.\"\n",
        "            ],\n",
        "            \"aerial_view_commercial_area\": [\n",
        "                \"From above, this commercial zone shows {storefront_features} with {pedestrian_flow} moving between establishments.\",\n",
        "                \"This overhead view reveals {shopping_activity} amid {walkway_features} connecting different businesses.\",\n",
        "                \"The aerial perspective captures {retail_elements} organized along {commercial_layout} with visible customer activity.\"\n",
        "            ],\n",
        "            \"aerial_view_plaza\": [\n",
        "                \"This overhead view of the plaza shows {pedestrian_pattern} across an open public space.\",\n",
        "                \"From above, the plaza reveals {gathering_features} where people congregate in {movement_pattern}.\",\n",
        "                \"The aerial perspective captures {urban_elements} arranged around a central area where {public_activity} occurs.\"\n",
        "            ],\n",
        "            \"asian_night_market\": [\n",
        "                \"This bustling night market features {stall_elements} illuminated by {lighting_features} with crowds enjoying {food_elements}.\",\n",
        "                \"Rows of {vendor_stalls} line this vibrant market where {nighttime_activity} continues under {cultural_lighting}.\",\n",
        "                \"The market atmosphere is created by {asian_elements} and {night_market_sounds} amid {evening_crowd_behavior}.\"\n",
        "            ],\n",
        "            \"asian_temple_area\": [\n",
        "                \"This sacred space features {architectural_elements} displaying {cultural_symbols} with visitors engaging in {ritual_activities}.\",\n",
        "                \"The temple area contains {religious_structures} adorned with {decorative_features} where people practice {cultural_practices}.\",\n",
        "                \"Traditional {temple_architecture} creates a spiritual atmosphere enhanced by {sensory_elements} and {visitor_activities}.\"\n",
        "            ],\n",
        "            \"european_plaza\": [\n",
        "                \"This historic plaza is framed by {architectural_style} surrounding an open space where {public_activities} take place.\",\n",
        "                \"The European square features {historic_elements} and {urban_design} creating a space for {social_behaviors}.\",\n",
        "                \"Classical {european_features} define this public space where {tourist_activities} blend with {local_customs}.\"\n",
        "            ],\n",
        "            \"nighttime_street\": [\n",
        "                \"The night transforms this street with {lighting_effects} casting {shadow_patterns} across {urban_features}.\",\n",
        "                \"After dark, this urban corridor is defined by {illuminated_elements} with {evening_activities} visible in the artificial light.\",\n",
        "                \"The nocturnal street scene captures {light_sources} creating contrast between {lit_areas} and {shadowed_zones}.\"\n",
        "            ],\n",
        "            \"nighttime_commercial_district\": [\n",
        "                \"After sunset, this commercial area comes alive with {illuminated_signage} and {evening_activities} under {colorful_lighting}.\",\n",
        "                \"The district's nighttime character is defined by {neon_elements} highlighting {storefront_features} amid {night_crowd_behavior}.\",\n",
        "                \"Evening transforms this zone through {light_displays} that accentuate {building_features} and frame {nightlife_activities}.\"\n",
        "            ],\n",
        "            \"indoor_outdoor_cafe\": [\n",
        "                \"This cafe blends indoor comfort with outdoor atmosphere through {transitional_elements} connecting {indoor_features} with {outdoor_setting}.\",\n",
        "                \"Customers enjoy both {interior_amenities} and {exterior_features} in this space that bridges indoor comfort and outdoor ambiance.\",\n",
        "                \"The cafe design creates flow between {inside_elements} and {outside_spaces} allowing patrons to experience {dual_environment_benefits}.\"\n",
        "            ],\n",
        "            \"transit_station_platform\": [\n",
        "                \"This transit platform combines covered areas with open sections where {passenger_activities} occur while awaiting {transportation_types}.\",\n",
        "                \"The station design balances {sheltered_elements} with {exposed_areas} for passengers engaged in {waiting_behaviors}.\",\n",
        "                \"Commuters navigate between {indoor_facilities} and {platform_features} while {transit_routines} unfold around arriving vehicles.\"\n",
        "            ],\n",
        "            \"sports_stadium\": [\n",
        "                \"This athletic venue features {seating_arrangement} surrounding {playing_surface} where {sporting_activities} take place.\",\n",
        "                \"The stadium design incorporates {spectator_facilities} overlooking {competition_space} designed for {sports_events}.\",\n",
        "                \"Fans occupy {viewing_areas} arranged to maximize visibility of {field_elements} where athletes engage in {game_activities}.\"\n",
        "            ],\n",
        "            \"construction_site\": [\n",
        "                \"This development area shows {construction_equipment} amid {building_materials} where workers conduct {construction_activities}.\",\n",
        "                \"The construction process is visible through {work_elements} positioned around {structural_components} in various stages of completion.\",\n",
        "                \"Workers utilize {site_equipment} to transform {raw_materials} following {construction_process} stages.\"\n",
        "            ],\n",
        "            \"medical_facility\": [\n",
        "                \"This healthcare environment features {medical_elements} arranged to support {clinical_activities} in a {facility_design}.\",\n",
        "                \"The medical space incorporates {healthcare_features} where {patient_interactions} occur in a controlled environment.\",\n",
        "                \"Professional medical staff utilize {equipment_types} while conducting {care_procedures} in specialized {treatment_spaces}.\"\n",
        "            ],\n",
        "            \"educational_setting\": [\n",
        "                \"This learning environment contains {educational_furniture} arranged to facilitate {learning_activities} through {instructional_design}.\",\n",
        "                \"The educational space features {classroom_elements} organized for {teaching_methods} and {student_engagement}.\",\n",
        "                \"Students and educators interact within {learning_spaces} equipped with {educational_tools} supporting {knowledge_transfer}.\"\n",
        "            ],\n",
        "            \"beach_water_recreation\": [\n",
        "                \"A coastal recreation area with {beach_equipment} and people enjoying {water_activities}.\",\n",
        "                \"This shoreline space features {beach_equipment} where visitors engage in {water_activities}.\",\n",
        "                \"An outdoor water recreation zone with {beach_equipment} set up for {water_activities}.\"\n",
        "            ],\n",
        "            \"sports_venue\": [\n",
        "                \"A professional sports facility with {sports_equipment} arranged for {competitive_activities}.\",\n",
        "                \"This athletics venue features {sports_equipment} with spaces designated for {competitive_activities}.\",\n",
        "                \"A specialized sports arena containing {sports_equipment} designed for {competitive_activities}.\"\n",
        "            ],\n",
        "            \"professional_kitchen\": [\n",
        "                \"A commercial cooking space with {kitchen_equipment} organized for {food_preparation}.\",\n",
        "                \"This professional culinary area contains {kitchen_equipment} arranged in stations for {food_preparation}.\",\n",
        "                \"An industrial kitchen featuring {kitchen_equipment} designed for efficient {food_preparation}.\"\n",
        "            ],\n",
        "            \"tourist_landmark\": [\n",
        "                \"This notable landmark attracts visitors who come to see {landmark_features} and experience {tourist_activities}.\",\n",
        "                \"A famous landmark site where tourists can observe {landmark_features} and engage in {tourist_activities}.\",\n",
        "                \"This iconic landmark showcases {landmark_features} and is a popular destination for {tourist_activities}.\"\n",
        "            ],\n",
        "            \"natural_landmark\": [\n",
        "                \"This natural landmark features {landmark_features} and offers opportunities for {outdoor_activities}.\",\n",
        "                \"A scenic natural formation with {landmark_features} where visitors enjoy {outdoor_activities}.\",\n",
        "                \"This impressive natural landmark displays {landmark_features} and attracts nature enthusiasts for {outdoor_activities}.\"\n",
        "            ],\n",
        "            \"historical_monument\": [\n",
        "                \"This historical monument exhibits {landmark_features} and has significance related to {historical_elements}.\",\n",
        "                \"An important historical site featuring {landmark_features} and representing {historical_elements}.\",\n",
        "                \"This heritage monument showcases {landmark_features} and commemorates {historical_elements}.\"\n",
        "            ]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jraYFP_PXgVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f30589-6474-493e-d3fa-76389068ff87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing object_template_fillers.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile object_template_fillers.py\n",
        "\n",
        "OBJECT_TEMPLATE_FILLERS = {\n",
        "                \"furniture\": [\"designer chairs\", \"wooden dining table\", \"stylish seating\", \"upholstered armchairs\", \"elegant dining furniture\"],\n",
        "                \"design_elements\": [\"art pieces\", \"decorative wreaths\", \"statement lighting\", \"seasonal decorations\", \"sophisticated decor\"],\n",
        "                \"lighting\": [\"pendant lights\", \"decorative fixtures\", \"geometric lighting\", \"modern chandeliers\", \"ambient illumination\"],\n",
        "                \"table_setup\": [\"elegantly set table\", \"tabletop decorations\", \"seasonal centerpieces\", \"formal place settings\", \"floral arrangements\"],\n",
        "                \"seating\": [\"upholstered chairs\", \"accent armchairs\", \"mixed seating styles\", \"designer dining chairs\", \"comfortable dining seats\"],\n",
        "                \"table_description\": [\"solid wood table\", \"designer dining table\", \"expansive dining surface\", \"artisanal table\", \"statement dining table\"],\n",
        "\n",
        "                \"storefront_features\": [\"multi-story shops\", \"illuminated signs\", \"merchandise displays\", \"compact storefronts\", \"vertical retail spaces\"],\n",
        "                \"pedestrian_flow\": [\"people walking\", \"shoppers\", \"pedestrians\", \"locals and tourists\", \"urban foot traffic\"],\n",
        "                \"asian_elements\": [\"Asian language signage\", \"decorative lanterns\", \"local storefronts\", \"character-based text\", \"regional design elements\"],\n",
        "                \"cultural_elements\": [\"red lanterns\", \"local typography\", \"distinctive architecture\", \"cultural symbols\", \"traditional decorations\"],\n",
        "                \"signage\": [\"bright store signs\", \"multilingual text\", \"vertical signboards\", \"neon displays\", \"electronic advertisements\"],\n",
        "                \"street_activities\": [\"shopping\", \"commuting\", \"socializing\", \"vendor transactions\", \"urban navigation\"],\n",
        "\n",
        "                \"buildings\": [\"high-rise office buildings\", \"corporate towers\", \"skyscrapers\", \"financial institutions\", \"commercial headquarters\"],\n",
        "                \"traffic_elements\": [\"vehicle lights\", \"trams/street cars\", \"lane markers\", \"traffic signals\", \"urban transit\"],\n",
        "                \"skyscrapers\": [\"glass and steel buildings\", \"tall structures\", \"modern architecture\", \"office towers\", \"urban high-rises\"],\n",
        "                \"road_features\": [\"wide avenues\", \"tram tracks\", \"traffic lanes\", \"median dividers\", \"urban throughways\"],\n",
        "                \"architectural_elements\": [\"contemporary buildings\", \"urban design\", \"varied architectural styles\", \"corporate architecture\", \"city planning features\"],\n",
        "                \"city_landmarks\": [\"distant bridge\", \"skyline features\", \"iconic structures\", \"urban monuments\", \"signature buildings\"],\n",
        "\n",
        "                \"crossing_pattern\": [\"zebra crosswalks\", \"pedestrian walkways\", \"crosswalk markings\", \"intersection design\", \"safety stripes\"],\n",
        "                \"pedestrian_density\": [\"groups of people\", \"commuters\", \"diverse pedestrians\", \"urban crowds\", \"varying foot traffic\"],\n",
        "                \"pedestrian_behavior\": [\"walking in different directions\", \"crossing together\", \"waiting for signals\", \"navigating intersections\", \"following traffic rules\"],\n",
        "                \"traffic_pattern\": [\"four-way intersection\", \"crossroad\", \"junction\", \"multi-directional traffic\", \"regulated crossing\"],\n",
        "                \"pedestrian_flow\": [\"people crossing\", \"directional movement\", \"coordinated crossing\", \"timed pedestrian traffic\", \"intersection navigation\"],\n",
        "\n",
        "                \"transit_vehicles\": [\"buses\", \"trams\", \"trains\", \"taxis\", \"shuttles\"],\n",
        "                \"passenger_activity\": [\"boarding\", \"waiting\", \"exiting vehicles\", \"checking schedules\", \"navigating stations\"],\n",
        "                \"transportation_modes\": [\"public transit\", \"private vehicles\", \"ride services\", \"light rail\", \"bus systems\"],\n",
        "                \"passenger_needs\": [\"waiting areas\", \"information displays\", \"ticketing services\", \"transit connections\", \"seating\"],\n",
        "                \"transit_infrastructure\": [\"stations\", \"platforms\", \"boarding areas\", \"transit lanes\", \"signaling systems\"],\n",
        "                \"passenger_movement\": [\"transfers\", \"entrances and exits\", \"queueing\", \"platform access\", \"terminal navigation\"],\n",
        "\n",
        "                \"retail_elements\": [\"storefronts\", \"display windows\", \"shopping bags\", \"merchandise\", \"retail signage\"],\n",
        "                \"shopping_activity\": [\"browsing\", \"carrying purchases\", \"window shopping\", \"social shopping\", \"consumer activities\"],\n",
        "                \"store_types\": [\"boutiques\", \"brand stores\", \"local shops\", \"chain retailers\", \"specialty stores\"],\n",
        "                \"walkway_features\": [\"pedestrian paths\", \"shopping promenades\", \"retail corridors\", \"commercial walkways\", \"shopping streets\"],\n",
        "                \"commercial_signage\": [\"brand logos\", \"sale announcements\", \"store names\", \"advertising displays\", \"digital signage\"],\n",
        "                \"consumer_behavior\": [\"shopping in groups\", \"individual browsing\", \"carrying bags\", \"examining products\", \"moving between stores\"],\n",
        "\n",
        "                \"beach_equipment\": [\"beach umbrellas\", \"surfboards\", \"beach towels\", \"sun protection\", \"recreational equipment\"],\n",
        "                \"water_activities\": [\"water sports\", \"surfing\", \"beach recreation\", \"sun bathing\", \"coastal leisure\"],\n",
        "                \"sports_equipment\": [\"game balls\", \"professional equipment\", \"athletic gear\", \"sports apparatus\", \"competition items\"],\n",
        "                \"competitive_activities\": [\"team sports\", \"athletic contests\", \"competitive games\", \"sporting events\", \"professional matches\"],\n",
        "                \"kitchen_equipment\": [\"professional appliances\", \"cooking stations\", \"preparation surfaces\", \"culinary tools\", \"industrial equipment\"],\n",
        "                \"food_preparation\": [\"meal production\", \"culinary operations\", \"food service preparation\", \"commercial cooking\", \"kitchen workflow\"],\n",
        "\n",
        "                \"crossing_pattern\": [\"grid-like pedestrian crossings\", \"multi-directional crosswalks\", \"cross-shaped intersection design\", \"perpendicular crossing lanes\", \"zebra-striped crosswalks viewed from above\"],\n",
        "                \"pedestrian_pattern\": [\"scattered distribution of people\", \"organized flow of pedestrians\", \"clustered gatherings\", \"radial movement patterns\", \"linear procession of individuals\"],\n",
        "                \"commercial_layout\": [\"parallel shopping streets\", \"interconnected shopping blocks\", \"radial marketplace design\", \"grid-like retail arrangement\", \"meandering commercial pathways\"],\n",
        "                \"movement_pattern\": [\"circular crowd motion\", \"directional pedestrian flow\", \"scattered individual movement\", \"converging foot traffic\", \"diverging pedestrian patterns\"],\n",
        "\n",
        "                \"stall_elements\": [\"food vendors with steaming woks\", \"trinket sellers with colorful displays\", \"lantern-lit stalls\", \"bamboo-framed shops\", \"canvas-covered market stands\"],\n",
        "                \"asian_elements\": [\"hanging red lanterns\", \"character-based signage\", \"ornate temple decorations\", \"traditional paper decorations\", \"stylized gateway arches\"],\n",
        "                \"cultural_lighting\": [\"paper lantern illumination\", \"neon character signs\", \"strung festival lights\", \"hanging light chains\", \"colorful shop front lighting\"],\n",
        "                \"architectural_elements\": [\"tiered pagoda roofs\", \"ornate dragon sculptures\", \"stone guardian statues\", \"intricately carved railings\", \"traditional wooden beams\"],\n",
        "                \"cultural_symbols\": [\"dharma wheels\", \"lotus motifs\", \"yin-yang symbols\", \"zodiac animal representations\", \"traditional calligraphy\"],\n",
        "                \"architectural_style\": [\"Baroque facades\", \"Gothic spires\", \"Renaissance colonnades\", \"Neoclassical pediments\", \"Medieval archways\"],\n",
        "                \"european_features\": [\"cobblestone paving\", \"ornate fountains\", \"bronze statuary\", \"wrought iron lampposts\", \"cafe terraces\"],\n",
        "\n",
        "                \"lighting_effects\": [\"streetlamp pools of light\", \"neon sign glow\", \"illuminated window squares\", \"headlight streams\", \"traffic signal flashes\"],\n",
        "                \"illuminated_elements\": [\"lit storefront windows\", \"glowing traffic signals\", \"illuminated advertising\", \"headlight-lit streets\", \"backlit silhouettes\"],\n",
        "                \"neon_elements\": [\"colorful shop signs\", \"animated light displays\", \"illuminated brand logos\", \"glowing storefront outlines\", \"digital advertising screens\"],\n",
        "                \"illuminated_signage\": [\"bright LED displays\", \"glowing brand names\", \"projected light advertisements\", \"illuminated menu boards\", \"digital information screens\"],\n",
        "                \"colorful_lighting\": [\"multi-colored neon\", \"warm ambient illumination\", \"cool blue accent lights\", \"festive string lighting\", \"dynamic color-changing displays\"],\n",
        "\n",
        "                \"transitional_elements\": [\"retractable glass walls\", \"indoor-outdoor bar counters\", \"terraced seating areas\", \"threshold planters\", \"partial canopy coverage\"],\n",
        "                \"indoor_features\": [\"climate-controlled spaces\", \"soft seating arrangements\", \"interior decor accents\", \"mood lighting fixtures\", \"sound-dampened areas\"],\n",
        "                \"outdoor_setting\": [\"sidewalk tables\", \"patio seating\", \"garden furniture\", \"open-air counters\", \"courtyard arrangements\"],\n",
        "                \"seating_arrangement\": [\"tiered spectator stands\", \"premium viewing boxes\", \"courtside seating\", \"general admission benches\", \"stadium chair rows\"],\n",
        "                \"playing_surface\": [\"marked court boundaries\", \"manicured field turf\", \"running tracks\", \"competition equipment\", \"sports field markers\"],\n",
        "                \"construction_equipment\": [\"tower cranes\", \"excavators\", \"cement mixers\", \"scaffolding structures\", \"construction barriers\"],\n",
        "                \"medical_elements\": [\"examination furniture\", \"monitoring equipment\", \"sanitation stations\", \"privacy screens\", \"medical supply carts\"],\n",
        "                \"educational_furniture\": [\"student desks\", \"lecture podiums\", \"laboratory benches\", \"learning stations\", \"collaborative workspace tables\"],\n",
        "\n",
        "                \"landmark_features\": [\"distinctive architecture\", \"iconic structural elements\", \"famous design features\", \"recognized silhouette\", \"impressive proportions\"],\n",
        "                \"tourist_activities\": [\"sightseeing\", \"guided tours\", \"photography\",  \"cultural exploration\", \"souvenir shopping\"],\n",
        "                \"outdoor_activities\": [\"nature photography\", \"hiking\",  \"scenic viewing\", \"wildlife observation\", \"outdoor exploration\"],\n",
        "                \"historical_elements\": [\"cultural heritage\", \"historical events\", \"architectural periods\", \"traditional craftsmanship\", \"significant achievements\"]\n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY-fgRtuXgTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1292a04b-3759-4c34-a139-cff1b13535e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing safety_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile safety_templates.py\n",
        "SAFETY_TEMPLATES = {\n",
        "    \"general\": \"Pay attention to {safety_element}.\",\n",
        "    \"warning\": \"Be cautious of {hazard} in this environment.\",\n",
        "    \"notice\": \"Note the presence of {element_of_interest}.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqOJTYVxXgQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e862dd20-7488-44c8-9d73-80e9f4194034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing activity_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile activity_templates.py\n",
        "\n",
        "ACTIVITY_TEMPLATES = {\n",
        "            \"living_room\": [\n",
        "                \"Watching TV\",\n",
        "                \"Relaxing on the sofa\",\n",
        "                \"Reading\",\n",
        "                \"Socializing\"\n",
        "            ],\n",
        "            \"bedroom\": [\n",
        "                \"Sleeping\",\n",
        "                \"Resting\",\n",
        "                \"Getting dressed\",\n",
        "                \"Reading in bed\"\n",
        "            ],\n",
        "            \"dining_area\": [\n",
        "                \"Eating a meal\",\n",
        "                \"Having a conversation\",\n",
        "                \"Working at table\"\n",
        "            ],\n",
        "            \"kitchen\": [\n",
        "                \"Cooking\",\n",
        "                \"Food preparation\",\n",
        "                \"Cleaning dishes\"\n",
        "            ],\n",
        "            \"office_workspace\": [\n",
        "                \"Working on computer\",\n",
        "                \"Office work\",\n",
        "                \"Virtual meetings\",\n",
        "                \"Reading documents\"\n",
        "            ],\n",
        "            \"meeting_room\": [\n",
        "                \"Group meeting\",\n",
        "                \"Presentation\",\n",
        "                \"Team discussion\",\n",
        "                \"Collaboration\"\n",
        "            ],\n",
        "            \"city_street\": [\n",
        "                \"Walking\",\n",
        "                \"Commuting\",\n",
        "                \"Shopping\",\n",
        "                \"Waiting for transportation\"\n",
        "            ],\n",
        "            \"parking_lot\": [\n",
        "                \"Parking vehicles\",\n",
        "                \"Loading/unloading items\",\n",
        "                \"Entering/exiting vehicles\"\n",
        "            ],\n",
        "            \"park_area\": [\n",
        "                \"Walking\",\n",
        "                \"Relaxing outdoors\",\n",
        "                \"Exercising\",\n",
        "                \"Social gathering\"\n",
        "            ],\n",
        "            \"retail_store\": [\n",
        "                \"Shopping\",\n",
        "                \"Browsing products\",\n",
        "                \"Purchasing items\"\n",
        "            ],\n",
        "            \"supermarket\": [\n",
        "                \"Grocery shopping\",\n",
        "                \"Selecting products\",\n",
        "                \"Checking out\"\n",
        "            ],\n",
        "            \"upscale_dining\": [\n",
        "                \"Fine dining\",\n",
        "                \"Social gathering\",\n",
        "                \"Special occasion meal\",\n",
        "                \"Family dinner\",\n",
        "                \"Business meeting\",\n",
        "                \"Celebratory meal\"\n",
        "            ],\n",
        "            \"asian_commercial_street\": [\n",
        "                \"Shopping\",\n",
        "                \"Sightseeing\",\n",
        "                \"Walking to destinations\",\n",
        "                \"Visiting local shops\",\n",
        "                \"Cultural exploration\",\n",
        "                \"Urban commuting\",\n",
        "                \"Meeting friends\"\n",
        "            ],\n",
        "            \"financial_district\": [\n",
        "                \"Commuting\",\n",
        "                \"Business travel\",\n",
        "                \"Urban transit\",\n",
        "                \"Sightseeing\",\n",
        "                \"City navigation\",\n",
        "                \"Professional activities\",\n",
        "                \"Corporate meetings\"\n",
        "            ],\n",
        "            \"urban_intersection\": [\n",
        "                \"Street crossing\",\n",
        "                \"Waiting for signals\",\n",
        "                \"Urban navigation\",\n",
        "                \"Commuting\",\n",
        "                \"Group movement\",\n",
        "                \"Following traffic patterns\",\n",
        "                \"Pedestrian coordination\"\n",
        "            ],\n",
        "            \"transit_hub\": [\n",
        "                \"Commuting\",\n",
        "                \"Waiting for transportation\",\n",
        "                \"Transferring between vehicles\",\n",
        "                \"Starting/ending journeys\",\n",
        "                \"Meeting travelers\",\n",
        "                \"Checking transit schedules\",\n",
        "                \"Urban transportation\"\n",
        "            ],\n",
        "            \"shopping_district\": [\n",
        "                \"Retail shopping\",\n",
        "                \"Window browsing\",\n",
        "                \"Social shopping\",\n",
        "                \"Product comparison\",\n",
        "                \"Making purchases\",\n",
        "                \"Brand exploration\",\n",
        "                \"Recreational shopping\"\n",
        "            ],\n",
        "            \"bus_stop\": [\n",
        "                \"Waiting for the bus\",\n",
        "                \"Checking schedules\",\n",
        "                \"Boarding or alighting\",\n",
        "                \"Standing under shelter\"\n",
        "            ],\n",
        "            \"bus_station\": [\n",
        "                \"Navigating between platforms\",\n",
        "                \"Handling luggage\",\n",
        "                \"Boarding buses\",\n",
        "                \"Gathering at waiting areas\"\n",
        "            ],\n",
        "            \"zoo\": [\n",
        "                \"Watching animal exhibits\",\n",
        "                \"Taking photos of wildlife\",\n",
        "                \"Walking along enclosures\",\n",
        "                \"Reading informational signs\"\n",
        "            ],\n",
        "            \"harbor\": [\n",
        "                \"Observing docked boats\",\n",
        "                \"Commuting by watercraft\",\n",
        "                \"Loading or unloading cargo\",\n",
        "                \"Strolling along the pier\"\n",
        "            ],\n",
        "            \"playground\": [\n",
        "                \"Playing ball games\",\n",
        "                \"Swinging or sliding\",\n",
        "                \"Running around\",\n",
        "                \"Socializing with friends\"\n",
        "            ],\n",
        "            \"sports_field\": [\n",
        "                \"Practicing ball drills\",\n",
        "                \"Competing in matches\",\n",
        "                \"Warming up or stretching\",\n",
        "                \"Team training sessions\"\n",
        "            ],\n",
        "            \"narrow_commercial_alley\": [\n",
        "                \"Walking through alley\",\n",
        "                \"Browsing storefronts\",\n",
        "                \"Navigating light traffic\",\n",
        "                \"Carrying shopping bags\"\n",
        "            ],\n",
        "            \"daytime_shopping_street\": [\n",
        "                \"Shopping\",\n",
        "                \"Window browsing\",\n",
        "                \"Street photography\",\n",
        "                \"Commuting by vehicle\"\n",
        "            ],\n",
        "            \"urban_pedestrian_crossing\": [\n",
        "                \"Crossing the street\",\n",
        "                \"Waiting for signal\",\n",
        "                \"Following traffic rules\",\n",
        "                \"Checking for vehicles\"\n",
        "            ],\n",
        "            \"aerial_view_intersection\": [\n",
        "                \"Crossing multiple directions\",\n",
        "                \"Following traffic signals\",\n",
        "                \"Navigating pedestrian paths\",\n",
        "                \"Traffic management\",\n",
        "                \"Multi-directional movement\",\n",
        "                \"Organized crossing patterns\",\n",
        "                \"Waiting at signals\"\n",
        "            ],\n",
        "            \"aerial_view_commercial_area\": [\n",
        "                \"Shopping district navigation\",\n",
        "                \"Retail browsing\",\n",
        "                \"Store-to-store movement\",\n",
        "                \"Commercial zone foot traffic\",\n",
        "                \"Shopping center traversal\",\n",
        "                \"Retail area engagement\",\n",
        "                \"Walking between stores\"\n",
        "            ],\n",
        "            \"aerial_view_plaza\": [\n",
        "                \"Public gathering\",\n",
        "                \"Open space traversal\",\n",
        "                \"Community congregation\",\n",
        "                \"Plaza navigation\",\n",
        "                \"Public square activities\",\n",
        "                \"Urban space utilization\"\n",
        "            ],\n",
        "            \"asian_night_market\": [\n",
        "                \"Street food sampling\",\n",
        "                \"Night market browsing\",\n",
        "                \"Evening shopping\",\n",
        "                \"Cultural food exploration\",\n",
        "                \"Vendor interaction\",\n",
        "                \"Social night dining\",\n",
        "                \"Market stall hopping\"\n",
        "            ],\n",
        "            \"asian_temple_area\": [\n",
        "                \"Temple visiting\",\n",
        "                \"Cultural site exploration\",\n",
        "                \"Spiritual observance\",\n",
        "                \"Traditional rituals\",\n",
        "                \"Historical site appreciation\",\n",
        "                \"Religious tourism\",\n",
        "                \"Cultural photography\"\n",
        "            ],\n",
        "            \"european_plaza\": [\n",
        "                \"Urban sightseeing\",\n",
        "                \"Historical appreciation\",\n",
        "                \"Tourist photography\",\n",
        "                \"Public space relaxation\",\n",
        "                \"Casual strolling\"\n",
        "            ],\n",
        "            \"nighttime_street\": [\n",
        "                \"Evening commuting\",\n",
        "                \"Night walking\",\n",
        "                \"After-hours travel\",\n",
        "                \"Nighttime navigation\",\n",
        "                \"Evening errands\",\n",
        "                \"Late-night transportation\",\n",
        "                \"Nocturnal urban movement\"\n",
        "            ],\n",
        "            \"nighttime_commercial_district\": [\n",
        "                \"Evening shopping\",\n",
        "                \"Nightlife participation\",\n",
        "                \"Nighttime entertainment\",\n",
        "                \"After-dark dining\",\n",
        "                \"Evening social gathering\",\n",
        "                \"Night market browsing\",\n",
        "                \"Illumination appreciation\"\n",
        "            ],\n",
        "            \"indoor_outdoor_cafe\": [\n",
        "                \"Al fresco dining\",\n",
        "                \"Sidewalk coffee enjoyment\",\n",
        "                \"Indoor-outdoor socializing\",\n",
        "                \"Patio relaxation\",\n",
        "                \"Open-air refreshment\",\n",
        "                \"Transitional space usage\",\n",
        "                \"Weather-dependent positioning\"\n",
        "            ],\n",
        "            \"transit_station_platform\": [\n",
        "                \"Transit waiting\",\n",
        "                \"Platform navigation\",\n",
        "                \"Boarding preparation\",\n",
        "                \"Arrival monitoring\",\n",
        "                \"Schedule checking\",\n",
        "                \"Departure positioning\",\n",
        "                \"Platform traversal\"\n",
        "            ],\n",
        "            \"sports_stadium\": [\n",
        "                \"Spectator viewing\",\n",
        "                \"Sports fan cheering\",\n",
        "                \"Game attendance\",\n",
        "                \"Stadium navigation\",\n",
        "                \"Athletic event watching\",\n",
        "                \"Audience participation\",\n",
        "                \"Sports appreciation\"\n",
        "            ],\n",
        "            \"construction_site\": [\n",
        "                \"Construction work\",\n",
        "                \"Building development\",\n",
        "                \"Site management\",\n",
        "                \"Material handling\",\n",
        "                \"Construction supervision\",\n",
        "                \"Safety monitoring\",\n",
        "                \"Building process\"\n",
        "            ],\n",
        "            \"medical_facility\": [\n",
        "                \"Healthcare consultation\",\n",
        "                \"Medical treatment\",\n",
        "                \"Patient waiting\",\n",
        "                \"Healthcare delivery\",\n",
        "                \"Medical examination\",\n",
        "                \"Professional care\",\n",
        "                \"Health monitoring\"\n",
        "            ],\n",
        "            \"educational_setting\": [\n",
        "                \"Classroom learning\",\n",
        "                \"Educational instruction\",\n",
        "                \"Student participation\",\n",
        "                \"Academic engagement\",\n",
        "                \"Knowledge acquisition\",\n",
        "                \"Educational discussion\",\n",
        "                \"Scholastic activities\"\n",
        "            ],\n",
        "            \"beach_water_recreation\": [\n",
        "                \"Surfing\",\n",
        "                \"Sunbathing\",\n",
        "                \"Beach volleyball\",\n",
        "                \"Swimming\",\n",
        "                \"Relaxing by the water\",\n",
        "                \"Flying beach kites\",\n",
        "                \"Beach picnicking\",\n",
        "                \"Coastal walking\"\n",
        "            ],\n",
        "            \"sports_venue\": [\n",
        "                \"Professional game playing\",\n",
        "                \"Sports competition\",\n",
        "                \"Athletic training\",\n",
        "                \"Team practice\",\n",
        "                \"Spectator viewing\",\n",
        "                \"Sports coaching\",\n",
        "                \"Tournament participation\",\n",
        "                \"Athletic performance\"\n",
        "            ],\n",
        "            \"professional_kitchen\": [\n",
        "                \"Professional cooking\",\n",
        "                \"Food preparation\",\n",
        "                \"Meal service coordination\",\n",
        "                \"Kitchen operations\",\n",
        "                \"Culinary production\",\n",
        "                \"Chef activities\",\n",
        "                \"Commercial food handling\",\n",
        "                \"Restaurant meal preparation\"\n",
        "            ],\n",
        "            \"tourist_landmark\": [\n",
        "                \"Sightseeing\",\n",
        "                \"Photography\",\n",
        "                \"Guided tours\",\n",
        "                \"Learning about landmark history\",\n",
        "                \"Souvenir shopping\",\n",
        "                \"Cultural appreciation\",\n",
        "                \"Architectural observation\"\n",
        "            ],\n",
        "            \"natural_landmark\": [\n",
        "                \"Nature photography\",\n",
        "                \"Scenic viewing\",\n",
        "                \"Hiking\",\n",
        "                \"Nature appreciation\",\n",
        "                \"Wildlife watching\",\n",
        "                \"Outdoor recreation\",\n",
        "                \"Environmental education\"\n",
        "            ],\n",
        "            \"historical_monument\": [\n",
        "                \"Historical tours\",\n",
        "                \"Cultural heritage appreciation\",\n",
        "                \"Educational visits\",\n",
        "                \"Historical photography\",\n",
        "                \"Learning about past events\",\n",
        "                \"Architectural study\",\n",
        "                \"Heritage tourism\"\n",
        "            ],\n",
        "             \"general_indoor_space\": [\n",
        "                \"Engaging in general indoor activities\",\n",
        "                \"Resting or relaxing in an indoor setting\",\n",
        "                \"Possibly having a conversation or reading\"\n",
        "            ],\n",
        "            \"generic_street_view\": [\n",
        "                \"People walking or commuting\",\n",
        "                \"Vehicles driving on the road\",\n",
        "                \"Observing street traffic and urban activity\",\n",
        "                \"Waiting at a crosswalk or bus stop (if applicable objects present)\"\n",
        "            ],\n",
        "            \"desk_area_workspace\": [\n",
        "                \"Working on a computer or laptop\",\n",
        "                \"Studying or reading documents\",\n",
        "                \"Writing or taking notes\",\n",
        "                \"Participating in an online meeting (if computer present)\"\n",
        "            ],\n",
        "            \"outdoor_gathering_spot\": [\n",
        "                \"People socializing outdoors\",\n",
        "                \"Relaxing on a bench or in a park-like setting\",\n",
        "                \"Engaging in light recreational activities\",\n",
        "                \"Having a picnic (if food items or backpacks are present)\"\n",
        "            ],\n",
        "            \"kitchen_counter_or_utility_area\": [\n",
        "                \"Preparing food or drinks\",\n",
        "                \"Using kitchen appliances like a microwave or toaster\",\n",
        "                \"Washing dishes or cleaning\",\n",
        "                \"Storing food items\"\n",
        "            ]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDPI2oYww-eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b6f6f1-583a-4d79-e8fb-2576b1daa078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing object_categories.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile object_categories.py\n",
        "OBJECT_CATEGORIES = {\n",
        "                \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "                \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "                \"kitchen_items\": [39, 40, 41, 42, 43, 44, 45],\n",
        "                \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "                \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "                \"personal_items\": [24, 25, 26, 27, 28, 73, 78, 79]\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslRwREno-GS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13214031-21bb-4711-faae-e44b16ff489e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lighting_conditions.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile lighting_conditions.py\n",
        "\n",
        "LIGHTING_CONDITIONS = {\n",
        "    \"time_descriptions\": {\n",
        "        \"day_clear\": {\n",
        "        \"general\": \"The scene is captured during clear daylight hours with bright natural lighting.\",\n",
        "        \"bright\": \"The scene is brightly lit with strong, clear daylight.\",\n",
        "        \"medium\": \"The scene is illuminated with moderate daylight under clear conditions.\",\n",
        "        \"dim\": \"The scene is captured in soft daylight on a clear day.\"\n",
        "        },\n",
        "        \"day_cloudy\": {\n",
        "        \"general\": \"The scene is captured during daytime under overcast conditions.\",\n",
        "        \"bright\": \"The scene has the diffused bright lighting of an overcast day.\",\n",
        "        \"medium\": \"The scene has even, soft lighting typical of a cloudy day.\",\n",
        "        \"dim\": \"The scene has the muted lighting of a heavily overcast day.\"\n",
        "        },\n",
        "         \"day_cloudy_gray\": {\n",
        "        \"general\": \"The scene is captured during an overcast day with muted gray lighting.\",\n",
        "        \"bright\": \"The scene has bright but diffused gray daylight from heavy cloud cover.\",\n",
        "        \"medium\": \"The scene has even, muted lighting typical of a gray, overcast day.\",\n",
        "        \"dim\": \"The scene has subdued lighting under thick gray clouds.\"\n",
        "        },\n",
        "        \"indoor_residential_natural\": {\n",
        "            \"general\": \"The scene is captured in a residential setting with natural window lighting.\",\n",
        "            \"bright\": \"The residential space is brightly lit with abundant natural light from windows.\",\n",
        "            \"medium\": \"The home interior has comfortable natural lighting complemented by artificial sources.\",\n",
        "            \"dim\": \"The residential space has soft natural lighting creating a cozy atmosphere.\"\n",
        "        },\n",
        "        \"indoor_designer_residential\": {\n",
        "            \"general\": \"The scene is captured in a well-designed residential space with curated lighting.\",\n",
        "            \"bright\": \"The residential interior features bright, designer lighting creating an elegant atmosphere.\",\n",
        "            \"medium\": \"The home space has thoughtfully planned lighting balancing aesthetics and functionality.\",\n",
        "            \"dim\": \"The residential area has sophisticated mood lighting enhancing the design elements.\"\n",
        "        },\n",
        "        \"indoor_bright_natural_mix\": {\n",
        "            \"general\": \"The scene is captured indoors with a blend of natural and artificial lighting.\",\n",
        "            \"bright\": \"The indoor space combines bright natural window light with artificial illumination.\",\n",
        "            \"medium\": \"The interior has balanced mixed lighting from windows and electric sources.\",\n",
        "            \"dim\": \"The indoor area has gentle mixed lighting creating comfortable illumination.\"\n",
        "        },\n",
        "        \"indoor_restaurant_bar\": {\n",
        "            \"general\": \"The scene is captured inside a restaurant or bar with characteristic warm lighting.\",\n",
        "            \"bright\": \"The dining establishment is well-lit with warm illumination emphasizing ambiance.\",\n",
        "            \"medium\": \"The restaurant/bar has moderate warm lighting creating a comfortable social atmosphere.\",\n",
        "            \"dim\": \"The establishment features soft, warm lighting creating an intimate dining or social atmosphere.\"\n",
        "        },\n",
        "        \"sunset/sunrise\": {\n",
        "        \"general\": \"The scene is captured during golden hour with warm lighting.\",\n",
        "        \"bright\": \"The scene is illuminated with bright golden hour light with long shadows.\",\n",
        "        \"medium\": \"The scene has the warm orange-yellow glow typical of sunset or sunrise.\",\n",
        "        \"dim\": \"The scene has soft, warm lighting characteristic of early sunrise or late sunset.\"\n",
        "        },\n",
        "        \"night\": {\n",
        "        \"general\": \"The scene is captured at night with limited natural lighting.\",\n",
        "        \"bright\": \"The scene is captured at night but well-lit with artificial lighting.\",\n",
        "        \"medium\": \"The scene is captured at night with moderate artificial lighting.\",\n",
        "        \"dim\": \"The scene is captured in low-light night conditions with minimal illumination.\"\n",
        "        },\n",
        "        \"indoor_bright\": {\n",
        "        \"general\": \"The scene is captured indoors with ample lighting.\",\n",
        "        \"bright\": \"The indoor space is brightly lit, possibly with natural light from windows.\",\n",
        "        \"medium\": \"The indoor space has good lighting conditions.\",\n",
        "        \"dim\": \"The indoor space has adequate lighting.\"\n",
        "        },\n",
        "        \"indoor_moderate\": {\n",
        "        \"general\": \"The scene is captured indoors with moderate lighting.\",\n",
        "        \"bright\": \"The indoor space has comfortable, moderate lighting.\",\n",
        "        \"medium\": \"The indoor space has standard interior lighting.\",\n",
        "        \"dim\": \"The indoor space has somewhat subdued lighting.\"\n",
        "        },\n",
        "        \"indoor_dim\": {\n",
        "        \"general\": \"The scene is captured indoors with dim or mood lighting.\",\n",
        "        \"bright\": \"The indoor space has dim but sufficient lighting.\",\n",
        "        \"medium\": \"The indoor space has low, atmospheric lighting.\",\n",
        "        \"dim\": \"The indoor space has very dim, possibly mood-oriented lighting.\"\n",
        "        },\n",
        "        \"beach_daylight\": {\n",
        "            \"general\": \"The scene is captured during daytime at a beach with bright natural sunlight.\",\n",
        "            \"bright\": \"The beach scene is intensely illuminated by direct sunlight.\",\n",
        "            \"medium\": \"The coastal area has even natural daylight.\",\n",
        "            \"dim\": \"The beach has softer lighting, possibly from a partially cloudy sky.\"\n",
        "        },\n",
        "        \"sports_arena\": {\n",
        "            \"general\": \"The scene is captured in a sports venue with specialized arena lighting.\",\n",
        "            \"bright\": \"The sports facility is brightly illuminated with powerful overhead lights.\",\n",
        "            \"medium\": \"The venue has standard sports event lighting providing clear visibility.\",\n",
        "            \"dim\": \"The sports area has reduced illumination, possibly before or after an event.\"\n",
        "        },\n",
        "        \"kitchen_working\": {\n",
        "            \"general\": \"The scene is captured in a professional kitchen with task-oriented lighting.\",\n",
        "            \"bright\": \"The kitchen is intensely illuminated with clear, functional lighting.\",\n",
        "            \"medium\": \"The culinary space has standard working lights focused on preparation areas.\",\n",
        "            \"dim\": \"The kitchen has reduced lighting, possibly during off-peak hours.\"\n",
        "        },\n",
        "        \"unknown\": {\n",
        "        \"general\": \"The lighting conditions in this scene are not easily determined.\"\n",
        "        }\n",
        "    },\n",
        "    \"template_modifiers\": {\n",
        "        \"day_clear\": \"brightly-lit\",\n",
        "        \"day_cloudy\": \"softly-lit\",\n",
        "        \"sunset/sunrise\": \"warmly-lit\",\n",
        "        \"night\": \"night-time\",\n",
        "        \"indoor_bright\": \"well-lit indoor\",\n",
        "        \"indoor_moderate\": \"indoor\",\n",
        "        \"indoor_dim\": \"dimly-lit indoor\",\n",
        "        \"indoor_commercial\": \"retail-lit\",\n",
        "        \"indoor_restaurant\": \"atmospherically-lit\",\n",
        "        \"neon_night\": \"neon-illuminated\",\n",
        "        \"stadium_lighting\": \"flood-lit\",\n",
        "        \"mixed_lighting\": \"transitionally-lit\",\n",
        "        \"beach_lighting\": \"sun-drenched\",\n",
        "        \"sports_venue_lighting\": \"arena-lit\",\n",
        "        \"professional_kitchen_lighting\": \"kitchen-task lit\",\n",
        "        \"day_cloudy_gray\": \"gray-lit\",\n",
        "        \"indoor_residential_natural\": \"naturally-lit residential\",\n",
        "        \"indoor_designer_residential\": \"designer-lit residential\",\n",
        "        \"indoor_bright_natural_mix\": \"mixed-lit indoor\",\n",
        "        \"unknown\": \"\"\n",
        "    },\n",
        "    \"activity_modifiers\": {\n",
        "        \"day_clear\": [\"active\", \"lively\", \"busy\"],\n",
        "        \"day_cloudy\": [\"calm\", \"relaxed\", \"casual\"],\n",
        "        \"sunset/sunrise\": [\"peaceful\", \"transitional\", \"atmospheric\"],\n",
        "        \"night\": [\"quiet\", \"subdued\", \"nocturnal\"],\n",
        "        \"indoor_bright\": [\"focused\", \"productive\", \"engaged\"],\n",
        "        \"indoor_moderate\": [\"comfortable\", \"social\", \"casual\"],\n",
        "        \"indoor_dim\": [\"intimate\", \"relaxed\", \"private\"],\n",
        "        \"indoor_commercial\": [\"shopping\", \"browsing\", \"consumer-oriented\"],\n",
        "        \"indoor_restaurant\": [\"dining\", \"social\", \"culinary\"],\n",
        "        \"neon_night\": [\"vibrant\", \"energetic\", \"night-life\"],\n",
        "        \"stadium_lighting\": [\"event-focused\", \"spectator-oriented\", \"performance-based\"],\n",
        "        \"mixed_lighting\": [\"transitional\", \"adaptable\", \"variable\"],\n",
        "        \"unknown\": []\n",
        "    },\n",
        "    \"indoor_commercial\": {\n",
        "    \"general\": \"The scene is captured inside a commercial setting with retail-optimized lighting.\",\n",
        "    \"bright\": \"The space is brightly illuminated with commercial display lighting to highlight merchandise.\",\n",
        "    \"medium\": \"The commercial interior has standard retail lighting that balances visibility and ambiance.\",\n",
        "    \"dim\": \"The commercial space has subdued lighting creating an upscale or intimate shopping atmosphere.\"\n",
        "    },\n",
        "    \"indoor_restaurant\": {\n",
        "        \"general\": \"The scene is captured inside a restaurant with characteristic dining lighting.\",\n",
        "        \"bright\": \"The restaurant is well-lit with clear illumination emphasizing food presentation.\",\n",
        "        \"medium\": \"The dining space has moderate lighting striking a balance between functionality and ambiance.\",\n",
        "        \"dim\": \"The restaurant features soft, low lighting creating an intimate dining atmosphere.\"\n",
        "    },\n",
        "    \"neon_night\": {\n",
        "        \"general\": \"The scene is captured at night with colorful neon lighting typical of entertainment districts.\",\n",
        "        \"bright\": \"The night scene is illuminated by vibrant neon signs creating a lively, colorful atmosphere.\",\n",
        "        \"medium\": \"The evening setting features moderate neon lighting creating a characteristic urban nightlife scene.\",\n",
        "        \"dim\": \"The night area has subtle neon accents against the darkness, creating a moody urban atmosphere.\"\n",
        "    },\n",
        "    \"stadium_lighting\": {\n",
        "        \"general\": \"The scene is captured under powerful stadium lights designed for spectator events.\",\n",
        "        \"bright\": \"The venue is intensely illuminated by stadium floodlights creating daylight-like conditions.\",\n",
        "        \"medium\": \"The sports facility has standard event lighting providing clear visibility across the venue.\",\n",
        "        \"dim\": \"The stadium has reduced illumination typical of pre-event or post-event conditions.\"\n",
        "    },\n",
        "    \"mixed_lighting\": {\n",
        "        \"general\": \"The scene features a mix of indoor and outdoor lighting creating transitional illumination.\",\n",
        "        \"bright\": \"The space blends bright natural and artificial light sources across indoor-outdoor boundaries.\",\n",
        "        \"medium\": \"The area combines moderate indoor lighting with outdoor illumination in a balanced way.\",\n",
        "        \"dim\": \"The transition space features subtle lighting gradients between indoor and outdoor zones.\"\n",
        "    },\n",
        "    \"stadium_or_floodlit_area\": {\n",
        "    \"general\": \"The scene is captured under powerful floodlights creating uniform bright illumination.\",\n",
        "    \"bright\": \"The area is intensely illuminated by floodlights, similar to stadium conditions.\",\n",
        "    \"medium\": \"The space has even, powerful lighting typical of sports facilities or outdoor events.\",\n",
        "    \"dim\": \"The area has moderate floodlight illumination providing consistent lighting across the space.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noAkFOxfchU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76466323-1d34-4fc3-d055-0ec3cac3dff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing viewpoint_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile viewpoint_templates.py\n",
        "\n",
        "VIEWPOINT_TEMPLATES = {\n",
        "    \"eye_level\": {\n",
        "        \"prefix\": \"From a standard eye-level perspective, \",\n",
        "        \"observation\": \"the scene shows {scene_elements} arranged in a typical front-facing view.\"\n",
        "    },\n",
        "    \"aerial\": {\n",
        "        \"prefix\": \"From an aerial perspective, \",\n",
        "        \"observation\": \"the scene shows {scene_elements} as viewed from above, revealing the spatial layout.\"\n",
        "    },\n",
        "    \"elevated\": {\n",
        "        \"prefix\": \"From an elevated viewpoint, \",\n",
        "        \"observation\": \"the scene presents {scene_elements} with a slight downward angle.\"\n",
        "    },\n",
        "    \"low_angle\": {\n",
        "        \"prefix\": \"From a low angle, \",\n",
        "        \"observation\": \"the scene depicts {scene_elements} from below, emphasizing vertical elements.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay8jbYNpchSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7ebefa-dd2c-4641-8366-38eff95ccf86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cultural_templates.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile cultural_templates.py\n",
        "\n",
        "CULTURAL_TEMPLATES = {\n",
        "    \"asian\": {\n",
        "        \"elements\": [\"character signage\", \"lanterns\", \"dense urban layout\"],\n",
        "        \"description\": \"The scene shows distinctive Asian cultural elements such as {elements}.\"\n",
        "    },\n",
        "    \"european\": {\n",
        "        \"elements\": [\"classical architecture\", \"cobblestone streets\", \"café terraces\"],\n",
        "        \"description\": \"The environment has European characteristics including {elements}.\"\n",
        "    },\n",
        "    \"middle_eastern\": {\n",
        "        \"elements\": [\"ornate archways\", \"geometric patterns\", \"domed structures\"],\n",
        "        \"description\": \"The scene contains Middle Eastern architectural features such as {elements}.\"\n",
        "    },\n",
        "    \"north_american\": {\n",
        "        \"elements\": [\"grid street pattern\", \"modern skyscrapers\", \"wide boulevards\"],\n",
        "        \"description\": \"The layout shows typical North American urban design with {elements}.\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile region_analyzer.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class RegionAnalyzer:\n",
        "    \"\"\"\n",
        "    負責處理圖像區域劃分和基礎空間分析功能\n",
        "    專注於3x3網格的區域劃分、物件分布分析和空間多樣性計算\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化區域分析器，定義3x3網格區域\"\"\"\n",
        "        try:\n",
        "            # 定義圖像的3x3網格區域\n",
        "            self.regions = {\n",
        "                \"top_left\": (0, 0, 1/3, 1/3),\n",
        "                \"top_center\": (1/3, 0, 2/3, 1/3),\n",
        "                \"top_right\": (2/3, 0, 1, 1/3),\n",
        "                \"middle_left\": (0, 1/3, 1/3, 2/3),\n",
        "                \"middle_center\": (1/3, 1/3, 2/3, 2/3),\n",
        "                \"middle_right\": (2/3, 1/3, 1, 2/3),\n",
        "                \"bottom_left\": (0, 2/3, 1/3, 1),\n",
        "                \"bottom_center\": (1/3, 2/3, 2/3, 1),\n",
        "                \"bottom_right\": (2/3, 2/3, 1, 1)\n",
        "            }\n",
        "            logger.info(\"RegionAnalyzer initialized successfully with 3x3 grid regions\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize RegionAnalyzer: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def determine_region(self, x: float, y: float) -> str:\n",
        "        \"\"\"\n",
        "        判斷點位於哪個區域\n",
        "\n",
        "        Args:\n",
        "            x: 標準化x座標 (0-1)\n",
        "            y: 標準化y座標 (0-1)\n",
        "\n",
        "        Returns:\n",
        "            區域名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for region_name, (x1, y1, x2, y2) in self.regions.items():\n",
        "                if x1 <= x < x2 and y1 <= y < y2:\n",
        "                    return region_name\n",
        "\n",
        "            logger.warning(f\"Point ({x}, {y}) does not fall into any defined region\")\n",
        "            return \"unknown\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error determining region for point ({x}, {y}): {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"unknown\"\n",
        "\n",
        "    def get_spatial_description_phrase(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        將region ID轉換為完整的空間描述短語，包含適當的介詞結構\n",
        "\n",
        "        Args:\n",
        "            region: 區域標識符（如 \"middle_center\", \"top_left\"）\n",
        "\n",
        "        Returns:\n",
        "            str: 完整的空間描述短語，空值時返回空字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 處理空值或無效輸入\n",
        "            if not region or region.strip() == \"\" or region == \"unknown\":\n",
        "                return \"within the visible area\"\n",
        "\n",
        "            # 清理region格式，移除底線\n",
        "            clean_region = region.replace('_', ' ').strip().lower()\n",
        "\n",
        "            # 根據區域位置生成自然語言描述\n",
        "            region_mappings = {\n",
        "                \"top left\": \"in the upper left area\",\n",
        "                \"top center\": \"in the upper area\",\n",
        "                \"top right\": \"in the upper right area\",\n",
        "                \"middle left\": \"on the left side\",\n",
        "                \"middle center\": \"in the center\",\n",
        "                \"center\": \"in the center\",\n",
        "                \"middle right\": \"on the right side\",\n",
        "                \"bottom left\": \"in the lower left area\",\n",
        "                \"bottom center\": \"in the lower area\",\n",
        "                \"bottom right\": \"in the lower right area\"\n",
        "            }\n",
        "\n",
        "            # 直接映射匹配\n",
        "            if clean_region in region_mappings:\n",
        "                return region_mappings[clean_region]\n",
        "\n",
        "            # 模糊匹配方位的處理\n",
        "            if \"top\" in clean_region and \"left\" in clean_region:\n",
        "                return \"in the upper left area\"\n",
        "            elif \"top\" in clean_region and \"right\" in clean_region:\n",
        "                return \"in the upper right area\"\n",
        "            elif \"bottom\" in clean_region and \"left\" in clean_region:\n",
        "                return \"in the lower left area\"\n",
        "            elif \"bottom\" in clean_region and \"right\" in clean_region:\n",
        "                return \"in the lower right area\"\n",
        "            elif \"top\" in clean_region:\n",
        "                return \"in the upper area\"\n",
        "            elif \"bottom\" in clean_region:\n",
        "                return \"in the lower area\"\n",
        "            elif \"left\" in clean_region:\n",
        "                return \"on the left side\"\n",
        "            elif \"right\" in clean_region:\n",
        "                return \"on the right side\"\n",
        "            elif \"center\" in clean_region or \"middle\" in clean_region:\n",
        "                return \"in the center\"\n",
        "            else:\n",
        "                # 對於無法辨識的區域，返回通用描述\n",
        "                return f\"in the {clean_region} area\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating spatial description for region '{region}': {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def get_contextual_spatial_description(self, region: str, object_type: str = \"\") -> str:\n",
        "        \"\"\"\n",
        "        根據物件類型提供更具情境的空間描述\n",
        "\n",
        "        Args:\n",
        "            region: 區域標識符\n",
        "            object_type: 物件類型，用於優化描述語境\n",
        "\n",
        "        Returns:\n",
        "            str: 情境化的空間描述短語\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 獲取基礎空間描述\n",
        "            base_description = self.get_spatial_description_phrase(region)\n",
        "\n",
        "            if not base_description:\n",
        "                return \"\"\n",
        "\n",
        "            # 根據物件類型調整描述語境\n",
        "            if object_type:\n",
        "                object_type_lower = object_type.lower()\n",
        "\n",
        "                # 對於辨識到人相關，用更自然的位置描述\n",
        "                if \"person\" in object_type_lower or \"people\" in object_type_lower:\n",
        "                    if \"center\" in base_description:\n",
        "                        return \"in the central area\"\n",
        "                    elif \"upper\" in base_description:\n",
        "                        return \"in the background\"\n",
        "                    elif \"lower\" in base_description:\n",
        "                        return \"in the foreground\"\n",
        "\n",
        "                # 對於車輛，強調道路位置\n",
        "                elif any(vehicle in object_type_lower for vehicle in [\"car\", \"vehicle\", \"truck\", \"bus\"]):\n",
        "                    if \"left\" in base_description:\n",
        "                        return \"on the left side of the scene\"\n",
        "                    elif \"right\" in base_description:\n",
        "                        return \"on the right side of the scene\"\n",
        "                    elif \"center\" in base_description:\n",
        "                        return \"in the central area\"\n",
        "\n",
        "                # 對於交通設施，使用更具體的位置描述\n",
        "                elif \"traffic\" in object_type_lower:\n",
        "                    if \"upper\" in base_description:\n",
        "                        return \"positioned in the upper portion\"\n",
        "                    elif \"center\" in base_description:\n",
        "                        return \"centrally positioned\"\n",
        "                    else:\n",
        "                        return base_description.replace(\"in the\", \"positioned in the\")\n",
        "\n",
        "            return base_description\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating contextual spatial description: {str(e)}\")\n",
        "            return self.get_spatial_description_phrase(region)\n",
        "\n",
        "\n",
        "    def validate_region_input(self, region: str) -> bool:\n",
        "        \"\"\"\n",
        "        驗證region輸入是否有效\n",
        "\n",
        "        Args:\n",
        "            region: 待驗證的區域標識符\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否為有效的region\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not region or region.strip() == \"\":\n",
        "                return False\n",
        "\n",
        "            # 清理並檢查是否為已知區域\n",
        "            clean_region = region.replace('_', ' ').strip().lower()\n",
        "\n",
        "            known_regions = [\n",
        "                \"top left\", \"top center\", \"top right\",\n",
        "                \"middle left\", \"middle center\", \"middle right\",\n",
        "                \"bottom left\", \"bottom center\", \"bottom right\",\n",
        "                \"center\", \"unknown\"\n",
        "            ]\n",
        "\n",
        "            # 直接匹配或包含關鍵詞匹配\n",
        "            if clean_region in known_regions:\n",
        "                return True\n",
        "\n",
        "            # 檢查是否包含有效的位置關鍵詞組合\n",
        "            position_keywords = [\"top\", \"bottom\", \"left\", \"right\", \"center\", \"middle\"]\n",
        "            has_valid_keyword = any(keyword in clean_region for keyword in position_keywords)\n",
        "\n",
        "            return has_valid_keyword\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error validating region input '{region}': {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_enhanced_directional_description(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        增強版的方位描述生成，提供更豐富的方位資訊\n",
        "        擴展原有的get_directional_description方法功能\n",
        "\n",
        "        Args:\n",
        "            region: 區域名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 增強的方位描述字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.validate_region_input(region):\n",
        "                return \"central\"\n",
        "\n",
        "            region_lower = region.replace('_', ' ').strip().lower()\n",
        "\n",
        "            # 用比較準確的方位映射\n",
        "            direction_mappings = {\n",
        "                \"top left\": \"northwest\",\n",
        "                \"top center\": \"north\",\n",
        "                \"top right\": \"northeast\",\n",
        "                \"middle left\": \"west\",\n",
        "                \"middle center\": \"central\",\n",
        "                \"center\": \"central\",\n",
        "                \"middle right\": \"east\",\n",
        "                \"bottom left\": \"southwest\",\n",
        "                \"bottom center\": \"south\",\n",
        "                \"bottom right\": \"southeast\"\n",
        "            }\n",
        "\n",
        "            if region_lower in direction_mappings:\n",
        "                return direction_mappings[region_lower]\n",
        "\n",
        "            # 模糊匹配邏輯保持與原方法相同\n",
        "            if \"top\" in region_lower and \"left\" in region_lower:\n",
        "                return \"northwest\"\n",
        "            elif \"top\" in region_lower and \"right\" in region_lower:\n",
        "                return \"northeast\"\n",
        "            elif \"bottom\" in region_lower and \"left\" in region_lower:\n",
        "                return \"southwest\"\n",
        "            elif \"bottom\" in region_lower and \"right\" in region_lower:\n",
        "                return \"southeast\"\n",
        "            elif \"top\" in region_lower:\n",
        "                return \"north\"\n",
        "            elif \"bottom\" in region_lower:\n",
        "                return \"south\"\n",
        "            elif \"left\" in region_lower:\n",
        "                return \"west\"\n",
        "            elif \"right\" in region_lower:\n",
        "                return \"east\"\n",
        "            else:\n",
        "                return \"central\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting enhanced directional description for region '{region}': {str(e)}\")\n",
        "            return \"central\"\n",
        "\n",
        "    def analyze_regions(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析物件在各區域的分布情況\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 包含位置資訊的檢測物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含區域分析結果的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                logger.warning(\"No detected objects provided for region analysis\")\n",
        "                return {\n",
        "                    \"counts\": {region: 0 for region in self.regions.keys()},\n",
        "                    \"main_focus\": [],\n",
        "                    \"objects_by_region\": {region: [] for region in self.regions.keys()}\n",
        "                }\n",
        "\n",
        "            # 計算每個區域的物件數量\n",
        "            region_counts = {region: 0 for region in self.regions.keys()}\n",
        "            region_objects = {region: [] for region in self.regions.keys()}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                try:\n",
        "                    region = obj.get(\"region\", \"unknown\")\n",
        "                    if region in region_counts:\n",
        "                        region_counts[region] += 1\n",
        "                        region_objects[region].append({\n",
        "                            \"class_id\": obj.get(\"class_id\"),\n",
        "                            \"class_name\": obj.get(\"class_name\")\n",
        "                        })\n",
        "                    else:\n",
        "                        logger.warning(f\"Unknown region '{region}' found in object\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error processing object in region analysis: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # 確定主要焦點區域（按物件數量排序的前1-2個區域）\n",
        "            sorted_regions = sorted(region_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "            main_regions = [region for region, count in sorted_regions if count > 0][:2]\n",
        "\n",
        "            result = {\n",
        "                \"counts\": region_counts,\n",
        "                \"main_focus\": main_regions,\n",
        "                \"objects_by_region\": region_objects\n",
        "            }\n",
        "\n",
        "            logger.info(f\"Region analysis completed. Main focus areas: {main_regions}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in region analysis: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            # 返回空的結果結構而不是拋出異常\n",
        "            return {\n",
        "                \"counts\": {region: 0 for region in self.regions.keys()},\n",
        "                \"main_focus\": [],\n",
        "                \"objects_by_region\": {region: [] for region in self.regions.keys()}\n",
        "            }\n",
        "\n",
        "    def create_distribution_map(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        創建物件在各區域分布的詳細地圖，用於空間分析\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含各區域分布詳情的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                logger.warning(\"No detected objects provided for distribution map creation\")\n",
        "                return self._get_empty_distribution_map()\n",
        "\n",
        "            distribution = {}\n",
        "\n",
        "            # 初始化所有區域\n",
        "            for region in self.regions.keys():\n",
        "                distribution[region] = {\n",
        "                    \"total\": 0,\n",
        "                    \"objects\": {},\n",
        "                    \"density\": 0\n",
        "                }\n",
        "\n",
        "            # 填充分布資料\n",
        "            for obj in detected_objects:\n",
        "                try:\n",
        "                    region = obj.get(\"region\", \"unknown\")\n",
        "                    class_id = obj.get(\"class_id\")\n",
        "                    class_name = obj.get(\"class_name\", \"unknown\")\n",
        "\n",
        "                    if region not in distribution:\n",
        "                        logger.warning(f\"Unknown region '{region}' found, skipping object\")\n",
        "                        continue\n",
        "\n",
        "                    distribution[region][\"total\"] += 1\n",
        "\n",
        "                    if class_id not in distribution[region][\"objects\"]:\n",
        "                        distribution[region][\"objects\"][class_id] = {\n",
        "                            \"name\": class_name,\n",
        "                            \"count\": 0,\n",
        "                            \"positions\": []\n",
        "                        }\n",
        "\n",
        "                    distribution[region][\"objects\"][class_id][\"count\"] += 1\n",
        "\n",
        "                    # 儲存位置資訊用於空間關係分析\n",
        "                    normalized_center = obj.get(\"normalized_center\")\n",
        "                    if normalized_center:\n",
        "                        distribution[region][\"objects\"][class_id][\"positions\"].append(normalized_center)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error processing object in distribution map: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # 計算每個區域的物件密度\n",
        "            for region, data in distribution.items():\n",
        "                # 假設所有區域在網格中大小相等\n",
        "                data[\"density\"] = data[\"total\"] / 1\n",
        "\n",
        "            logger.info(\"Distribution map created successfully\")\n",
        "            return distribution\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating distribution map: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return self._get_empty_distribution_map()\n",
        "\n",
        "    def calculate_spatial_diversity(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件空間分布的多樣性\n",
        "        評估物件是否分散在不同區域，避免所有物件集中在單一區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            空間多樣性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                logger.warning(\"No detected objects provided for spatial diversity calculation\")\n",
        "                return 0.0\n",
        "\n",
        "            regions = set()\n",
        "            for obj in detected_objects:\n",
        "                region = obj.get(\"region\", \"center\")\n",
        "                regions.add(region)\n",
        "\n",
        "            unique_regions = len(regions)\n",
        "            diversity_score = min(unique_regions / 2.0, 1.0)\n",
        "\n",
        "            logger.info(f\"Spatial diversity calculated: {diversity_score:.3f} (regions: {unique_regions})\")\n",
        "            return diversity_score\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating spatial diversity: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0.0\n",
        "\n",
        "    def get_directional_description(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        將區域名稱轉換為方位描述（東西南北）\n",
        "\n",
        "        Args:\n",
        "            region: 區域名稱\n",
        "\n",
        "        Returns:\n",
        "            方位描述字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            region_lower = region.lower()\n",
        "\n",
        "            if \"top\" in region_lower and \"left\" in region_lower:\n",
        "                return \"northwest\"\n",
        "            elif \"top\" in region_lower and \"right\" in region_lower:\n",
        "                return \"northeast\"\n",
        "            elif \"bottom\" in region_lower and \"left\" in region_lower:\n",
        "                return \"southwest\"\n",
        "            elif \"bottom\" in region_lower and \"right\" in region_lower:\n",
        "                return \"southeast\"\n",
        "            elif \"top\" in region_lower:\n",
        "                return \"north\"\n",
        "            elif \"bottom\" in region_lower:\n",
        "                return \"south\"\n",
        "            elif \"left\" in region_lower:\n",
        "                return \"west\"\n",
        "            elif \"right\" in region_lower:\n",
        "                return \"east\"\n",
        "            else:\n",
        "                return \"central\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting directional description for region '{region}': {str(e)}\")\n",
        "            return \"central\"\n",
        "\n",
        "    def _get_empty_distribution_map(self) -> Dict:\n",
        "        \"\"\"\n",
        "        返回空的分布地圖結構\n",
        "\n",
        "        Returns:\n",
        "            空的分布地圖字典\n",
        "        \"\"\"\n",
        "        distribution = {}\n",
        "        for region in self.regions.keys():\n",
        "            distribution[region] = {\n",
        "                \"total\": 0,\n",
        "                \"objects\": {},\n",
        "                \"density\": 0\n",
        "            }\n",
        "        return distribution"
      ],
      "metadata": {
        "id": "fJQeQ_MrrRLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b186d949-9449-445b-c345-ea022b5a507a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing region_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile object_extractor.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ObjectExtractor:\n",
        "    \"\"\"\n",
        "    專門處理物件檢測結果的提取和預處理\n",
        "    負責從YOLO檢測結果提取物件資訊、物件分類和核心物件的辨識\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, object_categories: Dict[str, List[int]] = None):\n",
        "        \"\"\"\n",
        "        初始化物件提取器\n",
        "\n",
        "        Args:\n",
        "            class_names: 類別ID到類別名稱的映射字典\n",
        "            object_categories: 物件類別分組字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.class_names = class_names or {}\n",
        "            self.object_categories = object_categories or {}\n",
        "\n",
        "            # 1. 讀取並設定基本信心度門檻（如果外部沒傳，就預設 0.25）\n",
        "            self.base_conf_threshold = 0.25\n",
        "\n",
        "            # 2. 動態信心度調整映射表 (key: 小寫 class_name, value: 調整係數)\n",
        "            #    最終的門檻 = base_conf_threshold * factor\n",
        "            #    如果某個 class_name 沒在這裡，就直接用 base_conf_threshold（相當於 factor=1.0）\n",
        "            self.dynamic_conf_map = {\n",
        "                \"traffic light\": 0.6,  # 0.25 * 0.6 = 0.15\n",
        "                \"car\": 0.8,            # 0.25 * 0.8 = 0.20\n",
        "                \"person\": 0.7,         # 0.25 * 0.7 = 0.175\n",
        "\n",
        "            }\n",
        "\n",
        "            logger.info(f\"ObjectExtractor initialized with {len(self.class_names)} class names and {len(self.object_categories)} object categories\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize ObjectExtractor: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def _get_dynamic_threshold(self, class_name: str) -> float:\n",
        "        \"\"\"\n",
        "        根據 class_name 從 dynamic_conf_map 拿到 factor，計算最終的信心度門檻：\n",
        "            threshold = base_conf_threshold * factor\n",
        "\n",
        "        如果 class_name 不在映射表裡，就回傳 base_conf_threshold。\n",
        "        \"\"\"\n",
        "        # 使用小寫做匹配，確保在 dynamic_conf_map 裡的 key 也都用小寫\n",
        "        key = class_name.lower()\n",
        "        factor = self.dynamic_conf_map.get(key, 1.0)\n",
        "        return self.base_conf_threshold * factor\n",
        "\n",
        "    def extract_detected_objects(\n",
        "            self,\n",
        "            detection_result: Any,\n",
        "            confidence_threshold: float = 0.25,\n",
        "            region_analyzer=None\n",
        "        ) -> List[Dict]:\n",
        "            \"\"\"\n",
        "            從檢測結果中提取物件資訊，包含位置資訊\n",
        "\n",
        "            Args:\n",
        "                detection_result: YOLO檢測結果\n",
        "                confidence_threshold: 改由動態門檻決定\n",
        "                region_analyzer: 區域分析器實例，用於判斷物件所屬區域\n",
        "\n",
        "            Returns:\n",
        "                包含檢測物件資訊的字典列表\n",
        "            \"\"\"\n",
        "            try:\n",
        "                # 調試信息：記錄當前類別映射狀態\n",
        "                logger.info(f\"ObjectExtractor.extract_detected_objects called\")\n",
        "                logger.info(f\"Current class_names keys: {list(self.class_names.keys()) if self.class_names else 'None'}\")\n",
        "\n",
        "                if detection_result is None:\n",
        "                    logger.warning(\"Detection result is None\")\n",
        "                    return []\n",
        "\n",
        "                if not hasattr(detection_result, 'boxes'):\n",
        "                    logger.error(\"Detection result does not have boxes attribute\")\n",
        "                    return []\n",
        "\n",
        "                boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
        "                classes = detection_result.boxes.cls.cpu().numpy().astype(int)\n",
        "                confidences = detection_result.boxes.conf.cpu().numpy()\n",
        "\n",
        "                # 獲取圖像尺寸\n",
        "                img_height, img_width = detection_result.orig_shape[:2]\n",
        "\n",
        "                detected_objects = []\n",
        "\n",
        "                for box, class_id, confidence in zip(boxes, classes, confidences):\n",
        "                    try:\n",
        "                        # 1. 先拿到這筆偵測物件的 class_name\n",
        "                        class_name = self.class_names.get(int(class_id), f\"unknown_class_{class_id}\")\n",
        "                        # 2. 計算這個 class 應該採用的動態 threshold\n",
        "                        dyn_thr = self._get_dynamic_threshold(class_name)  # e.g. 0.25 * factor\n",
        "                        # 3. 如果 confidence < dyn_thr，就跳過這一筆\n",
        "                        if confidence < dyn_thr:\n",
        "                            continue\n",
        "\n",
        "                        # 後面維持原本的座標、中心、大小、區域等資訊計算\n",
        "                        x1, y1, x2, y2 = box\n",
        "                        width = x2 - x1\n",
        "                        height = y2 - y1\n",
        "\n",
        "                        # 中心點計算\n",
        "                        center_x = (x1 + x2) / 2\n",
        "                        center_y = (y1 + y2) / 2\n",
        "\n",
        "                        # 標準化位置 (0-1)\n",
        "                        norm_x = center_x / img_width\n",
        "                        norm_y = center_y / img_height\n",
        "                        norm_width = width / img_width\n",
        "                        norm_height = height / img_height\n",
        "\n",
        "                        # 面積計算\n",
        "                        area = width * height\n",
        "                        norm_area = area / (img_width * img_height)\n",
        "\n",
        "                        # 區域判斷\n",
        "                        object_region = \"unknown\"\n",
        "                        if region_analyzer:\n",
        "                            object_region = region_analyzer.determine_region(norm_x, norm_y)\n",
        "\n",
        "                        # 調試信息：記錄映射過程\n",
        "                        if class_name.startswith(\"unknown_class_\"):\n",
        "                            logger.warning(\n",
        "                                f\"Class ID {class_id} not found in class_names. \"\n",
        "                                f\"Available keys: {list(self.class_names.keys())}\"\n",
        "                            )\n",
        "                        else:\n",
        "                            logger.debug(f\"Successfully mapped class ID {class_id} to '{class_name}'\")\n",
        "\n",
        "                        detected_objects.append({\n",
        "                            \"class_id\": int(class_id),\n",
        "                            \"class_name\": class_name,\n",
        "                            \"confidence\": float(confidence),\n",
        "                            \"box\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                            \"center\": [float(center_x), float(center_y)],\n",
        "                            \"normalized_center\": [float(norm_x), float(norm_y)],\n",
        "                            \"size\": [float(width), float(height)],\n",
        "                            \"normalized_size\": [float(norm_width), float(norm_height)],\n",
        "                            \"area\": float(area),\n",
        "                            \"normalized_area\": float(norm_area),\n",
        "                            \"region\": object_region\n",
        "                        })\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error processing object with class_id {class_id}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                logger.info(f\"Extracted {len(detected_objects)} objects from detection result\")\n",
        "                return detected_objects\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error extracting detected objects: {str(e)}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "                return []\n",
        "\n",
        "    def update_class_names(self, class_names: Dict[int, str]):\n",
        "        \"\"\"\n",
        "        動態更新類別名稱映射\n",
        "\n",
        "        Args:\n",
        "            class_names: 新的類別名稱映射字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.class_names = class_names or {}\n",
        "            logger.info(f\"Class names updated: {len(self.class_names)} classes\")\n",
        "            logger.debug(f\"Updated class names: {self.class_names}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to update class names: {str(e)}\")\n",
        "\n",
        "    def categorize_object(self, obj: Dict) -> str:\n",
        "        \"\"\"\n",
        "        將檢測到的物件分類到功能類別中，用於區域識別\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典\n",
        "\n",
        "        Returns:\n",
        "            物件功能類別字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            class_id = obj.get(\"class_id\", -1)\n",
        "            class_name = obj.get(\"class_name\", \"\").lower()\n",
        "\n",
        "            # 使用現有的類別映射（如果可用）\n",
        "            if self.object_categories:\n",
        "                for category, ids in self.object_categories.items():\n",
        "                    if class_id in ids:\n",
        "                        return category\n",
        "\n",
        "            # 基於COCO類別名稱的後備分類\n",
        "            furniture_items = [\"chair\", \"couch\", \"bed\", \"dining table\", \"toilet\"]\n",
        "            plant_items = [\"potted plant\"]\n",
        "            electronic_items = [\"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\"]\n",
        "            vehicle_items = [\"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\"]\n",
        "            person_items = [\"person\"]\n",
        "            kitchen_items = [\"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
        "                            \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\n",
        "                            \"pizza\", \"donut\", \"cake\", \"refrigerator\", \"oven\", \"toaster\", \"sink\", \"microwave\"]\n",
        "            sports_items = [\"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "                        \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\"]\n",
        "            personal_items = [\"handbag\", \"tie\", \"suitcase\", \"umbrella\", \"backpack\"]\n",
        "\n",
        "            if any(item in class_name for item in furniture_items):\n",
        "                return \"furniture\"\n",
        "            elif any(item in class_name for item in plant_items):\n",
        "                return \"plant\"\n",
        "            elif any(item in class_name for item in electronic_items):\n",
        "                return \"electronics\"\n",
        "            elif any(item in class_name for item in vehicle_items):\n",
        "                return \"vehicle\"\n",
        "            elif any(item in class_name for item in person_items):\n",
        "                return \"person\"\n",
        "            elif any(item in class_name for item in kitchen_items):\n",
        "                return \"kitchen_items\"\n",
        "            elif any(item in class_name for item in sports_items):\n",
        "                return \"sports\"\n",
        "            elif any(item in class_name for item in personal_items):\n",
        "                return \"personal_items\"\n",
        "            else:\n",
        "                return \"misc\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error categorizing object: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"misc\"\n",
        "\n",
        "    def get_object_categories(self, detected_objects: List[Dict]) -> set:\n",
        "        \"\"\"\n",
        "        從檢測到的物件中取得唯一的物件類別\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            唯一物件類別的集合\n",
        "        \"\"\"\n",
        "        try:\n",
        "            object_categories = set()\n",
        "            for obj in detected_objects:\n",
        "                category = self.categorize_object(obj)\n",
        "                if category:\n",
        "                    object_categories.add(category)\n",
        "\n",
        "            logger.info(f\"Found {len(object_categories)} unique object categories\")\n",
        "            return object_categories\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting object categories: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return set()\n",
        "\n",
        "    def identify_core_objects_for_scene(self, detected_objects: List[Dict], scene_type: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        識別定義特定場景類型的核心物件\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            場景的核心物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            core_objects = []\n",
        "\n",
        "            # 場景核心物件映射\n",
        "            scene_core_mapping = {\n",
        "                \"bedroom\": [59],  # bed\n",
        "                \"kitchen\": [68, 69, 71, 72],  # microwave, oven, sink, refrigerator\n",
        "                \"living_room\": [57, 58, 62],  # sofa, chair, tv\n",
        "                \"dining_area\": [60, 46, 47],  # dining table, fork, knife\n",
        "                \"office_workspace\": [63, 64, 66, 73]  # laptop, mouse, keyboard, book\n",
        "            }\n",
        "\n",
        "            if scene_type in scene_core_mapping:\n",
        "                core_class_ids = scene_core_mapping[scene_type]\n",
        "                for obj in detected_objects:\n",
        "                    if obj.get(\"class_id\") in core_class_ids and obj.get(\"confidence\", 0) >= 0.4:\n",
        "                        core_objects.append(obj)\n",
        "\n",
        "            logger.info(f\"Identified {len(core_objects)} core objects for scene type '{scene_type}'\")\n",
        "            return core_objects\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying core objects for scene '{scene_type}': {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return []\n",
        "\n",
        "    def group_objects_by_category_and_region(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        將物件按類別和區域分組\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            按類別和區域分組的物件字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            category_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                category = self.categorize_object(obj)\n",
        "                if not category:\n",
        "                    continue\n",
        "\n",
        "                if category not in category_regions:\n",
        "                    category_regions[category] = {}\n",
        "\n",
        "                region = obj.get(\"region\", \"center\")\n",
        "                if region not in category_regions[category]:\n",
        "                    category_regions[category][region] = []\n",
        "\n",
        "                category_regions[category][region].append(obj)\n",
        "\n",
        "            logger.info(f\"Grouped objects into {len(category_regions)} categories across regions\")\n",
        "            return category_regions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error grouping objects by category and region: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def filter_objects_by_confidence(self, detected_objects: List[Dict], min_confidence: float) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        根據信心度過濾物件\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            min_confidence: 最小信心度閾值\n",
        "\n",
        "        Returns:\n",
        "            過濾後的物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            filtered_objects = [\n",
        "                obj for obj in detected_objects\n",
        "                if obj.get(\"confidence\", 0) >= min_confidence\n",
        "            ]\n",
        "\n",
        "            logger.info(f\"Filtered {len(detected_objects)} objects to {len(filtered_objects)} objects with confidence >= {min_confidence}\")\n",
        "            return filtered_objects\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error filtering objects by confidence: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return detected_objects  # 發生錯誤時返回原始列表"
      ],
      "metadata": {
        "id": "uFY-3nYHrRJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3da5db-8aee-40a5-fd4f-6e5ec5afb511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing object_extractor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile scene_viewpoint_analyzer.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SceneViewpointAnalyzer:\n",
        "    \"\"\"\n",
        "    負責場景視角的檢測和模式辨識\n",
        "    專注於檢測場景視角（俯視、平視等）並識別特殊場景模式（如十字路口、人流方向等）\n",
        "    提供詳細的場景空間分析和視角相關的場景理解功能\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, enhanced_scene_describer=None):\n",
        "        \"\"\"\n",
        "        初始化場景視角分析器\n",
        "\n",
        "        Args:\n",
        "            enhanced_scene_describer: 增強場景描述器，用於基本視角檢測\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.enhanced_scene_describer = enhanced_scene_describer\n",
        "            logger.info(\"SceneViewpointAnalyzer initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize SceneViewpointAnalyzer: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def detect_viewpoint(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        檢測圖像視角類型\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的視角類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 使用內部的場景視角檢測方法\n",
        "            viewpoint_info = self.detect_scene_viewpoint(detected_objects)\n",
        "            return viewpoint_info.get(\"viewpoint\", \"eye_level\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error detecting viewpoint: {str(e)}\")\n",
        "            return \"eye_level\"\n",
        "\n",
        "    def get_viewpoint_confidence(self, detected_objects: List[Dict]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        獲取視角檢測結果及其信心度\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, float]: (視角類型, 信心度)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            viewpoint_info = self.detect_scene_viewpoint(detected_objects)\n",
        "            viewpoint = viewpoint_info.get(\"viewpoint\", \"eye_level\")\n",
        "\n",
        "            # 根據檢測到的模式計算信心度\n",
        "            patterns = viewpoint_info.get(\"patterns\", [])\n",
        "            confidence = 0.5  # 基礎信心度\n",
        "\n",
        "            if \"crosswalk_intersection\" in patterns:\n",
        "                confidence += 0.3\n",
        "            if \"consistent_object_size\" in patterns:\n",
        "                confidence += 0.2\n",
        "            if \"multi_directional_movement\" in patterns:\n",
        "                confidence += 0.1\n",
        "\n",
        "            confidence = min(confidence, 1.0)\n",
        "            return viewpoint, confidence\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting viewpoint confidence: {str(e)}\")\n",
        "            return \"eye_level\", 0.5\n",
        "\n",
        "    def detect_scene_viewpoint(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        檢測場景視角並識別特殊場景模式\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含視角和場景模式資訊的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                logger.warning(\"No detected objects provided for viewpoint detection\")\n",
        "                return {\"viewpoint\": \"eye_level\", \"patterns\": []}\n",
        "\n",
        "            # 從物件位置中提取資訊\n",
        "            patterns = []\n",
        "\n",
        "            # 檢測行人位置模式 - 篩選出所有行人物件\n",
        "            pedestrian_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 0]\n",
        "\n",
        "            # 檢查是否有足夠的行人來辨識模式，至少需要4個行人才能進行模式分析\n",
        "            if len(pedestrian_objs) >= 4:\n",
        "                # 提取行人的標準化中心座標用於模式分析\n",
        "                pedestrian_positions = [obj[\"normalized_center\"] for obj in pedestrian_objs]\n",
        "\n",
        "                # 檢測十字交叉模式，這通常出現在斑馬線交叉口的俯視圖\n",
        "                if self._detect_cross_pattern(pedestrian_positions):\n",
        "                    patterns.append(\"crosswalk_intersection\")\n",
        "\n",
        "                # 檢測多方向行人流 - 分析行人是否在多個方向移動\n",
        "                directions = self._analyze_movement_directions(pedestrian_positions)\n",
        "                if len(directions) >= 2:\n",
        "                    patterns.append(\"multi_directional_movement\")\n",
        "\n",
        "            # 檢查物件的大小一致性，在空中俯視圖中，物件大小通常更一致\n",
        "            # 因為距離相對均勻，不像地面視角會有遠近差異\n",
        "            if len(detected_objects) >= 5:\n",
        "                sizes = [obj.get(\"normalized_area\", 0) for obj in detected_objects]\n",
        "                # 計算標準化變異數，避免受平均值影響\n",
        "                size_variance = np.var(sizes) / (np.mean(sizes) ** 2) if np.mean(sizes) > 0 else 0\n",
        "\n",
        "                # 低變異表示大小一致，可能是俯視角度\n",
        "                if size_variance < 0.3:\n",
        "                    patterns.append(\"consistent_object_size\")\n",
        "\n",
        "            # 基本視角檢測，使用增強場景描述器進行基礎視角判斷\n",
        "            viewpoint = \"eye_level\"  # 預設值\n",
        "            if self.enhanced_scene_describer and hasattr(self.enhanced_scene_describer, '_detect_viewpoint'):\n",
        "                viewpoint = self.enhanced_scene_describer._detect_viewpoint(detected_objects)\n",
        "\n",
        "            # 根據檢測到的模式增強視角判斷\n",
        "            # 如果檢測到斑馬線交叉但視角判斷不是空中視角，優先採用模式判斷\n",
        "            if \"crosswalk_intersection\" in patterns and viewpoint != \"aerial\":\n",
        "                viewpoint = \"aerial\"\n",
        "\n",
        "            result = {\n",
        "                \"viewpoint\": viewpoint,\n",
        "                \"patterns\": patterns\n",
        "            }\n",
        "\n",
        "            logger.info(f\"Viewpoint detection completed: {viewpoint}, patterns: {patterns}\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in scene viewpoint detection: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {\"viewpoint\": \"eye_level\", \"patterns\": []}\n",
        "\n",
        "    def _detect_cross_pattern(self, positions: List[List[float]]) -> bool:\n",
        "        \"\"\"\n",
        "        檢測位置中的十字交叉模式\n",
        "        這種模式通常出現在十字路口的俯視圖中，行人分布呈現十字形\n",
        "\n",
        "        Args:\n",
        "            positions: 位置列表 [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "        Returns:\n",
        "            是否檢測到十字交叉模式\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(positions) < 8:  # 需要足夠多的點才能形成有意義的十字模式\n",
        "                return False\n",
        "\n",
        "            # 提取 x 和 y 座標進行分析\n",
        "            x_coords = [pos[0] for pos in positions]\n",
        "            y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "            # 計算座標的平均值，用於確定中心線位置\n",
        "            x_mean = np.mean(x_coords)\n",
        "            y_mean = np.mean(y_coords)\n",
        "\n",
        "            # 計算在中心線附近的點數量\n",
        "            # 如果有足夠多的點在垂直和水平中心線附近，可能是十字交叉\n",
        "            near_x_center = sum(1 for x in x_coords if abs(x - x_mean) < 0.1)  # 10%的偏差\n",
        "            near_y_center = sum(1 for y in y_coords if abs(y - y_mean) < 0.1)  # 10%的偏差\n",
        "\n",
        "            # 十字交叉模式的判斷條件：垂直和水平方向都有足夠的點聚集\n",
        "            is_cross_pattern = near_x_center >= 3 and near_y_center >= 3\n",
        "\n",
        "            if is_cross_pattern:\n",
        "                logger.info(f\"Cross pattern detected with {near_x_center} points near vertical center and {near_y_center} points near horizontal center\")\n",
        "\n",
        "            return is_cross_pattern\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error detecting cross pattern: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return False\n",
        "\n",
        "    def _analyze_movement_directions(self, positions: List[List[float]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        分析位置中的移動方向\n",
        "        通過分析座標分布範圍來推斷主要的移動方向\n",
        "\n",
        "        Args:\n",
        "            positions: 位置列表 [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "        Returns:\n",
        "            檢測到的主要方向列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(positions) < 6:  # 需要足夠的點才能分析方向性\n",
        "                return []\n",
        "\n",
        "            # 提取 x 和 y 座標\n",
        "            x_coords = [pos[0] for pos in positions]\n",
        "            y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "            directions = []\n",
        "\n",
        "            # 水平移動分析（左右移動）\n",
        "            # 計算x座標的標準差和範圍來判斷水平方向的分散程度\n",
        "            x_std = np.std(x_coords)\n",
        "            x_range = max(x_coords) - min(x_coords)\n",
        "\n",
        "            # 垂直移動分析（上下移動）\n",
        "            # 計算y座標的標準差和範圍來判斷垂直方向的分散程度\n",
        "            y_std = np.std(y_coords)\n",
        "            y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "            # 足夠大的範圍表示該方向有明顯的運動或分散\n",
        "            # 40%的圖像範圍被認為是有意義的移動範圍\n",
        "            if x_range > 0.4:\n",
        "                directions.append(\"horizontal\")\n",
        "                logger.debug(f\"Horizontal movement detected with range: {x_range:.3f}\")\n",
        "\n",
        "            if y_range > 0.4:\n",
        "                directions.append(\"vertical\")\n",
        "                logger.debug(f\"Vertical movement detected with range: {y_range:.3f}\")\n",
        "\n",
        "            logger.info(f\"Movement directions analyzed: {directions}\")\n",
        "            return directions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing movement directions: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return []\n",
        "\n",
        "    def detect_aerial_view_indicators(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        檢測俯視角度的指標\n",
        "        分析物件分布特徵來判斷是否為俯視角度\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含俯視角度指標的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            indicators = {\n",
        "                \"consistent_sizing\": False,\n",
        "                \"grid_like_distribution\": False,\n",
        "                \"high_object_density\": False,\n",
        "                \"aerial_score\": 0.0\n",
        "            }\n",
        "\n",
        "            if not detected_objects:\n",
        "                return indicators\n",
        "\n",
        "            # 檢查物件大小的一致性\n",
        "            sizes = [obj.get(\"normalized_area\", 0) for obj in detected_objects]\n",
        "            if len(sizes) >= 3:\n",
        "                size_variance = np.var(sizes) / (np.mean(sizes) ** 2) if np.mean(sizes) > 0 else 1\n",
        "                # 俯視角度通常物件大小較為一致\n",
        "                indicators[\"consistent_sizing\"] = size_variance < 0.3\n",
        "\n",
        "            # 檢查是否有網格狀分布（如停車場的俯視圖）\n",
        "            positions = [obj.get(\"normalized_center\", [0.5, 0.5]) for obj in detected_objects]\n",
        "            if len(positions) >= 6:\n",
        "                # 簡化的網格檢測：檢查是否有規律的行列分布\n",
        "                x_coords = [pos[0] for pos in positions]\n",
        "                y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "                # 計算座標的分布是否接近規律網格\n",
        "                x_unique = len(set([round(x, 1) for x in x_coords]))  # 四捨五入到小數第一位\n",
        "                y_unique = len(set([round(y, 1) for y in y_coords]))\n",
        "\n",
        "                # 如果x和y方向都有多個不同的規律位置，可能是網格分布\n",
        "                indicators[\"grid_like_distribution\"] = x_unique >= 3 and y_unique >= 3\n",
        "\n",
        "            # 檢查物件密度\n",
        "            total_objects = len(detected_objects)\n",
        "            # 俯視角度通常能看到更多物件\n",
        "            indicators[\"high_object_density\"] = total_objects >= 8\n",
        "\n",
        "            # 計算俯視角度評分\n",
        "            score = 0\n",
        "            if indicators[\"consistent_sizing\"]:\n",
        "                score += 0.4\n",
        "            if indicators[\"grid_like_distribution\"]:\n",
        "                score += 0.4\n",
        "            if indicators[\"high_object_density\"]:\n",
        "                score += 0.2\n",
        "\n",
        "            indicators[\"aerial_score\"] = score\n",
        "\n",
        "            logger.info(f\"Aerial view indicators: score={score:.2f}, consistent_sizing={indicators['consistent_sizing']}, grid_distribution={indicators['grid_like_distribution']}, high_density={indicators['high_object_density']}\")\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error detecting aerial view indicators: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"consistent_sizing\": False,\n",
        "                \"grid_like_distribution\": False,\n",
        "                \"high_object_density\": False,\n",
        "                \"aerial_score\": 0.0\n",
        "            }"
      ],
      "metadata": {
        "id": "eXLOwGKcrRGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3614a95-24d2-42c8-de88-2e4b3b8fdeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_viewpoint_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile zone_evaluator.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ZoneEvaluator:\n",
        "    \"\"\"\n",
        "    負責功能區域辨識的可行性評估和物件關聯性計算\n",
        "    評估是否應該進行區域劃分以及計算物件間的功能關聯性\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化區域評估器\"\"\"\n",
        "        try:\n",
        "            # 定義物件間的功能關聯性評分表\n",
        "            # 分數越高表示兩個物件在功能上越相關，更可能出現在同一功能區域\n",
        "            self.relationship_pairs = {\n",
        "                # 家具組合關係 - 這些組合通常出現在特定功能區域\n",
        "                frozenset([56, 60]): 1.0,  # 椅子+桌子 (dining/work area)\n",
        "                frozenset([57, 62]): 0.9,  # 沙發+電視 (living area)\n",
        "                frozenset([59, 58]): 0.7,  # 床+植物 (bedroom decor)\n",
        "\n",
        "                # 工作相關組合 - 工作環境的典型配置\n",
        "                frozenset([63, 66]): 0.9,  # 筆電+鍵盤 (workspace)\n",
        "                frozenset([63, 64]): 0.8,  # 筆電+滑鼠 (workspace)\n",
        "                frozenset([60, 63]): 0.8,  # 桌子+筆電 (workspace)\n",
        "\n",
        "                # 廚房相關組合 - 廚房設備的常見的物品\n",
        "                frozenset([68, 72]): 0.9,  # 微波爐+冰箱 (kitchen)\n",
        "                frozenset([69, 71]): 0.8,  # 烤箱+水槽 (kitchen)\n",
        "\n",
        "                # 用餐相關組合 - 餐廳或用餐區域的典型物品\n",
        "                frozenset([60, 40]): 0.8,  # 桌子+酒杯 (dining)\n",
        "                frozenset([60, 41]): 0.8,  # 桌子+杯子 (dining)\n",
        "                frozenset([56, 40]): 0.7,  # 椅子+酒杯 (dining)\n",
        "\n",
        "                # 交通相關組合 - 城市交通的環境\n",
        "                frozenset([2, 9]): 0.8,   # 汽車+交通燈 (traffic)\n",
        "                frozenset([0, 9]): 0.7,   # 行人+交通燈 (crosswalk)\n",
        "            }\n",
        "\n",
        "            logger.info(\"ZoneEvaluator initialized with predefined relationship pairs\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize ZoneEvaluator: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def evaluate_zone_identification_feasibility(self, detected_objects: List[Dict], scene_type: str) -> bool:\n",
        "        \"\"\"\n",
        "        基於物件關聯性和分布特徵的彈性可行性評估\n",
        "        決定是否應該進行功能區域劃分\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            是否適合進行區域識別\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(detected_objects) < 2:\n",
        "                logger.info(\"Insufficient objects for zone identification (minimum 2 required)\")\n",
        "                return False\n",
        "\n",
        "            # 計算不同置信度層級的物件分布\n",
        "            # 高信心度物件更可靠，用於核心區域判斷\n",
        "            high_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.6]\n",
        "            # 中等置信度物件提供補充資訊\n",
        "            medium_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "            # 基礎條件：至少需要一定數量的可信物件才值得進行區域分析\n",
        "            if len(medium_conf_objects) < 2:\n",
        "                logger.info(\"Insufficient medium confidence objects for zone identification\")\n",
        "                return False\n",
        "\n",
        "            # 評估物件間的功能關聯性，關聯性高的物件更適合劃分功能區域\n",
        "            functional_relationships = self.calculate_functional_relationships(detected_objects)\n",
        "\n",
        "            # 評估空間分布多樣性 - 物件分散在多個區域才有劃分的意義\n",
        "            spatial_diversity = self.calculate_spatial_diversity(detected_objects)\n",
        "\n",
        "            # 綜合評分機制，用各項指標加權計算最終可行性評分\n",
        "            feasibility_score = 0\n",
        "\n",
        "            # 物件數量的貢獻（權重30%）- 更多物件提供更多劃分依據\n",
        "            object_count_score = min(len(detected_objects) / 5.0, 1.0) * 0.3\n",
        "\n",
        "            # 信心度質量貢獻（權重25%）- 高置信度物件比例影響可靠性\n",
        "            confidence_score = len(high_conf_objects) / max(len(detected_objects), 1) * 0.25\n",
        "\n",
        "            # 功能關聯性貢獻（權重25%）- 有功能關聯的物件更適合劃分區域\n",
        "            relationship_score = functional_relationships * 0.25\n",
        "\n",
        "            # 空間多樣性貢獻（權重20%）- 分散的物件才需要區域劃分\n",
        "            diversity_score = spatial_diversity * 0.20\n",
        "\n",
        "            feasibility_score = object_count_score + confidence_score + relationship_score + diversity_score\n",
        "\n",
        "            # 動態閾值：根據場景複雜度調整可行性標準\n",
        "            complexity_threshold = self.get_complexity_threshold(scene_type)\n",
        "\n",
        "            is_feasible = feasibility_score >= complexity_threshold\n",
        "\n",
        "            logger.info(f\"Zone identification feasibility: {is_feasible} (score: {feasibility_score:.3f}, threshold: {complexity_threshold:.3f})\")\n",
        "            logger.debug(f\"Score breakdown - objects: {object_count_score:.3f}, confidence: {confidence_score:.3f}, relationships: {relationship_score:.3f}, diversity: {diversity_score:.3f}\")\n",
        "\n",
        "            return is_feasible\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error evaluating zone identification feasibility: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return False\n",
        "\n",
        "    def calculate_functional_relationships(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件間的功能關聯性評分\n",
        "        基於常見的物件組合模式評估功能相關性\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            功能關聯性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            detected_class_ids = set(obj.get(\"class_id\") for obj in detected_objects)\n",
        "            max_possible_score = 0\n",
        "            actual_score = 0\n",
        "\n",
        "            # 遍歷所有預定義的關聯性組合，計算實際場景中的關聯性評分\n",
        "            for pair, score in self.relationship_pairs.items():\n",
        "                max_possible_score += score\n",
        "                # 如果檢測到的物件中包含這個關聯組合，累加其評分\n",
        "                if pair.issubset(detected_class_ids):\n",
        "                    actual_score += score\n",
        "                    logger.debug(f\"Found functional relationship: {pair} with score {score}\")\n",
        "\n",
        "            # 標準化評分：實際評分除以最大可能評分\n",
        "            relationship_score = actual_score / max_possible_score if max_possible_score > 0 else 0\n",
        "\n",
        "            logger.info(f\"Functional relationships calculated: {relationship_score:.3f} (found {actual_score:.1f}/{max_possible_score:.1f} possible relationships)\")\n",
        "            return relationship_score\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating functional relationships: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0\n",
        "\n",
        "    def calculate_spatial_diversity(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件空間分布的多樣性\n",
        "        評估物件是否分散在不同區域，避免所有物件集中在單一區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            空間多樣性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 收集所有物件所在的不同區域\n",
        "            regions = set(obj.get(\"region\", \"center\") for obj in detected_objects)\n",
        "            unique_regions = len(regions)\n",
        "\n",
        "            # 標準化多樣性評分：假設理想情況是物件分散在2個以上區域\n",
        "            # 更多區域意味著更高的空間多樣性，更適合進行區域劃分\n",
        "            diversity_score = min(unique_regions / 2.0, 1.0)\n",
        "\n",
        "            logger.info(f\"Spatial diversity calculated: {diversity_score:.3f} (objects distributed across {unique_regions} regions)\")\n",
        "            return diversity_score\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating spatial diversity: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0\n",
        "\n",
        "    def get_complexity_threshold(self, scene_type: str) -> float:\n",
        "        \"\"\"\n",
        "        根據場景類型返回適當的複雜度閾值\n",
        "        平衡不同場景的區域劃分需求\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            複雜度閾值 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 較簡單場景需要較高分數才進行區域劃分\n",
        "            # 這些場景通常功能較為單純，不太需要細分\n",
        "            simple_scenes = [\"bedroom\", \"bathroom\", \"closet\"]\n",
        "\n",
        "            # 較複雜場景可以較低分數進行區域劃分\n",
        "            # 這些場景通常有多種功能，適合劃分不同區域\n",
        "            complex_scenes = [\"living_room\", \"kitchen\", \"office_workspace\", \"dining_area\"]\n",
        "\n",
        "            if scene_type in simple_scenes:\n",
        "                threshold = 0.65  # 較高閾值，避免過度細分\n",
        "                logger.debug(f\"Using high threshold {threshold} for simple scene: {scene_type}\")\n",
        "            elif scene_type in complex_scenes:\n",
        "                threshold = 0.45  # 較低閾值，允許合理劃分\n",
        "                logger.debug(f\"Using low threshold {threshold} for complex scene: {scene_type}\")\n",
        "            else:\n",
        "                threshold = 0.55  # 中等閾值，平衡策略\n",
        "                logger.debug(f\"Using medium threshold {threshold} for scene: {scene_type}\")\n",
        "\n",
        "            return threshold\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting complexity threshold for scene '{scene_type}': {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0.55  # 預設中等閾值\n",
        "\n",
        "    def analyze_object_clustering(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析物件的聚集模式\n",
        "        識別物件是否形成明顯的聚集群組，這有助於功能區域的劃分\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含聚集分析結果的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            clustering_result = {\n",
        "                \"has_clusters\": False,\n",
        "                \"cluster_count\": 0,\n",
        "                \"cluster_regions\": [],\n",
        "                \"clustering_score\": 0.0\n",
        "            }\n",
        "\n",
        "            if len(detected_objects) < 3:\n",
        "                logger.info(\"Insufficient objects for clustering analysis\")\n",
        "                return clustering_result\n",
        "\n",
        "            # 統計每個區域的物件數量\n",
        "            region_counts = {}\n",
        "            for obj in detected_objects:\n",
        "                region = obj.get(\"region\", \"unknown\")\n",
        "                region_counts[region] = region_counts.get(region, 0) + 1\n",
        "\n",
        "            # 找出有顯著物件聚集的區域（物件數量 >= 2）\n",
        "            significant_regions = [region for region, count in region_counts.items() if count >= 2]\n",
        "\n",
        "            # 計算聚集：聚集區域數量與總區域數量的比例\n",
        "            total_regions_with_objects = len([count for count in region_counts.values() if count > 0])\n",
        "            clustering_score = len(significant_regions) / max(total_regions_with_objects, 1)\n",
        "\n",
        "            clustering_result.update({\n",
        "                \"has_clusters\": len(significant_regions) >= 2,\n",
        "                \"cluster_count\": len(significant_regions),\n",
        "                \"cluster_regions\": significant_regions,\n",
        "                \"clustering_score\": clustering_score\n",
        "            })\n",
        "\n",
        "            logger.info(f\"Object clustering analysis: {len(significant_regions)} clusters found in regions {significant_regions}\")\n",
        "            return clustering_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing object clustering: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"has_clusters\": False,\n",
        "                \"cluster_count\": 0,\n",
        "                \"cluster_regions\": [],\n",
        "                \"clustering_score\": 0.0\n",
        "            }"
      ],
      "metadata": {
        "id": "hBqLQYEVrREC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4317240f-9608-413d-9ea0-0d7e5d423f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting zone_evaluator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile scene_zone_identifier.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SceneZoneIdentifier:\n",
        "    \"\"\"\n",
        "    負責不同場景類型的區域識別邏輯\n",
        "    專注於根據場景類型執行相應的功能區域識別策略\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化場景區域辨識器\"\"\"\n",
        "        try:\n",
        "            logger.info(\"SceneZoneIdentifier initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize SceneZoneIdentifier: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def identify_indoor_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        平衡化的室內功能區域識別並標準化命名\n",
        "        採用通用的物件關聯性分析，避免只針對特定場景\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            識別出的室內功能區域字典，使用描述性鍵名\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 主要功能區域（基於物件關聯性而非場景類型）\n",
        "            primary_zone = self._identify_primary_functional_area(detected_objects)\n",
        "            if primary_zone:\n",
        "                # 基於區域內容生成描述性鍵名\n",
        "                descriptive_key = self._generate_descriptive_zone_key_from_data(primary_zone, \"primary\")\n",
        "                zones[descriptive_key] = primary_zone\n",
        "\n",
        "            # 只有明確證據且物件數量足夠時創建次要功能區域\n",
        "            if len(zones) >= 1 and len(detected_objects) >= 6:\n",
        "                secondary_zone = self._identify_secondary_functional_area(detected_objects, zones)\n",
        "                if secondary_zone:\n",
        "                    # 基於區域內容生成描述性鍵名\n",
        "                    descriptive_key = self._generate_descriptive_zone_key_from_data(secondary_zone, \"secondary\")\n",
        "                    zones[descriptive_key] = secondary_zone\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} indoor zones for scene type '{scene_type}'\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying indoor zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _generate_descriptive_zone_key_from_data(self, zone_data: Dict, priority_level: str) -> str:\n",
        "        \"\"\"\n",
        "        基於區域數據生成描述性鍵名\n",
        "\n",
        "        Args:\n",
        "            zone_data: 區域數據字典\n",
        "            priority_level: 優先級別（primary/secondary）\n",
        "\n",
        "        Returns:\n",
        "            str: 描述性區域鍵名\n",
        "        \"\"\"\n",
        "        try:\n",
        "            objects = zone_data.get(\"objects\", [])\n",
        "            region = zone_data.get(\"region\", \"\")\n",
        "            description = zone_data.get(\"description\", \"\")\n",
        "\n",
        "            # 基於物件內容確定功能類型\n",
        "            if any(\"dining\" in obj.lower() or \"table\" in obj.lower() for obj in objects):\n",
        "                base_name = \"dining area\"\n",
        "            elif any(\"chair\" in obj.lower() or \"sofa\" in obj.lower() for obj in objects):\n",
        "                base_name = \"seating area\"\n",
        "            elif any(\"bed\" in obj.lower() for obj in objects):\n",
        "                base_name = \"sleeping area\"\n",
        "            elif any(\"laptop\" in obj.lower() or \"keyboard\" in obj.lower() for obj in objects):\n",
        "                base_name = \"workspace area\"\n",
        "            elif any(\"plant\" in obj.lower() or \"vase\" in obj.lower() for obj in objects):\n",
        "                base_name = \"decorative area\"\n",
        "            elif any(\"refrigerator\" in obj.lower() or \"microwave\" in obj.lower() for obj in objects):\n",
        "                base_name = \"kitchen area\"\n",
        "            else:\n",
        "                # 基於描述內容推斷\n",
        "                if \"dining\" in description.lower():\n",
        "                    base_name = \"dining area\"\n",
        "                elif \"seating\" in description.lower() or \"relaxation\" in description.lower():\n",
        "                    base_name = \"seating area\"\n",
        "                elif \"work\" in description.lower():\n",
        "                    base_name = \"workspace area\"\n",
        "                elif \"decorative\" in description.lower():\n",
        "                    base_name = \"decorative area\"\n",
        "                else:\n",
        "                    base_name = \"functional area\"\n",
        "\n",
        "            # 為次要區域添加位置標識以區分\n",
        "            if priority_level == \"secondary\" and region:\n",
        "                spatial_context = self._get_spatial_context_description(region)\n",
        "                if spatial_context:\n",
        "                    return f\"{spatial_context} {base_name}\"\n",
        "\n",
        "            return base_name\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating descriptive zone key: {str(e)}\")\n",
        "            return \"activity area\"\n",
        "\n",
        "    def _get_spatial_context_description(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取空間上下文描述\n",
        "\n",
        "        Args:\n",
        "            region: 區域位置標識\n",
        "\n",
        "        Returns:\n",
        "            str: 空間上下文描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            spatial_mapping = {\n",
        "                \"top_left\": \"upper left\",\n",
        "                \"top_center\": \"upper\",\n",
        "                \"top_right\": \"upper right\",\n",
        "                \"middle_left\": \"left side\",\n",
        "                \"middle_center\": \"central\",\n",
        "                \"middle_right\": \"right side\",\n",
        "                \"bottom_left\": \"lower left\",\n",
        "                \"bottom_center\": \"lower\",\n",
        "                \"bottom_right\": \"lower right\"\n",
        "            }\n",
        "\n",
        "            return spatial_mapping.get(region, \"\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error getting spatial context for region '{region}': {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def identify_outdoor_general_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        識別一般戶外場景的功能區域\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 特定戶外場景類型\n",
        "\n",
        "        Returns:\n",
        "            戶外功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別行人區域\n",
        "            people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            if people_objs:\n",
        "                people_regions = {}\n",
        "                for obj in people_objs:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in people_regions:\n",
        "                        people_regions[region] = []\n",
        "                    people_regions[region].append(obj)\n",
        "\n",
        "                if people_regions:\n",
        "                    # 找到主要的行人活動區域\n",
        "                    main_people_regions = sorted(people_regions.items(),\n",
        "                                            key=lambda x: len(x[1]),\n",
        "                                            reverse=True)[:2]  # 取前2個區域\n",
        "\n",
        "                    for idx, (region, objs) in enumerate(main_people_regions):\n",
        "                        if len(objs) > 0:\n",
        "                            # 生成基於位置的描述性鍵名\n",
        "                            spatial_desc = self._get_directional_description(region)\n",
        "                            if spatial_desc and spatial_desc != \"central\":\n",
        "                                zone_key = f\"{spatial_desc} pedestrian area\"\n",
        "                            else:\n",
        "                                zone_key = \"main pedestrian area\" if idx == 0 else \"secondary pedestrian area\"\n",
        "\n",
        "                            zones[zone_key] = {\n",
        "                                \"region\": region,\n",
        "                                \"objects\": [\"person\"] * len(objs),\n",
        "                                \"description\": f\"Pedestrian area with {len(objs)} {'people' if len(objs) > 1 else 'person'}\"\n",
        "                            }\n",
        "\n",
        "            # 識別車輛區域，適用於街道和停車場\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7]]\n",
        "            if vehicle_objs:\n",
        "                vehicle_regions = {}\n",
        "                for obj in vehicle_objs:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in vehicle_regions:\n",
        "                        vehicle_regions[region] = []\n",
        "                    vehicle_regions[region].append(obj)\n",
        "\n",
        "                if vehicle_regions:\n",
        "                    main_vehicle_region = max(vehicle_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        default=(None, []))\n",
        "\n",
        "                    if main_vehicle_region[0] is not None:\n",
        "                        vehicle_types = [obj[\"class_name\"] for obj in main_vehicle_region[1]]\n",
        "                        zones[\"vehicle_zone\"] = {\n",
        "                            \"region\": main_vehicle_region[0],\n",
        "                            \"objects\": vehicle_types,\n",
        "                            \"description\": f\"Traffic area with {', '.join(list(set(vehicle_types))[:3])}\"\n",
        "                        }\n",
        "\n",
        "            # 針對公園區域的特殊處理\n",
        "            if scene_type == \"park_area\":\n",
        "                zones.update(self._identify_park_recreational_zones(detected_objects))\n",
        "\n",
        "            # 針對停車場的特殊處理\n",
        "            if scene_type == \"parking_lot\":\n",
        "                zones.update(self._identify_parking_zones(detected_objects))\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} outdoor zones for scene type '{scene_type}'\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying outdoor general zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_intersection_zones(self, category_regions: Dict, detected_objects: List[Dict], viewpoint: str) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識城市十字路口的功能區域，無論是否有行人，只要偵測到紅綠燈就一定顯示 Traffic Control Area；\n",
        "        若有行人，則額外建立 Crossing Zone 並把行人 + 同 region 的紅綠燈歸在一起。\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和 region 分組的物件字典\n",
        "            detected_objects: YOLO 檢測到的所有物件列表\n",
        "            viewpoint: 偵測到的視角字串\n",
        "\n",
        "        Returns:\n",
        "            zones: 最終的十字路口功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 1. 按 class_id 分出行人、車輛、紅綠燈\n",
        "            pedestrian_objs    = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            vehicle_objs       = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 7]]\n",
        "            traffic_light_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 9]\n",
        "\n",
        "            # 2. Step A: 無條件建立 Traffic Control Area\n",
        "            #    把每個 region 下的紅綠燈都先分群，生成對應 zone，確保「只要偵測到紅綠燈就一定顯示」\n",
        "            signal_regions_all = {}\n",
        "            for t in traffic_light_objs:\n",
        "                region = t[\"region\"]\n",
        "                signal_regions_all.setdefault(region, []).append(t)\n",
        "\n",
        "            for idx, (region, signals) in enumerate(signal_regions_all.items()):\n",
        "                # 先決定 zone_key (依 direction 或 primary/auxiliary)\n",
        "                direction = self._get_directional_description(region)\n",
        "                if direction and direction != \"central\":\n",
        "                    zone_key = f\"{direction} traffic control area\"\n",
        "                else:\n",
        "                    zone_key = \"primary traffic control area\" if idx == 0 else \"auxiliary traffic control area\"\n",
        "\n",
        "                # 確保命名不衝突\n",
        "                if zone_key in zones:\n",
        "                    suffix = 1\n",
        "                    new_key = f\"{zone_key} ({suffix})\"\n",
        "                    while new_key in zones:\n",
        "                        suffix += 1\n",
        "                        new_key = f\"{zone_key} ({suffix})\"\n",
        "                    zone_key = new_key\n",
        "\n",
        "                zones[zone_key] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": [\"traffic light\"] * len(signals),\n",
        "                    \"description\": f\"Traffic control area with {len(signals)} traffic lights in {region}\"\n",
        "                }\n",
        "\n",
        "            # (用於後面計算 Crossing 使用掉的 traffic light)\n",
        "            used_tl_count_per_region = dict.fromkeys(signal_regions_all.keys(), 0)\n",
        "\n",
        "            # 3. Step B: 如果有行人，就建立 Crossing Zone，並移除已被打包的紅綠燈\n",
        "            if pedestrian_objs:\n",
        "                # 先呼叫 _analyze_crossing_patterns，讓它回傳「行人 + 同 region 的紅綠燈」區\n",
        "                crossing_zones = self._analyze_crossing_patterns(pedestrian_objs, traffic_light_objs)\n",
        "\n",
        "                # 把 Crossing Zone 加到最終 zones，並同時記錄已使用掉的紅綠燈數量\n",
        "                for zone_key, zone_info in crossing_zones.items():\n",
        "                    region = zone_info.get(\"region\", \"\")\n",
        "                    obj_list = zone_info.get(\"objects\", [])\n",
        "\n",
        "                    # 如果該 zone_info[\"objects\"] 裡含有紅綠燈，就累加到 used_tl_count_per_region\n",
        "                    count_in_zone = obj_list.count(\"traffic light\")\n",
        "                    if count_in_zone > 0:\n",
        "                        used_tl_count_per_region[region] = used_tl_count_per_region.get(region, 0) + count_in_zone\n",
        "\n",
        "                    # 加入最終結果\n",
        "                    # 如果 key 重複，也可以在此加上 index，或直接覆蓋\n",
        "                    if zone_key in zones:\n",
        "                        suffix = 1\n",
        "                        new_key = f\"{zone_key} ({suffix})\"\n",
        "                        while new_key in zones:\n",
        "                            suffix += 1\n",
        "                            new_key = f\"{zone_key} ({suffix})\"\n",
        "                        zone_key = new_key\n",
        "\n",
        "                    zones[zone_key] = {\n",
        "                        \"region\": region,\n",
        "                        \"objects\": obj_list,\n",
        "                        \"description\": zone_info.get(\"description\", \"\")\n",
        "                    }\n",
        "\n",
        "            # 4. Step C: 計算並顯示 debug 資訊 (Total / Used / Remaining)\n",
        "            for region, signals in signal_regions_all.items():\n",
        "                total = len(signals)\n",
        "                used = used_tl_count_per_region.get(region, 0)\n",
        "                remaining = total - used\n",
        "                # print(f\"[DEBUG] Region '{region}': Total TL = {total}, Used in crossing = {used}, Remaining = {remaining}\")\n",
        "\n",
        "            # 5. Step D: 分析車輛交通區域（Vehicle Zones）\n",
        "            if vehicle_objs:\n",
        "                traffic_zones = self._analyze_traffic_zones(vehicle_objs)\n",
        "                # _analyze_traffic_zones 內部已用英文 debug，直接更新\n",
        "                for zone_key, zone_info in traffic_zones.items():\n",
        "                    if zone_key in zones:\n",
        "                        suffix = 1\n",
        "                        new_key = f\"{zone_key} ({suffix})\"\n",
        "                        while new_key in zones:\n",
        "                            suffix += 1\n",
        "                            new_key = f\"{zone_key} ({suffix})\"\n",
        "                        zone_key = new_key\n",
        "                    zones[zone_key] = zone_info\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} intersection zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in identify_intersection_zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_aerial_view_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識空中視角場景的功能區域\n",
        "        專注於模式和流動而非特定區域\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 特定場景類型\n",
        "\n",
        "        Returns:\n",
        "            空中視角功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別行人模式\n",
        "            people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            if people_objs:\n",
        "                # 將位置轉換為數組進行模式分析\n",
        "                positions = np.array([obj[\"normalized_center\"] for obj in people_objs])\n",
        "\n",
        "                if len(positions) >= 3:\n",
        "                    # 計算分布指標\n",
        "                    x_coords = positions[:, 0]\n",
        "                    y_coords = positions[:, 1]\n",
        "\n",
        "                    x_mean = np.mean(x_coords)\n",
        "                    y_mean = np.mean(y_coords)\n",
        "                    x_std = np.std(x_coords)\n",
        "                    y_std = np.std(y_coords)\n",
        "\n",
        "                    # 判斷人群是否組織成線性模式\n",
        "                    if x_std < 0.1 or y_std < 0.1:\n",
        "                        # 沿一個軸的線性分布\n",
        "                        pattern_direction = \"vertical\" if x_std < y_std else \"horizontal\"\n",
        "\n",
        "                        zones[\"pedestrian_pattern\"] = {\n",
        "                            \"region\": \"central\",\n",
        "                            \"objects\": [\"person\"] * len(people_objs),\n",
        "                            \"description\": f\"Aerial view shows a {pattern_direction} pedestrian movement pattern\"\n",
        "                        }\n",
        "                    else:\n",
        "                        # 更分散的模式\n",
        "                        zones[\"pedestrian_distribution\"] = {\n",
        "                            \"region\": \"wide\",\n",
        "                            \"objects\": [\"person\"] * len(people_objs),\n",
        "                            \"description\": f\"Aerial view shows pedestrians distributed across the area\"\n",
        "                        }\n",
        "\n",
        "            # 識別車輛模式進行交通分析\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7]]\n",
        "            if vehicle_objs:\n",
        "                zones.update(self._analyze_aerial_traffic_patterns(vehicle_objs))\n",
        "\n",
        "            # 針對十字路口特定空中視角的處理\n",
        "            if \"intersection\" in scene_type:\n",
        "                zones.update(self._identify_aerial_intersection_features(detected_objects))\n",
        "\n",
        "            # 針對廣場空中視角的處理\n",
        "            if \"plaza\" in scene_type:\n",
        "                zones.update(self._identify_aerial_plaza_features(people_objs))\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} aerial view zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying aerial view zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_asian_cultural_zones(self, category_regions: Dict, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識有亞洲文化背景的場景功能區域\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 特定場景類型\n",
        "\n",
        "        Returns:\n",
        "            亞洲文化功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別店面區域\n",
        "            # 由於店面不能直接檢測，從情境推斷\n",
        "            # 例如，尋找有標誌、行人和小物件的區域\n",
        "            storefront_regions = {}\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] == 0:  # Person\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in storefront_regions:\n",
        "                        storefront_regions[region] = []\n",
        "                    storefront_regions[region].append(obj)\n",
        "\n",
        "            # 將人最多的區域作為店面區域\n",
        "            if storefront_regions:\n",
        "                main_storefront_regions = sorted(storefront_regions.items(),\n",
        "                                            key=lambda x: len(x[1]),\n",
        "                                            reverse=True)[:2]  # 前2個區域\n",
        "\n",
        "                for idx, (region, objs) in enumerate(main_storefront_regions):\n",
        "                    # 生成基於位置的描述性鍵名\n",
        "                    spatial_desc = self._get_directional_description(region)\n",
        "                    if spatial_desc and spatial_desc != \"central\":\n",
        "                        zone_key = f\"{spatial_desc} commercial area\"\n",
        "                    else:\n",
        "                        zone_key = \"main commercial area\" if idx == 0 else \"secondary commercial area\"\n",
        "\n",
        "                    zones[zone_key] = {\n",
        "                        \"region\": region,\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in objs],\n",
        "                        \"description\": f\"Asian commercial storefront with pedestrian activity\"\n",
        "                    }\n",
        "\n",
        "            # 辨識行人通道\n",
        "            zones.update(self._identify_asian_pedestrian_pathway(detected_objects))\n",
        "\n",
        "            # 辨識攤販區域（小攤/商店 - 從情境推斷）\n",
        "            zones.update(self._identify_vendor_zones(detected_objects))\n",
        "\n",
        "            # 針對夜市的特殊處理\n",
        "            if scene_type == \"asian_night_market\":\n",
        "                zones[\"food_stall_zone\"] = {\n",
        "                    \"region\": \"middle_center\",\n",
        "                    \"objects\": [\"inferred food stalls\"],\n",
        "                    \"description\": \"Food stall area typical of Asian night markets\"\n",
        "                }\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} Asian cultural zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying Asian cultural zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_upscale_dining_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識高級餐飲設置的功能區域\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            高級餐飲功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 辨識餐桌區域\n",
        "            dining_items = []\n",
        "            dining_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [40, 41, 42, 43, 44, 45, 60]:  # Wine glass, cup, fork, knife, spoon, bowl, table\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in dining_regions:\n",
        "                        dining_regions[region] = []\n",
        "                    dining_regions[region].append(obj)\n",
        "                    dining_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if dining_items:\n",
        "                main_dining_region = max(dining_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_dining_region[0] is not None:\n",
        "                    zones[\"formal_dining_zone\"] = {\n",
        "                        \"region\": main_dining_region[0],\n",
        "                        \"objects\": list(set(dining_items)),\n",
        "                        \"description\": f\"Formal dining area with {', '.join(list(set(dining_items))[:3])}\"\n",
        "                    }\n",
        "\n",
        "            # 識別裝飾區域，增強檢測\n",
        "            zones.update(self._identify_upscale_decorative_zones(detected_objects))\n",
        "\n",
        "            # 識別座位安排區域\n",
        "            zones.update(self._identify_dining_seating_zones(detected_objects))\n",
        "\n",
        "            # 識別服務區域（如果與餐飲區域不同）\n",
        "            zones.update(self._identify_serving_zones(detected_objects, zones))\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} upscale dining zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying upscale dining zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_financial_district_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        金融區場景的功能區域\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            金融區功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別交通區域\n",
        "            traffic_items = []\n",
        "            traffic_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [1, 2, 3, 5, 6, 7, 9]:  # 各種車輛和交通燈\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in traffic_regions:\n",
        "                        traffic_regions[region] = []\n",
        "                    traffic_regions[region].append(obj)\n",
        "                    traffic_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if traffic_items:\n",
        "                main_traffic_region = max(traffic_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_traffic_region[0] is not None:\n",
        "                    zones[\"traffic_zone\"] = {\n",
        "                        \"region\": main_traffic_region[0],\n",
        "                        \"objects\": list(set(traffic_items)),\n",
        "                        \"description\": f\"Urban traffic area with {', '.join(list(set(traffic_items))[:3])}\"\n",
        "                    }\n",
        "\n",
        "            # 側邊建築區域（從場景情境推斷）\n",
        "            zones.update(self._identify_building_zones(detected_objects))\n",
        "\n",
        "            # 行人區域\n",
        "            zones.update(self._identify_financial_pedestrian_zones(detected_objects))\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} financial district zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying financial district zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def identify_landmark_zones(self, landmark_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        辨識與地標相關的功能區域\n",
        "\n",
        "        Args:\n",
        "            landmark_objects: 被辨識為地標的物體列表\n",
        "\n",
        "        Returns:\n",
        "            地標相關的功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            landmark_zones = {}\n",
        "\n",
        "            # 如果沒有任何地標，就直接回空字典\n",
        "            if not landmark_objects:\n",
        "                logger.warning(\"No landmark objects provided to identify_landmark_zones\")\n",
        "                return landmark_zones\n",
        "\n",
        "            # 只取第一個地標來示範：至少產生一個地標\n",
        "            landmark = landmark_objects[0]\n",
        "            # 確保傳入的 landmark 是 dict\n",
        "            if not isinstance(landmark, dict):\n",
        "                logger.warning(\"First landmark object is not a dict\")\n",
        "                return landmark_zones\n",
        "\n",
        "            # 從 landmark dict 拿出必要欄位\n",
        "            landmark_id = landmark.get(\"landmark_id\", \"unknown_landmark\")\n",
        "            landmark_name = landmark.get(\"class_name\", \"Landmark\")\n",
        "            landmark_type = landmark.get(\"landmark_type\", \"architectural\")\n",
        "            landmark_region = landmark.get(\"region\", \"middle_center\")\n",
        "\n",
        "            # 如果 location 沒提供，就給預設 \"this area\"\n",
        "            location = landmark.get(\"location\")\n",
        "            if not location:\n",
        "                location = \"this area\"\n",
        "\n",
        "            # 為地標創建主要觀景區\n",
        "            zone_id = f\"{landmark_name.lower().replace(' ', '_')}_viewing_area\"\n",
        "            zone_name = f\"{landmark_name} Viewing Area\"\n",
        "\n",
        "            # 根據地標類型調整描述，並確保帶入地點\n",
        "            if landmark_type == \"natural\":\n",
        "                zone_description = (\n",
        "                    f\"Scenic viewpoint for observing {landmark_name}, \"\n",
        "                    f\"a notable natural landmark in {location}.\"\n",
        "                )\n",
        "                primary_function = \"Nature observation and photography\"\n",
        "            elif landmark_type == \"monument\":\n",
        "                zone_description = (\n",
        "                    f\"Viewing area around {landmark_name}, \"\n",
        "                    f\"a significant monument in {location}.\"\n",
        "                )\n",
        "                primary_function = \"Historical appreciation and cultural tourism\"\n",
        "            else:  # architectural\n",
        "                zone_description = (\n",
        "                    f\"Area centered around {landmark_name}, \"\n",
        "                    f\"where visitors can observe and appreciate this iconic structure in {location}.\"\n",
        "                )\n",
        "                primary_function = \"Architectural tourism and photography\"\n",
        "\n",
        "            # 確定與地標相關的物體（如果被偵測到）\n",
        "            related_objects = []\n",
        "            for o in landmark_objects:\n",
        "                cn = o.get(\"class_name\", \"\").lower()\n",
        "                if cn in [\"person\", \"camera\", \"cell phone\", \"backpack\"]:\n",
        "                    related_objects.append(cn)\n",
        "\n",
        "            # 建立地標功能區\n",
        "            landmark_zones[zone_id] = {\n",
        "                \"name\": zone_name,\n",
        "                \"description\": zone_description,\n",
        "                \"objects\": [\"landmark\"] + related_objects,\n",
        "                \"region\": landmark_region,\n",
        "                \"primary_function\": primary_function\n",
        "            }\n",
        "\n",
        "            # 創建相關輔助功能區，如攝影區、紀念品販賣區\n",
        "            auxiliary_zones = self._create_landmark_auxiliary_zones(landmark, 0)\n",
        "            if auxiliary_zones:\n",
        "                landmark_zones.update(auxiliary_zones)\n",
        "\n",
        "            logger.info(f\"Identified {len(landmark_zones)} landmark zones\")\n",
        "            return landmark_zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in identify_landmark_zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "\n",
        "    def _identify_primary_functional_area(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別主要功能區域，基於最強的物件關聯性組合\n",
        "        採用通用邏輯處理各種室內場景\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            主要功能區域字典或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 用餐區域檢測（桌椅組合）\n",
        "            dining_area = self._detect_functional_combination(\n",
        "                detected_objects,\n",
        "                primary_objects=[60],  # dining table\n",
        "                supporting_objects=[56, 40, 41, 42, 43],  # chair, wine glass, cup, fork, knife\n",
        "                min_supporting=2,\n",
        "                description_template=\"Dining area with table and seating arrangement\"\n",
        "            )\n",
        "            if dining_area:\n",
        "                return dining_area\n",
        "\n",
        "            # 休息區域檢測（沙發電視組合或床）\n",
        "            seating_area = self._detect_functional_combination(\n",
        "                detected_objects,\n",
        "                primary_objects=[57, 59],  # sofa, bed\n",
        "                supporting_objects=[62, 58, 56],  # tv, potted plant, chair\n",
        "                min_supporting=1,\n",
        "                description_template=\"Seating and relaxation area\"\n",
        "            )\n",
        "            if seating_area:\n",
        "                return seating_area\n",
        "\n",
        "            # 工作區域檢測（電子設備與家具組合）\n",
        "            work_area = self._detect_functional_combination(\n",
        "                detected_objects,\n",
        "                primary_objects=[63, 66],  # laptop, keyboard\n",
        "                supporting_objects=[60, 56, 64],  # dining table, chair, mouse\n",
        "                min_supporting=2,\n",
        "                description_template=\"Workspace area with electronics and furniture\"\n",
        "            )\n",
        "            if work_area:\n",
        "                return work_area\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying primary functional area: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None\n",
        "\n",
        "    def _identify_secondary_functional_area(self, detected_objects: List[Dict], existing_zones: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        識別次要功能區域，避免與主要區域重疊\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            existing_zones: 已存在的功能區域\n",
        "\n",
        "        Returns:\n",
        "            次要功能區域字典或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 獲取已使用的區域\n",
        "            used_regions = set(zone.get(\"region\") for zone in existing_zones.values())\n",
        "\n",
        "            # 裝飾區域檢測（植物集中區域）\n",
        "            decorative_area = self._detect_functional_combination(\n",
        "                detected_objects,\n",
        "                primary_objects=[58],  # potted plant\n",
        "                supporting_objects=[75],  # vase\n",
        "                min_supporting=0,\n",
        "                min_primary=3,  # 至少需要3個植物\n",
        "                description_template=\"Decorative area with plants and ornamental items\",\n",
        "                exclude_regions=used_regions\n",
        "            )\n",
        "            if decorative_area:\n",
        "                return decorative_area\n",
        "\n",
        "            # 儲存區域檢測（廚房電器組合）\n",
        "            storage_area = self._detect_functional_combination(\n",
        "                detected_objects,\n",
        "                primary_objects=[72, 68, 69],  # refrigerator, microwave, oven\n",
        "                supporting_objects=[71],  # sink\n",
        "                min_supporting=0,\n",
        "                min_primary=2,\n",
        "                description_template=\"Kitchen appliance and storage area\",\n",
        "                exclude_regions=used_regions\n",
        "            )\n",
        "            if storage_area:\n",
        "                return storage_area\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying secondary functional area: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None\n",
        "\n",
        "    def _detect_functional_combination(self, detected_objects: List[Dict], primary_objects: List[int],\n",
        "                                    supporting_objects: List[int], min_supporting: int,\n",
        "                                    description_template: str, min_primary: int = 1,\n",
        "                                    exclude_regions: set = None) -> Dict:\n",
        "        \"\"\"\n",
        "        通用的功能組合檢測方法\n",
        "        基於主要物件和支持物件的組合判斷功能區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            primary_objects: 主要物件的class_id列表\n",
        "            supporting_objects: 支持物件的class_id列表\n",
        "            min_supporting: 最少需要的支持物件數量\n",
        "            description_template: 描述模板\n",
        "            min_primary: 最少需要的主要物件數量\n",
        "            exclude_regions: 需要排除的區域集合\n",
        "\n",
        "        Returns:\n",
        "            功能區域資訊字典，如果不符合條件則返回None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if exclude_regions is None:\n",
        "                exclude_regions = set()\n",
        "\n",
        "            # 收集主要物件\n",
        "            primary_objs = [obj for obj in detected_objects\n",
        "                        if obj.get(\"class_id\") in primary_objects and obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "            # 收集支持物件\n",
        "            supporting_objs = [obj for obj in detected_objects\n",
        "                            if obj.get(\"class_id\") in supporting_objects and obj.get(\"confidence\", 0) >= 0.4]\n",
        "\n",
        "            # 檢查是否滿足最少數量要求\n",
        "            if len(primary_objs) < min_primary or len(supporting_objs) < min_supporting:\n",
        "                return None\n",
        "\n",
        "            # 按區域組織物件\n",
        "            region_combinations = {}\n",
        "            all_relevant_objs = primary_objs + supporting_objs\n",
        "\n",
        "            for obj in all_relevant_objs:\n",
        "                region = obj.get(\"region\")\n",
        "\n",
        "                # 排除指定區域\n",
        "                if region in exclude_regions:\n",
        "                    continue\n",
        "\n",
        "                if region not in region_combinations:\n",
        "                    region_combinations[region] = {\"primary\": [], \"supporting\": [], \"all\": []}\n",
        "\n",
        "                region_combinations[region][\"all\"].append(obj)\n",
        "\n",
        "                if obj.get(\"class_id\") in primary_objects:\n",
        "                    region_combinations[region][\"primary\"].append(obj)\n",
        "                else:\n",
        "                    region_combinations[region][\"supporting\"].append(obj)\n",
        "\n",
        "            # 找到最佳區域組合\n",
        "            best_region = None\n",
        "            best_score = 0\n",
        "\n",
        "            for region, objs in region_combinations.items():\n",
        "                # 計算該區域的評分\n",
        "                primary_count = len(objs[\"primary\"])\n",
        "                supporting_count = len(objs[\"supporting\"])\n",
        "\n",
        "                # 必須滿足最低要求\n",
        "                if primary_count < min_primary or supporting_count < min_supporting:\n",
        "                    continue\n",
        "\n",
        "                # 計算組合評分（主要物件權重較高）\n",
        "                score = primary_count * 2 + supporting_count\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_region = region\n",
        "\n",
        "            if best_region is None:\n",
        "                return None\n",
        "\n",
        "            best_combination = region_combinations[best_region]\n",
        "            all_objects = [obj[\"class_name\"] for obj in best_combination[\"all\"]]\n",
        "\n",
        "            return {\n",
        "                \"region\": best_region,\n",
        "                \"objects\": all_objects,\n",
        "                \"description\": description_template\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error detecting functional combination: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None\n",
        "\n",
        "    def _analyze_crossing_patterns(self, pedestrians: List[Dict], traffic_lights: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze pedestrian crossing patterns to identify crossing zones.\n",
        "        若同一 region 中同時有行人與紅綠燈，則將兩者都放入該區域的 objects。\n",
        "\n",
        "        Args:\n",
        "            pedestrians: 行人物件列表（每個 obj 應包含 'class_id', 'region', 'confidence' 等）\n",
        "            traffic_lights: 紅綠燈物件列表（每個 obj 應包含 'class_id', 'region', 'confidence' 等）\n",
        "\n",
        "        Returns:\n",
        "            crossing_zones: 字典，key 為 zone 名稱，value 包含 'region', 'objects', 'description'\n",
        "        \"\"\"\n",
        "        try:\n",
        "            crossing_zones = {}\n",
        "\n",
        "            # 如果沒有任何行人，就不辨識任何 crossing zone\n",
        "            if not pedestrians:\n",
        "                return crossing_zones\n",
        "\n",
        "            # (1) 按照 region 分組行人\n",
        "            pedestrian_regions = {}\n",
        "            for p in pedestrians:\n",
        "                region = p[\"region\"]\n",
        "                pedestrian_regions.setdefault(region, []).append(p)\n",
        "\n",
        "            # (2) 針對每個 region，看是否同時有紅綠燈\n",
        "            # 建立一個 mapping： region -> { \"pedestrians\": [...], \"traffic_lights\": [...] }\n",
        "            combined_regions = {}\n",
        "            for region, peds in pedestrian_regions.items():\n",
        "                # 取得該 region 下所有紅綠燈\n",
        "                tls_in_region = [t for t in traffic_lights if t[\"region\"] == region]\n",
        "                combined_regions[region] = {\n",
        "                    \"pedestrians\": peds,\n",
        "                    \"traffic_lights\": tls_in_region\n",
        "                }\n",
        "\n",
        "            # (3) 按照行人數量排序，找出前兩個需要建立 crossing zone 的 region\n",
        "            sorted_regions = sorted(\n",
        "                combined_regions.items(),\n",
        "                key=lambda x: len(x[1][\"pedestrians\"]),\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            # (4) 將前兩個 region 建立 Crossing Zone，objects 同時包含行人與紅綠燈\n",
        "            for idx, (region, group) in enumerate(sorted_regions[:2]):\n",
        "                peds = group[\"pedestrians\"]\n",
        "                tls  = group[\"traffic_lights\"]\n",
        "                has_nearby_signals = len(tls) > 0\n",
        "\n",
        "                # 生成 zone_name（基於 region 方向 + idx 決定主/次 crossing）\n",
        "                direction = self._get_directional_description(region)\n",
        "                if direction and direction != \"central\":\n",
        "                    zone_name = f\"{direction} crossing area\"\n",
        "                else:\n",
        "                    zone_name = \"main crossing area\" if idx == 0 else \"secondary crossing area\"\n",
        "\n",
        "                # 組合 description\n",
        "                description = f\"Pedestrian crossing area with {len(peds)} \"\n",
        "                description += \"person\" if len(peds) == 1 else \"people\"\n",
        "                if direction:\n",
        "                    description += f\" in {direction} direction\"\n",
        "                if has_nearby_signals:\n",
        "                    description += \" near traffic signals\"\n",
        "\n",
        "                # ======= 將行人 + 同區紅綠燈一併放入 objects =======\n",
        "                obj_list = [\"pedestrian\"] * len(peds)\n",
        "                if has_nearby_signals:\n",
        "                    obj_list += [\"traffic light\"] * len(tls)\n",
        "\n",
        "                crossing_zones[zone_name] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": obj_list,\n",
        "                    \"description\": description\n",
        "                }\n",
        "\n",
        "            return crossing_zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _analyze_crossing_patterns: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "\n",
        "    def _analyze_traffic_zones(self, vehicles: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析車輛分布以識別具有方向感知的交通區域\n",
        "\n",
        "        Args:\n",
        "            vehicles: 車輛物件列表\n",
        "\n",
        "        Returns:\n",
        "            識別出的交通區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            traffic_zones = {}\n",
        "\n",
        "            if not vehicles:\n",
        "                return traffic_zones\n",
        "\n",
        "            # 按區域分組車輛\n",
        "            vehicle_regions = {}\n",
        "            for v in vehicles:\n",
        "                region = v[\"region\"]\n",
        "                if region not in vehicle_regions:\n",
        "                    vehicle_regions[region] = []\n",
        "                vehicle_regions[region].append(v)\n",
        "\n",
        "            # 為有車輛的區域創建交通區域\n",
        "            main_traffic_region = max(vehicle_regions.items(), key=lambda x: len(x[1]), default=(None, []))\n",
        "\n",
        "            if main_traffic_region[0] is not None:\n",
        "                region = main_traffic_region[0]\n",
        "                vehicles_in_region = main_traffic_region[1]\n",
        "\n",
        "                # 獲取車輛類型列表用於描述\n",
        "                vehicle_types = [v[\"class_name\"] for v in vehicles_in_region]\n",
        "                unique_types = list(set(vehicle_types))\n",
        "\n",
        "                # 獲取方向描述\n",
        "                direction = self._get_directional_description(region)\n",
        "\n",
        "                # 創建描述性區域\n",
        "                traffic_zones[\"vehicle_zone\"] = {\n",
        "                    \"region\": region,\n",
        "                    \"objects\": vehicle_types,\n",
        "                    \"description\": f\"Vehicle traffic area with {', '.join(unique_types[:3])}\" +\n",
        "                                (f\" in {direction} area\" if direction else \"\")\n",
        "                }\n",
        "\n",
        "                # 如果車輛分布在多個區域，創建次要區域\n",
        "                if len(vehicle_regions) > 1:\n",
        "                    # 獲取第二大車輛聚集區域\n",
        "                    sorted_regions = sorted(vehicle_regions.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "                    if len(sorted_regions) > 1:\n",
        "                        second_region, second_vehicles = sorted_regions[1]\n",
        "                        direction = self._get_directional_description(second_region)\n",
        "                        vehicle_types = [v[\"class_name\"] for v in second_vehicles]\n",
        "                        unique_types = list(set(vehicle_types))\n",
        "\n",
        "                        traffic_zones[\"secondary_vehicle_zone\"] = {\n",
        "                            \"region\": second_region,\n",
        "                            \"objects\": vehicle_types,\n",
        "                            \"description\": f\"Secondary traffic area with {', '.join(unique_types[:2])}\" +\n",
        "                                        (f\" in {direction} direction\" if direction else \"\")\n",
        "                        }\n",
        "\n",
        "            return traffic_zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing traffic zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _get_directional_description(self, region: str) -> str:\n",
        "        \"\"\"\n",
        "        將區域名稱轉換為方位描述（東西南北）\n",
        "\n",
        "        Args:\n",
        "            region: 區域名稱\n",
        "\n",
        "        Returns:\n",
        "            方位描述字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            region_lower = region.lower()\n",
        "\n",
        "            if \"top\" in region_lower and \"left\" in region_lower:\n",
        "                return \"northwest\"\n",
        "            elif \"top\" in region_lower and \"right\" in region_lower:\n",
        "                return \"northeast\"\n",
        "            elif \"bottom\" in region_lower and \"left\" in region_lower:\n",
        "                return \"southwest\"\n",
        "            elif \"bottom\" in region_lower and \"right\" in region_lower:\n",
        "                return \"southeast\"\n",
        "            elif \"top\" in region_lower:\n",
        "                return \"north\"\n",
        "            elif \"bottom\" in region_lower:\n",
        "                return \"south\"\n",
        "            elif \"left\" in region_lower:\n",
        "                return \"west\"\n",
        "            elif \"right\" in region_lower:\n",
        "                return \"east\"\n",
        "            else:\n",
        "                return \"central\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting directional description for region '{region}': {str(e)}\")\n",
        "            return \"central\"\n",
        "\n",
        "    def _identify_park_recreational_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別公園的休閒活動區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            休閒區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 尋找休閒物件（運動球、風箏等）\n",
        "            rec_items = []\n",
        "            rec_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [32, 33, 34, 35, 38]:  # sports ball, kite, baseball bat, glove, tennis racket\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in rec_regions:\n",
        "                        rec_regions[region] = []\n",
        "                    rec_regions[region].append(obj)\n",
        "                    rec_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if rec_items:\n",
        "                main_rec_region = max(rec_regions.items(),\n",
        "                                key=lambda x: len(x[1]),\n",
        "                                default=(None, []))\n",
        "\n",
        "                if main_rec_region[0] is not None:\n",
        "                    zones[\"recreational_zone\"] = {\n",
        "                        \"region\": main_rec_region[0],\n",
        "                        \"objects\": list(set(rec_items)),\n",
        "                        \"description\": f\"Recreational area with {', '.join(list(set(rec_items)))}\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying park recreational zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_parking_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        停車場的停車區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            停車區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 尋找停放的汽車\n",
        "            car_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 2]  # cars\n",
        "\n",
        "            if len(car_objs) >= 3:\n",
        "                # 檢查汽車是否按模式排列（簡化）\n",
        "                car_positions = [obj[\"normalized_center\"] for obj in car_objs]\n",
        "\n",
        "                # 通過分析垂直位置檢查行模式\n",
        "                y_coords = [pos[1] for pos in car_positions]\n",
        "                y_clusters = {}\n",
        "\n",
        "                # 簡化聚類 - 按相似y坐標分組汽車\n",
        "                for i, y in enumerate(y_coords):\n",
        "                    assigned = False\n",
        "                    for cluster_y in y_clusters.keys():\n",
        "                        if abs(y - cluster_y) < 0.1:  # 圖像高度的10%內\n",
        "                            y_clusters[cluster_y].append(i)\n",
        "                            assigned = True\n",
        "                            break\n",
        "\n",
        "                    if not assigned:\n",
        "                        y_clusters[y] = [i]\n",
        "\n",
        "                # 如果有行模式\n",
        "                if max(len(indices) for indices in y_clusters.values()) >= 2:\n",
        "                    zones[\"parking_row\"] = {\n",
        "                        \"region\": \"central\",\n",
        "                        \"objects\": [\"car\"] * len(car_objs),\n",
        "                        \"description\": f\"Organized parking area with vehicles arranged in rows\"\n",
        "                    }\n",
        "                else:\n",
        "                    zones[\"parking_area\"] = {\n",
        "                        \"region\": \"wide\",\n",
        "                        \"objects\": [\"car\"] * len(car_objs),\n",
        "                        \"description\": f\"Parking area with {len(car_objs)} vehicles\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying parking zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _analyze_aerial_traffic_patterns(self, vehicle_objs: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析空中視角的車輛交通模式\n",
        "\n",
        "        Args:\n",
        "            vehicle_objs: 車輛物件列表\n",
        "\n",
        "        Returns:\n",
        "            交通模式區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            if not vehicle_objs:\n",
        "                return zones\n",
        "\n",
        "            # 將位置轉換為數組進行模式分析\n",
        "            positions = np.array([obj[\"normalized_center\"] for obj in vehicle_objs])\n",
        "\n",
        "            if len(positions) >= 2:\n",
        "                # 計算分布指標\n",
        "                x_coords = positions[:, 0]\n",
        "                y_coords = positions[:, 1]\n",
        "\n",
        "                x_mean = np.mean(x_coords)\n",
        "                y_mean = np.mean(y_coords)\n",
        "                x_std = np.std(x_coords)\n",
        "                y_std = np.std(y_coords)\n",
        "\n",
        "                # 判斷車輛是否組織成車道\n",
        "                if x_std < y_std * 0.5:\n",
        "                    # 車輛垂直對齊 - 表示南北交通\n",
        "                    zones[\"vertical_traffic_flow\"] = {\n",
        "                        \"region\": \"central_vertical\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"North-south traffic flow visible from aerial view\"\n",
        "                    }\n",
        "                elif y_std < x_std * 0.5:\n",
        "                    # 車輛水平對齊 - 表示東西交通\n",
        "                    zones[\"horizontal_traffic_flow\"] = {\n",
        "                        \"region\": \"central_horizontal\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"East-west traffic flow visible from aerial view\"\n",
        "                    }\n",
        "                else:\n",
        "                    # 車輛多方向 - 表示十字路口\n",
        "                    zones[\"intersection_traffic\"] = {\n",
        "                        \"region\": \"central\",\n",
        "                        \"objects\": [obj[\"class_name\"] for obj in vehicle_objs[:5]],\n",
        "                        \"description\": \"Multi-directional traffic at intersection visible from aerial view\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing aerial traffic patterns: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_aerial_intersection_features(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        空中視角十字路口特徵\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            十字路口特徵區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 檢查交通信號\n",
        "            traffic_light_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 9]\n",
        "            if traffic_light_objs:\n",
        "                zones[\"traffic_control_pattern\"] = {\n",
        "                    \"region\": \"intersection\",\n",
        "                    \"objects\": [\"traffic light\"] * len(traffic_light_objs),\n",
        "                    \"description\": f\"Intersection traffic control with {len(traffic_light_objs)} signals visible from above\"\n",
        "                }\n",
        "\n",
        "            # 人行道從空中視角的情境推斷\n",
        "            zones[\"crossing_pattern\"] = {\n",
        "                \"region\": \"central\",\n",
        "                \"objects\": [\"inferred crosswalk\"],\n",
        "                \"description\": \"Crossing pattern visible from aerial perspective\"\n",
        "            }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying aerial intersection features: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_aerial_plaza_features(self, people_objs: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別空中視角廣場特徵\n",
        "\n",
        "        Args:\n",
        "            people_objs: 行人物件列表\n",
        "\n",
        "        Returns:\n",
        "            廣場特徵區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            if people_objs:\n",
        "                # 檢查人群是否聚集在中央區域\n",
        "                central_people = [obj for obj in people_objs\n",
        "                                if \"middle\" in obj[\"region\"]]\n",
        "\n",
        "                if central_people:\n",
        "                    zones[\"central_gathering\"] = {\n",
        "                        \"region\": \"middle_center\",\n",
        "                        \"objects\": [\"person\"] * len(central_people),\n",
        "                        \"description\": f\"Central plaza gathering area with {len(central_people)} people viewed from above\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying aerial plaza features: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_asian_pedestrian_pathway(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        亞洲文化場景中的行人通道\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            行人通道區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            pathway_items = []\n",
        "            pathway_regions = {}\n",
        "\n",
        "            # 提取人群用於通道分析\n",
        "            people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "\n",
        "            # 分析人群是否形成線形（商業街的特徵）\n",
        "            people_positions = [obj[\"normalized_center\"] for obj in people_objs]\n",
        "\n",
        "            structured_path = False\n",
        "            path_direction = \"meandering\"\n",
        "\n",
        "            if len(people_positions) >= 3:\n",
        "                # 檢查人群是否沿相似y坐標排列（水平路徑）\n",
        "                y_coords = [pos[1] for pos in people_positions]\n",
        "                y_mean = sum(y_coords) / len(y_coords)\n",
        "                y_variance = sum((y - y_mean)**2 for y in y_coords) / len(y_coords)\n",
        "\n",
        "                horizontal_path = y_variance < 0.05  # 低變異表示水平對齊\n",
        "\n",
        "                # 檢查人群是否沿相似x坐標排列（垂直路徑）\n",
        "                x_coords = [pos[0] for pos in people_positions]\n",
        "                x_mean = sum(x_coords) / len(x_coords)\n",
        "                x_variance = sum((x - x_mean)**2 for x in x_coords) / len(x_coords)\n",
        "\n",
        "                vertical_path = x_variance < 0.05  # 低變異表示垂直對齊\n",
        "\n",
        "                structured_path = horizontal_path or vertical_path\n",
        "                path_direction = \"horizontal\" if horizontal_path else \"vertical\" if vertical_path else \"meandering\"\n",
        "\n",
        "            # 收集通道物件（人、自行車、摩托車在中間區域）\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [0, 1, 3]:  # Person, bicycle, motorcycle\n",
        "                    y_pos = obj[\"normalized_center\"][1]\n",
        "                    # 按垂直位置分組（圖像中間可能是通道）\n",
        "                    if 0.25 <= y_pos <= 0.75:\n",
        "                        region = obj[\"region\"]\n",
        "                        if region not in pathway_regions:\n",
        "                            pathway_regions[region] = []\n",
        "                        pathway_regions[region].append(obj)\n",
        "                        pathway_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if pathway_items:\n",
        "                path_desc = \"Pedestrian walkway with people moving through the commercial area\"\n",
        "                if structured_path:\n",
        "                    path_desc = f\"{path_direction.capitalize()} pedestrian walkway with organized foot traffic\"\n",
        "\n",
        "                zones[\"pedestrian_pathway\"] = {\n",
        "                    \"region\": \"middle_center\",  # 假設：通道通常在中間\n",
        "                    \"objects\": list(set(pathway_items)),\n",
        "                    \"description\": path_desc\n",
        "                }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying Asian pedestrian pathway: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_vendor_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別攤販區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            攤販區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別攤販區域（小攤/商店 - 從情境推斷）\n",
        "            has_small_objects = any(obj[\"class_id\"] in [24, 26, 39, 41] for obj in detected_objects)  # bags, bottles, cups\n",
        "            has_people = any(obj[\"class_id\"] == 0 for obj in detected_objects)\n",
        "\n",
        "            if has_small_objects and has_people:\n",
        "                # 可能的攤販區域是人群和小物件聚集的地方\n",
        "                small_obj_regions = {}\n",
        "\n",
        "                for obj in detected_objects:\n",
        "                    if obj[\"class_id\"] in [24, 26, 39, 41, 67]:  # bags, bottles, cups, phones\n",
        "                        region = obj[\"region\"]\n",
        "                        if region not in small_obj_regions:\n",
        "                            small_obj_regions[region] = []\n",
        "                        small_obj_regions[region].append(obj)\n",
        "\n",
        "                if small_obj_regions:\n",
        "                    main_vendor_region = max(small_obj_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        default=(None, []))\n",
        "\n",
        "                    if main_vendor_region[0] is not None:\n",
        "                        vendor_items = [obj[\"class_name\"] for obj in main_vendor_region[1]]\n",
        "                        zones[\"vendor_zone\"] = {\n",
        "                            \"region\": main_vendor_region[0],\n",
        "                            \"objects\": list(set(vendor_items)),\n",
        "                            \"description\": \"Vendor or market stall area with small merchandise\"\n",
        "                        }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying vendor zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_upscale_decorative_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別高級餐飲的裝飾區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            裝飾區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            decor_items = []\n",
        "            decor_regions = {}\n",
        "\n",
        "            # 尋找裝飾元素（花瓶、酒杯、未使用的餐具）\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [75, 40]:  # Vase, wine glass\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in decor_regions:\n",
        "                        decor_regions[region] = []\n",
        "                    decor_regions[region].append(obj)\n",
        "                    decor_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if decor_items:\n",
        "                main_decor_region = max(decor_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_decor_region[0] is not None:\n",
        "                    zones[\"decorative_zone\"] = {\n",
        "                        \"region\": main_decor_region[0],\n",
        "                        \"objects\": list(set(decor_items)),\n",
        "                        \"description\": f\"Decorative area with {', '.join(list(set(decor_items)))}\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying upscale decorative zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_dining_seating_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別餐廳座位安排區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            座位區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別座位安排區域\n",
        "            chairs = [obj for obj in detected_objects if obj[\"class_id\"] == 56]  # chairs\n",
        "            if len(chairs) >= 2:\n",
        "                chair_regions = {}\n",
        "                for obj in chairs:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in chair_regions:\n",
        "                        chair_regions[region] = []\n",
        "                    chair_regions[region].append(obj)\n",
        "\n",
        "                if chair_regions:\n",
        "                    main_seating_region = max(chair_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        default=(None, []))\n",
        "\n",
        "                    if main_seating_region[0] is not None:\n",
        "                        zones[\"dining_seating_zone\"] = {\n",
        "                            \"region\": main_seating_region[0],\n",
        "                            \"objects\": [\"chair\"] * len(main_seating_region[1]),\n",
        "                            \"description\": f\"Formal dining seating arrangement with {len(main_seating_region[1])} chairs\"\n",
        "                        }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying dining seating zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_serving_zones(self, detected_objects: List[Dict], existing_zones: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        識別服務區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            existing_zones: 已存在的功能區域\n",
        "\n",
        "        Returns:\n",
        "            服務區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            serving_items = []\n",
        "            serving_regions = {}\n",
        "\n",
        "            # 服務區域可能有瓶子、碗、容器\n",
        "            for obj in detected_objects:\n",
        "                if obj[\"class_id\"] in [39, 45]:  # Bottle, bowl\n",
        "                    # 檢查是否在與主餐桌不同的區域\n",
        "                    if \"formal_dining_zone\" in existing_zones and obj[\"region\"] != existing_zones[\"formal_dining_zone\"][\"region\"]:\n",
        "                        region = obj[\"region\"]\n",
        "                        if region not in serving_regions:\n",
        "                            serving_regions[region] = []\n",
        "                        serving_regions[region].append(obj)\n",
        "                        serving_items.append(obj[\"class_name\"])\n",
        "\n",
        "            if serving_items:\n",
        "                main_serving_region = max(serving_regions.items(),\n",
        "                                    key=lambda x: len(x[1]),\n",
        "                                    default=(None, []))\n",
        "\n",
        "                if main_serving_region[0] is not None:\n",
        "                    zones[\"serving_zone\"] = {\n",
        "                        \"region\": main_serving_region[0],\n",
        "                        \"objects\": list(set(serving_items)),\n",
        "                        \"description\": f\"Serving or sideboard area with {', '.join(list(set(serving_items)))}\"\n",
        "                    }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying serving zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_building_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別建築區域（從場景情境推斷）\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            建築區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 側邊建築區域（從場景情境推斷）\n",
        "            # 檢查是否有實際可能包含建築物的區域\n",
        "            left_side_regions = [\"top_left\", \"middle_left\", \"bottom_left\"]\n",
        "            right_side_regions = [\"top_right\", \"middle_right\", \"bottom_right\"]\n",
        "\n",
        "            # 檢查左側\n",
        "            left_building_evidence = True\n",
        "            for region in left_side_regions:\n",
        "                # 如果此區域有很多車輛或人群，不太可能是建築物\n",
        "                vehicle_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] in [1, 2, 3, 5, 7]\n",
        "                                    for obj in detected_objects)\n",
        "                people_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] == 0\n",
        "                                    for obj in detected_objects)\n",
        "\n",
        "                if vehicle_in_region or people_in_region:\n",
        "                    left_building_evidence = False\n",
        "                    break\n",
        "\n",
        "            # 檢查右側\n",
        "            right_building_evidence = True\n",
        "            for region in right_side_regions:\n",
        "                # 如果此區域有很多車輛或人群，不太可能是建築物\n",
        "                vehicle_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] in [1, 2, 3, 5, 7]\n",
        "                                    for obj in detected_objects)\n",
        "                people_in_region = any(obj[\"region\"] == region and obj[\"class_id\"] == 0\n",
        "                                    for obj in detected_objects)\n",
        "\n",
        "                if vehicle_in_region or people_in_region:\n",
        "                    right_building_evidence = False\n",
        "                    break\n",
        "\n",
        "            # 如果證據支持，添加建築區域\n",
        "            if left_building_evidence:\n",
        "                zones[\"building_zone_left\"] = {\n",
        "                    \"region\": \"middle_left\",\n",
        "                    \"objects\": [\"building\"],  # 推斷\n",
        "                    \"description\": \"Tall buildings line the left side of the street\"\n",
        "                }\n",
        "\n",
        "            if right_building_evidence:\n",
        "                zones[\"building_zone_right\"] = {\n",
        "                    \"region\": \"middle_right\",\n",
        "                    \"objects\": [\"building\"],  # 推斷\n",
        "                    \"description\": \"Tall buildings line the right side of the street\"\n",
        "                }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying building zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _identify_financial_pedestrian_zones(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        識別金融區的行人區域\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            行人區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 識別行人區域（如果有人群）\n",
        "            people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            if people_objs:\n",
        "                people_regions = {}\n",
        "                for obj in people_objs:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in people_regions:\n",
        "                        people_regions[region] = []\n",
        "                    people_regions[region].append(obj)\n",
        "\n",
        "                if people_regions:\n",
        "                    main_pedestrian_region = max(people_regions.items(),\n",
        "                                            key=lambda x: len(x[1]),\n",
        "                                            default=(None, []))\n",
        "\n",
        "                    if main_pedestrian_region[0] is not None:\n",
        "                        zones[\"pedestrian_zone\"] = {\n",
        "                            \"region\": main_pedestrian_region[0],\n",
        "                            \"objects\": [\"person\"] * len(main_pedestrian_region[1]),\n",
        "                            \"description\": f\"Pedestrian area with {len(main_pedestrian_region[1])} people navigating the financial district\"\n",
        "                        }\n",
        "\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying financial pedestrian zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _create_landmark_auxiliary_zones(self, landmark: Dict, index: int) -> Dict:\n",
        "        \"\"\"\n",
        "        創建地標相關的輔助區域（攝影區、紀念品區等）\n",
        "\n",
        "        Args:\n",
        "            landmark: 地標物件字典\n",
        "            index: 地標索引\n",
        "\n",
        "        Returns:\n",
        "            輔助區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            auxiliary_zones = {}\n",
        "            landmark_region = landmark.get(\"region\", \"middle_center\")\n",
        "            landmark_name = landmark.get(\"class_name\", \"Landmark\")\n",
        "\n",
        "            # 創建攝影區\n",
        "            # 根據地標位置調整攝影區位置（地標前方通常是攝影區）\n",
        "            region_mapping = {\n",
        "                \"top_left\": \"bottom_right\",\n",
        "                \"top_center\": \"bottom_center\",\n",
        "                \"top_right\": \"bottom_left\",\n",
        "                \"middle_left\": \"middle_right\",\n",
        "                \"middle_center\": \"bottom_center\",\n",
        "                \"middle_right\": \"middle_left\",\n",
        "                \"bottom_left\": \"top_right\",\n",
        "                \"bottom_center\": \"top_center\",\n",
        "                \"bottom_right\": \"top_left\"\n",
        "            }\n",
        "\n",
        "            photo_region = region_mapping.get(landmark_region, landmark_region)\n",
        "\n",
        "            photo_key = f\"{landmark_name.lower().replace(' ', '_')}_photography_spot\"\n",
        "            auxiliary_zones[photo_key] = {\n",
        "                \"name\": f\"{landmark_name} Photography Spot\",\n",
        "                \"description\": f\"Popular position for photographing {landmark_name} with optimal viewing angle.\",\n",
        "                \"objects\": [\"camera\", \"person\", \"cell phone\"],\n",
        "                \"region\": photo_region,\n",
        "                \"primary_function\": \"Tourist photography\"\n",
        "            }\n",
        "\n",
        "            # 如果是著名地標，可能有紀念品販售區\n",
        "            if landmark.get(\"confidence\", 0) > 0.7:  # 高置信度地標更可能有紀念品區\n",
        "                # 根據地標位置找到適合的紀念品區位置（通常在地標附近但不直接在地標上）\n",
        "                adjacent_regions = {\n",
        "                    \"top_left\": [\"top_center\", \"middle_left\"],\n",
        "                    \"top_center\": [\"top_left\", \"top_right\"],\n",
        "                    \"top_right\": [\"top_center\", \"middle_right\"],\n",
        "                    \"middle_left\": [\"top_left\", \"bottom_left\"],\n",
        "                    \"middle_center\": [\"middle_left\", \"middle_right\"],\n",
        "                    \"middle_right\": [\"top_right\", \"bottom_right\"],\n",
        "                    \"bottom_left\": [\"middle_left\", \"bottom_center\"],\n",
        "                    \"bottom_center\": [\"bottom_left\", \"bottom_right\"],\n",
        "                    \"bottom_right\": [\"bottom_center\", \"middle_right\"]\n",
        "                }\n",
        "\n",
        "                if landmark_region in adjacent_regions:\n",
        "                    souvenir_region = adjacent_regions[landmark_region][0]  # 選擇第一個相鄰區域\n",
        "\n",
        "                    souvenir_key = f\"{landmark_name.lower().replace(' ', '_')}_souvenir_area\"\n",
        "                    auxiliary_zones[souvenir_key] = {\n",
        "                        \"name\": f\"{landmark_name} Souvenir Area\",\n",
        "                        \"description\": f\"Area where visitors can purchase souvenirs and memorabilia related to {landmark_name}.\",\n",
        "                        \"objects\": [\"person\", \"handbag\", \"backpack\"],\n",
        "                        \"region\": souvenir_region,\n",
        "                        \"primary_function\": \"Tourism commerce\"\n",
        "                    }\n",
        "\n",
        "            return auxiliary_zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating landmark auxiliary zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}"
      ],
      "metadata": {
        "id": "mSaZ584MrrBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c30032-dfdb-4430-ddca-06e30c4bcacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scene_zone_identifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile functional_zone_identifier.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class FunctionalZoneIdentifier:\n",
        "    \"\"\"\n",
        "    作為功能區域辨識的主要窗口\n",
        "    整合區域評估和場景特定的區域辨識邏輯，提供統一的功能區域辨識接口\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, zone_evaluator=None, scene_zone_identifier=None, scene_viewpoint_analyzer=None):\n",
        "        \"\"\"\n",
        "        初始化功能區域識別器\n",
        "\n",
        "        Args:\n",
        "            zone_evaluator: 區域評估器實例\n",
        "            scene_zone_identifier: 場景區域辨識器實例\n",
        "            scene_viewpoint_analyzer: 場景視角分析器\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.zone_evaluator = zone_evaluator\n",
        "            self.scene_zone_identifier = scene_zone_identifier\n",
        "\n",
        "            self.scene_viewpoint_analyzer = scene_viewpoint_analyzer\n",
        "            self.viewpoint_detector = scene_viewpoint_analyzer\n",
        "\n",
        "            logger.info(\"FunctionalZoneIdentifier initialized successfully with SceneViewpointAnalyzer\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize FunctionalZoneIdentifier: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def identify_functional_zones(self, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        識別場景內的功能區域，具有針對不同視角和文化背景的改進檢測能力。\n",
        "        如果偵測到 is_landmark=True 的物件，則優先直接呼叫 identify_landmark_zones 並回傳結果。\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # 1. 如果沒有啟用地標功能，就先把所有有 is_landmark=True 的物件過濾掉\n",
        "            if not getattr(self, 'enable_landmark', True):\n",
        "                detected_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "\n",
        "            # 2. 只要檢測到任何 is_landmark=True 的物件，立即優先使用 identify_landmark_zones\n",
        "            landmark_objects = [obj for obj in detected_objects if obj.get(\"is_landmark\", False)]\n",
        "            if landmark_objects and self.scene_zone_identifier:\n",
        "                lm_zones = self.scene_zone_identifier.identify_landmark_zones(landmark_objects)\n",
        "                return self._standardize_zone_keys_and_descriptions(lm_zones)\n",
        "\n",
        "            # 3. city_street\n",
        "            if scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                scene_type = \"city_street\"\n",
        "\n",
        "            # 4.  判斷與物件數量檢查\n",
        "            if self.zone_evaluator:\n",
        "                should_identify = self.zone_evaluator.evaluate_zone_identification_feasibility(\n",
        "                    detected_objects, scene_type\n",
        "                )\n",
        "                if not should_identify:\n",
        "                    logger.info(f\"Zone identification not feasible for scene type '{scene_type}'\")\n",
        "                    return {}\n",
        "            else:\n",
        "                if len(detected_objects) < 2:\n",
        "                    logger.info(\"Insufficient objects for zone identification\")\n",
        "                    return {}\n",
        "\n",
        "            # 5. 建立 category_regions\n",
        "            category_regions = self._build_category_regions_mapping(detected_objects)\n",
        "            zones = {}\n",
        "\n",
        "            # 6. 檢測場景視角\n",
        "            viewpoint_info = {\"viewpoint\": \"eye_level\"}\n",
        "            if self.scene_viewpoint_analyzer:\n",
        "                viewpoint_info = self.scene_viewpoint_analyzer.detect_scene_viewpoint(detected_objects)\n",
        "\n",
        "            # 7. 根據不同 scene_type 使用各種自己的區域辨識\n",
        "            if scene_type in [\"living_room\", \"bedroom\", \"dining_area\", \"kitchen\", \"office_workspace\", \"meeting_room\"]:\n",
        "                if self.scene_zone_identifier:\n",
        "                    raw_zones = self.scene_zone_identifier.identify_indoor_zones(\n",
        "                        category_regions, detected_objects, scene_type\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(raw_zones))\n",
        "\n",
        "            elif scene_type in [\"city_street\", \"parking_lot\", \"park_area\"]:\n",
        "                if self.scene_zone_identifier:\n",
        "                    raw_zones = self.scene_zone_identifier.identify_outdoor_general_zones(\n",
        "                        category_regions, detected_objects, scene_type\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(raw_zones))\n",
        "\n",
        "            elif \"aerial\" in scene_type or viewpoint_info.get(\"viewpoint\") == \"aerial\":\n",
        "                if self.scene_zone_identifier:\n",
        "                    raw_zones = self.scene_zone_identifier.identify_aerial_view_zones(\n",
        "                        category_regions, detected_objects, scene_type\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(raw_zones))\n",
        "\n",
        "            elif \"asian\" in scene_type:\n",
        "                if self.scene_zone_identifier:\n",
        "                    asian_zones = self.scene_zone_identifier.identify_asian_cultural_zones(\n",
        "                        category_regions, detected_objects, scene_type\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(asian_zones))\n",
        "\n",
        "            elif scene_type == \"urban_intersection\":\n",
        "                if self.scene_zone_identifier:\n",
        "                    raw_zones = self.scene_zone_identifier.identify_intersection_zones(\n",
        "                        category_regions, detected_objects, viewpoint_info.get(\"viewpoint\")\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(raw_zones))\n",
        "                    used_tl_count_per_region = {}\n",
        "                    for zone_info in raw_zones.values():\n",
        "                        obj_list = zone_info.get(\"objects\", [])\n",
        "                        if \"traffic light\" in obj_list:\n",
        "                            rg = zone_info.get(\"region\", \"\")\n",
        "                            count_in_zone = obj_list.count(\"traffic light\")\n",
        "                            used_tl_count_per_region[rg] = used_tl_count_per_region.get(rg, 0) + count_in_zone\n",
        "\n",
        "                    signal_regions = {}\n",
        "                    for t in [obj for obj in detected_objects if obj.get(\"class_id\") == 9]:\n",
        "                        region = t.get(\"region\", \"\")\n",
        "                        signal_regions.setdefault(region, []).append(t)\n",
        "\n",
        "                    for idx, (region, signals) in enumerate(signal_regions.items()):\n",
        "                        total_in_region = len(signals)\n",
        "                        used_in_region = used_tl_count_per_region.get(region, 0)\n",
        "                        remaining_in_region = total_in_region - used_in_region\n",
        "\n",
        "                        if remaining_in_region > 0:\n",
        "                            direction = self._get_directional_description(region)\n",
        "                            if direction and direction != \"central\":\n",
        "                                zone_key = f\"{direction} traffic control area\"\n",
        "                            else:\n",
        "                                zone_key = \"primary traffic control area\" if idx == 0 else \"auxiliary traffic control area\"\n",
        "\n",
        "                            if zone_key in zones:\n",
        "                                suffix = 1\n",
        "                                new_key = f\"{zone_key} ({suffix})\"\n",
        "                                while new_key in zones:\n",
        "                                    suffix += 1\n",
        "                                    new_key = f\"{zone_key} ({suffix})\"\n",
        "                                zone_key = new_key\n",
        "\n",
        "                            zones[zone_key] = {\n",
        "                                \"region\": region,\n",
        "                                \"objects\": [\"traffic light\"] * remaining_in_region,\n",
        "                                \"description\": f\"Traffic control area with {remaining_in_region} traffic lights in {region}\"\n",
        "                            }\n",
        "\n",
        "                    for region, signals in signal_regions.items():\n",
        "                        used = used_tl_count_per_region.get(region, 0)\n",
        "                        total = len(signals)\n",
        "                        remaining = total - used\n",
        "                        # print(f\"[DEBUG] Region '{region}': Total TL = {total}, Used in crossing = {used}, Remaining = {remaining}\")\n",
        "\n",
        "            elif scene_type == \"financial_district\":\n",
        "                if self.scene_zone_identifier:\n",
        "                    fd_zones = self.scene_zone_identifier.identify_financial_district_zones(\n",
        "                        category_regions, detected_objects\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(fd_zones))\n",
        "\n",
        "            elif scene_type == \"upscale_dining\":\n",
        "                if self.scene_zone_identifier:\n",
        "                    ud_zones = self.scene_zone_identifier.identify_upscale_dining_zones(\n",
        "                        category_regions, detected_objects\n",
        "                    )\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(ud_zones))\n",
        "\n",
        "            else:\n",
        "                # 如果不是上述任何一種場景，就用「預設功能區」\n",
        "                default_zones = self._identify_default_zones(category_regions, detected_objects)\n",
        "                zones.update(self._standardize_zone_keys_and_descriptions(default_zones))\n",
        "\n",
        "            # 8. 如果此時 zones 仍為空，就會變成 default → basic → fallback\n",
        "            if not zones:\n",
        "                default_zones = self._identify_default_zones(category_regions, detected_objects)\n",
        "                if default_zones:\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(default_zones))\n",
        "                else:\n",
        "                    basic_zones = self._create_basic_zones_from_objects(detected_objects, scene_type)\n",
        "                    zones.update(self._standardize_zone_keys_and_descriptions(basic_zones))\n",
        "\n",
        "            # 通用 fallback：把所有還沒被列出的 (class_name, region) 通通補進去\n",
        "            fallback_zones = self._generate_category_fallback_zones(detected_objects, zones)\n",
        "            zones.update(fallback_zones)\n",
        "\n",
        "            # Debug: 列印出各功能區的 traffic light 統計\n",
        "            total_tl_in_zones = 0\n",
        "            for zone_key, zone_info in zones.items():\n",
        "                if isinstance(zone_info, dict):\n",
        "                    sub_objs = zone_info.get(\"objects\", [])\n",
        "                else:\n",
        "                    sub_objs = []\n",
        "                t_in_zone = [obj for obj in sub_objs if obj == \"traffic light\"]\n",
        "                # print(f\"[DEBUG] identify_functional_zones - Zone '{zone_key}' has {len(t_in_zone)} traffic light(s).\")\n",
        "                total_tl_in_zones += len(t_in_zone)\n",
        "            # print(f\"[DEBUG] identify_functional_zones - Total traffic lights in zones: {total_tl_in_zones}\")\n",
        "\n",
        "            logger.info(f\"Identified {len(zones)} functional zones for scene type '{scene_type}'\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying functional zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _standardize_zone_keys_and_descriptions(self, raw_zones: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        標準化區域鍵名和描述，將內部標識符轉換為描述性名稱\n",
        "\n",
        "        Args:\n",
        "            raw_zones: 原始區域識別結果\n",
        "\n",
        "        Returns:\n",
        "            Dict: 標準化後的區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            standardized_zones = {}\n",
        "\n",
        "            for zone_key, zone_data in raw_zones.items():\n",
        "                # 生成描述性的區域鍵名\n",
        "                descriptive_key = self._generate_descriptive_zone_key(zone_key, zone_data)\n",
        "\n",
        "                # 確保區域描述也經過標準化\n",
        "                if isinstance(zone_data, dict) and \"description\" in zone_data:\n",
        "                    zone_data[\"description\"] = self._enhance_zone_description(zone_data[\"description\"], zone_data)\n",
        "\n",
        "                standardized_zones[descriptive_key] = zone_data\n",
        "\n",
        "            return standardized_zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error standardizing zone keys and descriptions: {str(e)}\")\n",
        "            return raw_zones\n",
        "\n",
        "    def _generate_descriptive_zone_key(self, original_key: str, zone_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        基於區域內容生成描述性的鍵名\n",
        "        核心修改：只要該區域內有任一個 'traffic light'，就優先回傳 'traffic control zone'，\n",
        "        \"\"\"\n",
        "        try:\n",
        "            objects = zone_data.get(\"objects\", [])\n",
        "            region = zone_data.get(\"region\", \"\")\n",
        "\n",
        "            # 優先檢查是否含有 traffic light\n",
        "            if any(obj == \"traffic light\" or \"traffic light\" in obj for obj in objects):\n",
        "                return \"traffic control zone\"\n",
        "\n",
        "            # 如果沒有 traffic light，才繼續分析「主要物件」順序\n",
        "            primary_objects = self._analyze_primary_objects(objects)\n",
        "\n",
        "            # 依序檢查人、車、家具、紅綠燈等\n",
        "            if \"person\" in primary_objects:\n",
        "                if len([o for o in objects if o == \"person\"]) > 1:\n",
        "                    return \"pedestrian activity area\"\n",
        "                else:\n",
        "                    return \"individual activity zone\"\n",
        "            elif any(vehicle in primary_objects for vehicle in [\"car\", \"truck\", \"bus\", \"motorcycle\"]):\n",
        "                return \"vehicle movement area\"\n",
        "            elif any(furniture in primary_objects for furniture in [\"chair\", \"table\", \"sofa\", \"bed\"]):\n",
        "                return \"furniture arrangement area\"\n",
        "\n",
        "            # 若上述都不符合，改用「基於位置」做 fallback\n",
        "            position_descriptions = {\n",
        "                \"top_left\": \"upper left area\",\n",
        "                \"top_center\": \"upper central area\",\n",
        "                \"top_right\": \"upper right area\",\n",
        "                \"middle_left\": \"left side area\",\n",
        "                \"middle_center\": \"main crossing area\",\n",
        "                \"middle_right\": \"right side area\",\n",
        "                \"bottom_left\": \"lower left area\",\n",
        "                \"bottom_center\": \"lower central area\",\n",
        "                \"bottom_right\": \"lower right area\"\n",
        "            }\n",
        "            if region in position_descriptions:\n",
        "                return position_descriptions[region]\n",
        "\n",
        "            # 再次檢查主要物件，給出另一種 fallback 命名\n",
        "            if primary_objects:\n",
        "                if \"traffic light\" in primary_objects:\n",
        "                    return \"traffic control zone\"\n",
        "                elif any(vehicle in primary_objects for vehicle in [\"car\", \"truck\", \"bus\"]):\n",
        "                    return \"vehicle movement area\"\n",
        "                elif \"person\" in primary_objects:\n",
        "                    return \"pedestrian activity area\"\n",
        "\n",
        "            # 最後最後的備用名稱\n",
        "            return \"activity area\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating descriptive key for '{original_key}': {str(e)}\")\n",
        "            return \"activity area\"\n",
        "\n",
        "    def _analyze_primary_objects(self, objects: List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        分析區域中的主要物件類型\n",
        "\n",
        "        Args:\n",
        "            objects: 物件名稱列表\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 主要物件類型列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 計算物件出現頻率\n",
        "            object_counts = {}\n",
        "            for obj in objects:\n",
        "                normalized_obj = obj.replace('_', ' ').lower().strip()\n",
        "                object_counts[normalized_obj] = object_counts.get(normalized_obj, 0) + 1\n",
        "\n",
        "            # 按出現頻率排序，返回前三個主要物件\n",
        "            sorted_objects = sorted(object_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "            return [obj[0] for obj in sorted_objects[:3]]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error analyzing primary objects: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _enhance_zone_description(self, original_description: str, zone_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        增強區域描述的自然性和完整性\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not original_description or not original_description.strip():\n",
        "                return self._generate_fallback_description(zone_data)\n",
        "\n",
        "            import re\n",
        "            enhanced = original_description.strip()\n",
        "\n",
        "            # 改善技術性表達為自然語言\n",
        "            enhanced = re.sub(r'\\bin central direction\\b', 'in the center', enhanced)\n",
        "            enhanced = re.sub(r'\\bin west area\\b', 'on the left side', enhanced)\n",
        "            enhanced = re.sub(r'\\bin east direction\\b', 'on the right side', enhanced)\n",
        "            enhanced = re.sub(r'\\bnear traffic signals\\b', 'near the traffic lights', enhanced)\n",
        "            enhanced = re.sub(r'\\bwith (\\d+) (\\w+)\\b', r'where \\1 \\2 can be seen', enhanced)\n",
        "\n",
        "            # 移除重複和冗餘表達\n",
        "            enhanced = re.sub(r'\\barea with.*?in.*?area\\b', lambda m: m.group(0).split(' in ')[0], enhanced)\n",
        "            enhanced = enhanced.replace('traffic area', 'area').replace('crossing area', 'crossing')\n",
        "\n",
        "            # 標準化描述結構\n",
        "            if enhanced.startswith('Pedestrian'):\n",
        "                enhanced = re.sub(r'^Pedestrian crossing area', 'The main pedestrian crossing', enhanced)\n",
        "            elif enhanced.startswith('Vehicle'):\n",
        "                enhanced = re.sub(r'^Vehicle traffic area', 'The vehicle movement area', enhanced)\n",
        "            elif enhanced.startswith('Traffic control'):\n",
        "                enhanced = re.sub(r'^Traffic control area', 'Traffic management elements', enhanced)\n",
        "\n",
        "            # 移除內部標識符格式\n",
        "            enhanced = re.sub(r'\\b\\w+_\\w+(?:_\\w+)*\\b', lambda m: m.group(0).replace('_', ' '), enhanced)\n",
        "\n",
        "            # 確保描述的完整性\n",
        "            if not enhanced.endswith('.'):\n",
        "                enhanced += '.'\n",
        "\n",
        "            # 改善描述的自然性\n",
        "            enhanced = enhanced.replace('with with', 'with')\n",
        "            enhanced = re.sub(r'\\s{2,}', ' ', enhanced)\n",
        "\n",
        "            return enhanced\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error enhancing zone description: {str(e)}\")\n",
        "            return original_description if original_description else \"A functional area within the scene.\"\n",
        "\n",
        "    def _generate_fallback_description(self, zone_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        為缺少描述的區域生成備用描述\n",
        "\n",
        "        Args:\n",
        "            zone_data: 區域數據\n",
        "\n",
        "        Returns:\n",
        "            str: 備用描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            objects = zone_data.get(\"objects\", [])\n",
        "            region = zone_data.get(\"region\", \"\")\n",
        "\n",
        "            if objects:\n",
        "                object_count = len(objects)\n",
        "                unique_objects = list(set(objects))\n",
        "\n",
        "                if object_count == 1:\n",
        "                    return f\"Area containing {unique_objects[0].replace('_', ' ')}.\"\n",
        "                elif len(unique_objects) <= 3:\n",
        "                    obj_list = \", \".join([obj.replace('_', ' ') for obj in unique_objects])\n",
        "                    return f\"Area featuring {obj_list}.\"\n",
        "                else:\n",
        "                    return f\"Multi-functional area with {object_count} elements including various objects.\"\n",
        "\n",
        "            return \"Functional area within the scene.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating fallback description: {str(e)}\")\n",
        "            return \"Activity area.\"\n",
        "\n",
        "    def _build_category_regions_mapping(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        建立物件按類別和區域的分組映射\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            按類別和區域分組的物件字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            category_regions = {}\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                category = self._categorize_object(obj)\n",
        "                if not category:\n",
        "                    continue\n",
        "\n",
        "                if category not in category_regions:\n",
        "                    category_regions[category] = {}\n",
        "\n",
        "                region = obj.get(\"region\", \"center\")\n",
        "                if region not in category_regions[category]:\n",
        "                    category_regions[category][region] = []\n",
        "\n",
        "                category_regions[category][region].append(obj)\n",
        "\n",
        "            logger.debug(f\"Built category regions mapping with {len(category_regions)} categories\")\n",
        "            return category_regions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error building category regions mapping: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _categorize_object(self, obj: Dict) -> str:\n",
        "        \"\"\"\n",
        "        將檢測到的物件分類到功能類別中，用於區域識別\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典\n",
        "\n",
        "        Returns:\n",
        "            物件功能類別字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            class_id = obj.get(\"class_id\", -1)\n",
        "            class_name = obj.get(\"class_name\", \"\").lower()\n",
        "\n",
        "            # 使用現有的類別映射（如果可用）\n",
        "            if hasattr(self, 'OBJECT_CATEGORIES') and self.OBJECT_CATEGORIES:\n",
        "                for category, ids in self.OBJECT_CATEGORIES.items():\n",
        "                    if class_id in ids:\n",
        "                        return category\n",
        "\n",
        "            # 基於COCO類別名稱的後備分類\n",
        "            furniture_items = [\"chair\", \"couch\", \"bed\", \"dining table\", \"toilet\"]\n",
        "            plant_items = [\"potted plant\"]\n",
        "            electronic_items = [\"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\"]\n",
        "            vehicle_items = [\"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\"]\n",
        "            person_items = [\"person\"]\n",
        "            kitchen_items = [\"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
        "                            \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\n",
        "                            \"pizza\", \"donut\", \"cake\", \"refrigerator\", \"oven\", \"toaster\", \"sink\", \"microwave\"]\n",
        "            sports_items = [\"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "                        \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\"]\n",
        "            personal_items = [\"handbag\", \"tie\", \"suitcase\", \"umbrella\", \"backpack\"]\n",
        "\n",
        "            if any(item in class_name for item in furniture_items):\n",
        "                return \"furniture\"\n",
        "            elif any(item in class_name for item in plant_items):\n",
        "                return \"plant\"\n",
        "            elif any(item in class_name for item in electronic_items):\n",
        "                return \"electronics\"\n",
        "            elif any(item in class_name for item in vehicle_items):\n",
        "                return \"vehicle\"\n",
        "            elif any(item in class_name for item in person_items):\n",
        "                return \"person\"\n",
        "            elif any(item in class_name for item in kitchen_items):\n",
        "                return \"kitchen_items\"\n",
        "            elif any(item in class_name for item in sports_items):\n",
        "                return \"sports\"\n",
        "            elif any(item in class_name for item in personal_items):\n",
        "                return \"personal_items\"\n",
        "            else:\n",
        "                return \"misc\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error categorizing object: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"misc\"\n",
        "\n",
        "    def _identify_default_zones(self, category_regions: Dict, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        當沒有匹配到特定場景類型時的一般功能區域識別\n",
        "\n",
        "        Args:\n",
        "            category_regions: 按類別和區域分組的物件字典\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            預設功能區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 按類別分組物件並找到主要集中區域\n",
        "            for category, regions in category_regions.items():\n",
        "                if not regions:\n",
        "                    continue\n",
        "\n",
        "                # 找到此類別中物件最多的區域\n",
        "                main_region = max(regions.items(),\n",
        "                            key=lambda x: len(x[1]),\n",
        "                            default=(None, []))\n",
        "\n",
        "                if main_region[0] is None or len(main_region[1]) < 2:\n",
        "                    continue\n",
        "\n",
        "                # 創建基於物件類別的區域\n",
        "                zone_objects = [obj[\"class_name\"] for obj in main_region[1]]\n",
        "\n",
        "                # 如果物件太少，跳過\n",
        "                if len(zone_objects) < 2:\n",
        "                    continue\n",
        "\n",
        "                # 根據類別創建區域名稱和描述\n",
        "                if category == \"furniture\":\n",
        "                    zones[\"furniture arrangement area\"] = {\n",
        "                        \"region\": main_region[0],\n",
        "                        \"objects\": zone_objects,\n",
        "                        \"description\": f\"Furniture arrangement area featuring {self._format_object_list_naturally(zone_objects[:3])}\"\n",
        "                    }\n",
        "                elif category == \"electronics\":\n",
        "                    zones[\"electronics area\"] = {\n",
        "                        \"region\": main_region[0],\n",
        "                        \"objects\": zone_objects,\n",
        "                        \"description\": f\"Electronics area containing {self._format_object_list_naturally(zone_objects[:3])}\"\n",
        "                    }\n",
        "                elif category == \"kitchen_items\":\n",
        "                    zones[\"dining_zone\"] = {\n",
        "                        \"region\": main_region[0],\n",
        "                        \"objects\": zone_objects,\n",
        "                        \"description\": f\"Dining or food area with {', '.join(zone_objects[:3])}\"\n",
        "                    }\n",
        "                elif category == \"vehicle\":\n",
        "                    zones[\"vehicle_zone\"] = {\n",
        "                        \"region\": main_region[0],\n",
        "                        \"objects\": zone_objects,\n",
        "                        \"description\": f\"Area with vehicles including {', '.join(zone_objects[:3])}\"\n",
        "                    }\n",
        "                elif category == \"personal_items\":\n",
        "                    zones[\"personal_items_zone\"] = {\n",
        "                        \"region\": main_region[0],\n",
        "                        \"objects\": zone_objects,\n",
        "                        \"description\": f\"Area with personal items including {', '.join(zone_objects[:3])}\"\n",
        "                    }\n",
        "\n",
        "            # 檢查人群聚集\n",
        "            people_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            if len(people_objs) >= 2:\n",
        "                people_regions = {}\n",
        "                for obj in people_objs:\n",
        "                    region = obj[\"region\"]\n",
        "                    if region not in people_regions:\n",
        "                        people_regions[region] = []\n",
        "                    people_regions[region].append(obj)\n",
        "\n",
        "                if people_regions:\n",
        "                    main_people_region = max(people_regions.items(),\n",
        "                                        key=lambda x: len(x[1]),\n",
        "                                        default=(None, []))\n",
        "\n",
        "                    if main_people_region[0] is not None:\n",
        "                        zones[\"people_zone\"] = {\n",
        "                            \"region\": main_people_region[0],\n",
        "                            \"objects\": [\"person\"] * len(main_people_region[1]),\n",
        "                            \"description\": f\"Area with {len(main_people_region[1])} people\"\n",
        "                        }\n",
        "\n",
        "            logger.debug(f\"Identified {len(zones)} default zones\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error identifying default zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _format_object_list_naturally(self, object_list: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        將物件列表格式化為自然語言表達\n",
        "\n",
        "        Args:\n",
        "            object_list: 物件名稱列表\n",
        "\n",
        "        Returns:\n",
        "            str: 自然語言格式的物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not object_list:\n",
        "                return \"various items\"\n",
        "\n",
        "            # 標準化物件名稱\n",
        "            normalized_objects = []\n",
        "            for obj in object_list:\n",
        "                normalized = obj.replace('_', ' ').strip()\n",
        "                if normalized:\n",
        "                    normalized_objects.append(normalized)\n",
        "\n",
        "            if not normalized_objects:\n",
        "                return \"various items\"\n",
        "\n",
        "            # 格式化列表\n",
        "            if len(normalized_objects) == 1:\n",
        "                return normalized_objects[0]\n",
        "            elif len(normalized_objects) == 2:\n",
        "                return f\"{normalized_objects[0]} and {normalized_objects[1]}\"\n",
        "            else:\n",
        "                return \", \".join(normalized_objects[:-1]) + f\", and {normalized_objects[-1]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error formatting object list naturally: {str(e)}\")\n",
        "            return \"various items\"\n",
        "\n",
        "    def _create_basic_zones_from_objects(self, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        從個別高置信度物件創建基本功能區域\n",
        "        這是標準區域識別失敗時的後備方案\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            基本區域字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            zones = {}\n",
        "\n",
        "            # 專注於高置信度物件\n",
        "            high_conf_objects = [obj for obj in detected_objects if obj.get(\"confidence\", 0) >= 0.6]\n",
        "\n",
        "            if not high_conf_objects:\n",
        "                high_conf_objects = detected_objects  # 後備到所有物件\n",
        "\n",
        "            # 基於個別重要物件創建區域\n",
        "            processed_objects = set()  # 避免重複處理相同類型的物件\n",
        "\n",
        "            for obj in high_conf_objects[:3]:  # 限制為前3個物件\n",
        "                class_name = obj[\"class_name\"]\n",
        "                region = obj.get(\"region\", \"center\")\n",
        "\n",
        "                # 避免為同一類型物件創建多個區域\n",
        "                if class_name in processed_objects:\n",
        "                    continue\n",
        "                processed_objects.add(class_name)\n",
        "\n",
        "                # 基於物件類型創建描述性區域\n",
        "                zone_description = self._get_basic_zone_description(class_name, scene_type)\n",
        "                descriptive_key = self._generate_object_based_zone_key(class_name, region)\n",
        "\n",
        "                if zone_description and descriptive_key:\n",
        "                    zones[descriptive_key] = {\n",
        "                        \"region\": region,\n",
        "                        \"objects\": [class_name],\n",
        "                        \"description\": zone_description\n",
        "                    }\n",
        "\n",
        "            logger.debug(f\"Created {len(zones)} basic zones from high confidence objects\")\n",
        "            return zones\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating basic zones from objects: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _generate_object_based_zone_key(self, class_name: str, region: str) -> str:\n",
        "        \"\"\"\n",
        "        基於物件類型和位置生成描述性的區域鍵名\n",
        "\n",
        "        Args:\n",
        "            class_name: 物件類別名稱\n",
        "            region: 區域位置\n",
        "\n",
        "        Returns:\n",
        "            str: 描述性區域鍵名\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 標準化物件名稱\n",
        "            normalized_class = class_name.replace('_', ' ').lower().strip()\n",
        "\n",
        "            # 物件類型對應的區域描述\n",
        "            object_zone_mapping = {\n",
        "                'person': 'activity area',\n",
        "                'car': 'vehicle area',\n",
        "                'truck': 'vehicle area',\n",
        "                'bus': 'vehicle area',\n",
        "                'motorcycle': 'vehicle area',\n",
        "                'bicycle': 'cycling area',\n",
        "                'traffic light': 'traffic control area',\n",
        "                'chair': 'seating area',\n",
        "                'sofa': 'seating area',\n",
        "                'bed': 'rest area',\n",
        "                'dining table': 'dining area',\n",
        "                'tv': 'entertainment area',\n",
        "                'laptop': 'workspace area',\n",
        "                'potted plant': 'decorative area'\n",
        "            }\n",
        "\n",
        "            base_description = object_zone_mapping.get(normalized_class, f\"{normalized_class} area\")\n",
        "\n",
        "            # 添加位置信息以提供更具體的描述\n",
        "            position_modifiers = {\n",
        "                'top_left': 'upper left',\n",
        "                'top_center': 'upper central',\n",
        "                'top_right': 'upper right',\n",
        "                'middle_left': 'left side',\n",
        "                'middle_center': 'central',\n",
        "                'middle_right': 'right side',\n",
        "                'bottom_left': 'lower left',\n",
        "                'bottom_center': 'lower central',\n",
        "                'bottom_right': 'lower right'\n",
        "            }\n",
        "\n",
        "            if region in position_modifiers:\n",
        "                return f\"{position_modifiers[region]} {base_description}\"\n",
        "\n",
        "            return base_description\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error generating object-based zone key for '{class_name}': {str(e)}\")\n",
        "            return \"activity area\"\n",
        "\n",
        "    def _get_basic_zone_description(self, class_name: str, scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        基於物件和場景類型生成基本區域描述\n",
        "\n",
        "        Args:\n",
        "            class_name: 物件類別名稱\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            區域描述字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 物件特定描述\n",
        "            descriptions = {\n",
        "                \"bed\": \"Sleeping and rest area\",\n",
        "                \"sofa\": \"Seating and relaxation area\",\n",
        "                \"chair\": \"Seating area\",\n",
        "                \"dining table\": \"Dining and meal area\",\n",
        "                \"tv\": \"Entertainment and media area\",\n",
        "                \"laptop\": \"Work and computing area\",\n",
        "                \"potted plant\": \"Decorative and green space area\",\n",
        "                \"refrigerator\": \"Food storage and kitchen area\",\n",
        "                \"car\": \"Vehicle and transportation area\",\n",
        "                \"person\": \"Activity and social area\"\n",
        "            }\n",
        "\n",
        "            return descriptions.get(class_name, f\"Functional area with {class_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting basic zone description for '{class_name}': {str(e)}\")\n",
        "            return f\"Functional area with {class_name}\"\n",
        "\n",
        "\n",
        "    def _generate_category_fallback_zones(self, all_detected_objects: List[Dict], current_zones: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        通用 fallback：針對 all_detected_objects 裡，每一個 (class_name, region) 組合是否已經\n",
        "        在 current_zones 裡出現過。如果還沒，就為它們產生一個 fallback zone。\n",
        "        \"\"\"\n",
        "        general_fallback = {\n",
        "                0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',\n",
        "                6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',\n",
        "                11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',\n",
        "                16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear',\n",
        "                22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',\n",
        "                27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard',\n",
        "                32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',\n",
        "                36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',\n",
        "                40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',\n",
        "                46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',\n",
        "                51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair',\n",
        "                57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet',\n",
        "                62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard',\n",
        "                67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink',\n",
        "                72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors',\n",
        "                77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
        "\n",
        "        }\n",
        "\n",
        "        # 1. 統計 current_zones 裡，已使用掉的 (class_name, region) 次數\n",
        "        used_count = {}\n",
        "        for zone_info in current_zones.values():\n",
        "            rg = zone_info.get(\"region\", \"\")\n",
        "            for obj_name in zone_info.get(\"objects\", []):\n",
        "                key = (obj_name, rg)\n",
        "                used_count[key] = used_count.get(key, 0) + 1\n",
        "\n",
        "        # 2. 統計 all_detected_objects 裡的 (class_name, region) 總次數\n",
        "        total_count = {}\n",
        "        for obj in all_detected_objects:\n",
        "            cname = obj.get(\"class_name\", \"\")\n",
        "            rg = obj.get(\"region\", \"\")\n",
        "            key = (cname, rg)\n",
        "            total_count[key] = total_count.get(key, 0) + 1\n",
        "\n",
        "        # 3. 把 default_classes 轉換成「class_name → fallback 區域 type」的對照表\n",
        "        category_to_fallback = {\n",
        "            # 行人與交通工具\n",
        "            \"person\":        \"pedestrian area\",\n",
        "            \"bicycle\":       \"vehicle movement area\",\n",
        "            \"car\":           \"vehicle movement area\",\n",
        "            \"motorcycle\":    \"vehicle movement area\",\n",
        "            \"airplane\":      \"vehicle movement area\",\n",
        "            \"bus\":           \"vehicle movement area\",\n",
        "            \"train\":         \"vehicle movement area\",\n",
        "            \"truck\":         \"vehicle movement area\",\n",
        "            \"boat\":          \"vehicle movement area\",\n",
        "            \"traffic light\": \"traffic control area\",\n",
        "            \"fire hydrant\":  \"traffic control area\",\n",
        "            \"stop sign\":     \"traffic control area\",\n",
        "            \"parking meter\": \"traffic control area\",\n",
        "            \"bench\":         \"public furniture area\",\n",
        "\n",
        "            # 動物類、鳥類\n",
        "            \"bird\":          \"animal area\",\n",
        "            \"cat\":           \"animal area\",\n",
        "            \"dog\":           \"animal area\",\n",
        "            \"horse\":         \"animal area\",\n",
        "            \"sheep\":         \"animal area\",\n",
        "            \"cow\":           \"animal area\",\n",
        "            \"elephant\":      \"animal area\",\n",
        "            \"bear\":          \"animal area\",\n",
        "            \"zebra\":         \"animal area\",\n",
        "            \"giraffe\":       \"animal area\",\n",
        "\n",
        "            # 托運與行李\n",
        "            \"backpack\":      \"personal items area\",\n",
        "            \"umbrella\":      \"personal items area\",\n",
        "            \"handbag\":       \"personal items area\",\n",
        "            \"tie\":           \"personal items area\",\n",
        "            \"suitcase\":      \"personal items area\",\n",
        "\n",
        "            # 運動器材\n",
        "            \"frisbee\":       \"sports area\",\n",
        "            \"skis\":          \"sports area\",\n",
        "            \"snowboard\":     \"sports area\",\n",
        "            \"sports ball\":   \"sports area\",\n",
        "            \"kite\":          \"sports area\",\n",
        "            \"baseball bat\":  \"sports area\",\n",
        "            \"baseball glove\":\"sports area\",\n",
        "            \"skateboard\":    \"sports area\",\n",
        "            \"surfboard\":     \"sports area\",\n",
        "            \"tennis racket\": \"sports area\",\n",
        "\n",
        "            # 廚房與食品（Kitchen）\n",
        "            \"bottle\":        \"kitchen area\",\n",
        "            \"wine glass\":    \"kitchen area\",\n",
        "            \"cup\":           \"kitchen area\",\n",
        "            \"fork\":          \"kitchen area\",\n",
        "            \"knife\":         \"kitchen area\",\n",
        "            \"spoon\":         \"kitchen area\",\n",
        "            \"bowl\":          \"kitchen area\",\n",
        "            \"banana\":        \"kitchen area\",\n",
        "            \"apple\":         \"kitchen area\",\n",
        "            \"sandwich\":      \"kitchen area\",\n",
        "            \"orange\":        \"kitchen area\",\n",
        "            \"broccoli\":      \"kitchen area\",\n",
        "            \"carrot\":        \"kitchen area\",\n",
        "            \"hot dog\":       \"kitchen area\",\n",
        "            \"pizza\":         \"kitchen area\",\n",
        "            \"donut\":         \"kitchen area\",\n",
        "            \"cake\":          \"kitchen area\",\n",
        "            \"dining table\":  \"furniture arrangement area\",\n",
        "            \"refrigerator\":  \"kitchen area\",\n",
        "            \"oven\":          \"kitchen area\",\n",
        "            \"microwave\":     \"kitchen area\",\n",
        "            \"toaster\":       \"kitchen area\",\n",
        "            \"sink\":          \"kitchen area\",\n",
        "            \"book\":          \"miscellaneous area\",\n",
        "            \"clock\":         \"miscellaneous area\",\n",
        "            \"vase\":          \"decorative area\",\n",
        "            \"scissors\":      \"miscellaneous area\",\n",
        "            \"teddy bear\":    \"miscellaneous area\",\n",
        "            \"hair drier\":    \"miscellaneous area\",\n",
        "            \"toothbrush\":    \"miscellaneous area\",\n",
        "\n",
        "            # 電子產品\n",
        "            \"tv\":            \"electronics area\",\n",
        "            \"laptop\":        \"electronics area\",\n",
        "            \"mouse\":         \"electronics area\",\n",
        "            \"remote\":        \"electronics area\",\n",
        "            \"keyboard\":      \"electronics area\",\n",
        "            \"cell phone\":    \"electronics area\",\n",
        "\n",
        "            # 家具類\n",
        "            \"chair\":         \"furniture arrangement area\",\n",
        "            \"couch\":         \"furniture arrangement area\",\n",
        "            \"bed\":           \"furniture arrangement area\",\n",
        "            \"toilet\":        \"furniture arrangement area\",\n",
        "\n",
        "            # 植物（室內植物或戶外綠化）\n",
        "            \"potted plant\":  \"decorative area\",\n",
        "        }\n",
        "\n",
        "        # 4. 計算缺少的 (class_name, region) 並建立 fallback zone\n",
        "        for (cname, rg), total in total_count.items():\n",
        "            used = used_count.get((cname, rg), 0)\n",
        "            missing = total - used\n",
        "            if missing <= 0:\n",
        "                continue\n",
        "\n",
        "            # (A) 決定這個 cname 在 fallback 裡屬於哪個大 class（zone_type）\n",
        "            zone_type = category_to_fallback.get(cname, \"miscellaneous area\")\n",
        "\n",
        "            # (B) 根據 region 與 zone_type 組合成 fallback_key\n",
        "            fallback_key = f\"{rg} {zone_type}\"\n",
        "\n",
        "            # (C) 如果名稱重複，就在後面加 (1),(2),… 避免掉衝突\n",
        "            if fallback_key in current_zones or fallback_key in general_fallback:\n",
        "                suffix = 1\n",
        "                new_key = f\"{fallback_key} ({suffix})\"\n",
        "                while new_key in current_zones or new_key in general_fallback:\n",
        "                    suffix += 1\n",
        "                    new_key = f\"{fallback_key} ({suffix})\"\n",
        "                fallback_key = new_key\n",
        "\n",
        "            # (D) 建立這支 fallback zone，objects 裡放 missing 個 cname\n",
        "            general_fallback[fallback_key] = {\n",
        "                \"region\": rg,\n",
        "                \"objects\": [cname] * missing,\n",
        "                \"description\": f\"{missing} {cname}(s) placed in fallback {zone_type} for region {rg}\"\n",
        "            }\n",
        "\n",
        "        return general_fallback"
      ],
      "metadata": {
        "id": "YmDrGUZfr8pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfdd5c3-4e57-404f-cf9e-6d7c5fc7272e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting functional_zone_identifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile spatial_analyzer.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from region_analyzer import RegionAnalyzer\n",
        "# from object_extractor import ObjectExtractor\n",
        "# from scene_viewpoint_analyzer import SceneViewpointAnalyzer\n",
        "# from zone_evaluator import ZoneEvaluator\n",
        "# from scene_zone_identifier import SceneZoneIdentifier\n",
        "# from functional_zone_identifier import FunctionalZoneIdentifier\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SpatialAnalyzer:\n",
        "    \"\"\"\n",
        "    分析圖像中物件間空間關係的主要類別\n",
        "    處理區域分配、物件定位和功能區域識別\n",
        "    使用Facade模式整合多個子組件，保持外部接口的穩定性\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, object_categories=None):\n",
        "        \"\"\"\n",
        "        初始化空間分析器，包含圖像區域定義\n",
        "\n",
        "        Args:\n",
        "            class_names: 類別ID到類別名稱的映射字典\n",
        "            object_categories: 物件類別分組字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 初始化所有子組件\n",
        "            self.region_analyzer = RegionAnalyzer()\n",
        "            self.object_extractor = ObjectExtractor(class_names, object_categories)\n",
        "\n",
        "            self.scene_viewpoint_analyzer = SceneViewpointAnalyzer()\n",
        "\n",
        "            self.zone_evaluator = ZoneEvaluator()\n",
        "            self.scene_zone_identifier = SceneZoneIdentifier()\n",
        "            self.functional_zone_identifier = FunctionalZoneIdentifier(\n",
        "                zone_evaluator=self.zone_evaluator,\n",
        "                scene_zone_identifier=self.scene_zone_identifier,\n",
        "                scene_viewpoint_analyzer=self.scene_viewpoint_analyzer\n",
        "            )\n",
        "\n",
        "            self.class_names = class_names\n",
        "            self.OBJECT_CATEGORIES = object_categories or {}\n",
        "\n",
        "            self.enhance_descriptor = None\n",
        "\n",
        "            # 接近分析的距離閾值（標準化）\n",
        "            self.proximity_threshold = 0.2\n",
        "\n",
        "            logger.info(\"SpatialAnalyzer initialized successfully with all sub-components\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize SpatialAnalyzer: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def update_class_names(self, class_names: Dict[int, str]):\n",
        "        \"\"\"\n",
        "        更新類別名稱映射並傳遞給 ObjectExtractor\n",
        "\n",
        "        Args:\n",
        "            class_names: 新的類別名稱映射字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.class_names = class_names\n",
        "            if hasattr(self, 'object_extractor') and self.object_extractor:\n",
        "                self.object_extractor.update_class_names(class_names)\n",
        "                logger.info(f\"Updated class names in SpatialAnalyzer and ObjectExtractor\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to update class names in SpatialAnalyzer: {str(e)}\")\n",
        "\n",
        "    def _determine_region(self, x: float, y: float) -> str:\n",
        "        \"\"\"\n",
        "        判斷點位於哪個區域\n",
        "\n",
        "        Args:\n",
        "            x: 標準化x座標 (0-1)\n",
        "            y: 標準化y座標 (0-1)\n",
        "\n",
        "        Returns:\n",
        "            區域名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.region_analyzer.determine_region(x, y)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _determine_region: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"unknown\"\n",
        "\n",
        "    def _analyze_regions(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析物件在各區域的分布情況\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 包含位置資訊的檢測物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含區域分析結果的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.region_analyzer.analyze_regions(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _analyze_regions: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"counts\": {},\n",
        "                \"main_focus\": [],\n",
        "                \"objects_by_region\": {}\n",
        "            }\n",
        "\n",
        "    def _extract_detected_objects(self, detection_result: Any, confidence_threshold: float = 0.25) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        從檢測結果中提取物件資訊，包含位置資訊\n",
        "\n",
        "        Args:\n",
        "            detection_result: YOLOv8檢測結果\n",
        "            confidence_threshold: 最小信心度閾值\n",
        "\n",
        "        Returns:\n",
        "            包含檢測物件資訊的字典列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_extractor.extract_detected_objects(\n",
        "                detection_result,\n",
        "                confidence_threshold,\n",
        "                region_analyzer=self.region_analyzer\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _extract_detected_objects: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return []\n",
        "\n",
        "    def _detect_scene_viewpoint(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        檢測場景視角並識別特殊場景模式\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含視角和場景模式資訊的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 委託給新的場景視角分析器\n",
        "            return self.scene_viewpoint_analyzer.detect_scene_viewpoint(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _detect_scene_viewpoint: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {\"viewpoint\": \"eye_level\", \"patterns\": []}\n",
        "\n",
        "    def _identify_functional_zones(self, detected_objects: List[Dict], scene_type: str) -> Dict:\n",
        "        \"\"\"\n",
        "        識別場景內的功能區域，具有針對不同視角和文化背景的改進檢測能力\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 識別出的場景類型\n",
        "\n",
        "        Returns:\n",
        "            包含功能區域及其描述的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.functional_zone_identifier.identify_functional_zones(detected_objects, scene_type)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _identify_functional_zones: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _categorize_object(self, obj: Dict) -> str:\n",
        "        \"\"\"\n",
        "        將檢測到的物件分類到功能類別中，用於區域識別\n",
        "        確保所有返回值都使用自然語言格式，避免底線或技術性標識符\n",
        "        \"\"\"\n",
        "        try:\n",
        "            class_id = obj.get(\"class_id\", -1)\n",
        "            class_name = obj.get(\"class_name\", \"\").lower().strip()\n",
        "\n",
        "            # 優先處理 traffic light\n",
        "            # 只要 class_id == 9 或 class_name 包含 \"traffic light\"，就分類為 \"traffic light\"\n",
        "            if class_id == 9 or \"traffic light\" in class_name:\n",
        "                return \"traffic light\"\n",
        "\n",
        "            # 如果有自訂的 OBJECT_CATEGORIES 映射，優先使用它\n",
        "            if hasattr(self, 'OBJECT_CATEGORIES') and self.OBJECT_CATEGORIES:\n",
        "                for category, ids in self.OBJECT_CATEGORIES.items():\n",
        "                    if class_id in ids:\n",
        "                        # 確保返回的類別名稱使用自然語言格式\n",
        "                        return self._clean_category_name(category)\n",
        "\n",
        "            # COCO class default name\n",
        "            furniture_items = [\"chair\", \"couch\", \"bed\", \"dining table\", \"toilet\"]\n",
        "            plant_items = [\"potted plant\"]\n",
        "            electronic_items = [\"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\"]\n",
        "            vehicle_items = [\"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\"]\n",
        "            person_items = [\"person\"]\n",
        "            kitchen_items = [\n",
        "                \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
        "                \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\",\n",
        "                \"pizza\", \"donut\", \"cake\", \"refrigerator\", \"oven\", \"toaster\", \"sink\", \"microwave\"\n",
        "            ]\n",
        "            sports_items = [\n",
        "                \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "                \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\"\n",
        "            ]\n",
        "            personal_items = [\"handbag\", \"tie\", \"suitcase\", \"umbrella\", \"backpack\"]\n",
        "\n",
        "            # fallback natural language\n",
        "            if any(item in class_name for item in furniture_items):\n",
        "                return \"furniture\"\n",
        "            elif any(item in class_name for item in plant_items):\n",
        "                return \"plant\"\n",
        "            elif any(item in class_name for item in electronic_items):\n",
        "                return \"electronics\"\n",
        "            elif any(item in class_name for item in vehicle_items):\n",
        "                return \"vehicle\"\n",
        "            elif any(item in class_name for item in person_items):\n",
        "                return \"person\"\n",
        "            elif any(item in class_name for item in kitchen_items):\n",
        "                return \"kitchen items\"  # 移除底線\n",
        "            elif any(item in class_name for item in sports_items):\n",
        "                return \"sports\"\n",
        "            elif any(item in class_name for item in personal_items):\n",
        "                return \"personal items\"  # 移除底線\n",
        "            else:\n",
        "                return \"misc\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error categorizing object: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"misc\"\n",
        "\n",
        "    def _clean_category_name(self, category: str) -> str:\n",
        "        \"\"\"\n",
        "        清理類別名稱，移除底線並轉換為較自然的格式\n",
        "\n",
        "        Args:\n",
        "            category: 原始類別名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的類別名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not category:\n",
        "                return \"misc\"\n",
        "\n",
        "            # 將底線替換為空格\n",
        "            cleaned = category.replace('_', ' ')\n",
        "\n",
        "            # 處理常見的技術性命名模式\n",
        "            replacements = {\n",
        "                'kitchen items': 'kitchen items',\n",
        "                'personal items': 'personal items',\n",
        "                'traffic light': 'traffic light',\n",
        "                'misc items': 'misc'\n",
        "            }\n",
        "\n",
        "            # 應用特定的替換規則\n",
        "            for old_term, new_term in replacements.items():\n",
        "                if cleaned == old_term:\n",
        "                    return new_term\n",
        "\n",
        "            return cleaned.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error cleaning category name '{category}': {str(e)}\")\n",
        "            return \"misc\"\n",
        "\n",
        "    def _get_object_categories(self, detected_objects: List[Dict]) -> set:\n",
        "        \"\"\"\n",
        "        從檢測到的物件中獲取唯一的物件類別\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            唯一物件類別的集合\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_extractor.get_object_categories(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _get_object_categories: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return set()\n",
        "\n",
        "    def _identify_core_objects_for_scene(self, detected_objects: List[Dict], scene_type: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        識別定義特定場景類型的核心物件\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            場景的核心物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_extractor.identify_core_objects_for_scene(detected_objects, scene_type)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _identify_core_objects_for_scene: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return []\n",
        "\n",
        "    def _evaluate_zone_identification_feasibility(self, detected_objects: List[Dict], scene_type: str) -> bool:\n",
        "        \"\"\"\n",
        "        基於物件關聯性和分布特徵的彈性可行性評估\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            是否適合進行區域識別\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.zone_evaluator.evaluate_zone_identification_feasibility(detected_objects, scene_type)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _evaluate_zone_identification_feasibility: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return False\n",
        "\n",
        "    def _calculate_functional_relationships(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件間的功能關聯性評分\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            功能關聯性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.zone_evaluator.calculate_functional_relationships(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _calculate_functional_relationships: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0.0\n",
        "\n",
        "    def _calculate_spatial_diversity(self, detected_objects: List[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        計算物件空間分布的多樣性\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            空間多樣性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.zone_evaluator.calculate_spatial_diversity(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _calculate_spatial_diversity: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0.0\n",
        "\n",
        "    def _get_complexity_threshold(self, scene_type: str) -> float:\n",
        "        \"\"\"\n",
        "        根據場景類型返回適當的複雜度閾值\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            複雜度閾值 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.zone_evaluator.get_complexity_threshold(scene_type)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _get_complexity_threshold: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return 0.55\n",
        "\n",
        "    def _create_distribution_map(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        創建物件在各區域分布的詳細地圖，用於空間分析\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            包含各區域分布詳情的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.region_analyzer.create_distribution_map(detected_objects)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _create_distribution_map: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def _find_main_region(self, region_objects_dict: Dict) -> str:\n",
        "        \"\"\"\n",
        "        找到物件最多的主要區域\n",
        "\n",
        "        Args:\n",
        "            region_objects_dict: 區域物件字典\n",
        "\n",
        "        Returns:\n",
        "            主要區域名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not region_objects_dict:\n",
        "                return \"unknown\"\n",
        "\n",
        "            return max(region_objects_dict.items(),\n",
        "                    key=lambda x: len(x[1]),\n",
        "                    default=(\"unknown\", []))[0]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _find_main_region: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return \"unknown\"\n",
        "\n",
        "    def _detect_cross_pattern(self, positions):\n",
        "        \"\"\"檢測位置中的十字交叉模式 - 委託給SceneViewpointAnalyzer\"\"\"\n",
        "        try:\n",
        "            return self.scene_viewpoint_analyzer._detect_cross_pattern(positions)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _detect_cross_pattern: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _analyze_movement_directions(self, positions):\n",
        "        \"\"\"分析位置中的移動方向 - 委託給SceneViewpointAnalyzer\"\"\"\n",
        "        try:\n",
        "            return self.scene_viewpoint_analyzer._analyze_movement_directions(positions)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _analyze_movement_directions: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _get_directional_description(self, region: str) -> str:\n",
        "        \"\"\"將區域名稱轉換為方位描述 - 委託給RegionAnalyzer\"\"\"\n",
        "        try:\n",
        "            return self.region_analyzer.get_directional_description(region)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in _get_directional_description: {str(e)}\")\n",
        "            return \"central\"\n",
        "\n",
        "    @property\n",
        "    def regions(self):\n",
        "        \"\"\"提供對區域定義的向後兼容訪問\"\"\"\n",
        "        return self.region_analyzer.regions"
      ],
      "metadata": {
        "id": "SAfCPwCmrhNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d47835-79ff-4306-d256-574d38462066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting spatial_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48kGS4FtFNYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adea6bde-745d-4d06-f3d5-50e8544bad8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing places365_model.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile places365_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import logging\n",
        "\n",
        "class Places365Model:\n",
        "    \"\"\"\n",
        "    Places365 scene classification model wrapper for scene understanding integration.\n",
        "    Provides scene classification and scene attribute prediction capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'resnet50_places365', device: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize Places365 model with configurable architecture and device.\n",
        "\n",
        "        Args:\n",
        "            model_name: Model architecture name (默認 resnet50)\n",
        "            device: Target device for inference (auto-detected if None)\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        # Device configuration with fallback logic\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.scene_classes = []\n",
        "        self.scene_attributes = []\n",
        "\n",
        "        # Model configuration mapping\n",
        "        self.model_configs = {\n",
        "            'resnet18_places365': {\n",
        "                'arch': 'resnet18',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar'\n",
        "            },\n",
        "            'resnet50_places365': {\n",
        "                'arch': 'resnet50',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar'\n",
        "            },\n",
        "            'densenet161_places365': {\n",
        "                'arch': 'densenet161',\n",
        "                'num_classes': 365,\n",
        "                'url': 'http://places2.csail.mit.edu/models_places365/densenet161_places365.pth.tar'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self._load_model()\n",
        "        self._load_class_names()\n",
        "        self._setup_scene_mapping()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"載入與初始化 Places365 model\"\"\"\n",
        "        try:\n",
        "            if self.model_name not in self.model_configs:\n",
        "                raise ValueError(f\"Unsupported model name: {self.model_name}\")\n",
        "\n",
        "            config = self.model_configs[self.model_name]\n",
        "\n",
        "            # Import model architecture\n",
        "            if config['arch'].startswith('resnet'):\n",
        "                import torchvision.models as models\n",
        "                if config['arch'] == 'resnet18':\n",
        "                    self.model = models.resnet18(num_classes=config['num_classes'])\n",
        "                elif config['arch'] == 'resnet50':\n",
        "                    self.model = models.resnet50(num_classes=config['num_classes'])\n",
        "            elif config['arch'] == 'densenet161':\n",
        "                import torchvision.models as models\n",
        "                self.model = models.densenet161(num_classes=config['num_classes'])\n",
        "\n",
        "            # Load pretrained weights\n",
        "            checkpoint = torch.hub.load_state_dict_from_url(\n",
        "                config['url'],\n",
        "                map_location=self.device,\n",
        "                progress=True\n",
        "            )\n",
        "\n",
        "            # Handle different checkpoint formats\n",
        "            if 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "                # Remove 'module.' prefix if present\n",
        "                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "\n",
        "            self.model.load_state_dict(state_dict)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            self.logger.info(f\"Places365 model {self.model_name} loaded successfully on {self.device}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading Places365 model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _load_class_names(self):\n",
        "        \"\"\"Load Places365 class names and scene attributes.\"\"\"\n",
        "        try:\n",
        "            # Load scene class names (365 categories)\n",
        "            import urllib.request\n",
        "\n",
        "            class_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
        "            class_file = urllib.request.urlopen(class_url)\n",
        "\n",
        "            self.scene_classes = []\n",
        "            for line in class_file:\n",
        "                class_name = line.decode('utf-8').strip().split(' ')[0][3:]  # Remove /x/ prefix\n",
        "                self.scene_classes.append(class_name)\n",
        "\n",
        "            # Load scene attributes (optional, for enhanced description)\n",
        "            attr_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
        "            try:\n",
        "                attr_file = urllib.request.urlopen(attr_url)\n",
        "                self.scene_attributes = []\n",
        "                for line in attr_file:\n",
        "                    attr_name = line.decode('utf-8').strip()\n",
        "                    self.scene_attributes.append(attr_name)\n",
        "            except:\n",
        "                self.logger.warning(\"Scene attributes not loaded, continuing with basic classification\")\n",
        "                self.scene_attributes = []\n",
        "\n",
        "            self.logger.info(f\"Loaded {len(self.scene_classes)} scene classes and {len(self.scene_attributes)} attributes\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading class names: {str(e)}\")\n",
        "            # Fallback to basic class names if download fails\n",
        "            self.scene_classes = [f\"scene_class_{i}\" for i in range(365)]\n",
        "            self.scene_attributes = []\n",
        "\n",
        "    def _setup_scene_mapping(self):\n",
        "        \"\"\"Setup mapping from Places365 classes to common scene types.\"\"\"\n",
        "        # 建立Places365類別到通用場景類型的映射關係\n",
        "        self.scene_type_mapping = {\n",
        "            # Indoor scenes\n",
        "            'living_room': 'living_room',\n",
        "            'bedroom': 'bedroom',\n",
        "            'kitchen': 'kitchen',\n",
        "            'dining_room': 'dining_area',\n",
        "            'bathroom': 'bathroom',\n",
        "            'office': 'office_workspace',\n",
        "            'conference_room': 'office_workspace',\n",
        "            'classroom': 'educational_setting',\n",
        "            'library': 'library',\n",
        "            'restaurant': 'restaurant',\n",
        "            'cafe': 'cafe',\n",
        "            'bar': 'bar',\n",
        "            'hotel_room': 'hotel_room',\n",
        "            'hospital_room': 'medical_facility',\n",
        "            'gym': 'gym',\n",
        "            'supermarket': 'retail_store',\n",
        "            'clothing_store': 'retail_store',\n",
        "\n",
        "            # Outdoor urban scenes\n",
        "            'street': 'city_street',\n",
        "            'crosswalk': 'intersection',\n",
        "            'parking_lot': 'parking_lot',\n",
        "            'gas_station': 'gas_station',\n",
        "            'bus_station': 'bus_stop',\n",
        "            'train_station': 'train_station',\n",
        "            'airport_terminal': 'airport',\n",
        "            'subway_station': 'subway_station',\n",
        "            'bridge': 'bridge',\n",
        "            'highway': 'highway',\n",
        "            'downtown': 'commercial_district',\n",
        "            'shopping_mall': 'shopping_mall',\n",
        "\n",
        "            # Natural outdoor scenes\n",
        "            'park': 'park_area',\n",
        "            'beach': 'beach',\n",
        "            'forest': 'forest',\n",
        "            'mountain': 'mountain',\n",
        "            'lake': 'lake',\n",
        "            'river': 'river',\n",
        "            'ocean': 'ocean',\n",
        "            'desert': 'desert',\n",
        "            'field': 'field',\n",
        "            'garden': 'garden',\n",
        "\n",
        "            # Landmark and tourist areas\n",
        "            'castle': 'historical_monument',\n",
        "            'palace': 'historical_monument',\n",
        "            'temple': 'temple',\n",
        "            'church': 'church',\n",
        "            'mosque': 'mosque',\n",
        "            'museum': 'museum',\n",
        "            'art_gallery': 'art_gallery',\n",
        "            'tower': 'tourist_landmark',\n",
        "            'monument': 'historical_monument',\n",
        "\n",
        "            # Sports and entertainment\n",
        "            'stadium': 'stadium',\n",
        "            'basketball_court': 'sports_field',\n",
        "            'tennis_court': 'sports_field',\n",
        "            'swimming_pool': 'swimming_pool',\n",
        "            'playground': 'playground',\n",
        "            'amusement_park': 'amusement_park',\n",
        "            'theater': 'theater',\n",
        "            'concert_hall': 'concert_hall',\n",
        "\n",
        "            # Transportation\n",
        "            'airplane_cabin': 'airplane_cabin',\n",
        "            'train_interior': 'train_interior',\n",
        "            'car_interior': 'car_interior',\n",
        "\n",
        "            # Construction and industrial\n",
        "            'construction_site': 'construction_site',\n",
        "            'factory': 'factory',\n",
        "            'warehouse': 'warehouse'\n",
        "        }\n",
        "\n",
        "        # Indoor/outdoor classification helper\n",
        "        self.indoor_classes = {\n",
        "            'living_room', 'bedroom', 'kitchen', 'dining_room', 'bathroom', 'office',\n",
        "            'conference_room', 'classroom', 'library', 'restaurant', 'cafe', 'bar',\n",
        "            'hotel_room', 'hospital_room', 'gym', 'supermarket', 'clothing_store',\n",
        "            'airplane_cabin', 'train_interior', 'car_interior', 'theater', 'concert_hall',\n",
        "            'museum', 'art_gallery', 'shopping_mall'\n",
        "        }\n",
        "\n",
        "        self.outdoor_classes = {\n",
        "            'street', 'crosswalk', 'parking_lot', 'gas_station', 'bus_station',\n",
        "            'train_station', 'airport_terminal', 'bridge', 'highway', 'downtown',\n",
        "            'park', 'beach', 'forest', 'mountain', 'lake', 'river', 'ocean',\n",
        "            'desert', 'field', 'garden', 'stadium', 'basketball_court', 'tennis_court',\n",
        "            'swimming_pool', 'playground', 'amusement_park', 'construction_site',\n",
        "            'factory', 'warehouse', 'castle', 'palace', 'temple', 'church', 'mosque',\n",
        "            'tower', 'monument'\n",
        "        }\n",
        "\n",
        "    def preprocess(self, image_pil: Image.Image) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Preprocess PIL image for Places365 model inference.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Preprocessed image tensor\n",
        "        \"\"\"\n",
        "        # Places365 standard preprocessing\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Convert to RGB if needed\n",
        "        if image_pil.mode != 'RGB':\n",
        "            image_pil = image_pil.convert('RGB')\n",
        "\n",
        "        # Apply preprocessing\n",
        "        input_tensor = transform(image_pil).unsqueeze(0)\n",
        "        return input_tensor.to(self.device)\n",
        "\n",
        "    def predict(self, image_pil: Image.Image) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Predict scene classification and attributes for input image.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            Dict containing scene predictions and confidence scores\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Preprocess image\n",
        "            input_tensor = self.preprocess(image_pil)\n",
        "\n",
        "            # Model inference\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "            # 返回最有可能的項目\n",
        "            top_k = min(10, len(self.scene_classes))  # Configurable top-k\n",
        "            top_probs, top_indices = torch.topk(probabilities, top_k, dim=1)\n",
        "\n",
        "            # Extract results\n",
        "            top_probs = top_probs.cpu().numpy()[0]\n",
        "            top_indices = top_indices.cpu().numpy()[0]\n",
        "\n",
        "            # Build prediction results\n",
        "            predictions = []\n",
        "            for i in range(top_k):\n",
        "                class_idx = top_indices[i]\n",
        "                confidence = float(top_probs[i])\n",
        "                scene_class = self.scene_classes[class_idx]\n",
        "\n",
        "                predictions.append({\n",
        "                    'class_name': scene_class,\n",
        "                    'class_index': class_idx,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "            # Get primary prediction\n",
        "            primary_prediction = predictions[0]\n",
        "            primary_class = primary_prediction['class_name']\n",
        "\n",
        "            # 確認是 indoor/outdoor\n",
        "            is_indoor = self._classify_indoor_outdoor(primary_class)\n",
        "\n",
        "            # Map to common scene type\n",
        "            mapped_scene_type = self._map_places365_to_scene_types(primary_class)\n",
        "\n",
        "            # Determine scene attributes (basic inference based on class)\n",
        "            scene_attributes = self._infer_scene_attributes(primary_class)\n",
        "\n",
        "            result = {\n",
        "                'scene_label': primary_class,\n",
        "                'mapped_scene_type': mapped_scene_type,\n",
        "                'confidence': primary_prediction['confidence'],\n",
        "                'is_indoor': is_indoor,\n",
        "                'attributes': scene_attributes,\n",
        "                'top_predictions': predictions,\n",
        "                'all_probabilities': probabilities.cpu().numpy()[0].tolist()\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in Places365 prediction: {str(e)}\")\n",
        "            return {\n",
        "                'scene_label': 'unknown',\n",
        "                'mapped_scene_type': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'is_indoor': None,\n",
        "                'attributes': [],\n",
        "                'top_predictions': [],\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    def _classify_indoor_outdoor(self, scene_class: str) -> Optional[bool]:\n",
        "        \"\"\"\n",
        "        Classify if scene is indoor or outdoor based on Places365 class.\n",
        "\n",
        "        Args:\n",
        "            scene_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            bool or None: True for indoor, False for outdoor, None if uncertain\n",
        "        \"\"\"\n",
        "        if scene_class in self.indoor_classes:\n",
        "            return True\n",
        "        elif scene_class in self.outdoor_classes:\n",
        "            return False\n",
        "        else:\n",
        "            # For ambiguous classes, use heuristics\n",
        "            indoor_keywords = ['room', 'office', 'store', 'shop', 'hall', 'interior', 'indoor']\n",
        "            outdoor_keywords = ['street', 'road', 'park', 'field', 'beach', 'mountain', 'outdoor']\n",
        "\n",
        "            scene_lower = scene_class.lower()\n",
        "            if any(keyword in scene_lower for keyword in indoor_keywords):\n",
        "                return True\n",
        "            elif any(keyword in scene_lower for keyword in outdoor_keywords):\n",
        "                return False\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    def _map_places365_to_scene_types(self, places365_class: str) -> str:\n",
        "        \"\"\"\n",
        "        Map Places365 class to common scene type used by the system.\n",
        "\n",
        "        Args:\n",
        "            places365_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            str: Mapped scene type\n",
        "        \"\"\"\n",
        "        # Direct mapping lookup\n",
        "        if places365_class in self.scene_type_mapping:\n",
        "            return self.scene_type_mapping[places365_class]\n",
        "\n",
        "        # Fuzzy matching for similar classes\n",
        "        places365_lower = places365_class.lower()\n",
        "\n",
        "        # Indoor fuzzy matching\n",
        "        if any(keyword in places365_lower for keyword in ['living', 'bedroom', 'kitchen']):\n",
        "            return 'general_indoor_space'\n",
        "        elif any(keyword in places365_lower for keyword in ['office', 'conference', 'meeting']):\n",
        "            return 'office_workspace'\n",
        "        elif any(keyword in places365_lower for keyword in ['dining', 'restaurant', 'cafe']):\n",
        "            return 'dining_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['store', 'shop', 'market']):\n",
        "            return 'retail_store'\n",
        "        elif any(keyword in places365_lower for keyword in ['school', 'class', 'library']):\n",
        "            return 'educational_setting'\n",
        "\n",
        "        # Outdoor fuzzy matching\n",
        "        elif any(keyword in places365_lower for keyword in ['street', 'road', 'crosswalk']):\n",
        "            return 'city_street'\n",
        "        elif any(keyword in places365_lower for keyword in ['park', 'garden', 'plaza']):\n",
        "            return 'park_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['beach', 'ocean', 'lake']):\n",
        "            return 'beach'\n",
        "        elif any(keyword in places365_lower for keyword in ['mountain', 'forest', 'desert']):\n",
        "            return 'natural_outdoor_area'\n",
        "        elif any(keyword in places365_lower for keyword in ['parking', 'garage']):\n",
        "            return 'parking_lot'\n",
        "        elif any(keyword in places365_lower for keyword in ['station', 'terminal', 'airport']):\n",
        "            return 'transportation_hub'\n",
        "\n",
        "        # Landmark fuzzy matching\n",
        "        elif any(keyword in places365_lower for keyword in ['castle', 'palace', 'monument', 'temple']):\n",
        "            return 'historical_monument'\n",
        "        elif any(keyword in places365_lower for keyword in ['tower', 'landmark']):\n",
        "            return 'tourist_landmark'\n",
        "        elif any(keyword in places365_lower for keyword in ['museum', 'gallery']):\n",
        "            return 'cultural_venue'\n",
        "\n",
        "        # Default fallback based on indoor/outdoor\n",
        "        is_indoor = self._classify_indoor_outdoor(places365_class)\n",
        "        if is_indoor is True:\n",
        "            return 'general_indoor_space'\n",
        "        elif is_indoor is False:\n",
        "            return 'generic_street_view'\n",
        "        else:\n",
        "            return 'unknown'\n",
        "\n",
        "    def _infer_scene_attributes(self, scene_class: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Infer basic scene attributes from Places365 class.\n",
        "\n",
        "        Args:\n",
        "            scene_class: Places365 scene class name\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Inferred scene attributes\n",
        "        \"\"\"\n",
        "        attributes = []\n",
        "        scene_lower = scene_class.lower()\n",
        "\n",
        "        # Lighting attributes\n",
        "        if any(keyword in scene_lower for keyword in ['outdoor', 'street', 'park', 'beach']):\n",
        "            attributes.append('natural_lighting')\n",
        "        elif any(keyword in scene_lower for keyword in ['indoor', 'room', 'office']):\n",
        "            attributes.append('artificial_lighting')\n",
        "\n",
        "        # Functional attributes\n",
        "        if any(keyword in scene_lower for keyword in ['commercial', 'store', 'shop', 'restaurant']):\n",
        "            attributes.append('commercial')\n",
        "        elif any(keyword in scene_lower for keyword in ['residential', 'home', 'living', 'bedroom']):\n",
        "            attributes.append('residential')\n",
        "        elif any(keyword in scene_lower for keyword in ['office', 'conference', 'meeting']):\n",
        "            attributes.append('workplace')\n",
        "        elif any(keyword in scene_lower for keyword in ['recreation', 'park', 'playground', 'stadium']):\n",
        "            attributes.append('recreational')\n",
        "        elif any(keyword in scene_lower for keyword in ['educational', 'school', 'library', 'classroom']):\n",
        "            attributes.append('educational')\n",
        "\n",
        "        # Spatial attributes\n",
        "        if any(keyword in scene_lower for keyword in ['open', 'field', 'plaza', 'stadium']):\n",
        "            attributes.append('open_space')\n",
        "        elif any(keyword in scene_lower for keyword in ['enclosed', 'room', 'interior']):\n",
        "            attributes.append('enclosed_space')\n",
        "\n",
        "        return attributes\n",
        "\n",
        "    def get_scene_probabilities(self, image_pil: Image.Image) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Get probability distribution over all scene classes.\n",
        "\n",
        "        Args:\n",
        "            image_pil: Input PIL image\n",
        "\n",
        "        Returns:\n",
        "            Dict mapping scene class names to probabilities\n",
        "        \"\"\"\n",
        "        try:\n",
        "            input_tensor = self.preprocess(image_pil)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "            probs = probabilities.cpu().numpy()[0]\n",
        "\n",
        "            return {\n",
        "                self.scene_classes[i]: float(probs[i])\n",
        "                for i in range(len(self.scene_classes))\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting scene probabilities: {str(e)}\")\n",
        "            return {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile viewpoint_detector.py\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import numpy as np\n",
        "\n",
        "class ViewpointDetectionError(Exception):\n",
        "    \"\"\"Custom exception for errors during viewpoint detection.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ViewpointDetector:\n",
        "    \"\"\"\n",
        "    視角檢測器 - 分析物體分布模式以識別圖像視角類型\n",
        "\n",
        "    此class負責通過分析檢測到的物體在圖像中的空間分布、大小變化和位置模式，\n",
        "    來確定圖像的拍攝視角。特別針對行人密集的十字路口場景進行了優化。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 aerial_threshold: float = 0.7,\n",
        "                 aerial_size_variance_threshold: float = 0.15,\n",
        "                 low_angle_threshold: float = 0.3,\n",
        "                 vertical_size_ratio_threshold: float = 1.8,\n",
        "                 elevated_threshold: float = 0.6,\n",
        "                 elevated_top_threshold: float = 0.3,\n",
        "                 crosswalk_position_tolerance: float = 0.1,\n",
        "                 crosswalk_axis_tolerance: float = 0.15,\n",
        "                 min_people_for_crosswalk: int = 8,\n",
        "                 min_people_for_aerial: int = 10):\n",
        "        \"\"\"\n",
        "        初始化視角檢測器\n",
        "\n",
        "        Args:\n",
        "            aerial_threshold: 空中視角檢測的物體密度閾值\n",
        "            aerial_size_variance_threshold: 空中視角的大小變異閾值\n",
        "            low_angle_threshold: 低角度視角的底部分布閾值\n",
        "            vertical_size_ratio_threshold: 垂直大小比例閾值\n",
        "            elevated_threshold: 高位視角的物體分布閾值\n",
        "            elevated_top_threshold: 高位視角的頂部物體閾值\n",
        "            crosswalk_position_tolerance: 十字路口位置容差\n",
        "            crosswalk_axis_tolerance: 十字路口軸線容差\n",
        "            min_people_for_crosswalk: 檢測十字路口所需的最少人數\n",
        "            min_people_for_aerial: 檢測空中視角所需的最少人數\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        # 視角檢測參數配置\n",
        "        self.viewpoint_params = {\n",
        "            \"aerial_threshold\": aerial_threshold,\n",
        "            \"aerial_size_variance_threshold\": aerial_size_variance_threshold,\n",
        "            \"low_angle_threshold\": low_angle_threshold,\n",
        "            \"vertical_size_ratio_threshold\": vertical_size_ratio_threshold,\n",
        "            \"elevated_threshold\": elevated_threshold,\n",
        "            \"elevated_top_threshold\": elevated_top_threshold,\n",
        "            \"crosswalk_position_tolerance\": crosswalk_position_tolerance,\n",
        "            \"crosswalk_axis_tolerance\": crosswalk_axis_tolerance,\n",
        "            \"min_people_for_crosswalk\": min_people_for_crosswalk,\n",
        "            \"min_people_for_aerial\": min_people_for_aerial\n",
        "        }\n",
        "\n",
        "        self.logger.info(\"ViewpointDetector initialized with parameters: %s\", self.viewpoint_params)\n",
        "\n",
        "    def detect_viewpoint(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        檢測圖像視角類型\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表，每個物體應包含位置、大小等信息\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的視角類型 ('aerial', 'low_angle', 'elevated', 'eye_level')\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                self.logger.warning(\"No detected objects provided for viewpoint detection\")\n",
        "                return \"eye_level\"\n",
        "\n",
        "            self.logger.info(f\"Starting viewpoint detection with {len(detected_objects)} objects\")\n",
        "\n",
        "            # 優先檢測十字路口模式（通常為空中視角）\n",
        "            if self._detect_crosswalk_pattern(detected_objects):\n",
        "                self.logger.info(\"Crosswalk pattern detected - returning aerial viewpoint\")\n",
        "                return \"aerial\"\n",
        "\n",
        "            # 檢測基於行人分布的空中視角\n",
        "            if self._detect_aerial_from_pedestrian_distribution(detected_objects):\n",
        "                self.logger.info(\"Aerial viewpoint detected from pedestrian distribution\")\n",
        "                return \"aerial\"\n",
        "\n",
        "            # 標準視角檢測流程\n",
        "            return self._detect_standard_viewpoint(detected_objects)\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error during viewpoint detection: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            return \"eye_level\"  # 返回默認值\n",
        "\n",
        "    def _detect_crosswalk_pattern(self, detected_objects: List[Dict]) -> bool:\n",
        "        \"\"\"\n",
        "        檢測十字路口/斑馬線模式\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否檢測到十字路口模式\n",
        "        \"\"\"\n",
        "        try:\n",
        "            people_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 0]\n",
        "\n",
        "            if len(people_objs) < self.viewpoint_params[\"min_people_for_crosswalk\"]:\n",
        "                return False\n",
        "\n",
        "            # 提取行人位置\n",
        "            people_positions = []\n",
        "            for obj in people_objs:\n",
        "                if \"normalized_center\" in obj:\n",
        "                    people_positions.append(obj[\"normalized_center\"])\n",
        "\n",
        "            if len(people_positions) < 4:\n",
        "                return False\n",
        "\n",
        "            # 檢測十字形分布\n",
        "            if self._detect_cross_pattern(people_positions):\n",
        "                self.logger.debug(\"Cross pattern detected in pedestrian positions\")\n",
        "                return True\n",
        "\n",
        "            # 檢測線性聚類分布\n",
        "            if self._detect_linear_crosswalk_clusters(people_positions):\n",
        "                self.logger.debug(\"Linear crosswalk clusters detected\")\n",
        "                return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in crosswalk pattern detection: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _detect_cross_pattern(self, positions: List[Tuple[float, float]]) -> bool:\n",
        "        \"\"\"\n",
        "        檢測十字形分布模式\n",
        "\n",
        "        Args:\n",
        "            positions: 物體位置列表 [(x, y), ...]\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否檢測到十字形模式\n",
        "        \"\"\"\n",
        "        try:\n",
        "            x_coords = [pos[0] for pos in positions]\n",
        "            y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "            x_range = max(x_coords) - min(x_coords)\n",
        "            y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "            # 檢查 x 和 y 方向都有較大範圍且範圍相似\n",
        "            if x_range <= 0.5 or y_range <= 0.5:\n",
        "                return False\n",
        "\n",
        "            if not (0.7 < (x_range / y_range) < 1.3):\n",
        "                return False\n",
        "\n",
        "            # 計算到中心點的距離並檢查軸線分布\n",
        "            center_x = np.mean(x_coords)\n",
        "            center_y = np.mean(y_coords)\n",
        "\n",
        "            close_to_axis_count = 0\n",
        "            axis_tolerance = self.viewpoint_params[\"crosswalk_axis_tolerance\"]\n",
        "\n",
        "            for x, y in positions:\n",
        "                x_distance_to_center = abs(x - center_x)\n",
        "                y_distance_to_center = abs(y - center_y)\n",
        "\n",
        "                # 檢查是否接近水平或垂直軸線\n",
        "                if x_distance_to_center < axis_tolerance or y_distance_to_center < axis_tolerance:\n",
        "                    close_to_axis_count += 1\n",
        "\n",
        "            # 如果足夠多的點接近軸線，認為是十字路口\n",
        "            axis_ratio = close_to_axis_count / len(positions)\n",
        "            return axis_ratio >= 0.6\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting cross pattern: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _detect_linear_crosswalk_clusters(self, positions: List[Tuple[float, float]]) -> bool:\n",
        "        \"\"\"\n",
        "        檢測線性聚類分布（交叉的斑馬線）\n",
        "\n",
        "        Args:\n",
        "            positions: 物體位置列表\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否檢測到線性交叉模式\n",
        "        \"\"\"\n",
        "        try:\n",
        "            x_coords = [pos[0] for pos in positions]\n",
        "            y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "            # 檢測 x 和 y 方向的聚類\n",
        "            x_clusters = self._detect_linear_clusters(x_coords)\n",
        "            y_clusters = self._detect_linear_clusters(y_coords)\n",
        "\n",
        "            # 如果在 x 和 y 方向上都有多個聚類，可能是交叉的斑馬線\n",
        "            return len(x_clusters) >= 2 and len(y_clusters) >= 2\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting linear crosswalk clusters: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _detect_linear_clusters(self, coords: List[float], threshold: float = 0.05) -> List[List[float]]:\n",
        "        \"\"\"\n",
        "        檢測坐標中的線性聚類\n",
        "\n",
        "        Args:\n",
        "            coords: 一維坐標列表\n",
        "            threshold: 聚類閾值\n",
        "\n",
        "        Returns:\n",
        "            List[List[float]]: 聚類列表\n",
        "        \"\"\"\n",
        "        if not coords:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            sorted_coords = sorted(coords)\n",
        "            clusters = []\n",
        "            current_cluster = [sorted_coords[0]]\n",
        "\n",
        "            for i in range(1, len(sorted_coords)):\n",
        "                if sorted_coords[i] - sorted_coords[i-1] < threshold:\n",
        "                    current_cluster.append(sorted_coords[i])\n",
        "                else:\n",
        "                    if len(current_cluster) >= 2:\n",
        "                        clusters.append(current_cluster)\n",
        "                    current_cluster = [sorted_coords[i]]\n",
        "\n",
        "            # 添加最後一個聚類\n",
        "            if len(current_cluster) >= 2:\n",
        "                clusters.append(current_cluster)\n",
        "\n",
        "            return clusters\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in linear cluster detection: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _detect_aerial_from_pedestrian_distribution(self, detected_objects: List[Dict]) -> bool:\n",
        "        \"\"\"\n",
        "        基於行人分布檢測空中視角\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否為空中視角\n",
        "        \"\"\"\n",
        "        try:\n",
        "            people_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 0]\n",
        "\n",
        "            if len(people_objs) < self.viewpoint_params[\"min_people_for_aerial\"]:\n",
        "                return False\n",
        "\n",
        "            # 統計不同區域的行人數量\n",
        "            people_region_counts = {}\n",
        "            for obj in people_objs:\n",
        "                region = obj.get(\"region\", \"unknown\")\n",
        "                people_region_counts[region] = people_region_counts.get(region, 0) + 1\n",
        "\n",
        "            # 檢查行人是否分布在多個區域\n",
        "            regions_with_multiple_people = sum(1 for count in people_region_counts.values() if count >= 2)\n",
        "\n",
        "            if regions_with_multiple_people < 4:\n",
        "                return False\n",
        "\n",
        "            # 檢查行人分布的均勻性\n",
        "            region_counts = list(people_region_counts.values())\n",
        "            if not region_counts:\n",
        "                return False\n",
        "\n",
        "            region_counts_variance = np.var(region_counts)\n",
        "            region_counts_mean = np.mean(region_counts)\n",
        "\n",
        "            if region_counts_mean > 0:\n",
        "                variation_coefficient = region_counts_variance / region_counts_mean\n",
        "                return variation_coefficient < 0.5\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in aerial detection from pedestrian distribution: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _detect_standard_viewpoint(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        標準視角檢測流程\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的視角類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 計算基本統計指標\n",
        "            metrics = self._calculate_viewpoint_metrics(detected_objects)\n",
        "\n",
        "            # 基於計算的指標判斷視角類型\n",
        "            if self._is_aerial_viewpoint(metrics):\n",
        "                return \"aerial\"\n",
        "            elif self._is_low_angle_viewpoint(metrics):\n",
        "                return \"low_angle\"\n",
        "            elif self._is_elevated_viewpoint(metrics):\n",
        "                return \"elevated\"\n",
        "            else:\n",
        "                return \"eye_level\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in standard viewpoint detection: {str(e)}\")\n",
        "            return \"eye_level\"\n",
        "\n",
        "    def _calculate_viewpoint_metrics(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        計算視角檢測所需的各項指標\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含各項指標的字典\n",
        "        \"\"\"\n",
        "        total_objects = len(detected_objects)\n",
        "        top_region_count = 0\n",
        "        bottom_region_count = 0\n",
        "        sizes = []\n",
        "        height_width_ratios = []\n",
        "\n",
        "        try:\n",
        "            for obj in detected_objects:\n",
        "                # 統計頂部和底部區域的物體數量\n",
        "                region = obj.get(\"region\", \"\")\n",
        "                if \"top\" in region:\n",
        "                    top_region_count += 1\n",
        "                elif \"bottom\" in region:\n",
        "                    bottom_region_count += 1\n",
        "\n",
        "                # 收集大小信息\n",
        "                if \"normalized_area\" in obj:\n",
        "                    sizes.append(obj[\"normalized_area\"])\n",
        "\n",
        "                # 計算高寬比\n",
        "                if \"normalized_size\" in obj:\n",
        "                    width, height = obj[\"normalized_size\"]\n",
        "                    if width > 0:\n",
        "                        height_width_ratios.append(height / width)\n",
        "\n",
        "            # 計算比例\n",
        "            top_ratio = top_region_count / total_objects if total_objects > 0 else 0\n",
        "            bottom_ratio = bottom_region_count / total_objects if total_objects > 0 else 0\n",
        "\n",
        "            # 計算大小變異係數\n",
        "            size_variance_coefficient = 0\n",
        "            if sizes and len(sizes) > 1:\n",
        "                mean_size = np.mean(sizes)\n",
        "                if mean_size > 0:\n",
        "                    size_variance = np.var(sizes)\n",
        "                    size_variance_coefficient = size_variance / (mean_size ** 2)\n",
        "\n",
        "            # 計算平均高寬比\n",
        "            avg_height_width_ratio = np.mean(height_width_ratios) if height_width_ratios else 1.0\n",
        "\n",
        "            metrics = {\n",
        "                \"top_ratio\": top_ratio,\n",
        "                \"bottom_ratio\": bottom_ratio,\n",
        "                \"size_variance_coefficient\": size_variance_coefficient,\n",
        "                \"avg_height_width_ratio\": avg_height_width_ratio,\n",
        "                \"total_objects\": total_objects\n",
        "            }\n",
        "\n",
        "            self.logger.debug(f\"Calculated viewpoint metrics: {metrics}\")\n",
        "            return metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating viewpoint metrics: {str(e)}\")\n",
        "            return {\n",
        "                \"top_ratio\": 0,\n",
        "                \"bottom_ratio\": 0,\n",
        "                \"size_variance_coefficient\": 0,\n",
        "                \"avg_height_width_ratio\": 1.0,\n",
        "                \"total_objects\": total_objects\n",
        "            }\n",
        "\n",
        "    def _is_aerial_viewpoint(self, metrics: Dict) -> bool:\n",
        "        \"\"\"判斷是否為空中視角\"\"\"\n",
        "        return (metrics[\"size_variance_coefficient\"] < self.viewpoint_params[\"aerial_size_variance_threshold\"] and\n",
        "                metrics[\"bottom_ratio\"] < 0.3 and\n",
        "                metrics[\"top_ratio\"] > self.viewpoint_params[\"aerial_threshold\"])\n",
        "\n",
        "    def _is_low_angle_viewpoint(self, metrics: Dict) -> bool:\n",
        "        \"\"\"判斷是否為低角度視角\"\"\"\n",
        "        return (metrics[\"avg_height_width_ratio\"] > self.viewpoint_params[\"vertical_size_ratio_threshold\"] and\n",
        "                metrics[\"top_ratio\"] > self.viewpoint_params[\"low_angle_threshold\"])\n",
        "\n",
        "    def _is_elevated_viewpoint(self, metrics: Dict) -> bool:\n",
        "        \"\"\"判斷是否為高位視角\"\"\"\n",
        "        return (metrics[\"bottom_ratio\"] > self.viewpoint_params[\"elevated_threshold\"] and\n",
        "                metrics[\"top_ratio\"] < self.viewpoint_params[\"elevated_top_threshold\"])\n",
        "\n",
        "    def get_viewpoint_confidence(self, detected_objects: List[Dict]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        獲取視角檢測結果及其信心度\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, float]: (視角類型, 信心度)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            viewpoint = self.detect_viewpoint(detected_objects)\n",
        "\n",
        "            # 基於檢測條件計算信心度\n",
        "            if viewpoint == \"aerial\" and self._detect_crosswalk_pattern(detected_objects):\n",
        "                confidence = 0.95  # 十字路口模式有很高信心度\n",
        "            elif viewpoint == \"aerial\":\n",
        "                confidence = 0.8\n",
        "            elif viewpoint == \"eye_level\":\n",
        "                confidence = 0.7  # 默認視角信心度較低\n",
        "            else:\n",
        "                confidence = 0.85\n",
        "\n",
        "            self.logger.info(f\"Viewpoint detection result: {viewpoint} (confidence: {confidence:.2f})\")\n",
        "            return viewpoint, confidence\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(\"Using fallback viewpoint due to detection error\")\n",
        "            return \"eye_level\", 0.3"
      ],
      "metadata": {
        "id": "G4xLpv6Ktoit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2878cb5e-0557-4882-b0db-235ec68de480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing viewpoint_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile template_manager.py\n",
        "import logging\n",
        "import traceback\n",
        "import re\n",
        "import random\n",
        "from typing import Dict, List, Optional, Any\n",
        "import json\n",
        "\n",
        "# from scene_detail_templates import SCENE_DETAIL_TEMPLATES\n",
        "# from object_template_fillers import OBJECT_TEMPLATE_FILLERS\n",
        "# from viewpoint_templates import VIEWPOINT_TEMPLATES\n",
        "# from cultural_templates import CULTURAL_TEMPLATES\n",
        "# from lighting_conditions import LIGHTING_CONDITIONS\n",
        "# from confidence_templates import CONFIDENCE_TEMPLATES\n",
        "\n",
        "class TemplateLoadingError(Exception):\n",
        "    \"\"\"模板載入或處理相關錯誤的自訂例外\"\"\"\n",
        "    pass\n",
        "\n",
        "class TemplateFillError(Exception):\n",
        "    pass\n",
        "\n",
        "class TemplateManager:\n",
        "    \"\"\"\n",
        "    模板管理器 - 負責描述模板的載入、管理和填充\n",
        "\n",
        "    此class 管理所有用於場景描述生成的模板資源，提供模板填充功能，\n",
        "    並根據場景類型、物體檢測結果和上下文的資訊給出適當的描述內容。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, custom_templates_db: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        初始化模板管理器\n",
        "\n",
        "        Args:\n",
        "            custom_templates_db: 可選的自定義模板數據庫，如果提供則會與默認模板合併\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.template_registry = {}\n",
        "\n",
        "        try:\n",
        "            # 載入模板數據庫\n",
        "            self.templates = self._load_templates()\n",
        "\n",
        "            # 如果提供了自定義模板，則進行合併\n",
        "            if custom_templates_db:\n",
        "                self._merge_custom_templates(custom_templates_db)\n",
        "\n",
        "            # 驗證模板完整性\n",
        "            self._validate_templates()\n",
        "\n",
        "            self.logger.info(\"TemplateManager initialized successfully with %d template categories\",\n",
        "                        len(self.templates))\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize TemplateManager: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            # 初始化基本的空模板\n",
        "            self.templates = self._initialize_fallback_templates()\n",
        "\n",
        "    def _load_templates(self) -> Dict:\n",
        "        \"\"\"\n",
        "        載入所有描述模板\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含所有模板類別的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            templates = {}\n",
        "\n",
        "            # 載入場景詳細描述模板\n",
        "            self.logger.debug(\"Loading scene detail templates\")\n",
        "            try:\n",
        "                templates[\"scene_detail_templates\"] = SCENE_DETAIL_TEMPLATES\n",
        "            except NameError:\n",
        "                self.logger.warning(\"SCENE_DETAIL_TEMPLATES not defined, using empty dict\")\n",
        "                templates[\"scene_detail_templates\"] = {}\n",
        "\n",
        "            # 載入物體模板填充器\n",
        "            self.logger.debug(\"Loading object template fillers\")\n",
        "            try:\n",
        "                templates[\"object_template_fillers\"] = OBJECT_TEMPLATE_FILLERS\n",
        "            except NameError:\n",
        "                self.logger.warning(\"OBJECT_TEMPLATE_FILLERS not defined, using empty dict\")\n",
        "                templates[\"object_template_fillers\"] = {}\n",
        "\n",
        "            # 載入視角模板\n",
        "            self.logger.debug(\"Loading viewpoint templates\")\n",
        "            try:\n",
        "                templates[\"viewpoint_templates\"] = VIEWPOINT_TEMPLATES\n",
        "            except NameError:\n",
        "                self.logger.warning(\"VIEWPOINT_TEMPLATES not defined, using empty dict\")\n",
        "                templates[\"viewpoint_templates\"] = {}\n",
        "\n",
        "            # 載入文化模板\n",
        "            self.logger.debug(\"Loading cultural templates\")\n",
        "            try:\n",
        "                templates[\"cultural_templates\"] = CULTURAL_TEMPLATES\n",
        "            except NameError:\n",
        "                self.logger.warning(\"CULTURAL_TEMPLATES not defined, using empty dict\")\n",
        "                templates[\"cultural_templates\"] = {}\n",
        "\n",
        "            # 從照明條件模組載入照明模板\n",
        "            self.logger.debug(\"Loading lighting templates\")\n",
        "            try:\n",
        "                templates[\"lighting_templates\"] = self._extract_lighting_templates()\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Failed to extract lighting templates: {str(e)}\")\n",
        "                templates[\"lighting_templates\"] = {}\n",
        "\n",
        "            # 載入信心度模板\n",
        "            self.logger.debug(\"Loading confidence templates\")\n",
        "            try:\n",
        "                templates[\"confidence_templates\"] = CONFIDENCE_TEMPLATES\n",
        "            except NameError:\n",
        "                self.logger.warning(\"CONFIDENCE_TEMPLATES not defined, using empty dict\")\n",
        "                templates[\"confidence_templates\"] = {}\n",
        "\n",
        "            # 初始化默認模板（當成備份）\n",
        "            self._initialize_default_templates(templates)\n",
        "\n",
        "            self.logger.info(\"Successfully loaded %d template categories\", len(templates))\n",
        "            return templates\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Unexpected error during template loading: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            # 返回基本模板\n",
        "            return self._initialize_fallback_templates()\n",
        "\n",
        "    def _initialize_template_registry(self) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        初始化模板，包含各種場景類型的結構化模板\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Dict[str, Any]]: 模板註冊表字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            template_registry = {\n",
        "                \"indoor_detailed\": {\n",
        "                    \"scene_type\": \"indoor\",\n",
        "                    \"complexity\": \"high\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"This indoor scene presents a comprehensive view of a well-organized living space.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"functional_areas\",\n",
        "                            \"detail_level\": \"detailed\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_category\",\n",
        "                            \"include_counts\": True\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"analytical\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"indoor_moderate\": {\n",
        "                    \"scene_type\": \"indoor\",\n",
        "                    \"complexity\": \"medium\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"The indoor environment displays organized functional areas.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"main_areas\",\n",
        "                            \"detail_level\": \"moderate\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_function\",\n",
        "                            \"include_counts\": False\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"descriptive\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"indoor_simple\": {\n",
        "                    \"scene_type\": \"indoor\",\n",
        "                    \"complexity\": \"low\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"An indoor space with visible furniture and household items.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"basic_areas\",\n",
        "                            \"detail_level\": \"simple\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"general\",\n",
        "                            \"include_counts\": False\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"outdoor_detailed\": {\n",
        "                    \"scene_type\": \"outdoor\",\n",
        "                    \"complexity\": \"high\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"This outdoor scene captures a dynamic urban environment with multiple activity zones.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"activity_areas\",\n",
        "                            \"detail_level\": \"detailed\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_location\",\n",
        "                            \"include_counts\": True\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"environmental\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"outdoor_moderate\": {\n",
        "                    \"scene_type\": \"outdoor\",\n",
        "                    \"complexity\": \"medium\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"The outdoor scene shows organized public spaces and pedestrian areas.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"public_areas\",\n",
        "                            \"detail_level\": \"moderate\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_type\",\n",
        "                            \"include_counts\": False\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"observational\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"outdoor_simple\": {\n",
        "                    \"scene_type\": \"outdoor\",\n",
        "                    \"complexity\": \"low\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"An outdoor area with pedestrians and urban elements.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"basic_areas\",\n",
        "                            \"detail_level\": \"simple\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"general\",\n",
        "                            \"include_counts\": False\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"commercial_detailed\": {\n",
        "                    \"scene_type\": \"commercial\",\n",
        "                    \"complexity\": \"high\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"This commercial environment demonstrates organized retail and customer service areas.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"service_areas\",\n",
        "                            \"detail_level\": \"detailed\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_function\",\n",
        "                            \"include_counts\": True\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"business\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"transportation_detailed\": {\n",
        "                    \"scene_type\": \"transportation\",\n",
        "                    \"complexity\": \"high\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"This transportation hub features organized passenger facilities and transit infrastructure.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"transit_areas\",\n",
        "                            \"detail_level\": \"detailed\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"by_transit_function\",\n",
        "                            \"include_counts\": True\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"infrastructure\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "\n",
        "                \"default\": {\n",
        "                    \"scene_type\": \"general\",\n",
        "                    \"complexity\": \"medium\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"The scene displays various elements organized across functional areas.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"zone_analysis\",\n",
        "                            \"priority\": \"general_areas\",\n",
        "                            \"detail_level\": \"moderate\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"object_summary\",\n",
        "                            \"grouping\": \"general\",\n",
        "                            \"include_counts\": False\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"conclusion\",\n",
        "                            \"style\": \"general\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.logger.debug(f\"Initialized template registry with {len(template_registry)} templates\")\n",
        "            return template_registry\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error initializing template registry: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            # 返回最基本的註冊表\n",
        "            return {\n",
        "                \"default\": {\n",
        "                    \"scene_type\": \"general\",\n",
        "                    \"complexity\": \"low\",\n",
        "                    \"structure\": [\n",
        "                        {\n",
        "                            \"type\": \"opening\",\n",
        "                            \"content\": \"Scene analysis completed with identified objects and areas.\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "\n",
        "    def get_template_by_scene_type(self, scene_type: str, detected_objects: List[Dict],\n",
        "                              functional_zones: Dict) -> str:\n",
        "        \"\"\"\n",
        "        根據場景類型選擇合適的模板並進行標準化處理\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            functional_zones: 功能區域字典\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化後的模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 獲取場景的物件統計信息\n",
        "            object_stats = self._analyze_scene_composition(detected_objects)\n",
        "            zone_count = len(functional_zones) if functional_zones else 0\n",
        "\n",
        "            # 根據場景複雜度和類型選擇模板\n",
        "            if scene_type in self.templates:\n",
        "                scene_templates = self.templates[scene_type]\n",
        "\n",
        "                # 根據複雜度選擇合適的模板變體\n",
        "                if zone_count >= 3 and object_stats.get(\"total_objects\", 0) >= 10:\n",
        "                    template_key = \"complex\"\n",
        "                elif zone_count >= 2 or object_stats.get(\"total_objects\", 0) >= 5:\n",
        "                    template_key = \"moderate\"\n",
        "                else:\n",
        "                    template_key = \"simple\"\n",
        "\n",
        "                if template_key in scene_templates:\n",
        "                    raw_template = scene_templates[template_key]\n",
        "                else:\n",
        "                    raw_template = scene_templates.get(\"default\", scene_templates[list(scene_templates.keys())[0]])\n",
        "            else:\n",
        "                # 如果沒有特定場景的模板，使用通用模板\n",
        "                raw_template = self._get_generic_template(object_stats, zone_count)\n",
        "\n",
        "            # 標準化模板中的佔位符和格式\n",
        "            standardized_template = self._standardize_template_format(raw_template)\n",
        "            return standardized_template\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error selecting template for scene type '{scene_type}': {str(e)}\")\n",
        "            return self._get_fallback_template()\n",
        "\n",
        "    def _analyze_scene_composition(self, detected_objects: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        分析場景組成以確定模板複雜度\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 場景組成統計信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            total_objects = len(detected_objects)\n",
        "\n",
        "            # 統計不同類型的物件\n",
        "            object_categories = {}\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                object_categories[class_name] = object_categories.get(class_name, 0) + 1\n",
        "\n",
        "            # 計算場景多樣性\n",
        "            unique_categories = len(object_categories)\n",
        "\n",
        "            return {\n",
        "                \"total_objects\": total_objects,\n",
        "                \"unique_categories\": unique_categories,\n",
        "                \"category_distribution\": object_categories,\n",
        "                \"complexity_score\": min(total_objects * 0.3 + unique_categories * 0.7, 10)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error analyzing scene composition: {str(e)}\")\n",
        "            return {\"total_objects\": 0, \"unique_categories\": 0, \"complexity_score\": 0}\n",
        "\n",
        "    def _get_generic_template(self, object_stats: Dict, zone_count: int) -> str:\n",
        "        \"\"\"\n",
        "        獲取通用模板\n",
        "\n",
        "        Args:\n",
        "            object_stats: 物件統計信息\n",
        "            zone_count: 功能區域數量\n",
        "\n",
        "        Returns:\n",
        "            str: 通用模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            complexity_score = object_stats.get(\"complexity_score\", 0)\n",
        "\n",
        "            if complexity_score >= 7 or zone_count >= 3:\n",
        "                return \"This scene presents a comprehensive view featuring {functional_area} with {primary_objects}. The spatial organization demonstrates {spatial_arrangement} across multiple {activity_areas}, creating a dynamic environment with diverse elements and clear functional zones.\"\n",
        "            elif complexity_score >= 4 or zone_count >= 2:\n",
        "                return \"The scene displays {functional_area} containing {primary_objects}. The arrangement shows {spatial_organization} with distinct areas serving different purposes within the overall space.\"\n",
        "            else:\n",
        "                return \"A {scene_description} featuring {primary_objects} arranged in {basic_layout} within the visible area.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error getting generic template: {str(e)}\")\n",
        "            return self._get_fallback_template()\n",
        "\n",
        "    def _get_fallback_template(self) -> str:\n",
        "        \"\"\"\n",
        "        獲取備用模板\n",
        "\n",
        "        Returns:\n",
        "            str: 備用模板字符串\n",
        "        \"\"\"\n",
        "        return \"A scene featuring various elements and organized areas of activity within the visible space.\"\n",
        "\n",
        "    def _standardize_template_format(self, template: str) -> str:\n",
        "        \"\"\"\n",
        "        標準化模板格式，確保佔位符和表達方式符合自然語言要求\n",
        "\n",
        "        Args:\n",
        "            template: 原始模板字符串\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化後的模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not template:\n",
        "                return self._get_fallback_template()\n",
        "\n",
        "            import re\n",
        "            standardized = template\n",
        "\n",
        "            # 標準化佔位符格式，移除技術性標記\n",
        "            placeholder_mapping = {\n",
        "                r'\\{zone_\\d+\\}': '{functional_area}',\n",
        "                r'\\{object_group_\\d+\\}': '{primary_objects}',\n",
        "                r'\\{region_\\d+\\}': '{spatial_area}',\n",
        "                r'\\{category_\\d+\\}': '{object_category}',\n",
        "                r'\\{area_\\d+\\}': '{activity_area}',\n",
        "                r'\\{section_\\d+\\}': '{scene_section}'\n",
        "            }\n",
        "\n",
        "            for pattern, replacement in placeholder_mapping.items():\n",
        "                standardized = re.sub(pattern, replacement, standardized)\n",
        "\n",
        "            # 標準化常見的技術性術語\n",
        "            term_replacements = {\n",
        "                'functional_zones': 'areas of activity',\n",
        "                'object_detection': 'visible elements',\n",
        "                'category_regions': 'organized sections',\n",
        "                'spatial_distribution': 'arrangement throughout the space',\n",
        "                'viewpoint_analysis': 'perspective view'\n",
        "            }\n",
        "\n",
        "            for tech_term, natural_term in term_replacements.items():\n",
        "                standardized = standardized.replace(tech_term, natural_term)\n",
        "\n",
        "            # 確保模板語法的自然性\n",
        "            standardized = self._improve_template_readability(standardized)\n",
        "\n",
        "            return standardized\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error standardizing template format: {str(e)}\")\n",
        "            return template if template else self._get_fallback_template()\n",
        "\n",
        "    def _improve_template_readability(self, template: str) -> str:\n",
        "        \"\"\"\n",
        "        改善模板的可讀性和自然性\n",
        "\n",
        "        Args:\n",
        "            template: 模板字符串\n",
        "\n",
        "        Returns:\n",
        "            str: 改善後的模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 移除多餘的空格和換行\n",
        "            improved = re.sub(r'\\s+', ' ', template).strip()\n",
        "\n",
        "            # 改善句子連接\n",
        "            improved = improved.replace(' . ', '. ')\n",
        "            improved = improved.replace(' , ', ', ')\n",
        "            improved = improved.replace(' ; ', '; ')\n",
        "\n",
        "            # 確保適當的句號結尾\n",
        "            if improved and not improved.endswith(('.', '!', '?')):\n",
        "                improved += '.'\n",
        "\n",
        "            # 改善常見的表達問題\n",
        "            readability_fixes = [\n",
        "                (r'\\bthe the\\b', 'the'),\n",
        "                (r'\\ba a\\b', 'a'),\n",
        "                (r'\\ban an\\b', 'an'),\n",
        "                (r'\\bwith with\\b', 'with'),\n",
        "                (r'\\bin in\\b', 'in'),\n",
        "                (r'\\bof of\\b', 'of'),\n",
        "                (r'\\band and\\b', 'and')\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in readability_fixes:\n",
        "                improved = re.sub(pattern, replacement, improved, flags=re.IGNORECASE)\n",
        "\n",
        "            return improved\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error improving template readability: {str(e)}\")\n",
        "            return template\n",
        "\n",
        "    def _extract_lighting_templates(self) -> Dict:\n",
        "        \"\"\"\n",
        "        從照明條件模組提取照明描述模板\n",
        "\n",
        "        Returns:\n",
        "            Dict: 照明模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            lighting_templates = {}\n",
        "\n",
        "            # 從 LIGHTING_CONDITIONS 提取時間描述\n",
        "            time_descriptions = LIGHTING_CONDITIONS.get(\"time_descriptions\", {})\n",
        "\n",
        "            for time_key, time_data in time_descriptions.items():\n",
        "                if isinstance(time_data, dict) and \"general\" in time_data:\n",
        "                    lighting_templates[time_key] = time_data[\"general\"]\n",
        "                else:\n",
        "                    # 如果數據結構不符合預期，使用備用描述\n",
        "                    lighting_templates[time_key] = f\"The scene is captured during {time_key.replace('_', ' ')}.\"\n",
        "\n",
        "            # 確保至少有基本的照明模板\n",
        "            if not lighting_templates:\n",
        "                self.logger.warning(\"No lighting templates found, using defaults\")\n",
        "                lighting_templates = self._get_default_lighting_templates()\n",
        "\n",
        "            self.logger.debug(\"Extracted %d lighting templates\", len(lighting_templates))\n",
        "            return lighting_templates\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error extracting lighting templates: {str(e)}, using defaults\")\n",
        "            return self._get_default_lighting_templates()\n",
        "\n",
        "    def _get_default_lighting_templates(self) -> Dict:\n",
        "        \"\"\"獲取默認照明模板\"\"\"\n",
        "        return {\n",
        "            \"day_clear\": \"The scene is captured during clear daylight conditions.\",\n",
        "            \"day_overcast\": \"The scene is captured during overcast daylight.\",\n",
        "            \"night\": \"The scene is captured at night with artificial lighting.\",\n",
        "            \"dawn\": \"The scene is captured during dawn with soft natural lighting.\",\n",
        "            \"dusk\": \"The scene is captured during dusk with diminishing natural light.\",\n",
        "            \"unknown\": \"The lighting conditions are not clearly identifiable.\"\n",
        "        }\n",
        "\n",
        "    def _initialize_default_templates(self, templates: Dict):\n",
        "        \"\"\"\n",
        "        初始化默認模板作為備份機制\n",
        "\n",
        "        Args:\n",
        "            templates: 要檢查和補充的模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 置信度模板備份\n",
        "            if \"confidence_templates\" not in templates or not templates[\"confidence_templates\"]:\n",
        "                templates[\"confidence_templates\"] = {\n",
        "                    \"high\": \"{description} {details}\",\n",
        "                    \"medium\": \"This appears to be {description} {details}\",\n",
        "                    \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "                }\n",
        "\n",
        "            # 場景詳細模板備份\n",
        "            if \"scene_detail_templates\" not in templates or not templates[\"scene_detail_templates\"]:\n",
        "                templates[\"scene_detail_templates\"] = {\n",
        "                    \"default\": [\"A scene with various elements and objects.\"]\n",
        "                }\n",
        "\n",
        "            # 物體填充模板備份\n",
        "            if \"object_template_fillers\" not in templates or not templates[\"object_template_fillers\"]:\n",
        "                templates[\"object_template_fillers\"] = {\n",
        "                    \"default\": [\"various items\", \"different objects\", \"multiple elements\"]\n",
        "                }\n",
        "\n",
        "            # 視角模板備份\n",
        "            if \"viewpoint_templates\" not in templates or not templates[\"viewpoint_templates\"]:\n",
        "                templates[\"viewpoint_templates\"] = {\n",
        "                    \"eye_level\": {\n",
        "                        \"prefix\": \"From eye level, \",\n",
        "                        \"observation\": \"the scene is viewed straight ahead.\",\n",
        "                        \"short_desc\": \"at eye level\"\n",
        "                    },\n",
        "                    \"aerial\": {\n",
        "                        \"prefix\": \"From above, \",\n",
        "                        \"observation\": \"the scene is viewed from a bird's-eye perspective.\",\n",
        "                        \"short_desc\": \"from above\"\n",
        "                    },\n",
        "                    \"low_angle\": {\n",
        "                        \"prefix\": \"From a low angle, \",\n",
        "                        \"observation\": \"the scene is viewed from below looking upward.\",\n",
        "                        \"short_desc\": \"from below\"\n",
        "                    },\n",
        "                    \"elevated\": {\n",
        "                        \"prefix\": \"From an elevated position, \",\n",
        "                        \"observation\": \"the scene is viewed from a higher vantage point.\",\n",
        "                        \"short_desc\": \"from an elevated position\"\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            # 文化模板備份\n",
        "            if \"cultural_templates\" not in templates or not templates[\"cultural_templates\"]:\n",
        "                templates[\"cultural_templates\"] = {\n",
        "                    \"asian\": {\n",
        "                        \"elements\": [\"traditional architectural elements\", \"cultural signage\", \"Asian design features\"],\n",
        "                        \"description\": \"The scene displays distinctive Asian cultural characteristics with {elements}.\"\n",
        "                    },\n",
        "                    \"european\": {\n",
        "                        \"elements\": [\"classical architecture\", \"European design elements\", \"historic features\"],\n",
        "                        \"description\": \"The scene exhibits European architectural and cultural elements including {elements}.\"\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            self.logger.debug(\"Default templates initialized as backup\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error initializing default templates: {str(e)}\")\n",
        "\n",
        "    def _merge_custom_templates(self, custom_templates: Dict):\n",
        "        \"\"\"\n",
        "        合併自定義模板到現有模板庫\n",
        "\n",
        "        Args:\n",
        "            custom_templates: 自定義模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for template_category, custom_content in custom_templates.items():\n",
        "                if template_category in self.templates:\n",
        "                    if isinstance(self.templates[template_category], dict) and isinstance(custom_content, dict):\n",
        "                        self.templates[template_category].update(custom_content)\n",
        "                        self.logger.debug(f\"Merged custom templates for category: {template_category}\")\n",
        "                    else:\n",
        "                        self.templates[template_category] = custom_content\n",
        "                        self.logger.debug(f\"Replaced templates for category: {template_category}\")\n",
        "                else:\n",
        "                    self.templates[template_category] = custom_content\n",
        "                    self.logger.debug(f\"Added new template category: {template_category}\")\n",
        "\n",
        "            self.logger.info(\"Successfully merged custom templates\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error merging custom templates: {str(e)}\")\n",
        "\n",
        "    def _validate_templates(self):\n",
        "        \"\"\"\n",
        "        驗證模板完整性和有效性\n",
        "        \"\"\"\n",
        "        try:\n",
        "            required_categories = [\n",
        "                \"scene_detail_templates\",\n",
        "                \"object_template_fillers\",\n",
        "                \"viewpoint_templates\",\n",
        "                \"cultural_templates\",\n",
        "                \"lighting_templates\",\n",
        "                \"confidence_templates\"\n",
        "            ]\n",
        "\n",
        "            missing_categories = []\n",
        "            for category in required_categories:\n",
        "                if category not in self.templates:\n",
        "                    missing_categories.append(category)\n",
        "                elif not self.templates[category]:\n",
        "                    self.logger.warning(f\"Template category '{category}' is empty\")\n",
        "\n",
        "            if missing_categories:\n",
        "                error_msg = f\"Missing required template categories: {missing_categories}\"\n",
        "                self.logger.warning(error_msg)\n",
        "                # 為缺失的類別創建空模板\n",
        "                for category in missing_categories:\n",
        "                    self.templates[category] = {}\n",
        "\n",
        "            # 驗證視角模板結構\n",
        "            self._validate_viewpoint_templates()\n",
        "\n",
        "            # 驗證文化模板結構\n",
        "            self._validate_cultural_templates()\n",
        "\n",
        "            self.logger.debug(\"Template validation completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Template validation failed: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "\n",
        "    def _validate_viewpoint_templates(self):\n",
        "        \"\"\"驗證視角模板結構\"\"\"\n",
        "        viewpoint_templates = self.templates.get(\"viewpoint_templates\", {})\n",
        "\n",
        "        for viewpoint, template_data in viewpoint_templates.items():\n",
        "            if not isinstance(template_data, dict):\n",
        "                self.logger.warning(f\"Invalid viewpoint template structure for '{viewpoint}'\")\n",
        "                continue\n",
        "\n",
        "            required_keys = [\"prefix\", \"observation\"]\n",
        "            for key in required_keys:\n",
        "                if key not in template_data:\n",
        "                    self.logger.warning(f\"Missing '{key}' in viewpoint template '{viewpoint}'\")\n",
        "\n",
        "    def _validate_cultural_templates(self):\n",
        "        \"\"\"驗證文化模板結構\"\"\"\n",
        "        cultural_templates = self.templates.get(\"cultural_templates\", {})\n",
        "\n",
        "        for culture, template_data in cultural_templates.items():\n",
        "            if not isinstance(template_data, dict):\n",
        "                self.logger.warning(f\"Invalid cultural template structure for '{culture}'\")\n",
        "                continue\n",
        "\n",
        "            if \"elements\" not in template_data or \"description\" not in template_data:\n",
        "                self.logger.warning(f\"Missing required keys in cultural template '{culture}'\")\n",
        "\n",
        "    def get_template(self, category: str, key: Optional[str] = None) -> Any:\n",
        "        \"\"\"\n",
        "        獲取指定類別的模板\n",
        "\n",
        "        Args:\n",
        "            category: 模板類別名稱\n",
        "            key: 可選的具體模板鍵值\n",
        "\n",
        "        Returns:\n",
        "            Any: 請求的模板內容，如果不存在則返回空字典或空字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if category not in self.templates:\n",
        "                self.logger.warning(f\"Template category '{category}' not found\")\n",
        "                return {} if key is None else \"\"\n",
        "\n",
        "            if key is None:\n",
        "                return self.templates[category]\n",
        "\n",
        "            category_templates = self.templates[category]\n",
        "            if not isinstance(category_templates, dict):\n",
        "                self.logger.warning(f\"Template category '{category}' is not a dictionary\")\n",
        "                return \"\"\n",
        "\n",
        "            if key not in category_templates:\n",
        "                self.logger.warning(f\"Template key '{key}' not found in category '{category}'\")\n",
        "                return \"\"\n",
        "\n",
        "            return category_templates[key]\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error retrieving template {category}.{key}: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            return {} if key is None else \"\"\n",
        "\n",
        "    def fill_template(self, template: str, detected_objects: List[Dict], scene_type: str,\n",
        "             places365_info: Optional[Dict] = None,\n",
        "             object_statistics: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        填充模板中的佔位符，增強容錯處理\n",
        "\n",
        "        Args:\n",
        "            template: 包含佔位符的模板字符串\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            scene_type: 場景類型\n",
        "            places365_info: Places365場景分類信息\n",
        "            object_statistics: 物體統計信息\n",
        "\n",
        "        Returns:\n",
        "            str: 填充後的模板字符串，確保語法正確\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(f\"Filling template for scene_type: {scene_type}\")\n",
        "\n",
        "            if not template or not template.strip():\n",
        "                return \"A scene with various elements.\"\n",
        "\n",
        "            # 預處理模板，移除可能的問題模式\n",
        "            template = self._preprocess_template(template)\n",
        "\n",
        "            # 查找模板中的佔位符\n",
        "            placeholders = re.findall(r'\\{([^}]+)\\}', template)\n",
        "            filled_template = template\n",
        "\n",
        "            # 獲取模板填充器\n",
        "            fillers = self.templates.get(\"object_template_fillers\", {})\n",
        "\n",
        "            # 基於物體統計信息生成替換內容\n",
        "            statistics_based_replacements = self._generate_statistics_replacements(object_statistics)\n",
        "\n",
        "            # 生成默認替換內容\n",
        "            default_replacements = self._generate_default_replacements()\n",
        "\n",
        "            # 添加Places365上下文信息\n",
        "            places365_replacements = self._generate_places365_replacements(places365_info)\n",
        "\n",
        "            # 添加功能區域信息到場景數據中以便後續使用\n",
        "            scene_functional_zones = None\n",
        "            if hasattr(self, '_current_functional_zones'):\n",
        "                scene_functional_zones = self._current_functional_zones\n",
        "\n",
        "            # 合併所有替換內容（優先順序是統計信息 > Places365 > 默認）\n",
        "            all_replacements = {**default_replacements, **places365_replacements, **statistics_based_replacements}\n",
        "\n",
        "            # 填充每個佔位符\n",
        "            for placeholder in placeholders:\n",
        "                try:\n",
        "                    replacement = self._get_placeholder_replacement(\n",
        "                        placeholder, fillers, all_replacements, detected_objects, scene_type\n",
        "                    )\n",
        "\n",
        "                    # 確保替換內容不為空且有意義\n",
        "                    if not replacement or not replacement.strip():\n",
        "                        replacement = self._get_emergency_replacement(placeholder)\n",
        "\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", replacement)\n",
        "\n",
        "                except Exception as placeholder_error:\n",
        "                    self.logger.warning(f\"Failed to replace placeholder '{placeholder}': {str(placeholder_error)}\")\n",
        "                    # 使用緊急替換值\n",
        "                    emergency_replacement = self._get_emergency_replacement(placeholder)\n",
        "                    filled_template = filled_template.replace(f\"{{{placeholder}}}\", emergency_replacement)\n",
        "\n",
        "            # 修復可能的語法問題\n",
        "            filled_template = self._postprocess_filled_template(filled_template)\n",
        "\n",
        "            self.logger.debug(\"Template filling completed successfully\")\n",
        "            return filled_template\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error filling template: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            # 返回安全的備用內容\n",
        "            return self._generate_fallback_description(scene_type, detected_objects)\n",
        "\n",
        "    def _preprocess_template(self, template: str) -> str:\n",
        "        \"\"\"\n",
        "        預處理模板，修復常見問題\n",
        "\n",
        "        Args:\n",
        "            template: 原始模板字符串\n",
        "\n",
        "        Returns:\n",
        "            str: 預處理後的模板\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 移除可能導致問題的模式\n",
        "            template = re.sub(r'\\{[^}]*\\}\\s*,\\s*\\{[^}]*\\}', '{combined_elements}', template)\n",
        "\n",
        "            # 確保模板不以逗號開始\n",
        "            template = re.sub(r'^[,\\s]*', '', template)\n",
        "\n",
        "            return template.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error preprocessing template: {str(e)}\")\n",
        "            return template\n",
        "\n",
        "    def _get_emergency_replacement(self, placeholder: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取緊急替換值，確保不會產生語法錯誤\n",
        "\n",
        "        Args:\n",
        "            placeholder: 佔位符名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 安全的替換值\n",
        "        \"\"\"\n",
        "        emergency_replacements = {\n",
        "            \"crossing_pattern\": \"pedestrian walkways\",\n",
        "            \"pedestrian_behavior\": \"people moving through the area\",\n",
        "            \"traffic_pattern\": \"vehicle movement\",\n",
        "            \"scene_setting\": \"this location\",\n",
        "            \"urban_elements\": \"city features\",\n",
        "            \"street_elements\": \"urban components\"\n",
        "        }\n",
        "\n",
        "        if placeholder in emergency_replacements:\n",
        "            return emergency_replacements[placeholder]\n",
        "\n",
        "        # 基於佔位符名稱生成合理的替換\n",
        "        cleaned = placeholder.replace('_', ' ')\n",
        "        if len(cleaned.split()) > 1:\n",
        "            return cleaned\n",
        "        else:\n",
        "            return f\"various {cleaned}\"\n",
        "\n",
        "    def _postprocess_filled_template(self, filled_template: str) -> str:\n",
        "        \"\"\"\n",
        "        後處理填充完成的模板，修復語法問題\n",
        "\n",
        "        Args:\n",
        "            filled_template: 填充後的模板字符串\n",
        "\n",
        "        Returns:\n",
        "            str: 修復後的模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 修復 \"In , \" 模式\n",
        "            filled_template = re.sub(r'\\bIn\\s*,\\s*', 'In this scene, ', filled_template)\n",
        "            filled_template = re.sub(r'\\bAt\\s*,\\s*', 'At this location, ', filled_template)\n",
        "            filled_template = re.sub(r'\\bWithin\\s*,\\s*', 'Within this area, ', filled_template)\n",
        "\n",
        "            # 修復連續逗號\n",
        "            filled_template = re.sub(r',\\s*,', ',', filled_template)\n",
        "\n",
        "            # 修復開頭的逗號\n",
        "            filled_template = re.sub(r'^[,\\s]*', '', filled_template)\n",
        "\n",
        "            # 確保首字母大寫\n",
        "            if filled_template and not filled_template[0].isupper():\n",
        "                filled_template = filled_template[0].upper() + filled_template[1:]\n",
        "\n",
        "            # 確保以句號結尾\n",
        "            if filled_template and not filled_template.endswith(('.', '!', '?')):\n",
        "                filled_template += '.'\n",
        "\n",
        "            return filled_template.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error postprocessing filled template: {str(e)}\")\n",
        "            return filled_template\n",
        "\n",
        "    def _generate_fallback_description(self, scene_type: str, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        生成備用描述，當模板填充完全失敗時使用\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型\n",
        "            detected_objects: 檢測到的物體列表\n",
        "\n",
        "        Returns:\n",
        "            str: 備用描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            object_count = len(detected_objects)\n",
        "\n",
        "            if object_count == 0:\n",
        "                return f\"A {scene_type.replace('_', ' ')} scene.\"\n",
        "            elif object_count == 1:\n",
        "                return f\"A {scene_type.replace('_', ' ')} scene with one visible element.\"\n",
        "            else:\n",
        "                return f\"A {scene_type.replace('_', ' ')} scene with {object_count} visible elements.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating fallback description: {str(e)}\")\n",
        "            return \"A scene with various elements.\"\n",
        "\n",
        "    def _generate_statistics_replacements(self, object_statistics: Optional[Dict]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        基於物體統計信息生成模板替換內容\n",
        "\n",
        "        Args:\n",
        "            object_statistics: 物體統計信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, str]: 統計信息基礎的替換內容\n",
        "        \"\"\"\n",
        "        replacements = {}\n",
        "\n",
        "        if not object_statistics:\n",
        "            return replacements\n",
        "\n",
        "        try:\n",
        "            # 處理植物元素\n",
        "            if \"potted plant\" in object_statistics:\n",
        "                count = object_statistics[\"potted plant\"][\"count\"]\n",
        "                if count == 1:\n",
        "                    replacements[\"plant_elements\"] = \"a potted plant\"\n",
        "                elif count <= 3:\n",
        "                    replacements[\"plant_elements\"] = f\"{count} potted plants\"\n",
        "                else:\n",
        "                    replacements[\"plant_elements\"] = f\"multiple potted plants ({count} total)\"\n",
        "\n",
        "            # 處理座位\n",
        "            if \"chair\" in object_statistics:\n",
        "                count = object_statistics[\"chair\"][\"count\"]\n",
        "                if count == 1:\n",
        "                    replacements[\"seating\"] = \"a chair\"\n",
        "                elif count <= 4:\n",
        "                    replacements[\"seating\"] = f\"{count} chairs\"\n",
        "                else:\n",
        "                    replacements[\"seating\"] = f\"numerous chairs ({count} total)\"\n",
        "\n",
        "            # 處理人員\n",
        "            if \"person\" in object_statistics:\n",
        "                count = object_statistics[\"person\"][\"count\"]\n",
        "                if count == 1:\n",
        "                    replacements[\"people_and_vehicles\"] = \"a person\"\n",
        "                    replacements[\"pedestrian_flow\"] = \"an individual walking\"\n",
        "                elif count <= 5:\n",
        "                    replacements[\"people_and_vehicles\"] = f\"{count} people\"\n",
        "                    replacements[\"pedestrian_flow\"] = f\"{count} people walking\"\n",
        "                else:\n",
        "                    replacements[\"people_and_vehicles\"] = f\"many people ({count} individuals)\"\n",
        "                    replacements[\"pedestrian_flow\"] = f\"a crowd of {count} people\"\n",
        "\n",
        "            # 處理桌子設置\n",
        "            if \"dining table\" in object_statistics:\n",
        "                count = object_statistics[\"dining table\"][\"count\"]\n",
        "                if count == 1:\n",
        "                    replacements[\"table_setup\"] = \"a dining table\"\n",
        "                    replacements[\"table_description\"] = \"a dining surface\"\n",
        "                else:\n",
        "                    replacements[\"table_setup\"] = f\"{count} dining tables\"\n",
        "                    replacements[\"table_description\"] = f\"{count} dining surfaces\"\n",
        "\n",
        "            self.logger.debug(f\"Generated {len(replacements)} statistics-based replacements\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating statistics replacements: {str(e)}\")\n",
        "\n",
        "        return replacements\n",
        "\n",
        "    def _generate_places365_replacements(self, places365_info: Optional[Dict]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        基於Places365信息生成模板替換內容\n",
        "\n",
        "        Args:\n",
        "            places365_info: Places365場景分類信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, str]: Places365基礎的替換內容\n",
        "        \"\"\"\n",
        "        replacements = {}\n",
        "\n",
        "        if not places365_info or places365_info.get('confidence', 0) <= 0.35:\n",
        "            replacements[\"places365_context\"] = \"\"\n",
        "            replacements[\"places365_atmosphere\"] = \"\"\n",
        "            return replacements\n",
        "\n",
        "        try:\n",
        "            scene_label = places365_info.get('scene_label', '').replace('_', ' ')\n",
        "            attributes = places365_info.get('attributes', [])\n",
        "\n",
        "            # 生成場景上下文\n",
        "            if scene_label:\n",
        "                replacements[\"places365_context\"] = f\"characteristic of a {scene_label}\"\n",
        "            else:\n",
        "                replacements[\"places365_context\"] = \"\"\n",
        "\n",
        "            # 生成氛圍描述\n",
        "            if 'natural_lighting' in attributes:\n",
        "                replacements[\"places365_atmosphere\"] = \"with natural illumination\"\n",
        "            elif 'artificial_lighting' in attributes:\n",
        "                replacements[\"places365_atmosphere\"] = \"under artificial lighting\"\n",
        "            else:\n",
        "                replacements[\"places365_atmosphere\"] = \"\"\n",
        "\n",
        "            self.logger.debug(\"Generated Places365-based replacements\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating Places365 replacements: {str(e)}\")\n",
        "            replacements[\"places365_context\"] = \"\"\n",
        "            replacements[\"places365_atmosphere\"] = \"\"\n",
        "\n",
        "        return replacements\n",
        "\n",
        "    def _generate_default_replacements(self) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        生成默認的模板替換內容\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, str]: 默認替換內容\n",
        "        \"\"\"\n",
        "        return {\n",
        "\n",
        "            \"scene_introduction\": \"this scene\",\n",
        "            \"location_prefix\": \"this location\",\n",
        "            \"setting_description\": \"this setting\",\n",
        "            \"area_description\": \"this area\",\n",
        "            \"environment_description\": \"this environment\",\n",
        "            \"spatial_introduction\": \"this space\",\n",
        "\n",
        "            # 室內相關\n",
        "            \"furniture\": \"various furniture pieces\",\n",
        "            \"seating\": \"comfortable seating\",\n",
        "            \"electronics\": \"entertainment devices\",\n",
        "            \"bed_type\": \"a bed\",\n",
        "            \"bed_location\": \"room\",\n",
        "            \"bed_description\": \"sleeping arrangements\",\n",
        "            \"extras\": \"personal items\",\n",
        "            \"table_setup\": \"a dining table and chairs\",\n",
        "            \"table_description\": \"a dining surface\",\n",
        "            \"dining_items\": \"dining furniture and tableware\",\n",
        "            \"appliances\": \"kitchen appliances\",\n",
        "            \"kitchen_items\": \"cooking utensils and dishware\",\n",
        "            \"cooking_equipment\": \"cooking equipment\",\n",
        "            \"office_equipment\": \"work-related furniture and devices\",\n",
        "            \"desk_setup\": \"a desk and chair\",\n",
        "            \"computer_equipment\": \"electronic devices\",\n",
        "\n",
        "            # 室外/城市相關\n",
        "            \"traffic_description\": \"vehicles and pedestrians\",\n",
        "            \"people_and_vehicles\": \"people and various vehicles\",\n",
        "            \"street_elements\": \"urban infrastructure\",\n",
        "            \"park_features\": \"benches and greenery\",\n",
        "            \"outdoor_elements\": \"natural features\",\n",
        "            \"park_description\": \"outdoor amenities\",\n",
        "            \"store_elements\": \"merchandise displays\",\n",
        "            \"shopping_activity\": \"customers browse and shop\",\n",
        "            \"store_items\": \"products for sale\",\n",
        "\n",
        "            # 高級餐廳相關\n",
        "            \"design_elements\": \"elegant decor\",\n",
        "            \"lighting\": \"stylish lighting fixtures\",\n",
        "\n",
        "            # 亞洲商業街相\n",
        "            \"storefront_features\": \"compact shops\",\n",
        "            \"pedestrian_flow\": \"people walking\",\n",
        "            \"asian_elements\": \"distinctive cultural elements\",\n",
        "            \"cultural_elements\": \"traditional design features\",\n",
        "            \"signage\": \"colorful signs\",\n",
        "            \"street_activities\": \"busy urban activity\",\n",
        "\n",
        "            # 金融區相關\n",
        "            \"buildings\": \"tall buildings\",\n",
        "            \"traffic_elements\": \"vehicles\",\n",
        "            \"skyscrapers\": \"high-rise buildings\",\n",
        "            \"road_features\": \"wide streets\",\n",
        "            \"architectural_elements\": \"modern architecture\",\n",
        "            \"city_landmarks\": \"prominent structures\",\n",
        "\n",
        "            # 十字路口相關\n",
        "            \"crossing_pattern\": \"clearly marked pedestrian crossings\",\n",
        "            \"pedestrian_behavior\": \"careful pedestrian movement\",\n",
        "            \"pedestrian_density\": \"multiple groups of pedestrians\",\n",
        "            \"traffic_pattern\": \"well-regulated traffic flow\",\n",
        "            \"pedestrian_flow\": \"steady pedestrian movement\",\n",
        "            \"traffic_description\": \"active urban traffic\",\n",
        "            \"people_and_vehicles\": \"pedestrians and vehicles\",\n",
        "            \"street_elements\": \"urban infrastructure elements\",\n",
        "\n",
        "            # 交通相關\n",
        "            \"transit_vehicles\": \"public transportation vehicles\",\n",
        "            \"passenger_activity\": \"commuter movement\",\n",
        "            \"transportation_modes\": \"various transit options\",\n",
        "            \"passenger_needs\": \"waiting areas\",\n",
        "            \"transit_infrastructure\": \"transit facilities\",\n",
        "            \"passenger_movement\": \"commuter flow\",\n",
        "\n",
        "            # 購物區相關\n",
        "            \"retail_elements\": \"shops and displays\",\n",
        "            \"store_types\": \"various retail establishments\",\n",
        "            \"walkway_features\": \"pedestrian pathways\",\n",
        "            \"commercial_signage\": \"store signs\",\n",
        "            \"consumer_behavior\": \"shopping activities\",\n",
        "\n",
        "            # 空中視角相關\n",
        "            \"commercial_layout\": \"organized retail areas\",\n",
        "            \"pedestrian_pattern\": \"people movement patterns\",\n",
        "            \"gathering_features\": \"public gathering spaces\",\n",
        "            \"movement_pattern\": \"crowd flow patterns\",\n",
        "            \"urban_elements\": \"city infrastructure\",\n",
        "            \"public_activity\": \"social interaction\",\n",
        "\n",
        "            # 文化特定元素\n",
        "            \"stall_elements\": \"vendor booths\",\n",
        "            \"lighting_features\": \"decorative lights\",\n",
        "            \"food_elements\": \"food offerings\",\n",
        "            \"vendor_stalls\": \"market stalls\",\n",
        "            \"nighttime_activity\": \"evening commerce\",\n",
        "            \"cultural_lighting\": \"traditional lighting\",\n",
        "            \"night_market_sounds\": \"lively market sounds\",\n",
        "            \"evening_crowd_behavior\": \"nighttime social activity\",\n",
        "            \"architectural_elements\": \"cultural buildings\",\n",
        "            \"religious_structures\": \"sacred buildings\",\n",
        "            \"decorative_features\": \"ornamental designs\",\n",
        "            \"cultural_practices\": \"traditional activities\",\n",
        "            \"temple_architecture\": \"religious structures\",\n",
        "            \"sensory_elements\": \"atmospheric elements\",\n",
        "            \"visitor_activities\": \"cultural experiences\",\n",
        "            \"ritual_activities\": \"ceremonial practices\",\n",
        "            \"cultural_symbols\": \"meaningful symbols\",\n",
        "            \"architectural_style\": \"historical buildings\",\n",
        "            \"historic_elements\": \"traditional architecture\",\n",
        "            \"urban_design\": \"city planning elements\",\n",
        "            \"social_behaviors\": \"public interactions\",\n",
        "            \"european_features\": \"European architectural details\",\n",
        "            \"tourist_activities\": \"visitor activities\",\n",
        "            \"local_customs\": \"regional practices\",\n",
        "\n",
        "            # 時間特定元素\n",
        "            \"lighting_effects\": \"artificial lighting\",\n",
        "            \"shadow_patterns\": \"light and shadow\",\n",
        "            \"urban_features\": \"city elements\",\n",
        "            \"illuminated_elements\": \"lit structures\",\n",
        "            \"evening_activities\": \"nighttime activities\",\n",
        "            \"light_sources\": \"lighting points\",\n",
        "            \"lit_areas\": \"illuminated spaces\",\n",
        "            \"shadowed_zones\": \"darker areas\",\n",
        "            \"illuminated_signage\": \"bright signs\",\n",
        "            \"colorful_lighting\": \"multicolored lights\",\n",
        "            \"neon_elements\": \"neon signs\",\n",
        "            \"night_crowd_behavior\": \"evening social patterns\",\n",
        "            \"light_displays\": \"lighting installations\",\n",
        "            \"building_features\": \"architectural elements\",\n",
        "            \"nightlife_activities\": \"evening entertainment\",\n",
        "            \"lighting_modifier\": \"bright\",\n",
        "\n",
        "            # 混合環境元素\n",
        "            \"transitional_elements\": \"connecting features\",\n",
        "            \"indoor_features\": \"interior elements\",\n",
        "            \"outdoor_setting\": \"exterior spaces\",\n",
        "            \"interior_amenities\": \"inside comforts\",\n",
        "            \"exterior_features\": \"outside elements\",\n",
        "            \"inside_elements\": \"interior design\",\n",
        "            \"outside_spaces\": \"outdoor areas\",\n",
        "            \"dual_environment_benefits\": \"combined settings\",\n",
        "            \"passenger_activities\": \"waiting behaviors\",\n",
        "            \"transportation_types\": \"transit vehicles\",\n",
        "            \"sheltered_elements\": \"covered areas\",\n",
        "            \"exposed_areas\": \"open sections\",\n",
        "            \"waiting_behaviors\": \"passenger activities\",\n",
        "            \"indoor_facilities\": \"inside services\",\n",
        "            \"platform_features\": \"transit platform elements\",\n",
        "            \"transit_routines\": \"transportation procedures\",\n",
        "\n",
        "            # 專門場所元素\n",
        "            \"seating_arrangement\": \"spectator seating\",\n",
        "            \"playing_surface\": \"athletic field\",\n",
        "            \"sporting_activities\": \"sports events\",\n",
        "            \"spectator_facilities\": \"viewer accommodations\",\n",
        "            \"competition_space\": \"sports arena\",\n",
        "            \"sports_events\": \"athletic competitions\",\n",
        "            \"viewing_areas\": \"audience sections\",\n",
        "            \"field_elements\": \"field markings and equipment\",\n",
        "            \"game_activities\": \"competitive play\",\n",
        "            \"construction_equipment\": \"building machinery\",\n",
        "            \"building_materials\": \"construction supplies\",\n",
        "            \"construction_activities\": \"building work\",\n",
        "            \"work_elements\": \"construction tools\",\n",
        "            \"structural_components\": \"building structures\",\n",
        "            \"site_equipment\": \"construction gear\",\n",
        "            \"raw_materials\": \"building supplies\",\n",
        "            \"construction_process\": \"building phases\",\n",
        "            \"medical_elements\": \"healthcare equipment\",\n",
        "            \"clinical_activities\": \"medical procedures\",\n",
        "            \"facility_design\": \"healthcare layout\",\n",
        "            \"healthcare_features\": \"medical facilities\",\n",
        "            \"patient_interactions\": \"care activities\",\n",
        "            \"equipment_types\": \"medical devices\",\n",
        "            \"care_procedures\": \"health services\",\n",
        "            \"treatment_spaces\": \"clinical areas\",\n",
        "            \"educational_furniture\": \"learning furniture\",\n",
        "            \"learning_activities\": \"educational practices\",\n",
        "            \"instructional_design\": \"teaching layout\",\n",
        "            \"classroom_elements\": \"school equipment\",\n",
        "            \"teaching_methods\": \"educational approaches\",\n",
        "            \"student_engagement\": \"learning participation\",\n",
        "            \"learning_spaces\": \"educational areas\",\n",
        "            \"educational_tools\": \"teaching resources\",\n",
        "            \"knowledge_transfer\": \"learning exchanges\"\n",
        "        }\n",
        "\n",
        "    def _generate_objects_summary(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        基於檢測物件生成自然語言摘要，按重要性排序\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 物件摘要描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # detected_objects 裡有幾個 traffic light)\n",
        "            tl_count = len([obj for obj in detected_objects if obj.get(\"class_name\",\"\") == \"traffic light\"])\n",
        "            # print(f\"[DEBUG] _generate_objects_summary 傳入的 detected_objects 中 traffic light: {tl_count} 個\")\n",
        "            for obj in detected_objects:\n",
        "                if obj.get(\"class_name\",\"\") == \"traffic light\":\n",
        "                    print(f\"    - conf={obj.get('confidence',0):.4f}, bbox={obj.get('bbox')}, region={obj.get('region')}\")\n",
        "\n",
        "            if not detected_objects:\n",
        "                return \"various elements\"\n",
        "\n",
        "            # calculate object statistic\n",
        "            object_counts = {}\n",
        "            total_confidence = 0\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                confidence = obj.get(\"confidence\", 0.5)\n",
        "\n",
        "                if class_name not in object_counts:\n",
        "                    object_counts[class_name] = {\"count\": 0, \"total_confidence\": 0}\n",
        "\n",
        "                object_counts[class_name][\"count\"] += 1\n",
        "                object_counts[class_name][\"total_confidence\"] += confidence\n",
        "                total_confidence += confidence\n",
        "\n",
        "            # 計算平均置信度並排序\n",
        "            sorted_objects = []\n",
        "            for class_name, stats in object_counts.items():\n",
        "                avg_confidence = stats[\"total_confidence\"] / stats[\"count\"]\n",
        "                count = stats[\"count\"]\n",
        "\n",
        "                # 重要性評分：結合數量和置信度\n",
        "                importance_score = (count * 0.6) + (avg_confidence * 0.4)\n",
        "                sorted_objects.append((class_name, count, importance_score))\n",
        "\n",
        "            # 按重要性排序，取前5個最重要的物件\n",
        "            sorted_objects.sort(key=lambda x: x[2], reverse=True)\n",
        "            top_objects = sorted_objects[:5]\n",
        "\n",
        "            # 生成自然語言描述\n",
        "            descriptions = []\n",
        "            for class_name, count, _ in top_objects:\n",
        "                clean_name = class_name.replace('_', ' ')\n",
        "                if count == 1:\n",
        "                    article = \"an\" if clean_name[0].lower() in 'aeiou' else \"a\"\n",
        "                    descriptions.append(f\"{article} {clean_name}\")\n",
        "                else:\n",
        "                    descriptions.append(f\"{count} {clean_name}s\")\n",
        "\n",
        "            # 組合描述\n",
        "            if len(descriptions) == 1:\n",
        "                return descriptions[0]\n",
        "            elif len(descriptions) == 2:\n",
        "                return f\"{descriptions[0]} and {descriptions[1]}\"\n",
        "            else:\n",
        "                return \", \".join(descriptions[:-1]) + f\", and {descriptions[-1]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating objects summary: {str(e)}\")\n",
        "            return \"various elements\"\n",
        "\n",
        "    def _get_placeholder_replacement(self, placeholder: str, fillers: Dict,\n",
        "                           all_replacements: Dict, detected_objects: List[Dict],\n",
        "                           scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取特定佔位符的替換內容，確保永遠不返回空值\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 優先處理動態內容生成的佔位符\n",
        "            dynamic_placeholders = [\n",
        "                'primary_objects', 'detected_objects_summary', 'main_objects',\n",
        "                'functional_area', 'functional_zones_description', 'scene_elements'\n",
        "            ]\n",
        "\n",
        "            if placeholder in dynamic_placeholders:\n",
        "                dynamic_content = self._generate_objects_summary(detected_objects)\n",
        "                if dynamic_content and dynamic_content.strip():\n",
        "                    return dynamic_content.strip()\n",
        "\n",
        "            # 檢查預定義替換內容\n",
        "            if placeholder in all_replacements:\n",
        "                replacement = all_replacements[placeholder]\n",
        "                if replacement and replacement.strip():\n",
        "                    return replacement.strip()\n",
        "\n",
        "            # 檢查物體模板填充器\n",
        "            if placeholder in fillers:\n",
        "                options = fillers[placeholder]\n",
        "                if options and isinstance(options, list):\n",
        "                    valid_options = [opt.strip() for opt in options if opt and str(opt).strip()]\n",
        "                    if valid_options:\n",
        "                        num_items = min(len(valid_options), random.randint(1, 3))\n",
        "                        selected_items = random.sample(valid_options, num_items)\n",
        "\n",
        "                        if len(selected_items) == 1:\n",
        "                            return selected_items[0]\n",
        "                        elif len(selected_items) == 2:\n",
        "                            return f\"{selected_items[0]} and {selected_items[1]}\"\n",
        "                        else:\n",
        "                            return \", \".join(selected_items[:-1]) + f\", and {selected_items[-1]}\"\n",
        "\n",
        "            # 基於檢測對象生成動態內容\n",
        "            scene_specific_replacement = self._generate_scene_specific_content(\n",
        "                placeholder, detected_objects, scene_type\n",
        "            )\n",
        "            if scene_specific_replacement and scene_specific_replacement.strip():\n",
        "                return scene_specific_replacement.strip()\n",
        "\n",
        "            # 通用備用字典 - 擴展版本\n",
        "            fallback_replacements = {\n",
        "                # 交通和城市相關\n",
        "                \"crossing_pattern\": \"pedestrian crosswalks\",\n",
        "                \"pedestrian_behavior\": \"people moving carefully\",\n",
        "                \"traffic_pattern\": \"vehicle movement\",\n",
        "                \"urban_elements\": \"city infrastructure\",\n",
        "                \"street_elements\": \"urban features\",\n",
        "                \"intersection_features\": \"traffic management systems\",\n",
        "                \"pedestrian_density\": \"groups of people\",\n",
        "                \"pedestrian_flow\": \"pedestrian movement\",\n",
        "                \"traffic_description\": \"vehicle traffic\",\n",
        "                \"people_and_vehicles\": \"pedestrians and cars\",\n",
        "\n",
        "                # 場景設置相關\n",
        "                \"scene_setting\": \"this urban environment\",\n",
        "                \"location_context\": \"the area\",\n",
        "                \"spatial_context\": \"the scene\",\n",
        "                \"environmental_context\": \"this location\",\n",
        "\n",
        "                # 常見的家具和設備\n",
        "                \"furniture\": \"various furniture pieces\",\n",
        "                \"seating\": \"seating arrangements\",\n",
        "                \"electronics\": \"electronic devices\",\n",
        "                \"appliances\": \"household appliances\",\n",
        "\n",
        "                # 活動和行為\n",
        "                \"activities\": \"various activities\",\n",
        "                \"interactions\": \"people interacting\",\n",
        "                \"movement\": \"movement patterns\",\n",
        "\n",
        "                # 照明和氛圍\n",
        "                \"lighting_conditions\": \"ambient lighting\",\n",
        "                \"atmosphere\": \"the overall atmosphere\",\n",
        "                \"ambiance\": \"environmental ambiance\",\n",
        "\n",
        "                # 空間描述\n",
        "                \"spatial_arrangement\": \"spatial organization\",\n",
        "                \"layout\": \"the layout\",\n",
        "                \"composition\": \"visual composition\",\n",
        "\n",
        "                # 物體和元素\n",
        "                \"objects\": \"various objects\",\n",
        "                \"elements\": \"scene elements\",\n",
        "                \"features\": \"notable features\",\n",
        "                \"details\": \"observable details\"\n",
        "            }\n",
        "\n",
        "            if placeholder in fallback_replacements:\n",
        "                return fallback_replacements[placeholder]\n",
        "\n",
        "            # 基於場景類型的智能默認值\n",
        "            scene_based_defaults = self._get_scene_based_default(placeholder, scene_type)\n",
        "            if scene_based_defaults:\n",
        "                return scene_based_defaults\n",
        "\n",
        "            # 最終備用：將下劃線轉換為有意義的短語\n",
        "            cleaned_placeholder = placeholder.replace('_', ' ')\n",
        "\n",
        "            # 對常見模式提供更好的默認值\n",
        "            if placeholder.endswith('_pattern'):\n",
        "                return f\"{cleaned_placeholder.replace(' pattern', '')} arrangement\"\n",
        "            elif placeholder.endswith('_behavior'):\n",
        "                return f\"{cleaned_placeholder.replace(' behavior', '')} activity\"\n",
        "            elif placeholder.endswith('_description'):\n",
        "                return f\"{cleaned_placeholder.replace(' description', '')} elements\"\n",
        "            elif placeholder.endswith('_elements'):\n",
        "                return cleaned_placeholder\n",
        "            elif placeholder.endswith('_features'):\n",
        "                return cleaned_placeholder\n",
        "            else:\n",
        "                return cleaned_placeholder if cleaned_placeholder != placeholder else \"various elements\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting replacement for placeholder '{placeholder}': {str(e)}\")\n",
        "            # 確保即使在異常情況下也返回有意義的內容\n",
        "            return placeholder.replace('_', ' ') if placeholder else \"scene elements\"\n",
        "\n",
        "    def _get_scene_based_default(self, placeholder: str, scene_type: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        基於場景類型提供智能默認值\n",
        "\n",
        "        Args:\n",
        "            placeholder: 佔位符名稱\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 場景特定的默認值或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 針對不同場景類型的特定默認值\n",
        "            scene_defaults = {\n",
        "                \"urban_intersection\": {\n",
        "                    \"crossing_pattern\": \"marked crosswalks\",\n",
        "                    \"pedestrian_behavior\": \"pedestrians crossing carefully\",\n",
        "                    \"traffic_pattern\": \"controlled traffic flow\"\n",
        "                },\n",
        "                \"city_street\": {\n",
        "                    \"traffic_description\": \"urban vehicle traffic\",\n",
        "                    \"street_elements\": \"city infrastructure\",\n",
        "                    \"people_and_vehicles\": \"pedestrians and vehicles\"\n",
        "                },\n",
        "                \"living_room\": {\n",
        "                    \"furniture\": \"comfortable living room furniture\",\n",
        "                    \"seating\": \"sofas and chairs\",\n",
        "                    \"electronics\": \"entertainment equipment\"\n",
        "                },\n",
        "                \"kitchen\": {\n",
        "                    \"appliances\": \"kitchen appliances\",\n",
        "                    \"cooking_equipment\": \"cooking tools and equipment\"\n",
        "                },\n",
        "                \"office_workspace\": {\n",
        "                    \"office_equipment\": \"work furniture and devices\",\n",
        "                    \"desk_setup\": \"desk and office chair\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if scene_type in scene_defaults and placeholder in scene_defaults[scene_type]:\n",
        "                return scene_defaults[scene_type][placeholder]\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting scene-based default for '{placeholder}' in '{scene_type}': {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _generate_scene_specific_content(self, placeholder: str, detected_objects: List[Dict],\n",
        "                                       scene_type: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        基於場景特定邏輯生成佔位符內容\n",
        "\n",
        "        Args:\n",
        "            placeholder: 佔位符名稱\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 生成的內容或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if placeholder == \"furniture\":\n",
        "                # 提取家具物品\n",
        "                furniture_ids = [56, 57, 58, 59, 60, 61]  # 家具類別ID\n",
        "                furniture_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in furniture_ids]\n",
        "\n",
        "                if furniture_objects:\n",
        "                    furniture_names = [obj.get(\"class_name\", \"furniture\") for obj in furniture_objects[:3]]\n",
        "                    unique_names = list(set(furniture_names))\n",
        "                    return \", \".join(unique_names) if len(unique_names) > 1 else unique_names[0]\n",
        "                return \"various furniture items\"\n",
        "\n",
        "            elif placeholder == \"electronics\":\n",
        "                # 提取電子設備\n",
        "                electronics_ids = [62, 63, 64, 65, 66, 67, 68, 69, 70]  # 電子設備類別ID\n",
        "                electronics_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in electronics_ids]\n",
        "\n",
        "                if electronics_objects:\n",
        "                    electronics_names = [obj.get(\"class_name\", \"electronic device\") for obj in electronics_objects[:3]]\n",
        "                    unique_names = list(set(electronics_names))\n",
        "                    return \", \".join(unique_names) if len(unique_names) > 1 else unique_names[0]\n",
        "                return \"electronic devices\"\n",
        "\n",
        "            elif placeholder == \"people_count\":\n",
        "                # 計算人數\n",
        "                people_count = len([obj for obj in detected_objects if obj.get(\"class_id\") == 0])\n",
        "\n",
        "                if people_count == 0:\n",
        "                    return \"no people\"\n",
        "                elif people_count == 1:\n",
        "                    return \"one person\"\n",
        "                elif people_count < 5:\n",
        "                    return f\"{people_count} people\"\n",
        "                else:\n",
        "                    return \"several people\"\n",
        "\n",
        "            elif placeholder == \"seating\":\n",
        "                # 提取座位物品\n",
        "                seating_ids = [56, 57]  # chair, sofa\n",
        "                seating_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in seating_ids]\n",
        "\n",
        "                if seating_objects:\n",
        "                    seating_names = [obj.get(\"class_name\", \"seating\") for obj in seating_objects[:2]]\n",
        "                    unique_names = list(set(seating_names))\n",
        "                    return \", \".join(unique_names) if len(unique_names) > 1 else unique_names[0]\n",
        "                return \"seating arrangements\"\n",
        "\n",
        "            # 如果沒有匹配的特定邏輯，返回None\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating scene-specific content for '{placeholder}': {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_confidence_template(self, confidence_level: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取指定信心度級別的模板\n",
        "\n",
        "        Args:\n",
        "            confidence_level: 信心度級別 ('high', 'medium', 'low')\n",
        "\n",
        "        Returns:\n",
        "            str: 信心度模板字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            confidence_templates = self.templates.get(\"confidence_templates\", {})\n",
        "\n",
        "            if confidence_level in confidence_templates:\n",
        "                return confidence_templates[confidence_level]\n",
        "\n",
        "            # 備用模板\n",
        "            fallback_templates = {\n",
        "                \"high\": \"{description} {details}\",\n",
        "                \"medium\": \"This appears to be {description} {details}\",\n",
        "                \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "            }\n",
        "\n",
        "            return fallback_templates.get(confidence_level, \"{description} {details}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting confidence template for '{confidence_level}': {str(e)}\")\n",
        "            return \"{description} {details}\"\n",
        "\n",
        "    def get_lighting_template(self, lighting_type: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取指定照明類型的模板\n",
        "\n",
        "        Args:\n",
        "            lighting_type: 照明類型\n",
        "\n",
        "        Returns:\n",
        "            str: 照明描述模板\n",
        "        \"\"\"\n",
        "        try:\n",
        "            lighting_templates = self.templates.get(\"lighting_templates\", {})\n",
        "\n",
        "            if lighting_type in lighting_templates:\n",
        "                return lighting_templates[lighting_type]\n",
        "\n",
        "            # 備用模板\n",
        "            return f\"The scene is captured with {lighting_type.replace('_', ' ')} lighting conditions.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting lighting template for '{lighting_type}': {str(e)}\")\n",
        "            return \"The lighting conditions are not clearly identifiable.\"\n",
        "\n",
        "    def get_viewpoint_template(self, viewpoint: str) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        獲取指定視角的模板\n",
        "\n",
        "        Args:\n",
        "            viewpoint: 視角類型\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, str]: 包含prefix、observation等鍵的視角模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            viewpoint_templates = self.templates.get(\"viewpoint_templates\", {})\n",
        "\n",
        "            if viewpoint in viewpoint_templates:\n",
        "                return viewpoint_templates[viewpoint]\n",
        "\n",
        "            # 備用模板\n",
        "            fallback_templates = {\n",
        "                \"eye_level\": {\n",
        "                    \"prefix\": \"From eye level, \",\n",
        "                    \"observation\": \"the scene is viewed straight ahead.\",\n",
        "                    \"short_desc\": \"at eye level\"\n",
        "                },\n",
        "                \"aerial\": {\n",
        "                    \"prefix\": \"From above, \",\n",
        "                    \"observation\": \"the scene is viewed from a bird's-eye perspective.\",\n",
        "                    \"short_desc\": \"from above\"\n",
        "                },\n",
        "                \"low_angle\": {\n",
        "                    \"prefix\": \"From a low angle, \",\n",
        "                    \"observation\": \"the scene is viewed from below looking upward.\",\n",
        "                    \"short_desc\": \"from below\"\n",
        "                },\n",
        "                \"elevated\": {\n",
        "                    \"prefix\": \"From an elevated position, \",\n",
        "                    \"observation\": \"the scene is viewed from a higher vantage point.\",\n",
        "                    \"short_desc\": \"from an elevated position\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "            return fallback_templates.get(viewpoint, fallback_templates[\"eye_level\"])\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting viewpoint template for '{viewpoint}': {str(e)}\")\n",
        "            return {\n",
        "                \"prefix\": \"\",\n",
        "                \"observation\": \"the scene is viewed normally.\",\n",
        "                \"short_desc\": \"normally\"\n",
        "            }\n",
        "\n",
        "    def get_cultural_template(self, cultural_context: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取指定文化語境的模板\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 文化語境\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 文化模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cultural_templates = self.templates.get(\"cultural_templates\", {})\n",
        "\n",
        "            if cultural_context in cultural_templates:\n",
        "                return cultural_templates[cultural_context]\n",
        "\n",
        "            # 備用模板\n",
        "            return {\n",
        "                \"elements\": [\"cultural elements\"],\n",
        "                \"description\": f\"The scene displays {cultural_context} cultural characteristics.\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting cultural template for '{cultural_context}': {str(e)}\")\n",
        "            return {\n",
        "                \"elements\": [\"various elements\"],\n",
        "                \"description\": \"The scene displays cultural characteristics.\"\n",
        "            }\n",
        "\n",
        "    def get_scene_detail_templates(self, scene_type: str, viewpoint: Optional[str] = None) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取場景詳細描述模板\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型\n",
        "            viewpoint: 可選的視角類型\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 場景描述模板列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            scene_templates = self.templates.get(\"scene_detail_templates\", {})\n",
        "\n",
        "            # 首先嘗試獲取特定視角的模板\n",
        "            if viewpoint:\n",
        "                viewpoint_key = f\"{scene_type}_{viewpoint}\"\n",
        "                if viewpoint_key in scene_templates:\n",
        "                    return scene_templates[viewpoint_key]\n",
        "\n",
        "            # 然後嘗試獲取場景類型的通用模板\n",
        "            if scene_type in scene_templates:\n",
        "                return scene_templates[scene_type]\n",
        "\n",
        "            # 最後使用默認模板\n",
        "            if \"default\" in scene_templates:\n",
        "                return scene_templates[\"default\"]\n",
        "\n",
        "            # 備用模板\n",
        "            return [\"A scene with various elements and objects.\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting scene detail templates for '{scene_type}': {str(e)}\")\n",
        "            return [\"A scene with various elements and objects.\"]\n",
        "\n",
        "    def reload_templates(self):\n",
        "        \"\"\"\n",
        "        重新載入所有模板\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.template_manager.reload_templates()\n",
        "            self.logger.info(\"Templates reloaded successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error reloading templates: {str(e)}\")\n",
        "\n",
        "    def get_template_categories(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取所有可用的模板類別名稱\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 模板類別名稱列表\n",
        "        \"\"\"\n",
        "        return list(self.templates.keys())\n",
        "\n",
        "    def template_exists(self, category: str, key: Optional[str] = None) -> bool:\n",
        "        \"\"\"\n",
        "        檢查模板是否存在\n",
        "\n",
        "        Args:\n",
        "            category: 模板類別\n",
        "            key: 可選的模板鍵值\n",
        "\n",
        "        Returns:\n",
        "            bool: 模板是否存在\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if category not in self.templates:\n",
        "                return False\n",
        "\n",
        "            if key is None:\n",
        "                return True\n",
        "\n",
        "            category_templates = self.templates[category]\n",
        "            if isinstance(category_templates, dict):\n",
        "                return key in category_templates\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error checking template existence for {category}.{key}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def apply_template(self, template: Union[str, Dict[str, Any]], scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        應用選定的模板來生成場景描述\n",
        "\n",
        "        Args:\n",
        "            template: 模板字符串或模板內容字典\n",
        "            scene_data: 場景分析的資料字典\n",
        "\n",
        "        Returns:\n",
        "            str: 最終生成的場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 如果傳入的是字符串模板，直接使用填充邏輯\n",
        "            if isinstance(template, str):\n",
        "                self.logger.debug(\"Processing string template directly\")\n",
        "\n",
        "                # 提取場景數據\n",
        "                detected_objects = scene_data.get(\"detected_objects\", [])\n",
        "                scene_type = scene_data.get(\"scene_type\", \"general\")\n",
        "                places365_info = scene_data.get(\"places365_info\")\n",
        "                object_statistics = scene_data.get(\"object_statistics\")\n",
        "                functional_zones = scene_data.get(\"functional_zones\", {})\n",
        "\n",
        "                # 暫存功能區域資訊供填充邏輯使用\n",
        "                self._current_functional_zones = functional_zones\n",
        "\n",
        "                # 使用現有的填充邏輯\n",
        "                filled_description = self.fill_template(\n",
        "                    template,\n",
        "                    detected_objects,\n",
        "                    scene_type,\n",
        "                    places365_info,\n",
        "                    object_statistics\n",
        "                )\n",
        "\n",
        "                # 清理暫存資訊\n",
        "                if hasattr(self, '_current_functional_zones'):\n",
        "                    delattr(self, '_current_functional_zones')\n",
        "\n",
        "                return filled_description\n",
        "\n",
        "            # 如果傳入的是字典結構模板\n",
        "            elif isinstance(template, dict):\n",
        "                self.logger.debug(\"Processing structured template\")\n",
        "                return self._process_structured_template(template, scene_data)\n",
        "\n",
        "            # 如果是模板名稱字符串且需要從registry獲取\n",
        "            elif hasattr(self, 'template_registry') and template in self.template_registry:\n",
        "                template_dict = self.template_registry[template]\n",
        "                return self._process_structured_template(template_dict, scene_data)\n",
        "\n",
        "            else:\n",
        "                self.logger.warning(f\"Invalid template format or template not found: {type(template)}\")\n",
        "                return self._generate_fallback_scene_description(scene_data)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error applying template: {str(e)}\")\n",
        "            return self._generate_fallback_scene_description(scene_data)\n",
        "\n",
        "    def _process_structured_template(self, template: Dict[str, Any], scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        處理結構化模板字典\n",
        "\n",
        "        Args:\n",
        "            template: 結構化模板字典\n",
        "            scene_data: 場景分析資料\n",
        "\n",
        "        Returns:\n",
        "            str: 生成的場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 提取 scene_data 中各區塊資料\n",
        "            zone_data = scene_data.get(\"functional_zones\", scene_data.get(\"zones\", {}))\n",
        "            object_data = scene_data.get(\"detected_objects\", [])\n",
        "            scene_context = scene_data.get(\"scene_context\", \"\")\n",
        "\n",
        "            # 獲取模板結構\n",
        "            structure = template.get(\"structure\", [])\n",
        "            if not structure:\n",
        "                self.logger.warning(\"Template has no structure defined\")\n",
        "                return self._generate_fallback_scene_description(scene_data)\n",
        "\n",
        "            description_parts = []\n",
        "\n",
        "            # 按照模板結構生成描述\n",
        "            for section in structure:\n",
        "                section_type = section.get(\"type\", \"\")\n",
        "                content = section.get(\"content\", \"\")\n",
        "\n",
        "                if section_type == \"opening\":\n",
        "                    description_parts.append(content)\n",
        "\n",
        "                elif section_type == \"zone_analysis\":\n",
        "                    zone_descriptions = self._generate_zone_descriptions(zone_data, section)\n",
        "                    if zone_descriptions:\n",
        "                        description_parts.extend(zone_descriptions)\n",
        "\n",
        "                elif section_type == \"object_summary\":\n",
        "                    object_summary = self._generate_object_summary(object_data, section)\n",
        "                    if object_summary:\n",
        "                        description_parts.append(object_summary)\n",
        "\n",
        "                elif section_type == \"conclusion\":\n",
        "                    conclusion = self._generate_conclusion(template, zone_data, object_data)\n",
        "                    if conclusion:\n",
        "                        description_parts.append(conclusion)\n",
        "\n",
        "            # 合併並標準化輸出\n",
        "            final_description = self._standardize_final_description(\" \".join(description_parts))\n",
        "            self.logger.info(\"Successfully applied structured template\")\n",
        "            return final_description\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing structured template: {str(e)}\")\n",
        "            return self._generate_fallback_scene_description(scene_data)\n",
        "\n",
        "    def _generate_fallback_scene_description(self, scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        生成備用場景描述\n",
        "\n",
        "        Args:\n",
        "            scene_data: 場景分析資料\n",
        "\n",
        "        Returns:\n",
        "            str: 備用場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            detected_objects = scene_data.get(\"detected_objects\", [])\n",
        "            zones = scene_data.get(\"functional_zones\", scene_data.get(\"zones\", {}))\n",
        "            scene_type = scene_data.get(\"scene_type\", \"general\")\n",
        "\n",
        "            object_count = len(detected_objects)\n",
        "            zone_count = len(zones)\n",
        "\n",
        "            if zone_count > 0 and object_count > 0:\n",
        "                return f\"Scene analysis completed with {zone_count} functional areas containing {object_count} identified objects.\"\n",
        "            elif object_count > 0:\n",
        "                return f\"Scene analysis identified {object_count} objects in this {scene_type.replace('_', ' ')} environment.\"\n",
        "            else:\n",
        "                return f\"Scene analysis completed for this {scene_type.replace('_', ' ')} environment.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating fallback description: {str(e)}\")\n",
        "            return \"Scene analysis completed with detected objects and functional areas.\"\n",
        "\n",
        "\n",
        "    def _generate_zone_descriptions(self, zone_data: Dict[str, Any], section: Dict[str, Any]) -> List[str]:\n",
        "        \"\"\"\n",
        "        生成功能區域描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            descriptions = []\n",
        "\n",
        "            if not zone_data:\n",
        "                return descriptions\n",
        "\n",
        "            # 直接處理區域資料（zone_data 本身就是區域字典）\n",
        "            sorted_zones = sorted(zone_data.items(),\n",
        "                                key=lambda x: len(x[1].get(\"objects\", [])),\n",
        "                                reverse=True)\n",
        "\n",
        "            for zone_name, zone_info in sorted_zones:\n",
        "                description = zone_info.get(\"description\", \"\")\n",
        "                objects = zone_info.get(\"objects\", [])\n",
        "\n",
        "                if objects:\n",
        "                    # 使用現有描述或生成基於物件的描述\n",
        "                    if description and not any(tech in description.lower() for tech in ['zone', 'area', 'region']):\n",
        "                        zone_desc = description\n",
        "                    else:\n",
        "                        # 生成更自然的區域描述\n",
        "                        clean_zone_name = zone_name.replace('_', ' ').replace(' area', '').replace(' zone', '')\n",
        "                        object_list = ', '.join(objects[:3])\n",
        "\n",
        "                        if 'crossing' in zone_name or 'pedestrian' in zone_name:\n",
        "                            zone_desc = f\"In the central crossing area, there are {object_list}.\"\n",
        "                        elif 'vehicle' in zone_name or 'traffic' in zone_name:\n",
        "                            zone_desc = f\"The vehicle movement area includes {object_list}.\"\n",
        "                        elif 'control' in zone_name:\n",
        "                            zone_desc = f\"Traffic control elements include {object_list}.\"\n",
        "                        else:\n",
        "                            zone_desc = f\"The {clean_zone_name} contains {object_list}.\"\n",
        "\n",
        "                        if len(objects) > 3:\n",
        "                            zone_desc += f\" Along with {len(objects) - 3} additional elements.\"\n",
        "\n",
        "                    descriptions.append(zone_desc)\n",
        "\n",
        "            return descriptions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating zone descriptions: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def _generate_object_summary(self, object_data: List[Dict], section: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        生成物件摘要描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not object_data:\n",
        "                return \"\"\n",
        "\n",
        "            # 統計物件類型並計算重要性\n",
        "            object_stats = {}\n",
        "            for obj in object_data:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                confidence = obj.get(\"confidence\", 0.5)\n",
        "\n",
        "                if class_name not in object_stats:\n",
        "                    object_stats[class_name] = {\"count\": 0, \"total_confidence\": 0}\n",
        "\n",
        "                object_stats[class_name][\"count\"] += 1\n",
        "                object_stats[class_name][\"total_confidence\"] += confidence\n",
        "\n",
        "            # 按重要性排序（結合數量和置信度）\n",
        "            sorted_objects = []\n",
        "            for class_name, stats in object_stats.items():\n",
        "                count = stats[\"count\"]\n",
        "                avg_confidence = stats[\"total_confidence\"] / count\n",
        "                importance = count * 0.6 + avg_confidence * 0.4\n",
        "                sorted_objects.append((class_name, count, importance))\n",
        "\n",
        "            sorted_objects.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "            # 生成自然語言描述\n",
        "            descriptions = []\n",
        "            for class_name, count, _ in sorted_objects[:5]:\n",
        "                clean_name = class_name.replace('_', ' ')\n",
        "                if count == 1:\n",
        "                    article = \"an\" if clean_name[0].lower() in 'aeiou' else \"a\"\n",
        "                    descriptions.append(f\"{article} {clean_name}\")\n",
        "                else:\n",
        "                    descriptions.append(f\"{count} {clean_name}s\")\n",
        "\n",
        "            if len(descriptions) == 1:\n",
        "                return f\"The scene features {descriptions[0]}.\"\n",
        "            elif len(descriptions) == 2:\n",
        "                return f\"The scene features {descriptions[0]} and {descriptions[1]}.\"\n",
        "            else:\n",
        "                main_items = \", \".join(descriptions[:-1])\n",
        "                return f\"The scene features {main_items}, and {descriptions[-1]}.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating object summary: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _generate_conclusion(self, template: Dict[str, Any], zone_data: Dict[str, Any],\n",
        "                            object_data: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        生成結論描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            scene_type = template.get(\"scene_type\", \"general\")\n",
        "            zones_count = len(zone_data)\n",
        "            objects_count = len(object_data)\n",
        "\n",
        "            if scene_type == \"indoor\":\n",
        "                conclusion = f\"This indoor environment demonstrates clear functional organization with {zones_count} distinct areas and {objects_count} identified objects.\"\n",
        "            elif scene_type == \"outdoor\":\n",
        "                conclusion = f\"This outdoor scene shows dynamic activity patterns across {zones_count} functional zones with {objects_count} detected elements.\"\n",
        "            else:\n",
        "                conclusion = f\"The scene analysis reveals {zones_count} functional areas containing {objects_count} identifiable objects.\"\n",
        "\n",
        "            return conclusion\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating conclusion: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _standardize_final_description(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        對最終描述進行標準化處理\n",
        "\n",
        "        Args:\n",
        "            description: 原始描述文本\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化後的描述文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 移除多餘空格\n",
        "            description = \" \".join(description.split())\n",
        "\n",
        "            # 確保句子間有適當間距\n",
        "            description = description.replace(\". \", \". \")\n",
        "\n",
        "            # 移除任何殘留的技術性標識符\n",
        "            technical_patterns = [\n",
        "                r'zone_\\d+', r'area_\\d+', r'region_\\d+',\n",
        "                r'_zone', r'_area', r'_region'\n",
        "            ]\n",
        "\n",
        "            for pattern in technical_patterns:\n",
        "                description = re.sub(pattern, '', description, flags=re.IGNORECASE)\n",
        "\n",
        "            return description.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error standardizing final description: {str(e)}\")\n",
        "            return description"
      ],
      "metadata": {
        "id": "dDbfx9Oxtof4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43ab7a8-8bb9-484a-a9e8-7e0d9a0dd8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing template_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile object_description_generator.py\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import numpy as np\n",
        "\n",
        "class ObjectDescriptionError(Exception):\n",
        "    \"\"\"物件描述生成過程中的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ObjectDescriptionGenerator:\n",
        "    \"\"\"\n",
        "    物件描述生成器 - 負責將檢測到的物件轉換為自然語言描述\n",
        "\n",
        "    該類別處理物件相關的所有描述生成邏輯，包括重要物件的識別、\n",
        "    空間位置描述、物件列表格式化以及描述文本的優化。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 min_prominence_score: float = 0.1,\n",
        "                 max_categories_to_return: int = 5,\n",
        "                 max_total_objects: int = 7,\n",
        "                 confidence_threshold_for_description: float = 0.25,\n",
        "                 region_analyzer: Optional[Any] = None):\n",
        "        \"\"\"\n",
        "        初始化物件描述生成器\n",
        "\n",
        "        Args:\n",
        "            min_prominence_score: 物件顯著性的最低分數閾值\n",
        "            max_categories_to_return: 返回的物件類別最大數量\n",
        "            max_total_objects: 返回的物件總數上限\n",
        "            confidence_threshold_for_description: 用於描述的置信度閾值\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        self.min_prominence_score = min_prominence_score\n",
        "        self.max_categories_to_return = max_categories_to_return\n",
        "        self.max_total_objects = max_total_objects\n",
        "        self.confidence_threshold_for_description = confidence_threshold_for_description\n",
        "        self.region_analyzer = region_analyzer\n",
        "\n",
        "        self.logger.info(\"ObjectDescriptionGenerator initialized with prominence_score=%.2f, \"\n",
        "                        \"max_categories=%d, max_objects=%d, confidence_threshold=%.2f\",\n",
        "                        min_prominence_score, max_categories_to_return,\n",
        "                        max_total_objects, confidence_threshold_for_description)\n",
        "\n",
        "    def get_prominent_objects(self, detected_objects: List[Dict],\n",
        "                          min_prominence_score: float = 0.5,\n",
        "                          max_categories_to_return: Optional[int] = None) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        獲取最重要的物件，基於置信度、大小和位置計算重要性評分\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            min_prominence_score: 最小重要性分數閾值，範圍 0.0-1.0\n",
        "            max_categories_to_return: 可選的最大返回類別數量限制\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: 按重要性排序的物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                return []\n",
        "\n",
        "            prominent_objects = []\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                # 計算重要性評分\n",
        "                prominence_score = self._calculate_prominence_score(obj)\n",
        "\n",
        "                # 只保留超過閾值的物件\n",
        "                if prominence_score >= min_prominence_score:\n",
        "                    obj_copy = obj.copy()\n",
        "                    obj_copy['prominence_score'] = prominence_score\n",
        "                    prominent_objects.append(obj_copy)\n",
        "\n",
        "            # 按重要性評分排序（從高到低）\n",
        "            prominent_objects.sort(key=lambda x: x.get('prominence_score', 0), reverse=True)\n",
        "\n",
        "            # 如果指定了最大類別數量限制，進行過濾\n",
        "            if max_categories_to_return is not None and max_categories_to_return > 0:\n",
        "                categories_seen = set()\n",
        "                filtered_objects = []\n",
        "\n",
        "                for obj in prominent_objects:\n",
        "                    class_name = obj.get(\"class_name\", \"unknown\")\n",
        "\n",
        "                    # 如果是新類別且未達到限制\n",
        "                    if class_name not in categories_seen:\n",
        "                        if len(categories_seen) < max_categories_to_return:\n",
        "                            categories_seen.add(class_name)\n",
        "                            filtered_objects.append(obj)\n",
        "                    else:\n",
        "                        # 已見過的類別，直接添加\n",
        "                        filtered_objects.append(obj)\n",
        "\n",
        "                return filtered_objects\n",
        "\n",
        "            return prominent_objects\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating prominent objects: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def set_region_analyzer(self, region_analyzer: Any) -> None:\n",
        "        \"\"\"\n",
        "        設置RegionAnalyzer，用於標準化空間描述生成\n",
        "\n",
        "        Args:\n",
        "            region_analyzer: RegionAnalyzer實例\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.region_analyzer = region_analyzer\n",
        "            self.logger.info(\"RegionAnalyzer instance set for ObjectDescriptionGenerator\")\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error setting RegionAnalyzer: {str(e)}\")\n",
        "\n",
        "    def _get_standardized_spatial_description(self, obj: Dict) -> str:\n",
        "        \"\"\"\n",
        "        使用RegionAnalyzer生成標準化空間描述的內部方法\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化空間描述，失敗時返回空字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if hasattr(self, 'region_analyzer') and self.region_analyzer:\n",
        "                region = obj.get(\"region\", \"\")\n",
        "                object_type = obj.get(\"class_name\", \"\")\n",
        "\n",
        "                if hasattr(self.region_analyzer, 'get_contextual_spatial_description'):\n",
        "                    return self.region_analyzer.get_contextual_spatial_description(region, object_type)\n",
        "                elif hasattr(self.region_analyzer, 'get_spatial_description_phrase'):\n",
        "                    return self.region_analyzer.get_spatial_description_phrase(region)\n",
        "\n",
        "            return \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting standardized spatial description: {str(e)}\")\n",
        "            if object_type:\n",
        "                return f\"visible in the scene\"\n",
        "            return \"present in the view\"\n",
        "\n",
        "    def _calculate_prominence_score(self, obj: Dict) -> float:\n",
        "        \"\"\"\n",
        "        計算物件的重要性評分\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典，包含檢測信息\n",
        "\n",
        "        Returns:\n",
        "            float: 重要性評分 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 基礎置信度評分 (權重: 40%)\n",
        "            confidence = obj.get(\"confidence\", 0.5)\n",
        "            confidence_score = confidence * 0.4\n",
        "\n",
        "            # 大小評分 (權重: 30%)\n",
        "            normalized_area = obj.get(\"normalized_area\", 0.1)\n",
        "            # 使用對數縮放避免過大物件主導評分\n",
        "            size_score = min(np.log(normalized_area * 10 + 1) / np.log(11), 1.0) * 0.3\n",
        "\n",
        "            # 位置評分 (權重: 20%)\n",
        "            # 中心區域的物件通常更重要\n",
        "            center_x, center_y = obj.get(\"normalized_center\", [0.5, 0.5])\n",
        "            distance_from_center = np.sqrt((center_x - 0.5)**2 + (center_y - 0.5)**2)\n",
        "            position_score = (1 - min(distance_from_center * 2, 1.0)) * 0.2\n",
        "\n",
        "            # 類別重要性評分 (權重: 10%)\n",
        "            class_importance = self._get_class_importance(obj.get(\"class_name\", \"unknown\"))\n",
        "            class_score = class_importance * 0.1\n",
        "\n",
        "            total_score = confidence_score + size_score + position_score + class_score\n",
        "\n",
        "            # 確保評分在有效範圍內\n",
        "            return max(0.0, min(1.0, total_score))\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error calculating prominence score for object: {str(e)}\")\n",
        "            return 0.5  # 返回中等評分作為備用\n",
        "\n",
        "    def _get_class_importance(self, class_name: str) -> float:\n",
        "        \"\"\"\n",
        "        根據物件類別返回重要性係數\n",
        "\n",
        "        Args:\n",
        "            class_name: 物件類別名稱\n",
        "\n",
        "        Returns:\n",
        "            float: 類別重要性係數 (0.0-1.0)\n",
        "        \"\"\"\n",
        "        # 高重要性物件（人、車輛、建築）\n",
        "        high_importance = [\"person\", \"car\", \"truck\", \"bus\", \"motorcycle\", \"bicycle\", \"building\"]\n",
        "\n",
        "        # 中等重要性物件（家具、電器）\n",
        "        medium_importance = [\"chair\", \"couch\", \"tv\", \"laptop\", \"refrigerator\", \"dining table\", \"bed\"]\n",
        "\n",
        "        # 低重要性物件（小物品、配件）\n",
        "        low_importance = [\"handbag\", \"backpack\", \"umbrella\", \"cell phone\", \"remote\", \"mouse\"]\n",
        "\n",
        "        class_name_lower = class_name.lower()\n",
        "\n",
        "        if any(item in class_name_lower for item in high_importance):\n",
        "            return 1.0\n",
        "        elif any(item in class_name_lower for item in medium_importance):\n",
        "            return 0.7\n",
        "        elif any(item in class_name_lower for item in low_importance):\n",
        "            return 0.4\n",
        "        else:\n",
        "            return 0.6  # 預設中等重要性\n",
        "\n",
        "    def format_object_list_for_description(self,\n",
        "                                          objects: List[Dict],\n",
        "                                          use_indefinite_article_for_one: bool = False,\n",
        "                                          count_threshold_for_generalization: int = -1,\n",
        "                                          max_types_to_list: int = 5) -> str:\n",
        "        \"\"\"\n",
        "        將物件列表格式化為人類可讀的字符串，包含計數信息\n",
        "\n",
        "        Args:\n",
        "            objects: 物件字典列表，每個應包含 'class_name'\n",
        "            use_indefinite_article_for_one: 單個物件是否使用 \"a/an\"，否則使用 \"one\"\n",
        "            count_threshold_for_generalization: 超過此計數時使用通用術語，-1表示精確計數\n",
        "            max_types_to_list: 列表中包含的不同物件類型最大數量\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化的物件描述字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not objects:\n",
        "                return \"no specific objects clearly identified\"\n",
        "\n",
        "            counts: Dict[str, int] = {}\n",
        "            for obj in objects:\n",
        "                name = obj.get(\"class_name\", \"unknown object\")\n",
        "                if name == \"unknown object\" or not name:\n",
        "                    continue\n",
        "                counts[name] = counts.get(name, 0) + 1\n",
        "\n",
        "            if not counts:\n",
        "                return \"no specific objects clearly identified\"\n",
        "\n",
        "            descriptions = []\n",
        "            # 按計數降序然後按名稱升序排序，限制物件類型數量\n",
        "            sorted_counts = sorted(counts.items(), key=lambda item: (-item[1], item[0]))[:max_types_to_list]\n",
        "\n",
        "            for name, count in sorted_counts:\n",
        "                if count == 1:\n",
        "                    if use_indefinite_article_for_one:\n",
        "                        if name[0].lower() in 'aeiou':\n",
        "                            descriptions.append(f\"an {name}\")\n",
        "                        else:\n",
        "                            descriptions.append(f\"a {name}\")\n",
        "                    else:\n",
        "                        descriptions.append(f\"one {name}\")\n",
        "                else:\n",
        "                    # 處理複數形式\n",
        "                    plural_name = name\n",
        "                    if name.endswith(\"y\") and not name.lower().endswith((\"ay\", \"ey\", \"iy\", \"oy\", \"uy\")):\n",
        "                        plural_name = name[:-1] + \"ies\"\n",
        "                    elif name.endswith((\"s\", \"sh\", \"ch\", \"x\", \"z\")):\n",
        "                        plural_name = name + \"es\"\n",
        "                    elif not name.endswith(\"s\"):\n",
        "                        plural_name = name + \"s\"\n",
        "\n",
        "                    if count_threshold_for_generalization != -1 and count > count_threshold_for_generalization:\n",
        "                        if count <= count_threshold_for_generalization + 3:\n",
        "                            descriptions.append(f\"several {plural_name}\")\n",
        "                        else:\n",
        "                            descriptions.append(f\"many {plural_name}\")\n",
        "                    else:\n",
        "                        descriptions.append(f\"{count} {plural_name}\")\n",
        "\n",
        "            if not descriptions:\n",
        "                return \"no specific objects clearly identified\"\n",
        "\n",
        "            if len(descriptions) == 1:\n",
        "                return descriptions[0]\n",
        "            elif len(descriptions) == 2:\n",
        "                return f\"{descriptions[0]} and {descriptions[1]}\"\n",
        "            else:\n",
        "                # 使用牛津逗號格式\n",
        "                return \", \".join(descriptions[:-1]) + f\", and {descriptions[-1]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting object list: {str(e)}\")\n",
        "            return \"various objects\"\n",
        "\n",
        "    def get_spatial_description(self, obj: Dict, image_width: Optional[int] = None,\n",
        "                           image_height: Optional[int] = None,\n",
        "                           region_analyzer: Optional[Any] = None) -> str:\n",
        "        \"\"\"\n",
        "        為物件生成空間位置描述\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典\n",
        "            image_width: 可選的圖像寬度\n",
        "            image_height: 可選的圖像高度\n",
        "            region_analyzer: 可選的RegionAnalyzer實例，用於生成標準化描述\n",
        "\n",
        "        Returns:\n",
        "            str: 空間描述字符串，空值region時返回空字串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            region = obj.get(\"region\") or \"\"\n",
        "\n",
        "            # 處理空值或無效region，直接返回空字串避免不完整描述\n",
        "            if not region.strip() or region == \"unknown\":\n",
        "                # 根據物件類型提供合適的預設位置描述\n",
        "                if object_type and any(vehicle in object_type.lower() for vehicle in [\"car\", \"truck\", \"bus\"]):\n",
        "                    return \"positioned in the scene\"\n",
        "                elif object_type and \"person\" in object_type.lower():\n",
        "                    return \"present in the area\"\n",
        "                else:\n",
        "                    return \"located in the scene\"\n",
        "\n",
        "            # 如果提供了RegionAnalyzer實例，使用其標準化方法\n",
        "            if region_analyzer and hasattr(region_analyzer, 'get_spatial_description_phrase'):\n",
        "                object_type = obj.get(\"class_name\", \"\")\n",
        "                if hasattr(region_analyzer, 'get_contextual_spatial_description'):\n",
        "                    spatial_desc = region_analyzer.get_contextual_spatial_description(region, object_type)\n",
        "                else:\n",
        "                    spatial_desc = region_analyzer.get_spatial_description_phrase(region)\n",
        "\n",
        "                if spatial_desc:\n",
        "                    return spatial_desc\n",
        "\n",
        "            # 備用邏輯：使用改進的內建映射\n",
        "            clean_region = region.replace('_', ' ').strip().lower()\n",
        "\n",
        "            region_map = {\n",
        "                \"top left\": \"in the upper left area\",\n",
        "                \"top center\": \"in the upper area\",\n",
        "                \"top right\": \"in the upper right area\",\n",
        "                \"middle left\": \"on the left side\",\n",
        "                \"middle center\": \"in the center\",\n",
        "                \"center\": \"in the center\",\n",
        "                \"middle right\": \"on the right side\",\n",
        "                \"bottom left\": \"in the lower left area\",\n",
        "                \"bottom center\": \"in the lower area\",\n",
        "                \"bottom right\": \"in the lower right area\"\n",
        "            }\n",
        "\n",
        "            # 直接映射匹配\n",
        "            if clean_region in region_map:\n",
        "                return region_map[clean_region]\n",
        "\n",
        "            # 模糊匹配處理\n",
        "            if \"top\" in clean_region and \"left\" in clean_region:\n",
        "                return \"in the upper left area\"\n",
        "            elif \"top\" in clean_region and \"right\" in clean_region:\n",
        "                return \"in the upper right area\"\n",
        "            elif \"bottom\" in clean_region and \"left\" in clean_region:\n",
        "                return \"in the lower left area\"\n",
        "            elif \"bottom\" in clean_region and \"right\" in clean_region:\n",
        "                return \"in the lower right area\"\n",
        "            elif \"top\" in clean_region:\n",
        "                return \"in the upper area\"\n",
        "            elif \"bottom\" in clean_region:\n",
        "                return \"in the lower area\"\n",
        "            elif \"left\" in clean_region:\n",
        "                return \"on the left side\"\n",
        "            elif \"right\" in clean_region:\n",
        "                return \"on the right side\"\n",
        "            elif \"center\" in clean_region or \"middle\" in clean_region:\n",
        "                return \"in the center\"\n",
        "\n",
        "            # 如果region無法識別，使用normalized_center作為最後備用\n",
        "            norm_center = obj.get(\"normalized_center\")\n",
        "            if norm_center and image_width and image_height:\n",
        "                x_norm, y_norm = norm_center\n",
        "                h_pos = \"left\" if x_norm < 0.4 else \"right\" if x_norm > 0.6 else \"center\"\n",
        "                v_pos = \"upper\" if y_norm < 0.4 else \"lower\" if y_norm > 0.6 else \"center\"\n",
        "\n",
        "                if h_pos == \"center\" and v_pos == \"center\":\n",
        "                    return \"in the center\"\n",
        "                return f\"in the {v_pos} {h_pos} area\"\n",
        "\n",
        "            # 如果所有方法都失敗，返回空字串\n",
        "            return \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating spatial description: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def optimize_object_description(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        優化物件描述，避免重複列舉相同物件\n",
        "\n",
        "        Args:\n",
        "            description: 原始描述文本\n",
        "\n",
        "        Returns:\n",
        "            str: 優化後的描述文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 處理床鋪重複描述\n",
        "            if \"bed in the room\" in description:\n",
        "                description = description.replace(\"a bed in the room\", \"a bed\")\n",
        "\n",
        "            # 處理重複的物件列表\n",
        "            object_lists = re.findall(r'with ([^\\.]+?)(?:\\.|\\band\\b)', description)\n",
        "\n",
        "            for obj_list in object_lists:\n",
        "                # 計算每個物件出現次數\n",
        "                items = re.findall(r'([a-zA-Z\\s]+)(?:,|\\band\\b|$)', obj_list)\n",
        "                item_counts = {}\n",
        "\n",
        "                for item in items:\n",
        "                    item = item.strip()\n",
        "                    if item and item not in [\"and\", \"with\"]:\n",
        "                        if item not in item_counts:\n",
        "                            item_counts[item] = 0\n",
        "                        item_counts[item] += 1\n",
        "\n",
        "                # 生成優化後的物件列表\n",
        "                if item_counts:\n",
        "                    new_items = []\n",
        "                    for item, count in item_counts.items():\n",
        "                        if count > 1:\n",
        "                            new_items.append(f\"{count} {item}s\")\n",
        "                        else:\n",
        "                            new_items.append(item)\n",
        "\n",
        "                    # 格式化新列表\n",
        "                    if len(new_items) == 1:\n",
        "                        new_list = new_items[0]\n",
        "                    elif len(new_items) == 2:\n",
        "                        new_list = f\"{new_items[0]} and {new_items[1]}\"\n",
        "                    else:\n",
        "                        new_list = \", \".join(new_items[:-1]) + f\", and {new_items[-1]}\"\n",
        "\n",
        "                    # 替換原始列表\n",
        "                    description = description.replace(obj_list, new_list)\n",
        "\n",
        "            return description\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error optimizing object description: {str(e)}\")\n",
        "            return description\n",
        "\n",
        "    def generate_dynamic_everyday_description(self,\n",
        "                                            detected_objects: List[Dict],\n",
        "                                            lighting_info: Optional[Dict] = None,\n",
        "                                            viewpoint: str = \"eye_level\",\n",
        "                                            spatial_analysis: Optional[Dict] = None,\n",
        "                                            image_dimensions: Optional[Tuple[int, int]] = None,\n",
        "                                            places365_info: Optional[Dict] = None,\n",
        "                                            object_statistics: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        為日常場景動態生成描述，基於所有相關的檢測物件、計數和上下文\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            lighting_info: 照明信息\n",
        "            viewpoint: 視角類型\n",
        "            spatial_analysis: 空間分析結果\n",
        "            image_dimensions: 圖像尺寸\n",
        "            places365_info: Places365場景分類信息\n",
        "            object_statistics: 物件統計信息\n",
        "\n",
        "        Returns:\n",
        "            str: 動態生成的場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            description_segments = []\n",
        "            image_width, image_height = image_dimensions if image_dimensions else (None, None)\n",
        "\n",
        "            self.logger.debug(f\"Generating dynamic description for {len(detected_objects)} objects, \"\n",
        "                            f\"viewpoint: {viewpoint}, lighting: {lighting_info is not None}\")\n",
        "\n",
        "            # 1. 整體氛圍（照明和視角）\n",
        "            ambiance_parts = []\n",
        "            if lighting_info:\n",
        "                time_of_day = lighting_info.get(\"time_of_day\", \"unknown lighting\")\n",
        "                is_indoor = lighting_info.get(\"is_indoor\")\n",
        "                ambiance_statement = \"This is\"\n",
        "                if is_indoor is True:\n",
        "                    ambiance_statement += \" an indoor scene\"\n",
        "                elif is_indoor is False:\n",
        "                    ambiance_statement += \" an outdoor scene\"\n",
        "                else:\n",
        "                    ambiance_statement += \" a scene\"\n",
        "\n",
        "                # remove underline\n",
        "                readable_lighting = f\"with {time_of_day.replace('_', ' ')} lighting conditions\"\n",
        "                ambiance_statement += f\", likely {readable_lighting}.\"\n",
        "                ambiance_parts.append(ambiance_statement)\n",
        "\n",
        "            if viewpoint and viewpoint != \"eye_level\":\n",
        "                if not ambiance_parts:\n",
        "                    ambiance_parts.append(f\"From {viewpoint.replace('_', ' ')}, the general layout of the scene is observed.\")\n",
        "                else:\n",
        "                    ambiance_parts[-1] = ambiance_parts[-1].rstrip('.') + f\", viewed from {viewpoint.replace('_', ' ')}.\"\n",
        "\n",
        "            if ambiance_parts:\n",
        "                description_segments.append(\" \".join(ambiance_parts))\n",
        "\n",
        "            # 2. 描述所有檢測到的物件，按類別分組，使用準確計數和位置\n",
        "            if not detected_objects:\n",
        "                if not description_segments:\n",
        "                    description_segments.append(\"A general scene is visible, but no specific objects were clearly identified.\")\n",
        "                else:\n",
        "                    description_segments.append(\"Within this setting, no specific objects were clearly identified.\")\n",
        "            else:\n",
        "                objects_by_class: Dict[str, List[Dict]] = {}\n",
        "\n",
        "                # 使用置信度過濾\n",
        "                confident_objects = [obj for obj in detected_objects\n",
        "                                   if obj.get(\"confidence\", 0) >= self.confidence_threshold_for_description]\n",
        "\n",
        "                if not confident_objects:\n",
        "                    no_confident_obj_msg = \"While some elements might be present, no objects were identified with sufficient confidence for a detailed description.\"\n",
        "                    if not description_segments:\n",
        "                        description_segments.append(no_confident_obj_msg)\n",
        "                    else:\n",
        "                        description_segments.append(no_confident_obj_msg.lower().capitalize())\n",
        "                else:\n",
        "                    if object_statistics:\n",
        "                        # 使用預計算的統計信息，採用動態的信心度\n",
        "                        for class_name, stats in object_statistics.items():\n",
        "                            count = stats.get(\"count\", 0)\n",
        "                            avg_confidence = stats.get(\"avg_confidence\", 0)\n",
        "\n",
        "                            # 動態調整置信度閾值\n",
        "                            dynamic_threshold = self.confidence_threshold_for_description\n",
        "                            if class_name in [\"potted plant\", \"vase\", \"clock\", \"book\"]:\n",
        "                                dynamic_threshold = max(0.15, self.confidence_threshold_for_description * 0.6)\n",
        "                            elif count >= 3:\n",
        "                                dynamic_threshold = max(0.2, self.confidence_threshold_for_description * 0.8)\n",
        "\n",
        "                            if count > 0 and avg_confidence >= dynamic_threshold:\n",
        "                                matching_objects = [obj for obj in confident_objects if obj.get(\"class_name\") == class_name]\n",
        "                                if not matching_objects:\n",
        "                                    matching_objects = [obj for obj in detected_objects\n",
        "                                                      if obj.get(\"class_name\") == class_name and obj.get(\"confidence\", 0) >= dynamic_threshold]\n",
        "\n",
        "                                if matching_objects:\n",
        "                                    actual_count = min(stats[\"count\"], len(matching_objects))\n",
        "                                    objects_by_class[class_name] = matching_objects[:actual_count]\n",
        "                    else:\n",
        "                        # 備用邏輯，同樣使用動態閾值\n",
        "                        for obj in confident_objects:\n",
        "                            name = obj.get(\"class_name\", \"unknown object\")\n",
        "                            if name == \"unknown object\" or not name:\n",
        "                                continue\n",
        "                            if name not in objects_by_class:\n",
        "                                objects_by_class[name] = []\n",
        "                            objects_by_class[name].append(obj)\n",
        "\n",
        "                    if not objects_by_class:\n",
        "                        description_segments.append(\"No common objects were confidently identified for detailed description.\")\n",
        "                    else:\n",
        "                        # 物件組排序函數\n",
        "                        def sort_key_object_groups(item_tuple: Tuple[str, List[Dict]]):\n",
        "                            class_name_key, obj_group_list = item_tuple\n",
        "                            priority = 3\n",
        "                            count = len(obj_group_list)\n",
        "\n",
        "                            # 確保類別名稱已標準化\n",
        "                            normalized_class_name = self._normalize_object_class_name(class_name_key)\n",
        "\n",
        "                            # 動態優先級\n",
        "                            if normalized_class_name == \"person\":\n",
        "                                priority = 0\n",
        "                            elif normalized_class_name in [\"dining table\", \"chair\", \"sofa\", \"bed\"]:\n",
        "                                priority = 1\n",
        "                            elif normalized_class_name in [\"car\", \"bus\", \"truck\", \"traffic light\"]:\n",
        "                                priority = 2\n",
        "                            elif count >= 3:\n",
        "                                priority = max(1, priority - 1)\n",
        "                            elif normalized_class_name in [\"potted plant\", \"vase\", \"clock\", \"book\"] and count >= 2:\n",
        "                                priority = 2\n",
        "\n",
        "                            avg_area = sum(o.get(\"normalized_area\", 0.0) for o in obj_group_list) / len(obj_group_list) if obj_group_list else 0\n",
        "                            quantity_bonus = min(count / 5.0, 1.0)\n",
        "\n",
        "                            return (priority, -len(obj_group_list), -avg_area, -quantity_bonus)\n",
        "\n",
        "                        # remove duplicate\n",
        "                        deduplicated_objects_by_class = {}\n",
        "                        processed_positions = []\n",
        "\n",
        "                        for class_name, group_of_objects in objects_by_class.items():\n",
        "                            unique_objects = []\n",
        "\n",
        "                            for obj in group_of_objects:\n",
        "                                obj_position = obj.get(\"normalized_center\", [0.5, 0.5])\n",
        "                                is_duplicate = False\n",
        "\n",
        "                                for processed_pos in processed_positions:\n",
        "                                    position_distance = abs(obj_position[0] - processed_pos[0]) + abs(obj_position[1] - processed_pos[1])\n",
        "                                    if position_distance < 0.15:\n",
        "                                        is_duplicate = True\n",
        "                                        break\n",
        "\n",
        "                                if not is_duplicate:\n",
        "                                    unique_objects.append(obj)\n",
        "                                    processed_positions.append(obj_position)\n",
        "\n",
        "                            if unique_objects:\n",
        "                                deduplicated_objects_by_class[class_name] = unique_objects\n",
        "\n",
        "                        objects_by_class = deduplicated_objects_by_class\n",
        "                        sorted_object_groups = sorted(objects_by_class.items(), key=sort_key_object_groups)\n",
        "\n",
        "                        object_clauses = []\n",
        "\n",
        "                        for class_name, group_of_objects in sorted_object_groups:\n",
        "                            count = len(group_of_objects)\n",
        "                            if count == 0:\n",
        "                                continue\n",
        "\n",
        "                            # 標準化class name\n",
        "                            normalized_class_name = self._normalize_object_class_name(class_name)\n",
        "\n",
        "                            # 使用統計信息確保準確的數量描述\n",
        "                            if object_statistics and class_name in object_statistics:\n",
        "                                actual_count = object_statistics[class_name][\"count\"]\n",
        "                                formatted_name_with_exact_count = self._format_object_count_description(\n",
        "                                    normalized_class_name, actual_count\n",
        "                                )\n",
        "                            else:\n",
        "                                formatted_name_with_exact_count = self._format_object_count_description(\n",
        "                                    normalized_class_name, count\n",
        "                                )\n",
        "\n",
        "                            if formatted_name_with_exact_count == \"no specific objects clearly identified\" or not formatted_name_with_exact_count:\n",
        "                                continue\n",
        "\n",
        "                            # 確定群組的集體位置\n",
        "                            location_description_suffix = \"\"\n",
        "                            if count == 1:\n",
        "                                spatial_desc = self.get_spatial_description(group_of_objects[0], image_width, image_height, self.region_analyzer)\n",
        "                                if spatial_desc:\n",
        "                                    location_description_suffix = f\"is {spatial_desc}\"\n",
        "                                else:\n",
        "                                    distinct_regions = sorted(list(set(obj.get(\"region\", \"\") for obj in group_of_objects if obj.get(\"region\"))))\n",
        "                                    valid_regions = [r for r in distinct_regions if r and r != \"unknown\" and r.strip()]\n",
        "                                    if not valid_regions:\n",
        "                                        location_description_suffix = \"is positioned in the scene\"\n",
        "                                    elif len(valid_regions) == 1:\n",
        "                                        spatial_desc = self.get_spatial_description_phrase(valid_regions[0])\n",
        "                                        location_description_suffix = f\"is primarily {spatial_desc}\" if spatial_desc else \"is positioned in the scene\"\n",
        "                                    elif len(valid_regions) == 2:\n",
        "                                        clean_region1 = valid_regions[0].replace('_', ' ')\n",
        "                                        clean_region2 = valid_regions[1].replace('_', ' ')\n",
        "                                        location_description_suffix = f\"is mainly across the {clean_region1} and {clean_region2} areas\"\n",
        "                                    else:\n",
        "                                        location_description_suffix = \"is distributed in various parts of the scene\"\n",
        "                            else:\n",
        "                                distinct_regions = sorted(list(set(obj.get(\"region\", \"\") for obj in group_of_objects if obj.get(\"region\"))))\n",
        "                                valid_regions = [r for r in distinct_regions if r and r != \"unknown\" and r.strip()]\n",
        "                                if not valid_regions:\n",
        "                                    location_description_suffix = \"are visible in the scene\"\n",
        "                                elif len(valid_regions) == 1:\n",
        "                                    clean_region = valid_regions[0].replace('_', ' ')\n",
        "                                    location_description_suffix = f\"are primarily in the {clean_region} area\"\n",
        "                                elif len(valid_regions) == 2:\n",
        "                                    clean_region1 = valid_regions[0].replace('_', ' ')\n",
        "                                    clean_region2 = valid_regions[1].replace('_', ' ')\n",
        "                                    location_description_suffix = f\"are mainly across the {clean_region1} and {clean_region2} areas\"\n",
        "                                else:\n",
        "                                    location_description_suffix = \"are distributed in various parts of the scene\"\n",
        "\n",
        "                            # 首字母大寫\n",
        "                            formatted_name_capitalized = formatted_name_with_exact_count[0].upper() + formatted_name_with_exact_count[1:]\n",
        "                            object_clauses.append(f\"{formatted_name_capitalized} {location_description_suffix}\")\n",
        "\n",
        "                        if object_clauses:\n",
        "                            if not description_segments:\n",
        "                                if object_clauses:\n",
        "                                    first_clause = object_clauses.pop(0)\n",
        "                                    description_segments.append(first_clause + \".\")\n",
        "                            else:\n",
        "                                if object_clauses:\n",
        "                                    description_segments.append(\"The scene features:\")\n",
        "\n",
        "                            if object_clauses:\n",
        "                                joined_object_clauses = \". \".join(object_clauses)\n",
        "                                if joined_object_clauses and not joined_object_clauses.endswith(\".\"):\n",
        "                                    joined_object_clauses += \".\"\n",
        "                                description_segments.append(joined_object_clauses)\n",
        "\n",
        "                        elif not description_segments:\n",
        "                            return \"The image depicts a scene, but specific objects could not be described with confidence or detail.\"\n",
        "\n",
        "            # 最終組裝和格式化\n",
        "            raw_description = \"\"\n",
        "            for i, segment in enumerate(filter(None, description_segments)):\n",
        "                segment = segment.strip()\n",
        "                if not segment:\n",
        "                    continue\n",
        "\n",
        "                if not raw_description:\n",
        "                    raw_description = segment\n",
        "                else:\n",
        "                    if not raw_description.endswith(('.', '!', '?')):\n",
        "                        raw_description += \".\"\n",
        "                    raw_description += \" \" + (segment[0].upper() + segment[1:] if len(segment) > 1 else segment.upper())\n",
        "\n",
        "            if raw_description and not raw_description.endswith(('.', '!', '?')):\n",
        "                raw_description += \".\"\n",
        "\n",
        "            if not raw_description or len(raw_description.strip()) < 20:\n",
        "                if 'confident_objects' in locals() and confident_objects:\n",
        "                    return \"The scene contains several detected objects, but a detailed textual description could not be fully constructed.\"\n",
        "                else:\n",
        "                    return \"A general scene is depicted with no objects identified with high confidence.\"\n",
        "\n",
        "            return raw_description\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating dynamic everyday description: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise ObjectDescriptionError(error_msg) from e\n",
        "\n",
        "    def _format_object_count_description(self, class_name: str, count: int) -> str:\n",
        "        \"\"\"\n",
        "        格式化物件數量描述，提供多樣化的表達方式\n",
        "\n",
        "        Args:\n",
        "            class_name: 標準化後的類別名稱\n",
        "            count: 物件數量\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化的數量描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if count <= 0:\n",
        "                return \"\"\n",
        "\n",
        "            # 單數情況\n",
        "            if count == 1:\n",
        "                article = \"an\" if class_name[0].lower() in 'aeiou' else \"a\"\n",
        "                return f\"{article} {class_name}\"\n",
        "\n",
        "            # 複數情況\n",
        "            plural_form = self._get_plural_form(class_name)\n",
        "\n",
        "            # 根據數量選擇不同的表達方式\n",
        "            if count == 2:\n",
        "                return f\"two {plural_form}\"\n",
        "            elif count == 3:\n",
        "                return f\"three {plural_form}\"\n",
        "            elif count <= 5:\n",
        "                return f\"{count} {plural_form}\"\n",
        "            elif count <= 10:\n",
        "                return f\"several {plural_form}\"\n",
        "            else:\n",
        "                return f\"numerous {plural_form}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting object count for '{class_name}': {str(e)}\")\n",
        "            return f\"{count} {class_name}s\" if count > 1 else class_name\n",
        "\n",
        "    def _get_plural_form(self, word: str) -> str:\n",
        "        \"\"\"\n",
        "        獲取詞彙的複數形式\n",
        "\n",
        "        Args:\n",
        "            word: 單數詞彙\n",
        "\n",
        "        Returns:\n",
        "            str: 複數形式\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 特殊複數形式\n",
        "            irregular_plurals = {\n",
        "                'person': 'people',\n",
        "                'child': 'children',\n",
        "                'foot': 'feet',\n",
        "                'tooth': 'teeth',\n",
        "                'mouse': 'mice',\n",
        "                'man': 'men',\n",
        "                'woman': 'women'\n",
        "            }\n",
        "\n",
        "            if word.lower() in irregular_plurals:\n",
        "                return irregular_plurals[word.lower()]\n",
        "\n",
        "            # 規則複數形式\n",
        "            if word.endswith(('s', 'sh', 'ch', 'x', 'z')):\n",
        "                return word + 'es'\n",
        "            elif word.endswith('y') and word[-2] not in 'aeiou':\n",
        "                return word[:-1] + 'ies'\n",
        "            elif word.endswith('f'):\n",
        "                return word[:-1] + 'ves'\n",
        "            elif word.endswith('fe'):\n",
        "                return word[:-2] + 'ves'\n",
        "            else:\n",
        "                return word + 's'\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting plural form for '{word}': {str(e)}\")\n",
        "            return word + 's'\n",
        "\n",
        "    def _normalize_object_class_name(self, class_name: str) -> str:\n",
        "        \"\"\"\n",
        "        標準化物件類別名稱，確保輸出自然語言格式\n",
        "\n",
        "        Args:\n",
        "            class_name: 原始類別名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化後的類別名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not class_name or not isinstance(class_name, str):\n",
        "                return \"object\"\n",
        "\n",
        "            # 移除可能的技術性前綴或後綴\n",
        "            import re\n",
        "            normalized = re.sub(r'^(class_|id_|type_)', '', class_name.lower())\n",
        "            normalized = re.sub(r'(_class|_id|_type)$', '', normalized)\n",
        "\n",
        "            # 將下劃線和連字符替換為空格\n",
        "            normalized = normalized.replace('_', ' ').replace('-', ' ')\n",
        "\n",
        "            # 移除多餘空格\n",
        "            normalized = ' '.join(normalized.split())\n",
        "\n",
        "            # 特殊類別名稱的標準化映射\n",
        "            class_name_mapping = {\n",
        "                'traffic light': 'traffic light',\n",
        "                'stop sign': 'stop sign',\n",
        "                'fire hydrant': 'fire hydrant',\n",
        "                'dining table': 'dining table',\n",
        "                'potted plant': 'potted plant',\n",
        "                'tv monitor': 'television',\n",
        "                'cell phone': 'mobile phone',\n",
        "                'wine glass': 'wine glass',\n",
        "                'hot dog': 'hot dog',\n",
        "                'teddy bear': 'teddy bear',\n",
        "                'hair drier': 'hair dryer',\n",
        "                'toothbrush': 'toothbrush'\n",
        "            }\n",
        "\n",
        "            return class_name_mapping.get(normalized, normalized)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error normalizing class name '{class_name}': {str(e)}\")\n",
        "            return class_name if isinstance(class_name, str) else \"object\"\n",
        "\n",
        "    def generate_basic_details(self, scene_type: str, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        當模板不可用時生成基本詳細信息\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 基本場景詳細信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 處理特定場景類型的自定義邏輯\n",
        "            if scene_type == \"living_room\":\n",
        "                tv_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 62]  # TV\n",
        "                sofa_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 57]  # Sofa\n",
        "\n",
        "                if tv_objs and sofa_objs:\n",
        "                    tv_region = tv_objs[0].get(\"region\", \"center\")\n",
        "                    sofa_region = sofa_objs[0].get(\"region\", \"center\")\n",
        "\n",
        "                    arrangement = f\"The TV is in the {tv_region.replace('_', ' ')} of the image, \"\n",
        "                    arrangement += f\"while the sofa is in the {sofa_region.replace('_', ' ')}. \"\n",
        "\n",
        "                    return f\"{arrangement}This appears to be a space designed for relaxation and entertainment.\"\n",
        "\n",
        "            elif scene_type == \"bedroom\":\n",
        "                bed_objs = [obj for obj in detected_objects if obj.get(\"class_id\") == 59]  # Bed\n",
        "\n",
        "                if bed_objs:\n",
        "                    bed_region = bed_objs[0].get(\"region\", \"center\")\n",
        "                    extra_items = []\n",
        "\n",
        "                    for obj in detected_objects:\n",
        "                        if obj.get(\"class_id\") == 74:  # Clock\n",
        "                            extra_items.append(\"clock\")\n",
        "                        elif obj.get(\"class_id\") == 73:  # Book\n",
        "                            extra_items.append(\"book\")\n",
        "\n",
        "                    extras = \"\"\n",
        "                    if extra_items:\n",
        "                        extras = f\" There is also a {' and a '.join(extra_items)} visible.\"\n",
        "\n",
        "                    return f\"The bed is located in the {bed_region.replace('_', ' ')} of the image.{extras}\"\n",
        "\n",
        "            elif scene_type in [\"dining_area\", \"kitchen\"]:\n",
        "                # 計算食物和餐飲相關物品\n",
        "                food_items = []\n",
        "                for obj in detected_objects:\n",
        "                    if obj.get(\"class_id\") in [39, 41, 42, 43, 44, 45]:  # 廚房物品\n",
        "                        food_items.append(obj.get(\"class_name\", \"kitchen item\"))\n",
        "\n",
        "                food_str = \"\"\n",
        "                if food_items:\n",
        "                    unique_items = list(set(food_items))\n",
        "                    if len(unique_items) <= 3:\n",
        "                        food_str = f\" with {', '.join(unique_items)}\"\n",
        "                    else:\n",
        "                        food_str = f\" with {', '.join(unique_items[:3])} and other items\"\n",
        "\n",
        "                return f\"{food_str}.\"\n",
        "\n",
        "            elif scene_type == \"city_street\":\n",
        "                # 計算人員和車輛\n",
        "                people_count = len([obj for obj in detected_objects if obj.get(\"class_id\") == 0])\n",
        "                vehicle_count = len([obj for obj in detected_objects\n",
        "                                   if obj.get(\"class_id\") in [1, 2, 3, 5, 7]])  # Bicycle, car, motorbike, bus, truck\n",
        "\n",
        "                traffic_desc = \"\"\n",
        "                if people_count > 0 and vehicle_count > 0:\n",
        "                    traffic_desc = f\" with {people_count} {'people' if people_count > 1 else 'person'} and \"\n",
        "                    traffic_desc += f\"{vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "                elif people_count > 0:\n",
        "                    traffic_desc = f\" with {people_count} {'people' if people_count > 1 else 'person'}\"\n",
        "                elif vehicle_count > 0:\n",
        "                    traffic_desc = f\" with {vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "\n",
        "                return f\"{traffic_desc}.\"\n",
        "\n",
        "            elif scene_type == \"asian_commercial_street\":\n",
        "                # 尋找關鍵城市元素\n",
        "                people_count = len([obj for obj in detected_objects if obj.get(\"class_id\") == 0])\n",
        "                vehicle_count = len([obj for obj in detected_objects if obj.get(\"class_id\") in [1, 2, 3]])\n",
        "\n",
        "                # 分析行人分布\n",
        "                people_positions = []\n",
        "                for obj in detected_objects:\n",
        "                    if obj.get(\"class_id\") == 0:  # Person\n",
        "                        people_positions.append(obj.get(\"normalized_center\", (0.5, 0.5)))\n",
        "\n",
        "                # 檢查人員是否沿線分布（表示步行路徑）\n",
        "                structured_path = False\n",
        "                if len(people_positions) >= 3:\n",
        "                    # 簡化檢查 - 查看多個人員的y坐標是否相似\n",
        "                    y_coords = [pos[1] for pos in people_positions]\n",
        "                    y_mean = sum(y_coords) / len(y_coords)\n",
        "                    y_variance = sum((y - y_mean)**2 for y in y_coords) / len(y_coords)\n",
        "                    if y_variance < 0.05:  # 低變異數表示線性排列\n",
        "                        structured_path = True\n",
        "\n",
        "                street_desc = \"A commercial street with \"\n",
        "                if people_count > 0:\n",
        "                    street_desc += f\"{people_count} {'pedestrians' if people_count > 1 else 'pedestrian'}\"\n",
        "                    if vehicle_count > 0:\n",
        "                        street_desc += f\" and {vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "                elif vehicle_count > 0:\n",
        "                    street_desc += f\"{vehicle_count} {'vehicles' if vehicle_count > 1 else 'vehicle'}\"\n",
        "                else:\n",
        "                    street_desc += \"various commercial elements\"\n",
        "\n",
        "                if structured_path:\n",
        "                    street_desc += \". The pedestrians appear to be following a defined walking path\"\n",
        "\n",
        "                # 添加文化元素\n",
        "                street_desc += \". The signage and architectural elements suggest an Asian urban setting.\"\n",
        "\n",
        "                return street_desc\n",
        "\n",
        "            # 默認通用描述\n",
        "            return \"The scene contains various elements characteristic of this environment.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating basic details for scene_type '{scene_type}': {str(e)}\")\n",
        "            return \"The scene contains various elements characteristic of this environment.\"\n",
        "\n",
        "    def generate_placeholder_content(self, placeholder: str, detected_objects: List[Dict], scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        為模板佔位符生成內容\n",
        "\n",
        "        Args:\n",
        "            placeholder: 模板佔位符\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            scene_type: 場景類型\n",
        "\n",
        "        Returns:\n",
        "            str: 生成的佔位符內容\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 處理不同類型的佔位符與自定義邏輯\n",
        "            if placeholder == \"furniture\":\n",
        "                # 提取家具物品\n",
        "                furniture_ids = [56, 57, 58, 59, 60, 61]  # 家具類別ID示例\n",
        "                furniture_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in furniture_ids]\n",
        "\n",
        "                if furniture_objects:\n",
        "                    furniture_names = []\n",
        "                    for obj in furniture_objects[:3]:\n",
        "                        raw_name = obj.get(\"class_name\", \"furniture\")\n",
        "                        normalized_name = self._normalize_object_class_name(raw_name)\n",
        "                        furniture_names.append(normalized_name)\n",
        "\n",
        "                    unique_names = list(set(furniture_names))\n",
        "                    if len(unique_names) == 1:\n",
        "                        return unique_names[0]\n",
        "                    elif len(unique_names) == 2:\n",
        "                        return f\"{unique_names[0]} and {unique_names[1]}\"\n",
        "                    else:\n",
        "                        return \", \".join(unique_names[:-1]) + f\", and {unique_names[-1]}\"\n",
        "                return \"various furniture items\"\n",
        "\n",
        "            elif placeholder == \"electronics\":\n",
        "                # 提取電子物品\n",
        "                electronics_ids = [62, 63, 64, 65, 66, 67, 68, 69, 70]  # 電子設備類別ID示例\n",
        "                electronics_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in electronics_ids]\n",
        "\n",
        "                if electronics_objects:\n",
        "                    electronics_names = [obj.get(\"class_name\", \"electronic device\") for obj in electronics_objects[:3]]\n",
        "                    return \", \".join(set(electronics_names))\n",
        "                return \"electronic devices\"\n",
        "\n",
        "            elif placeholder == \"people_count\":\n",
        "                # 計算人數\n",
        "                people_count = len([obj for obj in detected_objects if obj.get(\"class_id\") == 0])\n",
        "\n",
        "                if people_count == 0:\n",
        "                    return \"no people\"\n",
        "                elif people_count == 1:\n",
        "                    return \"one person\"\n",
        "                elif people_count < 5:\n",
        "                    return f\"{people_count} people\"\n",
        "                else:\n",
        "                    return \"several people\"\n",
        "\n",
        "            elif placeholder == \"seating\":\n",
        "                # 提取座位物品\n",
        "                seating_ids = [56, 57]  # chair, sofa\n",
        "                seating_objects = [obj for obj in detected_objects if obj.get(\"class_id\") in seating_ids]\n",
        "\n",
        "                if seating_objects:\n",
        "                    seating_names = [obj.get(\"class_name\", \"seating\") for obj in seating_objects[:2]]\n",
        "                    return \", \".join(set(seating_names))\n",
        "                return \"seating arrangements\"\n",
        "\n",
        "            # 默認情況 - 空字符串\n",
        "            return \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating placeholder content for '{placeholder}': {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def describe_functional_zones(self, functional_zones: Dict) -> str:\n",
        "        \"\"\"\n",
        "        生成場景功能區域的描述，優化處理行人區域、人數統計和物品重複問題\n",
        "\n",
        "        Args:\n",
        "            functional_zones: 識別出的功能區域字典\n",
        "\n",
        "        Returns:\n",
        "            str: 功能區域描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not functional_zones:\n",
        "                return \"\"\n",
        "\n",
        "            # 處理不同類型的 functional_zones 參數\n",
        "            if isinstance(functional_zones, list):\n",
        "                # 如果是列表，轉換為字典格式\n",
        "                zones_dict = {}\n",
        "                for i, zone in enumerate(functional_zones):\n",
        "                    if isinstance(zone, dict) and 'name' in zone:\n",
        "                        zone_name = self._normalize_zone_name(zone['name'])\n",
        "                    else:\n",
        "                        zone_name = f\"functional area {i+1}\"\n",
        "                    zones_dict[zone_name] = zone if isinstance(zone, dict) else {\"description\": str(zone)}\n",
        "                functional_zones = zones_dict\n",
        "            elif not isinstance(functional_zones, dict):\n",
        "                return \"\"\n",
        "\n",
        "            # 標準化所有區域鍵名，移除內部標識符格式\n",
        "            normalized_zones = {}\n",
        "            for zone_key, zone_data in functional_zones.items():\n",
        "                normalized_key = self._normalize_zone_name(zone_key)\n",
        "                normalized_zones[normalized_key] = zone_data\n",
        "            functional_zones = normalized_zones\n",
        "\n",
        "            # 計算場景中的總人數\n",
        "            total_people_count = 0\n",
        "            people_by_zone = {}\n",
        "\n",
        "            # 計算每個區域的人數並累計總人數\n",
        "            for zone_name, zone_info in functional_zones.items():\n",
        "                if \"objects\" in zone_info:\n",
        "                    zone_people_count = zone_info[\"objects\"].count(\"person\")\n",
        "                    people_by_zone[zone_name] = zone_people_count\n",
        "                    total_people_count += zone_people_count\n",
        "\n",
        "            # 分類區域為行人區域和其他區域\n",
        "            pedestrian_zones = []\n",
        "            other_zones = []\n",
        "\n",
        "            for zone_name, zone_info in functional_zones.items():\n",
        "                # 檢查是否是行人相關區域\n",
        "                if any(keyword in zone_name.lower() for keyword in [\"pedestrian\", \"crossing\", \"people\"]):\n",
        "                    pedestrian_zones.append((zone_name, zone_info))\n",
        "                else:\n",
        "                    other_zones.append((zone_name, zone_info))\n",
        "\n",
        "            # 獲取最重要的行人區域和其他區域\n",
        "            main_pedestrian_zones = sorted(pedestrian_zones,\n",
        "                                        key=lambda z: people_by_zone.get(z[0], 0),\n",
        "                                        reverse=True)[:1]  # 最多1個主要行人區域\n",
        "\n",
        "            top_other_zones = sorted(other_zones,\n",
        "                                key=lambda z: len(z[1].get(\"objects\", [])),\n",
        "                                reverse=True)[:2]  # 最多2個其他區域\n",
        "\n",
        "            # 合併區域\n",
        "            top_zones = main_pedestrian_zones + top_other_zones\n",
        "\n",
        "            if not top_zones:\n",
        "                return \"\"\n",
        "\n",
        "            # 生成匯總描述\n",
        "            summary = \"\"\n",
        "            max_mentioned_people = 0  # 追蹤已經提到的最大人數\n",
        "\n",
        "            # 如果總人數顯著且還沒在主描述中提到，添加總人數描述\n",
        "            if total_people_count > 5:\n",
        "                summary = f\"The scene contains a significant number of pedestrians ({total_people_count} people). \"\n",
        "                max_mentioned_people = total_people_count  # 更新已提到的最大人數\n",
        "\n",
        "            # 處理每個區域的描述，確保人數信息的一致性\n",
        "            processed_zones = []\n",
        "\n",
        "            for zone_name, zone_info in top_zones:\n",
        "                zone_desc = zone_info.get(\"description\", \"a functional zone\")\n",
        "                zone_people_count = people_by_zone.get(zone_name, 0)\n",
        "\n",
        "                # 檢查描述中是否包含人數資訊\n",
        "                contains_people_info = \"with\" in zone_desc and (\"person\" in zone_desc.lower() or \"people\" in zone_desc.lower())\n",
        "\n",
        "                # 如果描述包含人數信息，且人數較小（小於已提到的最大人數），則修改描述\n",
        "                if contains_people_info and zone_people_count < max_mentioned_people:\n",
        "                    parts = zone_desc.split(\"with\")\n",
        "                    if len(parts) > 1:\n",
        "                        # 移除人數部分\n",
        "                        zone_desc = parts[0].strip() + \" area\"\n",
        "\n",
        "                processed_zones.append((zone_name, {\"description\": zone_desc}))\n",
        "\n",
        "            # 根據處理後的區域數量生成最終描述\n",
        "            final_desc = \"\"\n",
        "\n",
        "            if len(processed_zones) == 1:\n",
        "                _, zone_info = processed_zones[0]\n",
        "                zone_desc = zone_info[\"description\"]\n",
        "                final_desc = summary + f\"The scene includes {zone_desc}.\"\n",
        "            elif len(processed_zones) == 2:\n",
        "                _, zone1_info = processed_zones[0]\n",
        "                _, zone2_info = processed_zones[1]\n",
        "                zone1_desc = zone1_info[\"description\"]\n",
        "                zone2_desc = zone2_info[\"description\"]\n",
        "                final_desc = summary + f\"The scene is divided into two main areas: {zone1_desc} and {zone2_desc}.\"\n",
        "            else:\n",
        "                zones_desc = [\"The scene contains multiple functional areas including\"]\n",
        "                zone_descriptions = [z[1][\"description\"] for z in processed_zones]\n",
        "\n",
        "                # 格式化最終的多區域描述\n",
        "                if len(zone_descriptions) == 3:\n",
        "                    formatted_desc = f\"{zone_descriptions[0]}, {zone_descriptions[1]}, and {zone_descriptions[2]}\"\n",
        "                else:\n",
        "                    formatted_desc = \", \".join(zone_descriptions[:-1]) + f\", and {zone_descriptions[-1]}\"\n",
        "\n",
        "                final_desc = summary + f\"{zones_desc[0]} {formatted_desc}.\"\n",
        "\n",
        "            return self.optimize_object_description(final_desc)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error describing functional zones: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _normalize_zone_name(self, zone_name: str) -> str:\n",
        "        \"\"\"\n",
        "        將內部區域鍵名標準化為自然語言描述\n",
        "\n",
        "        Args:\n",
        "            zone_name: 原始區域名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 標準化後的區域名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not zone_name or not isinstance(zone_name, str):\n",
        "                return \"functional area\"\n",
        "\n",
        "            # 移除數字後綴（如 crossing_zone_1 -> crossing_zone）\n",
        "            import re\n",
        "            base_name = re.sub(r'_\\d+$', '', zone_name)\n",
        "\n",
        "            # 將下劃線替換為空格\n",
        "            normalized = base_name.replace('_', ' ')\n",
        "\n",
        "            # 標準化常見的區域類型名稱\n",
        "            zone_type_mapping = {\n",
        "                'crossing zone': 'pedestrian crossing area',\n",
        "                'vehicle zone': 'vehicle movement area',\n",
        "                'pedestrian zone': 'pedestrian activity area',\n",
        "                'traffic zone': 'traffic flow area',\n",
        "                'waiting zone': 'waiting area',\n",
        "                'seating zone': 'seating area',\n",
        "                'dining zone': 'dining area',\n",
        "                'furniture zone': 'furniture arrangement area',\n",
        "                'electronics zone': 'electronics area',\n",
        "                'people zone': 'social activity area',\n",
        "                'functional area': 'activity area'\n",
        "            }\n",
        "\n",
        "            # 檢查是否有對應的標準化名稱\n",
        "            for pattern, replacement in zone_type_mapping.items():\n",
        "                if pattern in normalized.lower():\n",
        "                    return replacement\n",
        "\n",
        "            # 如果沒有特定映射，使用通用格式\n",
        "            if 'zone' in normalized.lower():\n",
        "                normalized = normalized.replace('zone', 'area')\n",
        "            elif not any(keyword in normalized.lower() for keyword in ['area', 'space', 'region']):\n",
        "                normalized += ' area'\n",
        "\n",
        "            return normalized.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error normalizing zone name '{zone_name}': {str(e)}\")\n",
        "            return \"activity area\"\n",
        "\n",
        "    def get_configuration(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取當前配置參數\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 配置參數字典\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"min_prominence_score\": self.min_prominence_score,\n",
        "            \"max_categories_to_return\": self.max_categories_to_return,\n",
        "            \"max_total_objects\": self.max_total_objects,\n",
        "            \"confidence_threshold_for_description\": self.confidence_threshold_for_description\n",
        "        }\n",
        "\n",
        "    def update_configuration(self, **kwargs):\n",
        "        \"\"\"\n",
        "        更新配置參數\n",
        "\n",
        "        Args:\n",
        "            **kwargs: 要更新的配置參數\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for key, value in kwargs.items():\n",
        "                if hasattr(self, key):\n",
        "                    old_value = getattr(self, key)\n",
        "                    setattr(self, key, value)\n",
        "                    self.logger.info(f\"Updated {key}: {old_value} -> {value}\")\n",
        "                else:\n",
        "                    self.logger.warning(f\"Unknown configuration parameter: {key}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error updating configuration: {str(e)}\")\n",
        "            raise ObjectDescriptionError(f\"Failed to update configuration: {str(e)}\") from e"
      ],
      "metadata": {
        "id": "lhOibWo1tocy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c69c18-aa4a-4790-9983-49df84ff6959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing object_description_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile cultural_context_analyzer.py\n",
        "import logging\n",
        "import traceback\n",
        "import random\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "# from cultural_templates import CULTURAL_TEMPLATES\n",
        "\n",
        "class CulturalContextError(Exception):\n",
        "    \"\"\"文化語境分析過程中的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class CulturalContextAnalyzer:\n",
        "    \"\"\"\n",
        "    文化語境分析器 - 檢測場景中的文化特徵並生成相關的描述\n",
        "\n",
        "    該類別負責識別場景中的文化語境線索，包括建築風格、標誌特徵\n",
        "    和物件配置，然後生成適當的文化描述元素。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cultural_templates: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        初始化文化語境分析器\n",
        "\n",
        "        Args:\n",
        "            cultural_templates: 可選的自定義文化模板，如果提供則會與默認模板合併\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        try:\n",
        "            # 載入文化模板\n",
        "            self.cultural_templates = self._load_cultural_templates()\n",
        "\n",
        "            # 如果提供了自定義模板，進行合併\n",
        "            if cultural_templates:\n",
        "                self._merge_custom_templates(cultural_templates)\n",
        "\n",
        "            # 初始化場景類型到文化語境的映射\n",
        "            self.scene_cultural_mapping = self._initialize_scene_cultural_mapping()\n",
        "\n",
        "            self.logger.info(\"CulturalContextAnalyzer initialized with %d cultural templates\",\n",
        "                           len(self.cultural_templates))\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize CulturalContextAnalyzer: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise CulturalContextError(error_msg) from e\n",
        "\n",
        "    def _load_cultural_templates(self) -> Dict:\n",
        "        \"\"\"\n",
        "        載入文化模板\n",
        "\n",
        "        Returns:\n",
        "            Dict: 文化模板字典\n",
        "\n",
        "        Raises:\n",
        "            CulturalContextError: 當模板載入失敗時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Loading cultural templates\")\n",
        "\n",
        "            # 從配置模組載入文化模板\n",
        "            templates = CULTURAL_TEMPLATES.copy()\n",
        "\n",
        "            # 確保模板結構正確\n",
        "            self._validate_cultural_templates(templates)\n",
        "\n",
        "            # 如果沒有載入到模板，使用默認模板\n",
        "            if not templates:\n",
        "                self.logger.warning(\"No cultural templates loaded, using defaults\")\n",
        "                templates = self._get_default_cultural_templates()\n",
        "\n",
        "            self.logger.debug(\"Successfully loaded %d cultural template categories\", len(templates))\n",
        "            return templates\n",
        "\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Failed to import cultural templates: {str(e)}, using defaults\")\n",
        "            return self._get_default_cultural_templates()\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error loading cultural templates: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise CulturalContextError(error_msg) from e\n",
        "\n",
        "    def _get_default_cultural_templates(self) -> Dict:\n",
        "        \"\"\"\n",
        "        獲取默認文化模板\n",
        "\n",
        "        Returns:\n",
        "            Dict: 默認文化模板字典\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"asian\": {\n",
        "                \"elements\": [\n",
        "                    \"traditional architectural elements\",\n",
        "                    \"cultural signage\",\n",
        "                    \"Asian design features\",\n",
        "                    \"oriental decorative patterns\",\n",
        "                    \"traditional building materials\",\n",
        "                    \"characteristic roofline styles\",\n",
        "                    \"cultural landscaping elements\"\n",
        "                ],\n",
        "                \"description\": \"The scene displays distinctive Asian cultural characteristics with {elements}.\"\n",
        "            },\n",
        "            \"european\": {\n",
        "                \"elements\": [\n",
        "                    \"classical architecture\",\n",
        "                    \"European design elements\",\n",
        "                    \"historic features\",\n",
        "                    \"traditional stonework\",\n",
        "                    \"characteristic window styles\",\n",
        "                    \"ornamental facades\",\n",
        "                    \"heritage building elements\"\n",
        "                ],\n",
        "                \"description\": \"The scene exhibits European architectural and cultural elements including {elements}.\"\n",
        "            },\n",
        "            \"american\": {\n",
        "                \"elements\": [\n",
        "                    \"modern architectural styles\",\n",
        "                    \"contemporary design features\",\n",
        "                    \"commercial signage\",\n",
        "                    \"urban planning elements\",\n",
        "                    \"standardized building designs\"\n",
        "                ],\n",
        "                \"description\": \"The scene shows American urban characteristics featuring {elements}.\"\n",
        "            },\n",
        "            \"mediterranean\": {\n",
        "                \"elements\": [\n",
        "                    \"coastal architectural styles\",\n",
        "                    \"warm climate adaptations\",\n",
        "                    \"traditional building colors\",\n",
        "                    \"characteristic outdoor spaces\"\n",
        "                ],\n",
        "                \"description\": \"The scene reflects Mediterranean cultural influences with {elements}.\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _validate_cultural_templates(self, templates: Dict):\n",
        "        \"\"\"\n",
        "        驗證文化模板結構\n",
        "\n",
        "        Args:\n",
        "            templates: 要驗證的模板字典\n",
        "\n",
        "        Raises:\n",
        "            CulturalContextError: 當模板結構無效時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for culture, template_data in templates.items():\n",
        "                if not isinstance(template_data, dict):\n",
        "                    self.logger.warning(f\"Invalid cultural template structure for '{culture}': not a dictionary\")\n",
        "                    continue\n",
        "\n",
        "                required_keys = [\"elements\", \"description\"]\n",
        "                for key in required_keys:\n",
        "                    if key not in template_data:\n",
        "                        self.logger.warning(f\"Missing required key '{key}' in cultural template '{culture}'\")\n",
        "\n",
        "                # 驗證元素列表\n",
        "                if \"elements\" in template_data:\n",
        "                    if not isinstance(template_data[\"elements\"], list):\n",
        "                        self.logger.warning(f\"Cultural template '{culture}' elements should be a list\")\n",
        "                    elif not template_data[\"elements\"]:\n",
        "                        self.logger.warning(f\"Cultural template '{culture}' has empty elements list\")\n",
        "\n",
        "                # 驗證描述模板\n",
        "                if \"description\" in template_data:\n",
        "                    if not isinstance(template_data[\"description\"], str):\n",
        "                        self.logger.warning(f\"Cultural template '{culture}' description should be a string\")\n",
        "                    elif \"{elements}\" not in template_data[\"description\"]:\n",
        "                        self.logger.warning(f\"Cultural template '{culture}' description missing {{elements}} placeholder\")\n",
        "\n",
        "            self.logger.debug(\"Cultural templates validation completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error validating cultural templates: {str(e)}\")\n",
        "\n",
        "    def _merge_custom_templates(self, custom_templates: Dict):\n",
        "        \"\"\"\n",
        "        合併自定義文化模板\n",
        "\n",
        "        Args:\n",
        "            custom_templates: 自定義模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for culture, template_data in custom_templates.items():\n",
        "                if culture in self.cultural_templates:\n",
        "                    # 合併現有文化的模板\n",
        "                    if isinstance(self.cultural_templates[culture], dict) and isinstance(template_data, dict):\n",
        "                        # 合併元素列表\n",
        "                        if \"elements\" in template_data and \"elements\" in self.cultural_templates[culture]:\n",
        "                            existing_elements = self.cultural_templates[culture][\"elements\"]\n",
        "                            new_elements = template_data[\"elements\"]\n",
        "                            if isinstance(existing_elements, list) and isinstance(new_elements, list):\n",
        "                                self.cultural_templates[culture][\"elements\"] = existing_elements + new_elements\n",
        "\n",
        "                        # 更新其他鍵值\n",
        "                        for key, value in template_data.items():\n",
        "                            if key != \"elements\":\n",
        "                                self.cultural_templates[culture][key] = value\n",
        "                    else:\n",
        "                        self.cultural_templates[culture] = template_data\n",
        "                else:\n",
        "                    # 添加新的文化模板\n",
        "                    self.cultural_templates[culture] = template_data\n",
        "\n",
        "                self.logger.debug(f\"Merged custom template for culture: {culture}\")\n",
        "\n",
        "            self.logger.info(\"Successfully merged custom cultural templates\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error merging custom cultural templates: {str(e)}\")\n",
        "\n",
        "    def _initialize_scene_cultural_mapping(self) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        初始化場景類型到文化語境的display\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, str]: 場景類型到文化語境的映射字典\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"asian_commercial_street\": \"asian\",\n",
        "            \"asian_night_market\": \"asian\",\n",
        "            \"asian_temple_area\": \"asian\",\n",
        "            \"chinese_restaurant\": \"asian\",\n",
        "            \"japanese_restaurant\": \"asian\",\n",
        "            \"korean_restaurant\": \"asian\",\n",
        "            \"european_plaza\": \"european\",\n",
        "            \"european_cafe\": \"european\",\n",
        "            \"mediterranean_restaurant\": \"mediterranean\",\n",
        "            \"american_diner\": \"american\",\n",
        "            \"american_fast_food\": \"american\"\n",
        "        }\n",
        "\n",
        "    def detect_cultural_context(self, scene_type: str, detected_objects: List[Dict]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        檢測場景的文化語境\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 檢測到的文化語境（asian, european等）或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(f\"Detecting cultural context for scene_type: {scene_type}\")\n",
        "\n",
        "            # 檢查場景類型是否直接指示文化語境\n",
        "            if scene_type in self.scene_cultural_mapping:\n",
        "                cultural_context = self.scene_cultural_mapping[scene_type]\n",
        "                self.logger.debug(f\"Direct cultural mapping found: {scene_type} -> {cultural_context}\")\n",
        "                return cultural_context\n",
        "\n",
        "            # 基於場景類型名稱的模式匹配\n",
        "            cultural_context = self._detect_from_scene_name_patterns(scene_type)\n",
        "            if cultural_context:\n",
        "                self.logger.debug(f\"Cultural context detected from name patterns: {cultural_context}\")\n",
        "                return cultural_context\n",
        "\n",
        "            # 基於檢測物件的文化特徵分析\n",
        "            cultural_context = self._detect_from_object_analysis(detected_objects)\n",
        "            if cultural_context:\n",
        "                self.logger.debug(f\"Cultural context detected from object analysis: {cultural_context}\")\n",
        "                return cultural_context\n",
        "\n",
        "            # 沒有檢測到特定文化語境\n",
        "            self.logger.debug(\"No specific cultural context detected\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting cultural context: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _detect_from_scene_name_patterns(self, scene_type: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        基於場景類型名稱模式檢測文化語境\n",
        "\n",
        "        Args:\n",
        "            scene_type: 場景類型名稱\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 檢測到的文化語境或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            scene_lower = scene_type.lower()\n",
        "\n",
        "            # Asia\n",
        "            asian_keywords = [\n",
        "                \"asian\", \"chinese\", \"japanese\", \"korean\", \"thai\", \"vietnamese\",\n",
        "                \"temple\", \"pagoda\", \"zen\", \"oriental\", \"bamboo\", \"tatami\"\n",
        "            ]\n",
        "\n",
        "            # Europe\n",
        "            european_keywords = [\n",
        "                \"european\", \"french\", \"italian\", \"spanish\", \"german\", \"british\",\n",
        "                \"plaza\", \"piazza\", \"cathedral\", \"gothic\", \"baroque\", \"renaissance\",\n",
        "                \"cafe\", \"bistro\", \"pub\"\n",
        "            ]\n",
        "\n",
        "            # 地中海文化\n",
        "            mediterranean_keywords = [\n",
        "                \"mediterranean\", \"greek\", \"turkish\", \"coastal\", \"terrace\",\n",
        "                \"villa\", \"courtyard\"\n",
        "            ]\n",
        "\n",
        "            # 美國\n",
        "            american_keywords = [\n",
        "                \"american\", \"diner\", \"fast_food\", \"mall\", \"suburban\",\n",
        "                \"downtown\", \"strip_mall\"\n",
        "            ]\n",
        "\n",
        "            # 檢查各文化的key word\n",
        "            if any(keyword in scene_lower for keyword in asian_keywords):\n",
        "                return \"asian\"\n",
        "            elif any(keyword in scene_lower for keyword in european_keywords):\n",
        "                return \"european\"\n",
        "            elif any(keyword in scene_lower for keyword in mediterranean_keywords):\n",
        "                return \"mediterranean\"\n",
        "            elif any(keyword in scene_lower for keyword in american_keywords):\n",
        "                return \"american\"\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting cultural context from scene name patterns: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _detect_from_object_analysis(self, detected_objects: List[Dict]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        基於檢測物件分析文化特徵\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 檢測到的文化語境或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detected_objects:\n",
        "                return None\n",
        "\n",
        "            # 統計文化相關物件\n",
        "            cultural_indicators = {\n",
        "                \"asian\": 0,\n",
        "                \"european\": 0,\n",
        "                \"american\": 0,\n",
        "                \"mediterranean\": 0\n",
        "            }\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"\").lower()\n",
        "\n",
        "                # Asia 特色\n",
        "                if any(indicator in class_name for indicator in [\n",
        "                    \"lantern\", \"chopsticks\", \"rice\", \"noodles\", \"tea\",\n",
        "                    \"bamboo\", \"pagoda\", \"shrine\", \"torii\"\n",
        "                ]):\n",
        "                    cultural_indicators[\"asian\"] += 1\n",
        "\n",
        "                # 歐洲的特色\n",
        "                elif any(indicator in class_name for indicator in [\n",
        "                    \"wine\", \"cheese\", \"bread\", \"fountain\", \"column\",\n",
        "                    \"statue\", \"cathedral\", \"clock_tower\"\n",
        "                ]):\n",
        "                    cultural_indicators[\"european\"] += 1\n",
        "\n",
        "                # 地中海的特色\n",
        "                elif any(indicator in class_name for indicator in [\n",
        "                    \"olive\", \"terracotta\", \"pergola\", \"villa\",\n",
        "                    \"coastal\", \"maritime\"\n",
        "                ]):\n",
        "                    cultural_indicators[\"mediterranean\"] += 1\n",
        "\n",
        "                # 美國的特色\n",
        "                elif any(indicator in class_name for indicator in [\n",
        "                    \"burger\", \"pizza\", \"hotdog\", \"soda\",\n",
        "                    \"drive_through\", \"parking_lot\"\n",
        "                ]):\n",
        "                    cultural_indicators[\"american\"] += 1\n",
        "\n",
        "            # 找出得分最高的文化語境\n",
        "            if max(cultural_indicators.values()) > 0:\n",
        "                dominant_culture = max(cultural_indicators.items(), key=lambda x: x[1])[0]\n",
        "                max_score = cultural_indicators[dominant_culture]\n",
        "\n",
        "                # 需要至少2個指標物件才算有效檢測\n",
        "                if max_score >= 2:\n",
        "                    return dominant_culture\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting cultural context from object analysis: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_cultural_elements(self, cultural_context: str) -> str:\n",
        "        \"\"\"\n",
        "        為檢測到的文化語境生成描述元素\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 檢測到的文化語境\n",
        "\n",
        "        Returns:\n",
        "            str: 文化元素描述\n",
        "\n",
        "        Raises:\n",
        "            CulturalContextError: 當文化元素生成失敗時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not cultural_context:\n",
        "                return \"\"\n",
        "\n",
        "            self.logger.debug(f\"Generating cultural elements for context: {cultural_context}\")\n",
        "\n",
        "            # 獲取該文化語境的模板\n",
        "            if cultural_context not in self.cultural_templates:\n",
        "                self.logger.warning(f\"No template found for cultural context: {cultural_context}\")\n",
        "                return \"\"\n",
        "\n",
        "            template = self.cultural_templates[cultural_context]\n",
        "            elements = template.get(\"elements\", [])\n",
        "\n",
        "            if not elements:\n",
        "                self.logger.warning(f\"No elements found for cultural context: {cultural_context}\")\n",
        "                return \"\"\n",
        "\n",
        "            # 選擇1-2個隨機元素\n",
        "            num_elements = min(len(elements), random.randint(1, 2))\n",
        "            selected_elements = random.sample(elements, num_elements)\n",
        "\n",
        "            # 格式化元素列表\n",
        "            if len(selected_elements) == 1:\n",
        "                elements_text = selected_elements[0]\n",
        "            else:\n",
        "                elements_text = \" and \".join(selected_elements)\n",
        "\n",
        "            # 填充模板\n",
        "            description_template = template.get(\"description\", \"\")\n",
        "            if not description_template:\n",
        "                return f\"The scene displays {cultural_context} cultural characteristics.\"\n",
        "\n",
        "            # 替換佔位符\n",
        "            cultural_description = description_template.format(elements=elements_text)\n",
        "\n",
        "            self.logger.debug(f\"Generated cultural description: {cultural_description}\")\n",
        "            return cultural_description\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating cultural elements for context '{cultural_context}': {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise CulturalContextError(error_msg) from e\n",
        "\n",
        "    def get_cultural_template(self, cultural_context: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取指定文化語境的模板\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 文化語境名稱\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 文化模板字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if cultural_context in self.cultural_templates:\n",
        "                return self.cultural_templates[cultural_context].copy()\n",
        "\n",
        "            # 返回備用模板\n",
        "            self.logger.warning(f\"Cultural template not found for '{cultural_context}', using fallback\")\n",
        "            return {\n",
        "                \"elements\": [\"various cultural elements\"],\n",
        "                \"description\": f\"The scene displays {cultural_context} cultural characteristics.\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting cultural template for '{cultural_context}': {str(e)}\")\n",
        "            return {\n",
        "                \"elements\": [\"various elements\"],\n",
        "                \"description\": \"The scene displays cultural characteristics.\"\n",
        "            }\n",
        "\n",
        "    def add_cultural_template(self, cultural_context: str, template: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        添加或更新文化模板\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 文化語境名稱\n",
        "            template: 文化模板字典\n",
        "\n",
        "        Raises:\n",
        "            CulturalContextError: 當模板格式無效時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 驗證模板格式\n",
        "            if not isinstance(template, dict):\n",
        "                raise CulturalContextError(\"Template must be a dictionary\")\n",
        "\n",
        "            required_keys = [\"elements\", \"description\"]\n",
        "            for key in required_keys:\n",
        "                if key not in template:\n",
        "                    raise CulturalContextError(f\"Template missing required key: {key}\")\n",
        "\n",
        "            if not isinstance(template[\"elements\"], list):\n",
        "                raise CulturalContextError(\"Template 'elements' must be a list\")\n",
        "\n",
        "            if not isinstance(template[\"description\"], str):\n",
        "                raise CulturalContextError(\"Template 'description' must be a string\")\n",
        "\n",
        "            # 添加模板\n",
        "            self.cultural_templates[cultural_context] = template.copy()\n",
        "\n",
        "            self.logger.info(f\"Added cultural template for context: {cultural_context}\")\n",
        "\n",
        "        except CulturalContextError:\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error adding cultural template for '{cultural_context}': {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise CulturalContextError(error_msg) from e\n",
        "\n",
        "    def get_supported_cultures(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取所有支援的文化語境列表\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 支援的文化語境名稱列表\n",
        "        \"\"\"\n",
        "        return list(self.cultural_templates.keys())\n",
        "\n",
        "    def has_cultural_context(self, cultural_context: str) -> bool:\n",
        "        \"\"\"\n",
        "        檢查是否支援指定的文化語境\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 文化語境名稱\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否支援該文化語境\n",
        "        \"\"\"\n",
        "        return cultural_context in self.cultural_templates\n",
        "\n",
        "    def analyze_cultural_diversity(self, detected_objects: List[Dict]) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        分析場景中的文化多樣性\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: 各文化語境的指標物件計數\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cultural_scores = {culture: 0 for culture in self.cultural_templates.keys()}\n",
        "\n",
        "            if not detected_objects:\n",
        "                return cultural_scores\n",
        "\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"\").lower()\n",
        "\n",
        "                # 為每個文化語境計算指標分數\n",
        "                for culture in cultural_scores:\n",
        "                    if self._is_cultural_indicator(class_name, culture):\n",
        "                        cultural_scores[culture] += 1\n",
        "\n",
        "            self.logger.debug(f\"Cultural diversity analysis: {cultural_scores}\")\n",
        "            return cultural_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error analyzing cultural diversity: {str(e)}\")\n",
        "            return {culture: 0 for culture in self.cultural_templates.keys()}\n",
        "\n",
        "    def _is_cultural_indicator(self, object_name: str, culture: str) -> bool:\n",
        "        \"\"\"\n",
        "        檢查物件名稱是否為特定文化的指標\n",
        "\n",
        "        Args:\n",
        "            object_name: 物件名稱\n",
        "            culture: 文化語境\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否為該文化的指標物件\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cultural_keywords = {\n",
        "                \"asian\": [\n",
        "                    \"lantern\", \"chopsticks\", \"rice\", \"noodles\", \"tea\",\n",
        "                    \"bamboo\", \"pagoda\", \"shrine\", \"torii\", \"kimono\",\n",
        "                    \"sushi\", \"ramen\", \"dim_sum\"\n",
        "                ],\n",
        "                \"european\": [\n",
        "                    \"wine\", \"cheese\", \"bread\", \"fountain\", \"column\",\n",
        "                    \"statue\", \"cathedral\", \"clock_tower\", \"baguette\",\n",
        "                    \"croissant\", \"espresso\", \"gelato\"\n",
        "                ],\n",
        "                \"mediterranean\": [\n",
        "                    \"olive\", \"terracotta\", \"pergola\", \"villa\",\n",
        "                    \"coastal\", \"maritime\", \"cypress\", \"vineyard\"\n",
        "                ],\n",
        "                \"american\": [\n",
        "                    \"burger\", \"pizza\", \"hotdog\", \"soda\",\n",
        "                    \"drive_through\", \"parking_lot\", \"diner\",\n",
        "                    \"strip_mall\", \"suburb\"\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            if culture not in cultural_keywords:\n",
        "                return False\n",
        "\n",
        "            keywords = cultural_keywords[culture]\n",
        "            return any(keyword in object_name for keyword in keywords)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error checking cultural indicator for {object_name}, {culture}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_template_summary(self) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        獲取所有文化模板的摘要信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Dict[str, Any]]: 文化模板摘要\n",
        "        \"\"\"\n",
        "        try:\n",
        "            summary = {}\n",
        "\n",
        "            for culture, template in self.cultural_templates.items():\n",
        "                summary[culture] = {\n",
        "                    \"element_count\": len(template.get(\"elements\", [])),\n",
        "                    \"has_description\": bool(template.get(\"description\", \"\")),\n",
        "                    \"sample_elements\": template.get(\"elements\", [])[:3]  # 前3個元素作為樣本\n",
        "                }\n",
        "\n",
        "            return summary\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating template summary: {str(e)}\")\n",
        "            return {}"
      ],
      "metadata": {
        "id": "rFu8WJSZtoaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb028b7-981c-4abc-a228-7050439f1045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cultural_context_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile text_formatter.py\n",
        "import logging\n",
        "import traceback\n",
        "import re\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "\n",
        "class TextFormattingError(Exception):\n",
        "    \"\"\"文本格式化過程中的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class TextFormatter:\n",
        "    \"\"\"\n",
        "    文本格式化器 - 負責文本拼接、格式化和最終輸出優化\n",
        "\n",
        "    該類別處理所有與文本格式化相關的邏輯，包括智能文本拼接、\n",
        "    標點符號處理、大小寫規範化以及地標引用的過濾功能。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        初始化文本格式化器\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "        try:\n",
        "            # 載入地標數據用於引用過濾\n",
        "            self.landmark_data = self._load_landmark_data()\n",
        "\n",
        "            self.logger.info(\"TextFormatter initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize TextFormatter: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n",
        "            raise TextFormattingError(error_msg) from e\n",
        "\n",
        "    def _load_landmark_data(self) -> Dict:\n",
        "        \"\"\"\n",
        "        載入地標數據\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標數據字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return ALL_LANDMARKS\n",
        "        except ImportError:\n",
        "            self.logger.warning(\"Failed to import landmark data, landmark filtering will be disabled\")\n",
        "            return {}\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error loading landmark data: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def smart_append(self, current_text: str, new_fragment: str) -> str:\n",
        "        \"\"\"\n",
        "        將新文本片段附加到現有文本，處理標點符號和大小寫\n",
        "\n",
        "        Args:\n",
        "            current_text: 要加到的現有文本\n",
        "            new_fragment: 要加的新文本片段\n",
        "\n",
        "        Returns:\n",
        "            str: 合併後的文本，具有適當的格式化\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 處理空值情況\n",
        "            if not new_fragment:\n",
        "                return current_text\n",
        "\n",
        "            if not current_text:\n",
        "                # 確保第一個字符大寫\n",
        "                return new_fragment[0].upper() + new_fragment[1:] if new_fragment else \"\"\n",
        "\n",
        "            # 清理現有文本\n",
        "            current_text = current_text.rstrip()\n",
        "\n",
        "            # 檢查結尾標點符號\n",
        "            ends_with_sentence = current_text.endswith(('.', '!', '?'))\n",
        "            ends_with_comma = current_text.endswith(',')\n",
        "\n",
        "            # 特別處理 \"A xxx A yyy\" 模式\n",
        "            if (current_text.startswith(\"A \") or current_text.startswith(\"An \")) and \\\n",
        "               (new_fragment.startswith(\"A \") or new_fragment.startswith(\"An \")):\n",
        "                return current_text + \". \" + new_fragment\n",
        "\n",
        "            # 檢查新片段是否包含地標名稱（通常為專有名詞）\n",
        "            has_landmark_name = any(word[0].isupper() for word in new_fragment.split()\n",
        "                                  if len(word) > 2 and not word.startswith((\"A \", \"An \", \"The \")))\n",
        "\n",
        "            # 決定如何連接文本\n",
        "            if ends_with_sentence:\n",
        "                # 句子後，以大寫開始並添加適當間距\n",
        "                joined_text = current_text + \" \" + (new_fragment[0].upper() + new_fragment[1:])\n",
        "            elif ends_with_comma:\n",
        "                # 逗號後，要保持流暢性，除非是專有名詞或特殊情況\n",
        "                if new_fragment.startswith(('I ', 'I\\'', 'A ', 'An ', 'The ')) or new_fragment[0].isupper() or has_landmark_name:\n",
        "                    joined_text = current_text + \" \" + new_fragment\n",
        "                else:\n",
        "                    joined_text = current_text + \" \" + new_fragment[0].lower() + new_fragment[1:]\n",
        "            elif \"scene is\" in new_fragment.lower() or \"scene includes\" in new_fragment.lower():\n",
        "                # 加關於場景的新句子時，使用句號\n",
        "                joined_text = current_text + \". \" + new_fragment\n",
        "            else:\n",
        "                # 其他情況，根據內容決定\n",
        "                if self._is_related_phrases(current_text, new_fragment):\n",
        "                    if new_fragment.startswith(('I ', 'I\\'', 'A ', 'An ', 'The ')) or new_fragment[0].isupper() or has_landmark_name:\n",
        "                        joined_text = current_text + \", \" + new_fragment\n",
        "                    else:\n",
        "                        joined_text = current_text + \", \" + new_fragment[0].lower() + new_fragment[1:]\n",
        "                else:\n",
        "                    # 對不相關的短語使用句號\n",
        "                    joined_text = current_text + \". \" + (new_fragment[0].upper() + new_fragment[1:])\n",
        "\n",
        "            return joined_text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in smart_append: {str(e)}\")\n",
        "            # 備用簡單拼接\n",
        "            return f\"{current_text} {new_fragment}\" if current_text else new_fragment\n",
        "\n",
        "    def _is_related_phrases(self, text1: str, text2: str) -> bool:\n",
        "        \"\"\"\n",
        "        判斷兩個短語是否相關，應該用逗號\n",
        "\n",
        "        Args:\n",
        "            text1: 第一個文本片段\n",
        "            text2: 要加的第二個文本片段\n",
        "\n",
        "        Returns:\n",
        "            bool: 短語是否相關\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 檢查兩個短語是否都以 \"A\" 或 \"An\" 開始 - 這些是獨立的描述\n",
        "            if (text1.startswith(\"A \") or text1.startswith(\"An \")) and \\\n",
        "               (text2.startswith(\"A \") or text2.startswith(\"An \")):\n",
        "                return False  # 這些是獨立的描述，不是相關短語\n",
        "\n",
        "            # 檢查第二個短語是否以連接詞開始\n",
        "            connecting_words = [\"which\", \"where\", \"who\", \"whom\", \"whose\", \"with\", \"without\",\n",
        "                              \"this\", \"these\", \"that\", \"those\", \"and\", \"or\", \"but\"]\n",
        "\n",
        "            first_word = text2.split()[0].lower() if text2 else \"\"\n",
        "            if first_word in connecting_words:\n",
        "                return True\n",
        "\n",
        "            # 檢查第一個短語是否以暗示連續性的內容結尾\n",
        "            ending_patterns = [\"such as\", \"including\", \"like\", \"especially\", \"particularly\",\n",
        "                             \"for example\", \"for instance\", \"namely\", \"specifically\"]\n",
        "\n",
        "            for pattern in ending_patterns:\n",
        "                if text1.lower().endswith(pattern):\n",
        "                    return True\n",
        "\n",
        "            # 檢查兩個短語是否都關於場景\n",
        "            if \"scene\" in text1.lower() and \"scene\" in text2.lower():\n",
        "                return False  # 關於場景的獨立陳述應該是分開的句子\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error checking phrase relationship: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def format_final_description(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        格式化最終描述文本，確保正確的標點符號、大小寫和間距\n",
        "\n",
        "        Args:\n",
        "            text: 要格式化的文本\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not text or not text.strip():\n",
        "                return \"\"\n",
        "\n",
        "            # 首先修剪前導/尾隨空白\n",
        "            text = text.strip()\n",
        "\n",
        "            # 1. 處理連續的 \"A/An\" 段落（可能將它們分成句子）\n",
        "            text = re.sub(r'(A\\s+[^.!?]+?[\\w\\.])\\s+(A\\s+)', r'\\1. \\2', text, flags=re.IGNORECASE)\n",
        "            text = re.sub(r'(An\\s+[^.!?]+?[\\w\\.])\\s+(An?\\s+)', r'\\1. \\2', text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 2. 確保整個文本的第一個字符大寫\n",
        "            if text:\n",
        "                text = text[0].upper() + text[1:]\n",
        "\n",
        "            # 3. 規範化空白：多個空格變為一個\n",
        "            text = re.sub(r'\\s{2,}', ' ', text)\n",
        "\n",
        "            # 4. 句子結尾標點符號後大寫\n",
        "            def capitalize_after_punctuation(match):\n",
        "                return match.group(1) + match.group(2).upper()\n",
        "            text = re.sub(r'([.!?]\\s+)([a-z])', capitalize_after_punctuation, text)\n",
        "\n",
        "            # 5. 處理逗號後的大小寫\n",
        "            def fix_capitalization_after_comma(match):\n",
        "                leading_comma_space = match.group(1)  # (,\\s+)\n",
        "                word_after_comma = match.group(2)     # ([A-Z][a-zA-Z]*)\n",
        "\n",
        "                proper_nouns_exceptions = [\"I\", \"I'm\", \"I've\", \"I'd\", \"I'll\",\n",
        "                                         \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",\n",
        "                                         \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",\n",
        "                                         \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "                if word_after_comma in proper_nouns_exceptions:\n",
        "                    return match.group(0)\n",
        "\n",
        "                # 如果詞看起來像專有名詞（已經大寫且不是常用詞），保持不變\n",
        "                if len(word_after_comma) > 2 and word_after_comma[0].isupper() and word_after_comma.lower() not in [\"this\", \"that\", \"these\", \"those\", \"they\", \"their\", \"then\", \"thus\"]:\n",
        "                    return match.group(0)  # 如果看起來已經是專有名詞則保持不變\n",
        "\n",
        "                return leading_comma_space + word_after_comma[0].lower() + word_after_comma[1:]\n",
        "            text = re.sub(r'(,\\s+)([A-Z][a-zA-Z\\'\\-]+)', fix_capitalization_after_comma, text)\n",
        "\n",
        "            # 6. 修正標點符號周圍的間距\n",
        "            text = re.sub(r'\\s*([.,;:!?])\\s*', r'\\1 ', text)  # 確保標點符號後有一個空格，前面沒有\n",
        "            text = text.replace(' .', '.').replace(' ,', ',')  # 清理標點符號前可能的空格\n",
        "\n",
        "            # 7. 合併多個句子結尾標點符號\n",
        "            text = re.sub(r'[.!?]{2,}', '.', text)  # 將多個轉換為單個句號\n",
        "            text = re.sub(r',+', ',', text)  # 多個逗號變為一個\n",
        "\n",
        "            # 8. 確保文本以單個句子結尾標點符號結尾\n",
        "            text = text.strip()  # 檢查最後一個字符前移除尾隨空白\n",
        "            if text and not text[-1] in '.!?':\n",
        "                text += '.'\n",
        "\n",
        "            # 9. 處理空的佔位符和前導標點符號\n",
        "            text = re.sub(r'\\bIn\\s*,\\s*', 'In this scene, ', text)  # 修復 \"In , \" 問題\n",
        "            text = re.sub(r'\\s*,\\s*([A-Z])', r'. \\1', text)  # 修復逗號後直接跟大寫字母的問題\n",
        "            text = re.sub(r'^[.,;:!?\\s]+', '', text)  # 移除前導標點符號\n",
        "\n",
        "            # 10. 第一個字母大寫的最終檢查\n",
        "            if text:\n",
        "                text = text[0].upper() + text[1:]\n",
        "\n",
        "            # 11. 移除最終標點符號前的空格（如果規則7意外添加）\n",
        "            text = re.sub(r'\\s+([.!?])$', r'\\1', text)\n",
        "\n",
        "            return text.strip()  # 最終修剪\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting final description: {str(e)}\")\n",
        "            # 備用基本格式化\n",
        "            if text:\n",
        "                text = text.strip()\n",
        "                if text and not text.endswith(('.', '!', '?')):\n",
        "                    text += '.'\n",
        "                if text:\n",
        "                    text = text[0].upper() + text[1:]\n",
        "                return text\n",
        "            return \"\"\n",
        "\n",
        "    def filter_landmark_references(self, text: str, enable_landmark: bool = True) -> str:\n",
        "        \"\"\"\n",
        "        動態過濾文本中的地標引用\n",
        "\n",
        "        Args:\n",
        "            text: 需要過濾的文本\n",
        "            enable_landmark: 是否啟用地標功能\n",
        "\n",
        "        Returns:\n",
        "            str: 過濾後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if enable_landmark or not text:\n",
        "                return text\n",
        "\n",
        "            # 動態收集所有地標名稱和位置\n",
        "            landmark_names = []\n",
        "            locations = []\n",
        "\n",
        "            for landmark_id, info in self.landmark_data.items():\n",
        "                # 收集地標名稱及其別名\n",
        "                landmark_names.append(info[\"name\"])\n",
        "                landmark_names.extend(info.get(\"aliases\", []))\n",
        "\n",
        "                # 收集地理位置\n",
        "                if \"location\" in info:\n",
        "                    location = info[\"location\"]\n",
        "                    locations.append(location)\n",
        "\n",
        "                    # 處理分離的城市和國家名稱\n",
        "                    parts = location.split(\",\")\n",
        "                    if len(parts) >= 1:\n",
        "                        locations.append(parts[0].strip())\n",
        "                    if len(parts) >= 2:\n",
        "                        locations.append(parts[1].strip())\n",
        "\n",
        "            # 替換所有地標名稱\n",
        "            for name in landmark_names:\n",
        "                if name and len(name) > 2:  # 避免過短的名稱\n",
        "                    text = re.sub(r'\\b' + re.escape(name) + r'\\b', \"tall structure\", text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 動態替換所有位置引用\n",
        "            for location in locations:\n",
        "                if location and len(location) > 2:\n",
        "                    # 替換常見位置表述模式\n",
        "                    text = re.sub(r'in ' + re.escape(location), \"in the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'of ' + re.escape(location), \"of the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'\\b' + re.escape(location) + r'\\b', \"the urban area\", text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 通用地標描述模式替換\n",
        "            landmark_patterns = [\n",
        "                (r'a (tourist|popular|famous) landmark', r'an urban structure'),\n",
        "                (r'an iconic structure in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure in the area'),\n",
        "                (r'a famous (monument|tower|landmark) in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure in the area'),\n",
        "                (r'(centered|built|located|positioned) around the ([A-Z][a-zA-Z\\s]+? (Tower|Monument|Landmark))', r'located in this area'),\n",
        "                (r'(sightseeing|guided tours|cultural tourism) (at|around|near) (this landmark|the [A-Z][a-zA-Z\\s]+)', r'\\1 in this area'),\n",
        "                (r'this (famous|iconic|historic|well-known) (landmark|monument|tower|structure)', r'this urban structure'),\n",
        "                (r'([A-Z][a-zA-Z\\s]+) Tower', r'tall structure'),\n",
        "                (r'a (tower|structure) in ([A-Z][a-zA-Z\\s,]+)', r'a \\1 in the area'),\n",
        "                (r'landmark scene', r'urban scene'),\n",
        "                (r'tourist destination', r'urban area'),\n",
        "                (r'tourist attraction', r'urban area')\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in landmark_patterns:\n",
        "                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error filtering landmark references: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def optimize_text_flow(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        優化文本流暢性，減少重複和改善可讀性\n",
        "\n",
        "        Args:\n",
        "            text: 要優化的文本\n",
        "\n",
        "        Returns:\n",
        "            str: 優化後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not text:\n",
        "                return text\n",
        "\n",
        "            # 移除重複的短語\n",
        "            text = self._remove_duplicate_phrases(text)\n",
        "\n",
        "            # 優化連接詞使用\n",
        "            text = self._optimize_connectors(text)\n",
        "\n",
        "            # 平衡句子長度\n",
        "            text = self._balance_sentence_length(text)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error optimizing text flow: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def _remove_duplicate_phrases(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        移除文本中的重複短語\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            str: 移除重複後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 分割成句子\n",
        "            sentences = re.split(r'[.!?]+', text)\n",
        "            unique_sentences = []\n",
        "            seen_content = set()\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence = sentence.strip()\n",
        "                if not sentence:\n",
        "                    continue\n",
        "\n",
        "                # 規範化以進行比較（移除額外空白和標點符號）\n",
        "                normalized = re.sub(r'\\s+', ' ', sentence.lower().strip())\n",
        "\n",
        "                # 檢查是否實質相似\n",
        "                is_duplicate = False\n",
        "                for seen in seen_content:\n",
        "                    if self._sentences_similar(normalized, seen):\n",
        "                        is_duplicate = True\n",
        "                        break\n",
        "\n",
        "                if not is_duplicate:\n",
        "                    unique_sentences.append(sentence)\n",
        "                    seen_content.add(normalized)\n",
        "\n",
        "            return '. '.join(unique_sentences) + '.' if unique_sentences else \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error removing duplicate phrases: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def _sentences_similar(self, sent1: str, sent2: str) -> bool:\n",
        "        \"\"\"\n",
        "        檢查兩個句子是否相似\n",
        "\n",
        "        Args:\n",
        "            sent1: 第一個句子\n",
        "            sent2: 第二個句子\n",
        "\n",
        "        Returns:\n",
        "            bool: 句子是否相似\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 簡單的相似性檢查：如果80%的詞彙重疊\n",
        "            words1 = set(sent1.split())\n",
        "            words2 = set(sent2.split())\n",
        "\n",
        "            if not words1 or not words2:\n",
        "                return False\n",
        "\n",
        "            intersection = len(words1 & words2)\n",
        "            union = len(words1 | words2)\n",
        "\n",
        "            similarity = intersection / union if union > 0 else 0\n",
        "            return similarity > 0.8\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error checking sentence similarity: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _optimize_connectors(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        優化連接詞的使用\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            str: 優化連接詞後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 替換重複的連接詞\n",
        "            text = re.sub(r'\\band\\s+and\\b', 'and', text, flags=re.IGNORECASE)\n",
        "            text = re.sub(r'\\bwith\\s+with\\b', 'with', text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 改善過度使用 \"and\" 的情況\n",
        "            text = re.sub(r'(\\w+),\\s+and\\s+(\\w+),\\s+and\\s+(\\w+)', r'\\1, \\2, and \\3', text)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error optimizing connectors: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def _balance_sentence_length(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        平衡句子長度，分割過長的句子\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            str: 平衡句子長度後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            sentences = re.split(r'([.!?]+)', text)\n",
        "            balanced_text = \"\"\n",
        "\n",
        "            for i in range(0, len(sentences), 2):\n",
        "                if i + 1 < len(sentences):\n",
        "                    sentence = sentences[i]\n",
        "                    punctuation = sentences[i + 1]\n",
        "\n",
        "                    # 如果句子太長（超過150個字符），嘗試在適當位置分割\n",
        "                    if len(sentence) > 150:\n",
        "                        # 在逗號或連接詞處分割\n",
        "                        split_points = [m.start() for m in re.finditer(r',\\s+(?:and|but|or|while|when|where)', sentence)]\n",
        "                        if split_points:\n",
        "                            mid_point = split_points[len(split_points) // 2]\n",
        "                            first_part = sentence[:mid_point].strip()\n",
        "                            second_part = sentence[mid_point + 1:].strip()\n",
        "                            if second_part and not second_part[0].isupper():\n",
        "                                second_part = second_part[0].upper() + second_part[1:]\n",
        "                            balanced_text += first_part + \". \" + second_part + punctuation + \" \"\n",
        "                        else:\n",
        "                            balanced_text += sentence + punctuation + \" \"\n",
        "                    else:\n",
        "                        balanced_text += sentence + punctuation + \" \"\n",
        "\n",
        "            return balanced_text.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error balancing sentence length: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def validate_text_quality(self, text: str) -> Dict[str, bool]:\n",
        "        \"\"\"\n",
        "        驗證文本質量\n",
        "\n",
        "        Args:\n",
        "            text: 要驗證的文本\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, bool]: 質量檢查結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            quality_checks = {\n",
        "                \"has_content\": bool(text and text.strip()),\n",
        "                \"proper_capitalization\": bool(text and text[0].isupper()) if text else False,\n",
        "                \"ends_with_punctuation\": bool(text and text.strip()[-1] in '.!?') if text else False,\n",
        "                \"no_double_spaces\": \"  \" not in text if text else True,\n",
        "                \"no_leading_punctuation\": not bool(re.match(r'^[.,;:!?]', text.strip())) if text else True,\n",
        "                \"reasonable_length\": 20 <= len(text) <= 1000 if text else False\n",
        "            }\n",
        "\n",
        "            return quality_checks\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error validating text quality: {str(e)}\")\n",
        "            return {\"error\": True}\n",
        "\n",
        "    def get_text_statistics(self, text: str) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        獲取文本統計信息\n",
        "\n",
        "        Args:\n",
        "            text: 要分析的文本\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: 文本統計信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not text:\n",
        "                return {\"characters\": 0, \"words\": 0, \"sentences\": 0}\n",
        "\n",
        "            characters = len(text)\n",
        "            words = len(text.split())\n",
        "            sentences = len(re.findall(r'[.!?]+', text))\n",
        "\n",
        "            return {\n",
        "                \"characters\": characters,\n",
        "                \"words\": words,\n",
        "                \"sentences\": sentences\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting text statistics: {str(e)}\")\n",
        "            return {\"characters\": 0, \"words\": 0, \"sentences\": 0}"
      ],
      "metadata": {
        "id": "HpNQBiEatoXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573689f7-bb97-4836-f2b5-7ee0688779e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing text_formatter.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile enhanced_scene_describer.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from scene_detail_templates import SCENE_DETAIL_TEMPLATES\n",
        "# from object_template_fillers import OBJECT_TEMPLATE_FILLERS\n",
        "# from lighting_conditions import LIGHTING_CONDITIONS\n",
        "# from viewpoint_templates import VIEWPOINT_TEMPLATES\n",
        "# from cultural_templates import CULTURAL_TEMPLATES\n",
        "# from confidence_templates import CONFIDENCE_TEMPLATES\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "# from region_analyzer import RegionAnalyzer\n",
        "# from viewpoint_detector import ViewpointDetector, ViewpointDetectionError\n",
        "# from template_manager import TemplateManager, TemplateLoadingError, TemplateFillError\n",
        "# from object_description_generator import ObjectDescriptionGenerator, ObjectDescriptionError\n",
        "# from cultural_context_analyzer import CulturalContextAnalyzer, CulturalContextError\n",
        "# from text_formatter import TextFormatter, TextFormattingError\n",
        "\n",
        "class EnhancedSceneDescriberError(Exception):\n",
        "    \"\"\"場景描述生成過程中的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "class EnhancedSceneDescriber:\n",
        "    \"\"\"\n",
        "    增強場景描述器 - 提供詳細自然語言場景描述的主要窗口，其他相關class匯集於此\n",
        "\n",
        "    此class會協調多個專門組件來生成高質量的場景描述，包括視角檢測、\n",
        "    模板管理、物件描述、文化語境分析和文本格式化。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, templates_db: Optional[Dict] = None, scene_types: Optional[Dict] = None, spatial_analyzer_instance: Optional[Any] = None):\n",
        "        \"\"\"\n",
        "        初始化增強場景描述器\n",
        "\n",
        "        Args:\n",
        "            templates_db: 可選的自定義模板數據庫\n",
        "            scene_types: 場景類型定義字典\n",
        "            spatial_analyzer_instance: 空間分析器實例（保持兼容性）\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        # 如果沒有logger，就加一個\n",
        "        if not self.logger.hasHandlers():\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "\n",
        "        try:\n",
        "            # 載入場景類型定義\n",
        "            self.scene_types = scene_types or self._load_default_scene_types()\n",
        "\n",
        "            # 初始化子組件\n",
        "            self._initialize_components(templates_db)\n",
        "\n",
        "            # 保存空間分析器實例以保持兼容性\n",
        "            self.spatial_analyzer_instance = spatial_analyzer_instance\n",
        "\n",
        "            self.logger.info(\"EnhancedSceneDescriber initialized successfully with %d scene types\",\n",
        "                           len(self.scene_types))\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize EnhancedSceneDescriber: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{e.__class__.__name__}: {str(e)}\")\n",
        "            raise EnhancedSceneDescriberError(error_msg) from e\n",
        "\n",
        "    def _load_default_scene_types(self) -> Dict:\n",
        "        \"\"\"\n",
        "        載入默認場景類型\n",
        "\n",
        "        Returns:\n",
        "            Dict: 場景類型定義\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return SCENE_TYPES\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to import SCENE_TYPES: {str(e)}\")\n",
        "            return {}  # 返回空字典\n",
        "\n",
        "    def _initialize_components(self, templates_db: Optional[Dict]):\n",
        "        \"\"\"\n",
        "        初始化所有子組件\n",
        "\n",
        "        Args:\n",
        "            templates_db: 可選的模板數據庫\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 初始化視角檢測器\n",
        "            self.viewpoint_detector = ViewpointDetector()\n",
        "\n",
        "            # 初始化區域分析器\n",
        "            self.region_analyzer = RegionAnalyzer()\n",
        "\n",
        "            # 初始化模板管理器\n",
        "            self.template_manager = TemplateManager(custom_templates_db=templates_db)\n",
        "\n",
        "            # 初始化物件描述生成器，傳入區域分析器\n",
        "            self.object_description_generator = ObjectDescriptionGenerator(\n",
        "                region_analyzer=self.region_analyzer\n",
        "            )\n",
        "\n",
        "            # 初始化文化語境分析器\n",
        "            self.cultural_context_analyzer = CulturalContextAnalyzer()\n",
        "\n",
        "            # 初始化文本格式化器\n",
        "            self.text_formatter = TextFormatter()\n",
        "\n",
        "            self.logger.debug(\"All components initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Component initialization failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            # 初始化基本組件而不是拋出異常\n",
        "            self._initialize_fallback_components()\n",
        "\n",
        "\n",
        "    def generate_description(self, scene_type: str, detected_objects: List[Dict], confidence: float,\n",
        "                           lighting_info: Dict, functional_zones: List[str], enable_landmark: bool = True,\n",
        "                           scene_scores: Optional[Dict] = None, spatial_analysis: Optional[Dict] = None,\n",
        "                           image_dimensions: Optional[Tuple[int, int]] = None, # 改為 Tuple\n",
        "                           places365_info: Optional[Dict] = None,\n",
        "                           object_statistics: Optional[Dict] = None) -> str:\n",
        "        try:\n",
        "            traffic_list = [obj for obj in detected_objects if obj.get(\"class_name\", \"\") == \"traffic light\"]\n",
        "            # print(f\"[DEBUG] generate_description 一開始接收到的 traffic light 數量: {len(traffic_list)}\") # 原始的 print\n",
        "            self.logger.debug(f\"Initial traffic light count in generate_description: {len(traffic_list)}\") # 改用 logger\n",
        "            # for idx, tl in enumerate(traffic_list): # 這部分 log 可能過於詳細，先註解\n",
        "            #     self.logger.debug(f\"    idx={idx}, confidence={tl.get('confidence', 0):.4f}, bbox={tl.get('bbox')}, region={tl.get('region')}\")\n",
        "\n",
        "            if scene_type == \"unknown\" or confidence < 0.4:\n",
        "                generic_desc = self._generate_generic_description(detected_objects, lighting_info)\n",
        "                return self.text_formatter.format_final_description(generic_desc)\n",
        "\n",
        "            current_detected_objects = detected_objects\n",
        "            if not enable_landmark:\n",
        "                current_detected_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "\n",
        "            places365_context = \"\"\n",
        "            if places365_info and places365_info.get('confidence', 0) > 0.3:\n",
        "                scene_label = places365_info.get('scene_label', '')\n",
        "                attributes = places365_info.get('attributes', [])\n",
        "                is_indoor = places365_info.get('is_indoor', None)\n",
        "                if scene_label:\n",
        "                    places365_context = f\"Scene context: {scene_label}\"\n",
        "                    if attributes:\n",
        "                        places365_context += f\" with characteristics: {', '.join(attributes[:3])}\"\n",
        "                    if is_indoor is not None:\n",
        "                        indoor_outdoor = \"indoor\" if is_indoor else \"outdoor\"\n",
        "                        places365_context += f\" ({indoor_outdoor} environment)\"\n",
        "                self.logger.debug(f\"Enhanced description incorporating Places365 context: {places365_context}\")\n",
        "\n",
        "            landmark_objects_in_scene = [obj for obj in current_detected_objects if obj.get(\"is_landmark\", False)]\n",
        "            has_landmark_in_scene = len(landmark_objects_in_scene) > 0\n",
        "\n",
        "            if enable_landmark and (scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"] or has_landmark_in_scene):\n",
        "                landmark_desc = self._generate_landmark_description(\n",
        "                    scene_type, current_detected_objects, confidence,\n",
        "                    lighting_info, functional_zones, landmark_objects_in_scene\n",
        "                )\n",
        "                return self.text_formatter.format_final_description(landmark_desc)\n",
        "\n",
        "            viewpoint = self.viewpoint_detector.detect_viewpoint(current_detected_objects)\n",
        "            current_scene_type = scene_type\n",
        "\n",
        "            if viewpoint == \"aerial\":\n",
        "                if \"intersection\" in current_scene_type.lower() or self._is_intersection(current_detected_objects):\n",
        "                    current_scene_type = \"aerial_view_intersection\"\n",
        "                elif any(keyword in current_scene_type.lower() for keyword in [\"commercial\", \"shopping\", \"retail\"]):\n",
        "                    current_scene_type = \"aerial_view_commercial_area\"\n",
        "                elif any(keyword in current_scene_type.lower() for keyword in [\"plaza\", \"square\"]):\n",
        "                    current_scene_type = \"aerial_view_plaza\"\n",
        "                else:\n",
        "                    current_scene_type = \"aerial_view_general\"\n",
        "\n",
        "            current_scene_type = self._sanitize_scene_type_for_description(current_scene_type)\n",
        "\n",
        "            # 偵測文化背景資訊\n",
        "            cultural_context = None\n",
        "            if viewpoint != \"aerial\":\n",
        "                cultural_context = self.cultural_context_analyzer.detect_cultural_context(current_scene_type, current_detected_objects)\n",
        "\n",
        "             # 設定基礎描述\n",
        "            base_description = \"A scene\"\n",
        "            if viewpoint == \"aerial\":\n",
        "                if current_scene_type in self.scene_types: # 確保 self.scene_types 已有\n",
        "                    base_description = self.scene_types.get(current_scene_type, {}).get(\"description\", \"An aerial view showing the layout and movement patterns from above\")\n",
        "                else:\n",
        "                    base_description = \"An aerial view showing the layout and movement patterns from above\"\n",
        "            elif current_scene_type in self.scene_types: # 確保 self.scene_types 已有\n",
        "                 base_description = self.scene_types.get(current_scene_type, {}).get(\"description\", \"A scene\")\n",
        "\n",
        "            # 假設 template_manager 內部可以處理 List[str] 的 functional_zones\n",
        "            selected_template = self.template_manager.get_template_by_scene_type(\n",
        "                scene_type=current_scene_type,\n",
        "                detected_objects=current_detected_objects,\n",
        "                functional_zones=functional_zones or [] # 傳入 List[str]\n",
        "            )\n",
        "\n",
        "            # 用於 fill_template 中的某些佔位符\n",
        "            processed_functional_zones = {}\n",
        "            if functional_zones:\n",
        "                if isinstance(functional_zones, dict): # 如果外部傳入的就是dict\n",
        "                     processed_functional_zones = functional_zones\n",
        "                elif isinstance(functional_zones, list): # 如果是 list of strings\n",
        "                     processed_functional_zones = {f\"zone_{i}\": {\"description\": zone_desc} for i, zone_desc in enumerate(functional_zones)}\n",
        "\n",
        "\n",
        "            # 組織場景資料\n",
        "            scene_data = {\n",
        "                \"detected_objects\": current_detected_objects,\n",
        "                \"functional_zones\": processed_functional_zones, # 傳入處理過的字典\n",
        "                \"scene_type\": current_scene_type,\n",
        "                \"object_statistics\": object_statistics or {},\n",
        "                \"lighting_info\": lighting_info,\n",
        "                \"spatial_analysis\": spatial_analysis,\n",
        "                \"places365_info\": places365_info\n",
        "            }\n",
        "\n",
        "            # 應用模板產生核心場景描述\n",
        "            core_scene_details = self.template_manager.apply_template(selected_template, scene_data)\n",
        "\n",
        "            # 組合基礎描述與核心場景細節\n",
        "            description = base_description\n",
        "            if core_scene_details and core_scene_details.strip():\n",
        "                cleaned_scene_details = self._validate_and_clean_scene_details(core_scene_details)\n",
        "                if base_description.lower() == \"a scene\" and len(cleaned_scene_details) > len(base_description):\n",
        "                    description = cleaned_scene_details\n",
        "                else:\n",
        "                    description = self.text_formatter.smart_append(description, cleaned_scene_details)\n",
        "            elif not core_scene_details and not description: # 如果兩者都為空\n",
        "                description = self._generate_generic_description(current_detected_objects, lighting_info)\n",
        "\n",
        "            # 添加次要描述資訊\n",
        "            if current_scene_type in self.scene_types and \"secondary_description\" in self.scene_types[current_scene_type]:\n",
        "                secondary_desc = self.scene_types[current_scene_type][\"secondary_description\"]\n",
        "                if secondary_desc:\n",
        "                    description = self.text_formatter.smart_append(description, secondary_desc)\n",
        "\n",
        "            # 處理人物相關的描述\n",
        "            people_objs = [obj for obj in current_detected_objects if obj.get(\"class_id\") == 0]\n",
        "            if people_objs:\n",
        "                people_count = len(people_objs)\n",
        "                if people_count == 1: people_phrase = \"a single person\"\n",
        "                elif 1 < people_count <= 3: people_phrase = f\"{people_count} people\"\n",
        "                elif 3 < people_count <= 7: people_phrase = \"several people\"\n",
        "                else: people_phrase = \"multiple people\"\n",
        "                if not any(p_word in description.lower() for p_word in [\"person\", \"people\", \"pedestrian\"]):\n",
        "                    description = self.text_formatter.smart_append(description, f\"The scene includes {people_phrase}.\")\n",
        "\n",
        "            # 添加文化背景元素(非空中視角）\n",
        "            if cultural_context and viewpoint != \"aerial\":\n",
        "                cultural_elements = self.cultural_context_analyzer.generate_cultural_elements(cultural_context)\n",
        "                if cultural_elements:\n",
        "                    description = self.text_formatter.smart_append(description, cultural_elements)\n",
        "\n",
        "            # 處理光照條件描述\n",
        "            lighting_description_text = \"\"\n",
        "            if lighting_info and \"time_of_day\" in lighting_info:\n",
        "                lighting_type = lighting_info[\"time_of_day\"]\n",
        "                lighting_desc_template = self.template_manager.get_lighting_template(lighting_type)\n",
        "                if lighting_desc_template: lighting_description_text = lighting_desc_template\n",
        "            if lighting_description_text and lighting_description_text.lower() not in description.lower():\n",
        "                description = self.text_formatter.smart_append(description, lighting_description_text)\n",
        "\n",
        "             # 添加視角特定的觀察描述\n",
        "            if viewpoint != \"eye_level\":\n",
        "                viewpoint_template = self.template_manager.get_viewpoint_template(viewpoint)\n",
        "                prefix = viewpoint_template.get('prefix', '')\n",
        "                observation_template = viewpoint_template.get(\"observation\", \"\")\n",
        "                scene_elements_for_vp = \"the overall layout and objects\"\n",
        "                if viewpoint == \"aerial\": scene_elements_for_vp = \"crossing patterns and general layout\"\n",
        "                viewpoint_observation_text = observation_template.format(scene_elements=scene_elements_for_vp)\n",
        "                full_viewpoint_text = \"\"\n",
        "                if prefix:\n",
        "                    full_viewpoint_text = prefix.strip() + \" \"\n",
        "                    if viewpoint_observation_text and viewpoint_observation_text[0].islower():\n",
        "                        full_viewpoint_text += viewpoint_observation_text\n",
        "                    elif viewpoint_observation_text:\n",
        "                        full_viewpoint_text = prefix + (viewpoint_observation_text[0].lower() + viewpoint_observation_text[1:] if description else viewpoint_observation_text)\n",
        "                elif viewpoint_observation_text:\n",
        "                    full_viewpoint_text = viewpoint_observation_text[0].upper() + viewpoint_observation_text[1:]\n",
        "                if full_viewpoint_text and full_viewpoint_text.lower() not in description.lower():\n",
        "                    description = self.text_formatter.smart_append(description, full_viewpoint_text)\n",
        "\n",
        "            # 需要轉換或調整 describe_functional_zones\n",
        "            if functional_zones and len(functional_zones) > 0:\n",
        "                if isinstance(functional_zones, dict):\n",
        "                     zones_desc_text = self.object_description_generator.describe_functional_zones(functional_zones)\n",
        "                else: # 如果是 list of strings\n",
        "                     temp_zones_dict = {f\"area_{i}\": {\"description\": desc} for i, desc in enumerate(functional_zones)}\n",
        "                     zones_desc_text = self.object_description_generator.describe_functional_zones(temp_zones_dict)\n",
        "\n",
        "                if zones_desc_text:\n",
        "                    description = self.text_formatter.smart_append(description, zones_desc_text)\n",
        "\n",
        "            # 避免重複提到\n",
        "            if hasattr(self.text_formatter, 'deduplicate_sentences_in_description'):\n",
        "                deduplicated_description = self.text_formatter.deduplicate_sentences_in_description(description)\n",
        "                self.logger.info(f\"Description before pre-LLM deduplication (len {len(description)}): '{description[:150]}...'\")\n",
        "                self.logger.info(f\"Description after pre-LLM deduplication (len {len(deduplicated_description)}): '{deduplicated_description[:150]}...'\")\n",
        "                description = deduplicated_description # 更新 description 為去除重複後的版本\n",
        "            else:\n",
        "                self.logger.warning(\"TextFormatter does not have 'deduplicate_sentences_in_description'. Skipping pre-LLM deduplication of the internally generated description.\")\n",
        "\n",
        "            # 格式化最終描述\n",
        "            final_formatted_description = self.text_formatter.format_final_description(description)\n",
        "\n",
        "            # 如果禁用地標，過濾地標引用\n",
        "            if not enable_landmark:\n",
        "                final_formatted_description = self.text_formatter.filter_landmark_references(final_formatted_description, enable_landmark=False)\n",
        "\n",
        "            # 如果描述為空，使用備用描述\n",
        "            if not final_formatted_description.strip() or final_formatted_description.strip() == \".\":\n",
        "                self.logger.warning(f\"Description for scene_type '{current_scene_type}' became empty after processing. Falling back.\")\n",
        "                final_formatted_description = self.text_formatter.format_final_description(\n",
        "                    self._generate_generic_description(current_detected_objects, lighting_info)\n",
        "                )\n",
        "\n",
        "            return final_formatted_description\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating scene description: {str(e)}\"\n",
        "            self.logger.error(f\"{error_msg}\\n{e.__class__.__name__}: {str(e)}\")\n",
        "            try:\n",
        "                fallback_desc = self._generate_generic_description(detected_objects, lighting_info)\n",
        "                return self.text_formatter.format_final_description(fallback_desc)\n",
        "            except:\n",
        "                return \"A scene with various elements is visible.\"\n",
        "\n",
        "    def deduplicate_sentences_in_description(self, description: str, similarity_threshold: float = 0.80) -> str:\n",
        "        \"\"\"\n",
        "        從一段描述文本中移除重複或高度相似的句子。\n",
        "        此方法會嘗試保留更長、資訊更豐富的句子版本。\n",
        "\n",
        "        Args:\n",
        "            description (str): 原始描述文本。\n",
        "            similarity_threshold (float): 判斷句子是否相似的 Jaccard 相似度閾值 (0 到 1)。\n",
        "                                         預設為 0.8，表示詞彙重疊度達到80%即視為相似。\n",
        "\n",
        "        Returns:\n",
        "            str: 移除了重複或高度相似句子後的文本。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not description or not description.strip():\n",
        "                self.logger.debug(\"deduplicate_sentences_in_description: Received empty or blank description.\")\n",
        "                return \"\"\n",
        "\n",
        "            # 使用正則表達式分割句子，保留句尾標點符號\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', description.strip())\n",
        "\n",
        "            if not sentences:\n",
        "                self.logger.debug(\"deduplicate_sentences_in_description: No sentences found after splitting.\")\n",
        "                return \"\"\n",
        "\n",
        "            unique_sentences_data = []  # 存儲 (原始句子文本, 該句子的詞彙集合)\n",
        "\n",
        "            for current_sentence_text in sentences:\n",
        "                current_sentence_text = current_sentence_text.strip()\n",
        "                if not current_sentence_text:\n",
        "                    continue\n",
        "\n",
        "                # 預處理當前句子以進行比較：轉小寫、移除標點、分割成詞彙集合\n",
        "                simplified_current_text = re.sub(r'[^\\w\\s\\d]', '', current_sentence_text.lower()) # 保留數字\n",
        "                current_sentence_words = set(simplified_current_text.split())\n",
        "\n",
        "                if not current_sentence_words: # 如果處理後是空集合 (例如句子只包含標點)\n",
        "                    # 如果原始句子有內容（例如只有一個標點），就保留它\n",
        "                    if current_sentence_text and not unique_sentences_data: # 避免在開頭加入孤立標點\n",
        "                         unique_sentences_data.append((current_sentence_text, current_sentence_words))\n",
        "                    continue\n",
        "\n",
        "                is_subsumed_or_highly_similar = False\n",
        "                index_to_replace = -1\n",
        "\n",
        "                for i, (kept_sentence_text, kept_sentence_words) in enumerate(unique_sentences_data):\n",
        "                    if not kept_sentence_words: # 跳過已保留的空詞彙集合\n",
        "                        continue\n",
        "\n",
        "                    # 計算 Jaccard 相似度\n",
        "                    intersection_len = len(current_sentence_words.intersection(kept_sentence_words))\n",
        "                    union_len = len(current_sentence_words.union(kept_sentence_words))\n",
        "\n",
        "                    jaccard_similarity = 0.0\n",
        "                    if union_len > 0:\n",
        "                        jaccard_similarity = intersection_len / union_len\n",
        "                    elif not current_sentence_words and not kept_sentence_words: # 兩個都是空的\n",
        "                        jaccard_similarity = 1.0\n",
        "\n",
        "\n",
        "                    if jaccard_similarity >= similarity_threshold:\n",
        "                        # 如果當前句子比已保留的句子長，則標記替換舊的\n",
        "                        if len(current_sentence_words) > len(kept_sentence_words):\n",
        "                            self.logger.debug(f\"Deduplication: Replacing shorter \\\"{kept_sentence_text[:50]}...\\\" \"\n",
        "                                              f\"with longer similar \\\"{current_sentence_text[:50]}...\\\" (Jaccard: {jaccard_similarity:.2f})\")\n",
        "                            index_to_replace = i\n",
        "                            break # 找到一個可以被替換的，就跳出內層循環\n",
        "                        # 如果當前句子比已保留的句子短，或者長度相近但內容高度相似，則標記當前句子為重複\n",
        "                        else: # current_sentence_words is shorter or of similar length\n",
        "                            is_subsumed_or_highly_similar = True\n",
        "                            self.logger.debug(f\"Deduplication: Current sentence \\\"{current_sentence_text[:50]}...\\\" \"\n",
        "                                              f\"is subsumed by or highly similar to \\\"{kept_sentence_text[:50]}...\\\" (Jaccard: {jaccard_similarity:.2f}). Skipping.\")\n",
        "                            break\n",
        "\n",
        "                if index_to_replace != -1:\n",
        "                    unique_sentences_data[index_to_replace] = (current_sentence_text, current_sentence_words)\n",
        "                elif not is_subsumed_or_highly_similar:\n",
        "                    unique_sentences_data.append((current_sentence_text, current_sentence_words))\n",
        "\n",
        "            # 從 unique_sentences_data 中提取最終的句子文本\n",
        "            final_sentences = [s_data[0] for s_data in unique_sentences_data]\n",
        "\n",
        "            # 重組句子，確保每個句子以標點符號結尾，並且句子間有空格\n",
        "            reconstructed_response = \"\"\n",
        "            for i, s_text in enumerate(final_sentences):\n",
        "                s_text = s_text.strip()\n",
        "                if not s_text:\n",
        "                    continue\n",
        "                # 確保句子以標點結尾\n",
        "                if not re.search(r'[.!?]$', s_text):\n",
        "                    s_text += \".\"\n",
        "\n",
        "                reconstructed_response += s_text\n",
        "                if i < len(final_sentences) - 1: # 如果不是最後一句，添加空格\n",
        "                    reconstructed_response += \" \"\n",
        "\n",
        "            self.logger.debug(f\"Deduplicated description (len {len(reconstructed_response.strip())}): '{reconstructed_response.strip()[:150]}...'\")\n",
        "            return reconstructed_response.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in deduplicate_sentences_in_description: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return description # 發生錯誤時返回原始描述\n",
        "\n",
        "    def _extract_placeholders(self, template: str) -> List[str]:\n",
        "        \"\"\"提取模板中的佔位符\"\"\"\n",
        "        import re\n",
        "        return re.findall(r'\\{([^}]+)\\}', template)\n",
        "\n",
        "    def _generate_placeholder_content(self, placeholder: str, detected_objects: List[Dict],\n",
        "                                    functional_zones: List, scene_type: str,\n",
        "                                    object_statistics: Dict) -> str:\n",
        "        \"\"\"生成佔位符內容\"\"\"\n",
        "        all_replacements = self._generate_default_replacements()\n",
        "        return self._get_placeholder_replacement(\n",
        "            placeholder, {}, all_replacements, detected_objects, scene_type\n",
        "        )\n",
        "\n",
        "    def _preprocess_functional_zones(self, functional_zones: List) -> Dict:\n",
        "        \"\"\"預處理功能區域數據\"\"\"\n",
        "        if isinstance(functional_zones, list):\n",
        "            # 將列表轉換為字典格式\n",
        "            zones_dict = {}\n",
        "            for i, zone in enumerate(functional_zones):\n",
        "                if isinstance(zone, str):\n",
        "                    zones_dict[f\"area {i+1}\"] = {\"description\": zone}\n",
        "                elif isinstance(zone, dict):\n",
        "                    zones_dict[f\"area {i+1}\"] = zone\n",
        "            return zones_dict\n",
        "        elif isinstance(functional_zones, dict):\n",
        "            return functional_zones\n",
        "        else:\n",
        "            return {}\n",
        "\n",
        "    def _standardize_placeholder_content(self, content: str, placeholder_type: str) -> str:\n",
        "        \"\"\"標準化佔位符內容\"\"\"\n",
        "        if not content:\n",
        "            return \"various elements\"\n",
        "        return content.strip()\n",
        "\n",
        "    def _finalize_description_output(self, description: str) -> str:\n",
        "        \"\"\"最終化描述輸出\"\"\"\n",
        "        if not description:\n",
        "            return \"A scene featuring various elements and organized areas of activity.\"\n",
        "\n",
        "        # 基本清理\n",
        "        import re\n",
        "        finalized = re.sub(r'\\s+', ' ', description).strip()\n",
        "\n",
        "        # 確保適當結尾\n",
        "        if finalized and not finalized.endswith(('.', '!', '?')):\n",
        "            finalized += '.'\n",
        "\n",
        "        # 首字母大寫\n",
        "        if finalized:\n",
        "            finalized = finalized[0].upper() + finalized[1:] if len(finalized) > 1 else finalized.upper()\n",
        "\n",
        "        return finalized\n",
        "\n",
        "    def _sanitize_scene_type_for_description(self, scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        清理場景類型名稱，確保不包含內部標識符格式\n",
        "\n",
        "        Args:\n",
        "            scene_type: 原始場景類型名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的場景類型名稱\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 移除下劃線並轉換為空格分隔的自然語言\n",
        "            cleaned_type = scene_type.replace('_', ' ')\n",
        "\n",
        "            # 確保不直接在描述中使用技術性場景類型名稱\n",
        "            return cleaned_type\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error sanitizing scene type '{scene_type}': {str(e)}\")\n",
        "            return \"general scene\"\n",
        "\n",
        "    def _validate_and_clean_scene_details(self, scene_details: str) -> str:\n",
        "        \"\"\"\n",
        "        驗證並清理場景詳細信息，移除可能的模板填充錯誤\n",
        "\n",
        "        Args:\n",
        "            scene_details: 原始場景詳細信息\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的場景詳細信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not scene_details or not scene_details.strip():\n",
        "                return \"\"\n",
        "\n",
        "            cleaned = scene_details.strip()\n",
        "\n",
        "            # 移除常見的模板填充錯誤模式\n",
        "            import re\n",
        "\n",
        "            # 修復 \"In ,\" 類型的錯誤\n",
        "            cleaned = re.sub(r'\\bIn\\s*,\\s*', 'In this scene, ', cleaned)\n",
        "            cleaned = re.sub(r'\\bAt\\s*,\\s*', 'At this location, ', cleaned)\n",
        "            cleaned = re.sub(r'\\bWithin\\s*,\\s*', 'Within this area, ', cleaned)\n",
        "\n",
        "            # 移除內部標識符格式\n",
        "            cleaned = re.sub(r'\\b\\w+_\\w+(?:_\\w+)*\\b(?!\\s+(area|zone|region))',\n",
        "                            lambda m: m.group(0).replace('_', ' '), cleaned)\n",
        "\n",
        "            # 確保句子完整性\n",
        "            if cleaned and not cleaned.endswith(('.', '!', '?')):\n",
        "                cleaned += '.'\n",
        "\n",
        "            return cleaned\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error validating scene details: {str(e)}\")\n",
        "            return scene_details if scene_details else \"\"\n",
        "\n",
        "    def _generate_landmark_description(self,\n",
        "                                     scene_type: str,\n",
        "                                     detected_objects: List[Dict],\n",
        "                                     confidence: float,\n",
        "                                     lighting_info: Optional[Dict] = None,\n",
        "                                     functional_zones: Optional[Dict] = None,\n",
        "                                     landmark_objects: Optional[List[Dict]] = None) -> str:\n",
        "        \"\"\"\n",
        "        生成包含地標信息的場景描述\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            confidence: 場景分類置信度\n",
        "            lighting_info: 照明條件信息\n",
        "            functional_zones: 功能區域信息\n",
        "            landmark_objects: 識別為地標的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 包含地標信息的自然語言場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 如果沒有提供地標物件，從檢測物件中篩選\n",
        "            if landmark_objects is None:\n",
        "                landmark_objects = [obj for obj in detected_objects if obj.get(\"is_landmark\", False)]\n",
        "\n",
        "            # 如果沒有地標，退回到標準描述\n",
        "            if not landmark_objects:\n",
        "                if scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                    base_description = \"A scenic area that appears to be a tourist destination, though specific landmarks are not clearly identifiable.\"\n",
        "                else:\n",
        "                    return self.text_formatter.format_final_description(self._generate_scene_details(\n",
        "                        scene_type,\n",
        "                        detected_objects,\n",
        "                        lighting_info,\n",
        "                        self.viewpoint_detector.detect_viewpoint(detected_objects)\n",
        "                    ))\n",
        "            else:\n",
        "                # 獲取主要地標\n",
        "                primary_landmark = max(landmark_objects, key=lambda x: x.get(\"confidence\", 0))\n",
        "                landmark_name = primary_landmark.get(\"class_name\", \"landmark\")\n",
        "                # 先取原生 location\n",
        "                landmark_location = primary_landmark.get(\"location\", \"\")\n",
        "                # 如果 location 為空，就從全域 ALL_LANDMARKS 補上\n",
        "                lm_id = primary_landmark.get(\"landmark_id\")\n",
        "                if not landmark_location and lm_id and lm_id in ALL_LANDMARKS:\n",
        "                    landmark_location = ALL_LANDMARKS[lm_id].get(\"location\", \"\")\n",
        "\n",
        "                # 根據地標類型選擇適當的描述模板，並插入 location\n",
        "                if scene_type == \"natural_landmark\" or primary_landmark.get(\"landmark_type\") == \"natural\":\n",
        "                    base_description = f\"A natural landmark scene featuring {landmark_name} in {landmark_location}.\"\n",
        "                elif scene_type == \"historical_monument\" or primary_landmark.get(\"landmark_type\") == \"monument\":\n",
        "                    base_description = f\"A historical monument scene showcasing {landmark_name}, a significant landmark in {landmark_location}.\"\n",
        "                else:\n",
        "                    base_description = f\"A tourist landmark scene centered around {landmark_name}, an iconic structure in {landmark_location}.\"\n",
        "\n",
        "            # 添加地標的額外信息\n",
        "            landmark_details = []\n",
        "            for landmark in landmark_objects:\n",
        "                details = []\n",
        "\n",
        "                if \"year_built\" in landmark:\n",
        "                    details.append(f\"built in {landmark['year_built']}\")\n",
        "\n",
        "                if \"architectural_style\" in landmark:\n",
        "                    details.append(f\"featuring {landmark['architectural_style']} architectural style\")\n",
        "\n",
        "                if \"significance\" in landmark:\n",
        "                    details.append(landmark[\"significance\"])\n",
        "\n",
        "                # 補 location（如果該物件沒有 location，就再從 ALL_LANDMARKS 撈一次）\n",
        "                loc = landmark.get(\"location\", \"\")\n",
        "                lm_id_iter = landmark.get(\"landmark_id\")\n",
        "                if not loc and lm_id_iter and lm_id_iter in ALL_LANDMARKS:\n",
        "                    loc = ALL_LANDMARKS[lm_id_iter].get(\"location\", \"\")\n",
        "                if loc:\n",
        "                    details.append(f\"located in {loc}\")\n",
        "\n",
        "                if details:\n",
        "                    landmark_details.append(f\"{landmark['class_name']} ({', '.join(details)})\")\n",
        "\n",
        "            # 將詳細信息添加到基本描述中\n",
        "            if landmark_details:\n",
        "                description = base_description + \" The scene features \" + \", \".join(landmark_details) + \".\"\n",
        "            else:\n",
        "                description = base_description\n",
        "\n",
        "            # 獲取視角\n",
        "            viewpoint = self.viewpoint_detector.detect_viewpoint(detected_objects)\n",
        "\n",
        "            # 生成人員活動描述\n",
        "            people_count = len([obj for obj in detected_objects if obj[\"class_id\"] == 0])\n",
        "\n",
        "            if people_count > 0:\n",
        "                if people_count == 1:\n",
        "                    people_description = \"There is one person in the scene, likely a tourist or visitor.\"\n",
        "                elif people_count < 5:\n",
        "                    people_description = f\"There are {people_count} people in the scene, possibly tourists visiting the landmark.\"\n",
        "                else:\n",
        "                    people_description = f\"The scene includes a group of {people_count} people, indicating this is a popular tourist destination.\"\n",
        "\n",
        "                description = self.text_formatter.smart_append(description, people_description)\n",
        "\n",
        "            # 添加照明信息\n",
        "            if lighting_info and \"time_of_day\" in lighting_info:\n",
        "                lighting_type = lighting_info[\"time_of_day\"]\n",
        "                lighting_description = self.template_manager.get_lighting_template(lighting_type)\n",
        "                description = self.text_formatter.smart_append(description, lighting_description)\n",
        "\n",
        "            # 添加視角描述\n",
        "            if viewpoint != \"eye_level\":\n",
        "                viewpoint_template = self.template_manager.get_viewpoint_template(viewpoint)\n",
        "\n",
        "                prefix = viewpoint_template.get('prefix', '')\n",
        "                if prefix and not description.startswith(prefix):\n",
        "                    if description and description[0].isupper():\n",
        "                        description = prefix + description[0].lower() + description[1:]\n",
        "                    else:\n",
        "                        description = prefix + description\n",
        "\n",
        "                viewpoint_desc = viewpoint_template.get(\"observation\", \"\").format(\n",
        "                    scene_elements=\"the landmark and surrounding area\"\n",
        "                )\n",
        "\n",
        "                if viewpoint_desc and viewpoint_desc not in description:\n",
        "                    description = self.text_formatter.smart_append(description, viewpoint_desc)\n",
        "\n",
        "            # 添加功能區域描述\n",
        "            if functional_zones and len(functional_zones) > 0:\n",
        "                zones_desc = self.object_description_generator.describe_functional_zones(functional_zones)\n",
        "                if zones_desc:\n",
        "                    description = self.text_formatter.smart_append(description, zones_desc)\n",
        "\n",
        "            # 描述可能的活動\n",
        "            landmark_activities = []\n",
        "\n",
        "            if scene_type == \"natural_landmark\" or any(obj.get(\"landmark_type\") == \"natural\" for obj in landmark_objects):\n",
        "                landmark_activities = [\n",
        "                    \"nature photography\",\n",
        "                    \"scenic viewing\",\n",
        "                    \"hiking or walking\",\n",
        "                    \"guided nature tours\",\n",
        "                    \"outdoor appreciation\"\n",
        "                ]\n",
        "            elif scene_type == \"historical_monument\" or any(obj.get(\"landmark_type\") == \"monument\" for obj in landmark_objects):\n",
        "                landmark_activities = [\n",
        "                    \"historical sightseeing\",\n",
        "                    \"educational tours\",\n",
        "                    \"cultural appreciation\",\n",
        "                    \"photography of historical architecture\",\n",
        "                    \"learning about historical significance\"\n",
        "                ]\n",
        "            else:\n",
        "                landmark_activities = [\n",
        "                    \"sightseeing\",\n",
        "                    \"taking photographs\",\n",
        "                    \"guided tours\",\n",
        "                    \"cultural tourism\",\n",
        "                    \"souvenir shopping\"\n",
        "                ]\n",
        "\n",
        "            # 添加活動描述\n",
        "            if landmark_activities:\n",
        "                activities_text = \"Common activities at this location include \" + \", \".join(landmark_activities[:3]) + \".\"\n",
        "                description = self.text_formatter.smart_append(description, activities_text)\n",
        "\n",
        "            return self.text_formatter.format_final_description(description)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating landmark description: {str(e)}\")\n",
        "            # 備用處理\n",
        "            return self.text_formatter.format_final_description(\n",
        "                \"A landmark scene with notable architectural or natural features.\"\n",
        "            )\n",
        "\n",
        "\n",
        "    def _is_intersection(self, detected_objects: List[Dict]) -> bool:\n",
        "        \"\"\"\n",
        "        通過分析物件分布來判斷場景是否為十字路口\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否為十字路口\n",
        "        \"\"\"\n",
        "        try:\n",
        "            pedestrians = [obj for obj in detected_objects if obj.get(\"class_id\") == 0]\n",
        "\n",
        "            if len(pedestrians) >= 8:\n",
        "                positions = [obj.get(\"normalized_center\", (0, 0)) for obj in pedestrians]\n",
        "\n",
        "                x_coords = [pos[0] for pos in positions]\n",
        "                y_coords = [pos[1] for pos in positions]\n",
        "\n",
        "                x_variance = np.var(x_coords) if len(x_coords) > 1 else 0\n",
        "                y_variance = np.var(y_coords) if len(y_coords) > 1 else 0\n",
        "\n",
        "                x_range = max(x_coords) - min(x_coords)\n",
        "                y_range = max(y_coords) - min(y_coords)\n",
        "\n",
        "                if x_range > 0.5 and y_range > 0.5 and 0.7 < (x_range / y_range) < 1.3:\n",
        "                    return True\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting intersection: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _generate_generic_description(self, detected_objects: List[Dict], lighting_info: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        當場景類型未知或置信度極低時生成通用描述\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            lighting_info: 可選的照明條件信息\n",
        "\n",
        "        Returns:\n",
        "            str: 基於檢測物件的通用描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            obj_counts = {}\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown object\")\n",
        "                if class_name not in obj_counts:\n",
        "                    obj_counts[class_name] = 0\n",
        "                obj_counts[class_name] += 1\n",
        "\n",
        "            top_objects = sorted(obj_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "            if not top_objects:\n",
        "                base_desc = \"This scene displays various elements, though specific objects are not clearly identifiable.\"\n",
        "            else:\n",
        "                objects_text = []\n",
        "                for name, count in top_objects:\n",
        "                    # 確保物件名稱不包含技術性格式\n",
        "                    clean_name = name.replace('_', ' ') if isinstance(name, str) else str(name)\n",
        "                    if count > 1:\n",
        "                        objects_text.append(f\"{count} {clean_name}s\")\n",
        "                    else:\n",
        "                        objects_text.append(f\"a {clean_name}\" if clean_name[0].lower() not in 'aeiou' else f\"an {clean_name}\")\n",
        "\n",
        "                if len(objects_text) == 1:\n",
        "                    objects_list = objects_text[0]\n",
        "                elif len(objects_text) == 2:\n",
        "                    objects_list = f\"{objects_text[0]} and {objects_text[1]}\"\n",
        "                else:\n",
        "                    objects_list = \", \".join(objects_text[:-1]) + f\", and {objects_text[-1]}\"\n",
        "\n",
        "                base_desc = f\"This scene features {objects_list}.\"\n",
        "\n",
        "            # 添加照明信息\n",
        "            if lighting_info and \"time_of_day\" in lighting_info:\n",
        "                lighting_type = lighting_info[\"time_of_day\"]\n",
        "                lighting_desc = self.template_manager.get_lighting_template(lighting_type)\n",
        "                base_desc += f\" {lighting_desc}\"\n",
        "\n",
        "            return base_desc\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating generic description: {str(e)}\")\n",
        "            return \"A general scene is visible with various elements.\"\n",
        "\n",
        "    def _generate_scene_details(self,\n",
        "                              scene_type: str,\n",
        "                              detected_objects: List[Dict],\n",
        "                              lighting_info: Optional[Dict] = None,\n",
        "                              viewpoint: str = \"eye_level\",\n",
        "                              spatial_analysis: Optional[Dict] = None,\n",
        "                              image_dimensions: Optional[Tuple[int, int]] = None,\n",
        "                              places365_info: Optional[Dict] = None,\n",
        "                              object_statistics: Optional[Dict] = None) -> str:\n",
        "        \"\"\"\n",
        "        基於場景類型和檢測物件生成詳細描述\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            lighting_info: 可選的照明條件信息\n",
        "            viewpoint: 檢測到的視角\n",
        "            spatial_analysis: 可選的空間分析結果\n",
        "            image_dimensions: 可選的圖像尺寸\n",
        "            places365_info: 可選的 Places365 場景分類結果\n",
        "            object_statistics: 可選的詳細物件統計信息\n",
        "\n",
        "        Returns:\n",
        "            str: 詳細場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            scene_details = \"\"\n",
        "\n",
        "            # 日常場景類型列表\n",
        "            everyday_scene_types = [\n",
        "                \"general_indoor_space\", \"generic_street_view\",\n",
        "                \"desk_area_workspace\", \"outdoor_gathering_spot\",\n",
        "                \"kitchen_counter_or_utility_area\", \"unknown\"\n",
        "            ]\n",
        "\n",
        "            # 預處理場景類型以避免內部格式洩漏\n",
        "            processed_scene_type = self._sanitize_scene_type_for_description(scene_type)\n",
        "\n",
        "            # 確定場景描述方法\n",
        "            is_confident_specific_scene = scene_type not in everyday_scene_types and scene_type in self.template_manager.get_scene_detail_templates(scene_type)\n",
        "            treat_as_everyday = scene_type in everyday_scene_types\n",
        "\n",
        "            if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "                if scene_type not in [\"kitchen\", \"bedroom\", \"living_room\", \"office_workspace\", \"dining_area\", \"professional_kitchen\"]:\n",
        "                    treat_as_everyday = True\n",
        "\n",
        "            if treat_as_everyday or not is_confident_specific_scene:\n",
        "                self.logger.debug(f\"Generating dynamic description for scene_type: {scene_type}\")\n",
        "                scene_details = self.object_description_generator.generate_dynamic_everyday_description(\n",
        "                    detected_objects,\n",
        "                    lighting_info,\n",
        "                    viewpoint,\n",
        "                    spatial_analysis,\n",
        "                    image_dimensions,\n",
        "                    places365_info,\n",
        "                    object_statistics\n",
        "                )\n",
        "            else:\n",
        "                self.logger.debug(f\"Using template for scene_type: {scene_type}\")\n",
        "                templates_list = self.template_manager.get_scene_detail_templates(scene_type, viewpoint)\n",
        "\n",
        "                if templates_list:\n",
        "                    detail_template = random.choice(templates_list)\n",
        "                    scene_details = self.template_manager.fill_template(\n",
        "                        detail_template,\n",
        "                        detected_objects,\n",
        "                        scene_type,\n",
        "                        places365_info,\n",
        "                        object_statistics\n",
        "                    )\n",
        "                else:\n",
        "                    scene_details = self.object_description_generator.generate_dynamic_everyday_description(\n",
        "                        detected_objects, lighting_info, viewpoint, spatial_analysis,\n",
        "                        image_dimensions, places365_info, object_statistics\n",
        "                    )\n",
        "\n",
        "            # 如果禁用地標檢測，過濾地標引用\n",
        "            if hasattr(self, 'enable_landmark') and not self.enable_landmark:\n",
        "                scene_details = self.text_formatter.filter_landmark_references(scene_details, enable_landmark=False)\n",
        "\n",
        "            return scene_details if scene_details else \"A scene with some visual elements.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error generating scene details: {str(e)}\")\n",
        "            return \"A scene with various elements.\"\n",
        "\n",
        "    def filter_landmark_references(self, text, enable_landmark=True):\n",
        "        \"\"\"\n",
        "        動態過濾文本中的地標引用\n",
        "\n",
        "        Args:\n",
        "            text: 需要過濾的文本\n",
        "            enable_landmark: 是否啟用地標功能\n",
        "\n",
        "        Returns:\n",
        "            str: 過濾後的文本\n",
        "        \"\"\"\n",
        "        return self.text_formatter.filter_landmark_references(text, enable_landmark)\n",
        "\n",
        "    def get_prominent_objects(self, detected_objects: List[Dict],\n",
        "                          min_prominence_score: float = 0.5,\n",
        "                          max_categories_to_return: Optional[int] = None,\n",
        "                          max_total_objects: Optional[int] = None) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        獲取最重要的物件\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            min_prominence_score: 最小重要性分數閾值，預設為0.5\n",
        "            max_categories_to_return: 可選的最大返回類別數量限制\n",
        "            max_total_objects: 可選的最大返回物件總數限制\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: 重要物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 傳遞所有參數\n",
        "            prominent_objects = self.object_description_generator.get_prominent_objects(\n",
        "                detected_objects,\n",
        "                min_prominence_score,\n",
        "                max_categories_to_return\n",
        "            )\n",
        "\n",
        "            # 如果指定了最大物件總數限制，進行額外過濾\n",
        "            if max_total_objects is not None and max_total_objects > 0:\n",
        "                # 限制總物件數量，保持重要性排序\n",
        "                prominent_objects = prominent_objects[:max_total_objects]\n",
        "\n",
        "            # 如果指定了最大類別數量限制，則進行額外過濾\n",
        "            if max_categories_to_return is not None and max_categories_to_return > 0:\n",
        "                # 按類別分組物件\n",
        "                categories_seen = set()\n",
        "                filtered_objects = []\n",
        "\n",
        "                for obj in prominent_objects:\n",
        "                    class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                    if class_name not in categories_seen:\n",
        "                        categories_seen.add(class_name)\n",
        "                        filtered_objects.append(obj)\n",
        "\n",
        "                        # 如果已達到最大類別數量，停止添加新類別\n",
        "                        if len(categories_seen) >= max_categories_to_return:\n",
        "                            break\n",
        "                    elif class_name in categories_seen:\n",
        "                        # 如果是已見過的類別，仍然添加該物件\n",
        "                        filtered_objects.append(obj)\n",
        "\n",
        "                return filtered_objects\n",
        "\n",
        "            return prominent_objects\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting prominent objects: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def detect_viewpoint(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        檢測圖像視角類型\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的視角類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.viewpoint_detector.detect_viewpoint(detected_objects)\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error detecting viewpoint: {str(e)}\")\n",
        "            return \"eye_level\"\n",
        "\n",
        "    def detect_cultural_context(self, scene_type: str, detected_objects: List[Dict]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        檢測場景的文化語境\n",
        "\n",
        "        Args:\n",
        "            scene_type: 識別的場景類型\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: 檢測到的文化語境或None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.cultural_context_analyzer.detect_cultural_context(scene_type, detected_objects)\n",
        "        except CulturalContextError as e:\n",
        "            self.logger.warning(f\"Error detecting cultural context: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_cultural_elements(self, cultural_context: str) -> str:\n",
        "        \"\"\"\n",
        "        為檢測到的文化語境生成描述元素\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 檢測到的文化語境\n",
        "\n",
        "        Returns:\n",
        "            str: 文化元素描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.cultural_context_analyzer.generate_cultural_elements(cultural_context)\n",
        "        except CulturalContextError as e:\n",
        "            self.logger.warning(f\"Error generating cultural elements: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def format_object_list_for_description(self, objects: List[Dict],\n",
        "                                         use_indefinite_article_for_one: bool = False,\n",
        "                                         count_threshold_for_generalization: int = -1,\n",
        "                                         max_types_to_list: int = 5) -> str:\n",
        "        \"\"\"\n",
        "        將物件列表格式化為人類可讀的字符串\n",
        "\n",
        "        Args:\n",
        "            objects: 物件字典列表\n",
        "            use_indefinite_article_for_one: 單個物件是否使用 \"a/an\"\n",
        "            count_threshold_for_generalization: 計數閾值\n",
        "            max_types_to_list: 最大物件類型數量\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化的物件描述字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_description_generator.format_object_list_for_description(\n",
        "                objects, use_indefinite_article_for_one, count_threshold_for_generalization, max_types_to_list\n",
        "            )\n",
        "        except ObjectDescriptionError as e:\n",
        "            self.logger.warning(f\"Error formatting object list: {str(e)}\")\n",
        "            return \"various objects\"\n",
        "\n",
        "    def get_spatial_description(self, obj: Dict, image_width: Optional[int] = None,\n",
        "                              image_height: Optional[int] = None) -> str:\n",
        "        \"\"\"\n",
        "        為物件生成空間位置描述\n",
        "\n",
        "        Args:\n",
        "            obj: 物件字典\n",
        "            image_width: 可選的圖像寬度\n",
        "            image_height: 可選的圖像高度\n",
        "\n",
        "        Returns:\n",
        "            str: 空間描述字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_description_generator.get_spatial_description(obj, image_width, image_height)\n",
        "        except ObjectDescriptionError as e:\n",
        "            self.logger.warning(f\"Error generating spatial description: {str(e)}\")\n",
        "            return \"in the scene\"\n",
        "\n",
        "    def optimize_object_description(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        優化物件描述，避免重複列舉相同物件\n",
        "\n",
        "        Args:\n",
        "            description: 原始描述文本\n",
        "\n",
        "        Returns:\n",
        "            str: 優化後的描述文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_description_generator.optimize_object_description(description)\n",
        "        except ObjectDescriptionError as e:\n",
        "            self.logger.warning(f\"Error optimizing object description: {str(e)}\")\n",
        "            return description\n",
        "\n",
        "    def describe_functional_zones(self, functional_zones: Dict) -> str:\n",
        "        \"\"\"\n",
        "        生成場景功能區域的描述\n",
        "\n",
        "        Args:\n",
        "            functional_zones: 識別出的功能區域字典\n",
        "\n",
        "        Returns:\n",
        "            str: 功能區域描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.object_description_generator.describe_functional_zones(functional_zones)\n",
        "        except ObjectDescriptionError as e:\n",
        "            self.logger.warning(f\"Error describing functional zones: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def smart_append(self, current_text: str, new_fragment: str) -> str:\n",
        "        \"\"\"\n",
        "        智能地將新文本片段附加到現有文本\n",
        "\n",
        "        Args:\n",
        "            current_text: 要附加到的現有文本\n",
        "            new_fragment: 要附加的新文本片段\n",
        "\n",
        "        Returns:\n",
        "            str: 合併後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.text_formatter.smart_append(current_text, new_fragment)\n",
        "        except TextFormattingError as e:\n",
        "            self.logger.warning(f\"Error in smart append: {str(e)}\")\n",
        "            return f\"{current_text} {new_fragment}\" if current_text else new_fragment\n",
        "\n",
        "    def format_final_description(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        格式化最終描述文本\n",
        "\n",
        "        Args:\n",
        "            text: 要格式化的文本\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.text_formatter.format_final_description(text)\n",
        "        except TextFormattingError as e:\n",
        "            self.logger.warning(f\"Error formatting final description: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def get_template(self, category: str, key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        獲取指定類別的模板\n",
        "\n",
        "        Args:\n",
        "            category: 模板類別名稱\n",
        "            key: 可選的具體模板鍵值\n",
        "\n",
        "        Returns:\n",
        "            模板內容\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.template_manager.get_template(category, key)\n",
        "        except (TemplateLoadingError, TemplateFillError) as e:\n",
        "            self.logger.warning(f\"Error getting template: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_viewpoint_confidence(self, detected_objects: List[Dict]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        獲取視角檢測結果及其信心度\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, float]: (視角類型, 信心度)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.viewpoint_detector.get_viewpoint_confidence(detected_objects)\n",
        "        except ViewpointDetectionError as e:\n",
        "            self.logger.warning(f\"Error getting viewpoint confidence: {str(e)}\")\n",
        "            return \"eye_level\", 0.5\n",
        "\n",
        "    def get_supported_cultures(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取所有支援的文化語境列表\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 支援的文化語境名稱列表\n",
        "        \"\"\"\n",
        "        return self.cultural_context_analyzer.get_supported_cultures()\n",
        "\n",
        "    def has_cultural_context(self, cultural_context: str) -> bool:\n",
        "        \"\"\"\n",
        "        檢查是否支援指定的文化語境\n",
        "\n",
        "        Args:\n",
        "            cultural_context: 文化語境名稱\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否支援該文化語境\n",
        "        \"\"\"\n",
        "        return self.cultural_context_analyzer.has_cultural_context(cultural_context)\n",
        "\n",
        "    def validate_text_quality(self, text: str) -> Dict[str, bool]:\n",
        "        \"\"\"\n",
        "        驗證文本質量\n",
        "\n",
        "        Args:\n",
        "            text: 要驗證的文本\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, bool]: 質量檢查結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.text_formatter.validate_text_quality(text)\n",
        "        except TextFormattingError as e:\n",
        "            self.logger.warning(f\"Error validating text quality: {str(e)}\")\n",
        "            return {\"error\": True}\n",
        "\n",
        "    def get_text_statistics(self, text: str) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        獲取文本統計信息\n",
        "\n",
        "        Args:\n",
        "            text: 要分析的文本\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: 文本統計信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.text_formatter.get_text_statistics(text)\n",
        "        except TextFormattingError as e:\n",
        "            self.logger.warning(f\"Error getting text statistics: {str(e)}\")\n",
        "            return {\"characters\": 0, \"words\": 0, \"sentences\": 0}\n",
        "\n",
        "    def reload_templates(self):\n",
        "        \"\"\"\n",
        "        重新載入所有模板\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.template_manager.reload_templates()\n",
        "            self.logger.info(\"Templates reloaded successfully\")\n",
        "        except (TemplateLoadingError, TemplateFillError) as e:\n",
        "            self.logger.error(f\"Error reloading templates: {str(e)}\")\n",
        "            raise EnhancedSceneDescriberError(f\"Failed to reload templates: {str(e)}\") from e\n",
        "\n",
        "    def get_configuration(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取當前配置信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 配置信息字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                \"scene_types_count\": len(self.scene_types),\n",
        "                \"viewpoint_detector_config\": self.viewpoint_detector.viewpoint_params,\n",
        "                \"object_generator_config\": self.object_description_generator.get_configuration(),\n",
        "                \"supported_cultures\": self.cultural_context_analyzer.get_supported_cultures(),\n",
        "                \"template_categories\": self.template_manager.get_template_categories()\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error getting configuration: {str(e)}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def _initialize_fallback_components(self):\n",
        "        \"\"\"備用組件初始化\"\"\"\n",
        "        try:\n",
        "            self.region_analyzer = RegionAnalyzer()\n",
        "            self.object_description_generator = ObjectDescriptionGenerator(\n",
        "                region_analyzer=self.region_analyzer\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Fallback component initialization failed: {str(e)}\")"
      ],
      "metadata": {
        "id": "rvd-M_BptoUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b16947a-77c2-403a-d73c-7aed80bd23d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing enhanced_scene_describer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile configuration_manager.py\n",
        "from typing import Dict, Any, List, Tuple, Optional, Union\n",
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FeatureThresholds:\n",
        "    \"\"\"Configuration class for feature extraction thresholds.\"\"\"\n",
        "    dark_pixel_threshold: float = 50.0\n",
        "    bright_pixel_threshold: float = 220.0\n",
        "    sky_blue_hue_min: float = 95.0\n",
        "    sky_blue_hue_max: float = 135.0\n",
        "    sky_blue_sat_min: float = 40.0\n",
        "    sky_blue_val_min: float = 90.0\n",
        "    gray_sat_max: float = 70.0\n",
        "    gray_val_min: float = 60.0\n",
        "    gray_val_max: float = 220.0\n",
        "    light_source_abs_thresh: float = 220.0\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class IndoorOutdoorThresholds:\n",
        "    \"\"\"Configuration class for indoor/outdoor classification thresholds.\"\"\"\n",
        "    sky_blue_dominance_thresh: float = 0.18\n",
        "    sky_brightness_ratio_thresh: float = 1.25\n",
        "    openness_top_thresh: float = 0.68\n",
        "    sky_texture_complexity_thresh: float = 0.35\n",
        "    ceiling_likelihood_thresh: float = 0.4\n",
        "    boundary_clarity_thresh: float = 0.38\n",
        "    brightness_uniformity_thresh_indoor: float = 0.6\n",
        "    brightness_uniformity_thresh_outdoor: float = 0.40\n",
        "    many_bright_spots_thresh: int = 6\n",
        "    dim_scene_for_spots_thresh: float = 115.0\n",
        "    home_pattern_thresh_strong: float = 2.0\n",
        "    home_pattern_thresh_moderate: float = 1.0\n",
        "    warm_indoor_max_brightness_thresh: float = 135.0\n",
        "    aerial_top_dark_ratio_thresh: float = 0.9\n",
        "    aerial_top_complex_thresh: float = 0.60\n",
        "    aerial_min_avg_brightness_thresh: float = 65.0\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LightingThresholds:\n",
        "    \"\"\"Configuration class for lighting condition analysis thresholds.\"\"\"\n",
        "    outdoor_night_thresh_brightness: float = 80.0\n",
        "    outdoor_night_lights_thresh: int = 2\n",
        "    outdoor_dusk_dawn_thresh_brightness: float = 130.0\n",
        "    outdoor_dusk_dawn_color_thresh: float = 0.10\n",
        "    outdoor_day_bright_thresh: float = 140.0\n",
        "    outdoor_day_blue_thresh: float = 0.05\n",
        "    outdoor_day_cloudy_thresh: float = 120.0\n",
        "    outdoor_day_gray_thresh: float = 0.18\n",
        "    indoor_bright_thresh: float = 130.0\n",
        "    indoor_moderate_thresh: float = 95.0\n",
        "    commercial_min_brightness_thresh: float = 105.0\n",
        "    commercial_min_spots_thresh: int = 3\n",
        "    stadium_min_spots_thresh: int = 6\n",
        "    neon_yellow_orange_thresh: float = 0.12\n",
        "    neon_bright_spots_thresh: int = 4\n",
        "    neon_avg_saturation_thresh: float = 60.0\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WeightingFactors:\n",
        "    \"\"\"Configuration class for feature weighting factors.\"\"\"\n",
        "    # Sky/Openness weights (negative values push towards outdoor)\n",
        "    sky_blue_dominance_w: float = 3.5\n",
        "    sky_brightness_ratio_w: float = 3.0\n",
        "    openness_top_w: float = 2.8\n",
        "    sky_texture_w: float = 2.0\n",
        "\n",
        "    # Ceiling/Enclosure weights (positive values push towards indoor)\n",
        "    ceiling_likelihood_w: float = 1.5\n",
        "    boundary_clarity_w: float = 1.2\n",
        "\n",
        "    # Brightness weights\n",
        "    brightness_uniformity_w: float = 0.6\n",
        "    brightness_non_uniformity_outdoor_w: float = 1.0\n",
        "    brightness_non_uniformity_indoor_penalty_w: float = 0.1\n",
        "\n",
        "    # Light source weights\n",
        "    circular_lights_w: float = 1.2\n",
        "    indoor_light_score_w: float = 0.8\n",
        "    many_bright_spots_indoor_w: float = 0.3\n",
        "\n",
        "    # Color atmosphere weights\n",
        "    warm_atmosphere_indoor_w: float = 0.15\n",
        "\n",
        "    # Environment pattern weights\n",
        "    home_env_strong_w: float = 1.5\n",
        "    home_env_moderate_w: float = 0.7\n",
        "\n",
        "    # Structural pattern weights\n",
        "    aerial_street_w: float = 2.5\n",
        "    places365_outdoor_scene_w: float = 4.0\n",
        "    places365_indoor_scene_w: float = 3.0\n",
        "    places365_attribute_w: float = 1.5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OverrideFactors:\n",
        "    \"\"\"Configuration class for override and reduction factors.\"\"\"\n",
        "    sky_override_factor_ceiling: float = 0.1\n",
        "    sky_override_factor_boundary: float = 0.2\n",
        "    sky_override_factor_uniformity: float = 0.15\n",
        "    sky_override_factor_lights: float = 0.05\n",
        "    sky_override_factor_p365_indoor_decision: float = 0.3\n",
        "    aerial_enclosure_reduction_factor: float = 0.75\n",
        "    ceiling_sky_override_factor: float = 0.1\n",
        "    p365_outdoor_reduces_enclosure_factor: float = 0.3\n",
        "    p365_indoor_boosts_ceiling_factor: float = 1.5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ColorRanges:\n",
        "    \"\"\"Configuration class for color range definitions.\"\"\"\n",
        "    warm_hue_ranges: List[Tuple[float, float]] = field(\n",
        "        default_factory=lambda: [(0, 50), (330, 360)]\n",
        "    )\n",
        "    cool_hue_ranges: List[Tuple[float, float]] = field(\n",
        "        default_factory=lambda: [(90, 270)]\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AlgorithmParameters:\n",
        "    \"\"\"Configuration class for algorithm-specific parameters.\"\"\"\n",
        "    indoor_score_sigmoid_scale: float = 0.3\n",
        "    indoor_decision_threshold: float = 0.5\n",
        "    places365_high_confidence_thresh: float = 0.75\n",
        "    places365_moderate_confidence_thresh: float = 0.5\n",
        "    places365_attribute_confidence_thresh: float = 0.6\n",
        "    include_diagnostics: bool = True\n",
        "\n",
        "\n",
        "class ConfigurationManager:\n",
        "    \"\"\"\n",
        "    這主要是管理光線分析的參數，會有很多不同情況, 做parameters配置\n",
        "\n",
        "    This class provides type-safe access to all configuration parameters,\n",
        "    supports loading from external files, and includes validation mechanisms.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_path: Optional[Union[str, Path]] = None):\n",
        "        \"\"\"\n",
        "        Initialize the configuration manager.\n",
        "\n",
        "        Args:\n",
        "            config_path: Optional path to external configuration file.\n",
        "                        If None, uses default configuration.\n",
        "        \"\"\"\n",
        "        self._feature_thresholds = FeatureThresholds()\n",
        "        self._indoor_outdoor_thresholds = IndoorOutdoorThresholds()\n",
        "        self._lighting_thresholds = LightingThresholds()\n",
        "        self._weighting_factors = WeightingFactors()\n",
        "        self._override_factors = OverrideFactors()\n",
        "        self._color_ranges = ColorRanges()\n",
        "        self._algorithm_parameters = AlgorithmParameters()\n",
        "\n",
        "        if config_path is not None:\n",
        "            self.load_from_file(config_path)\n",
        "\n",
        "    @property\n",
        "    def feature_thresholds(self) -> FeatureThresholds:\n",
        "        \"\"\"Get feature extraction thresholds.\"\"\"\n",
        "        return self._feature_thresholds\n",
        "\n",
        "    @property\n",
        "    def indoor_outdoor_thresholds(self) -> IndoorOutdoorThresholds:\n",
        "        \"\"\"Get indoor/outdoor classification thresholds.\"\"\"\n",
        "        return self._indoor_outdoor_thresholds\n",
        "\n",
        "    @property\n",
        "    def lighting_thresholds(self) -> LightingThresholds:\n",
        "        \"\"\"Get lighting condition analysis thresholds.\"\"\"\n",
        "        return self._lighting_thresholds\n",
        "\n",
        "    @property\n",
        "    def weighting_factors(self) -> WeightingFactors:\n",
        "        \"\"\"Get feature weighting factors.\"\"\"\n",
        "        return self._weighting_factors\n",
        "\n",
        "    @property\n",
        "    def override_factors(self) -> OverrideFactors:\n",
        "        \"\"\"Get override and reduction factors.\"\"\"\n",
        "        return self._override_factors\n",
        "\n",
        "    @property\n",
        "    def color_ranges(self) -> ColorRanges:\n",
        "        \"\"\"Get color range definitions.\"\"\"\n",
        "        return self._color_ranges\n",
        "\n",
        "    @property\n",
        "    def algorithm_parameters(self) -> AlgorithmParameters:\n",
        "        \"\"\"Get algorithm-specific parameters.\"\"\"\n",
        "        return self._algorithm_parameters\n",
        "\n",
        "    def get_legacy_config_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate legacy configuration dictionary for backward compatibility.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all configuration parameters in the original format.\n",
        "        \"\"\"\n",
        "        config_dict = {}\n",
        "\n",
        "        # Feature thresholds\n",
        "        for field_name, field_value in self._feature_thresholds.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Indoor/outdoor thresholds\n",
        "        for field_name, field_value in self._indoor_outdoor_thresholds.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Lighting thresholds\n",
        "        for field_name, field_value in self._lighting_thresholds.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Override factors\n",
        "        for field_name, field_value in self._override_factors.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Color ranges\n",
        "        for field_name, field_value in self._color_ranges.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Algorithm parameters\n",
        "        for field_name, field_value in self._algorithm_parameters.__dict__.items():\n",
        "            config_dict[field_name] = field_value\n",
        "\n",
        "        # Weighting factors - stored under 'indoor_outdoor_weights' key\n",
        "        config_dict[\"indoor_outdoor_weights\"] = self._weighting_factors.__dict__.copy()\n",
        "\n",
        "        return config_dict\n",
        "\n",
        "    def load_from_file(self, config_path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Load configuration from external JSON file.\n",
        "\n",
        "        Args:\n",
        "            config_path: Path to the configuration file.\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If the configuration file doesn't exist.\n",
        "            ValueError: If the configuration file contains invalid data.\n",
        "        \"\"\"\n",
        "        config_path = Path(config_path)\n",
        "\n",
        "        if not config_path.exists():\n",
        "            raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n",
        "\n",
        "        try:\n",
        "            with open(config_path, 'r', encoding='utf-8') as file:\n",
        "                config_data = json.load(file)\n",
        "\n",
        "            self._update_from_dict(config_data)\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise ValueError(f\"Invalid JSON in configuration file: {e}\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading configuration: {e}\")\n",
        "\n",
        "    def save_to_file(self, config_path: Union[str, Path]) -> None:\n",
        "        \"\"\"\n",
        "        Save current configuration to JSON file.\n",
        "\n",
        "        Args:\n",
        "            config_path: Path where to save the configuration file.\n",
        "        \"\"\"\n",
        "        config_path = Path(config_path)\n",
        "        config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        config_dict = self.get_legacy_config_dict()\n",
        "\n",
        "        with open(config_path, 'w', encoding='utf-8') as file:\n",
        "            json.dump(config_dict, file, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def _update_from_dict(self, config_data: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Update configuration from dictionary data.\n",
        "\n",
        "        Args:\n",
        "            config_data: Dictionary containing configuration parameters.\n",
        "        \"\"\"\n",
        "        # Update feature thresholds\n",
        "        self._update_dataclass_from_dict(self._feature_thresholds, config_data)\n",
        "\n",
        "        # Update indoor/outdoor thresholds\n",
        "        self._update_dataclass_from_dict(self._indoor_outdoor_thresholds, config_data)\n",
        "\n",
        "        # Update lighting thresholds\n",
        "        self._update_dataclass_from_dict(self._lighting_thresholds, config_data)\n",
        "\n",
        "        # Update override factors\n",
        "        self._update_dataclass_from_dict(self._override_factors, config_data)\n",
        "\n",
        "        # Update color ranges\n",
        "        self._update_dataclass_from_dict(self._color_ranges, config_data)\n",
        "\n",
        "        # Update algorithm parameters\n",
        "        self._update_dataclass_from_dict(self._algorithm_parameters, config_data)\n",
        "\n",
        "        # Update weighting factors from nested dictionary\n",
        "        if \"indoor_outdoor_weights\" in config_data:\n",
        "            self._update_dataclass_from_dict(\n",
        "                self._weighting_factors,\n",
        "                config_data[\"indoor_outdoor_weights\"]\n",
        "            )\n",
        "\n",
        "    def _update_dataclass_from_dict(self, dataclass_instance: object, data_dict: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Update dataclass instance fields from dictionary.\n",
        "\n",
        "        Args:\n",
        "            dataclass_instance: The dataclass instance to update.\n",
        "            data_dict: Dictionary containing the update values.\n",
        "        \"\"\"\n",
        "        for field_name, field_value in data_dict.items():\n",
        "            if hasattr(dataclass_instance, field_name):\n",
        "                # Type validation could be added here\n",
        "                setattr(dataclass_instance, field_name, field_value)\n",
        "\n",
        "    def validate_configuration(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Validate the current configuration for logical consistency.\n",
        "\n",
        "        Returns:\n",
        "            List of validation error messages. Empty list if configuration is valid.\n",
        "        \"\"\"\n",
        "        errors = []\n",
        "\n",
        "        # Validate threshold ranges\n",
        "        ft = self._feature_thresholds\n",
        "        if ft.dark_pixel_threshold >= ft.bright_pixel_threshold:\n",
        "            errors.append(\"Dark pixel threshold must be less than bright pixel threshold\")\n",
        "\n",
        "        if ft.sky_blue_hue_min >= ft.sky_blue_hue_max:\n",
        "            errors.append(\"Sky blue hue min must be less than sky blue hue max\")\n",
        "\n",
        "        if ft.gray_val_min >= ft.gray_val_max:\n",
        "            errors.append(\"Gray value min must be less than gray value max\")\n",
        "\n",
        "        # Validate probability thresholds\n",
        "        ap = self._algorithm_parameters\n",
        "        if not (0.0 <= ap.indoor_decision_threshold <= 1.0):\n",
        "            errors.append(\"Indoor decision threshold must be between 0 and 1\")\n",
        "\n",
        "        if not (0.0 <= ap.places365_high_confidence_thresh <= 1.0):\n",
        "            errors.append(\"Places365 high confidence threshold must be between 0 and 1\")\n",
        "\n",
        "        # Validate color ranges\n",
        "        for warm_range in self._color_ranges.warm_hue_ranges:\n",
        "            if warm_range[0] >= warm_range[1]:\n",
        "                errors.append(f\"Invalid warm hue range: {warm_range}\")\n",
        "\n",
        "        for cool_range in self._color_ranges.cool_hue_ranges:\n",
        "            if cool_range[0] >= cool_range[1]:\n",
        "                errors.append(f\"Invalid cool hue range: {cool_range}\")\n",
        "\n",
        "        return errors\n",
        "\n",
        "    def get_threshold_value(self, threshold_name: str) -> Any:\n",
        "        \"\"\"\n",
        "        Get a specific threshold value by name.\n",
        "\n",
        "        Args:\n",
        "            threshold_name: Name of the threshold parameter.\n",
        "\n",
        "        Returns:\n",
        "            The threshold value.\n",
        "\n",
        "        Raises:\n",
        "            AttributeError: If the threshold name doesn't exist.\n",
        "        \"\"\"\n",
        "        # Search through all configuration sections\n",
        "        for config_section in [\n",
        "            self._feature_thresholds,\n",
        "            self._indoor_outdoor_thresholds,\n",
        "            self._lighting_thresholds,\n",
        "            self._override_factors,\n",
        "            self._algorithm_parameters\n",
        "        ]:\n",
        "            if hasattr(config_section, threshold_name):\n",
        "                return getattr(config_section, threshold_name)\n",
        "\n",
        "        # Check weighting factors\n",
        "        if hasattr(self._weighting_factors, threshold_name):\n",
        "            return getattr(self._weighting_factors, threshold_name)\n",
        "\n",
        "        raise AttributeError(f\"Threshold '{threshold_name}' not found\")\n",
        "\n",
        "    def update_threshold(self, threshold_name: str, value: Any) -> None:\n",
        "        \"\"\"\n",
        "        Update a specific threshold value.\n",
        "\n",
        "        Args:\n",
        "            threshold_name: Name of the threshold parameter.\n",
        "            value: New value for the threshold.\n",
        "\n",
        "        Raises:\n",
        "            AttributeError: If the threshold name doesn't exist.\n",
        "        \"\"\"\n",
        "        # Search through all configuration sections\n",
        "        for config_section in [\n",
        "            self._feature_thresholds,\n",
        "            self._indoor_outdoor_thresholds,\n",
        "            self._lighting_thresholds,\n",
        "            self._override_factors,\n",
        "            self._algorithm_parameters,\n",
        "            self._weighting_factors\n",
        "        ]:\n",
        "            if hasattr(config_section, threshold_name):\n",
        "                setattr(config_section, threshold_name, value)\n",
        "                return\n",
        "\n",
        "        raise AttributeError(f\"Threshold '{threshold_name}' not found\")"
      ],
      "metadata": {
        "id": "FTVYZyxXtJtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a48a16-e580-4843-d419-b76ce1f5c7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing configuration_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile feature_extractor.py\n",
        "import numpy as np\n",
        "import cv2\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Optional\n",
        "# from configuration_manager import ConfigurationManager\n",
        "\n",
        "\n",
        "class FeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extracts comprehensive lighting and scene features from images.（主要從圖片提取光線資訊)\n",
        "\n",
        "    This class handles all basic feature computation including brightness analysis,\n",
        "    color characteristics, texture complexity, and structural features for\n",
        "    lighting analysis and scene understanding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_manager: ConfigurationManager):\n",
        "        \"\"\"\n",
        "        Initialize the feature extractor.\n",
        "\n",
        "        Args:\n",
        "            config_manager: Configuration manager instance for accessing thresholds.\n",
        "        \"\"\"\n",
        "        self.config_manager = config_manager\n",
        "        self.logger = self._setup_logger()\n",
        "\n",
        "    def _setup_logger(self) -> logging.Logger:\n",
        "        \"\"\"Set up logger for feature extraction operations.\"\"\"\n",
        "        logger = logging.getLogger(f\"{__name__}.FeatureExtractor\")\n",
        "        if not logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "            logger.setLevel(logging.INFO)\n",
        "        return logger\n",
        "\n",
        "    def extract_features(self, image_rgb: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extract all features from an RGB image.\n",
        "\n",
        "        Args:\n",
        "            image_rgb: Input image as numpy array in RGB format.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all extracted features.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Validate input image\n",
        "            if not self._validate_image(image_rgb):\n",
        "                return self._get_default_features()\n",
        "\n",
        "            # Get image dimensions and prepare processing parameters\n",
        "            height, width = image_rgb.shape[:2]\n",
        "            scale_factor = self._calculate_scale_factor(height, width)\n",
        "\n",
        "            # Create processed image versions\n",
        "            small_rgb = cv2.resize(\n",
        "                image_rgb,\n",
        "                (width // scale_factor, height // scale_factor),\n",
        "                interpolation=cv2.INTER_AREA\n",
        "            )\n",
        "            hsv_img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
        "            gray_img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
        "            small_gray = cv2.cvtColor(small_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Extract features by category\n",
        "            brightness_features = self.compute_brightness_features(hsv_img, height, width)\n",
        "            color_features = self.compute_color_features(hsv_img, height, width)\n",
        "            texture_features = self.compute_texture_features(small_gray, gray_img, height, width)\n",
        "            structure_features = self.compute_structure_features(\n",
        "                small_gray, gray_img, hsv_img, height, width, scale_factor\n",
        "            )\n",
        "\n",
        "            # Combine all features\n",
        "            features = {**brightness_features, **color_features, **texture_features, **structure_features}\n",
        "\n",
        "            # Add compatibility features for legacy code\n",
        "            legacy_features = self._compute_legacy_compatibility_features(\n",
        "                hsv_img, small_gray, features, scale_factor\n",
        "            )\n",
        "            features.update(legacy_features)\n",
        "\n",
        "            self.logger.debug(f\"Successfully extracted {len(features)} features from image\")\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in feature extraction: {str(e)}\")\n",
        "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "            return self._get_default_features()\n",
        "\n",
        "    def compute_brightness_features(self, hsv_img: np.ndarray, height: int, width: int) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute brightness-related features from HSV image.\n",
        "\n",
        "        Args:\n",
        "            hsv_img: Image in HSV color space.\n",
        "            height: Image height.\n",
        "            width: Image width.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing brightness features.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            v_channel = hsv_img[:, :, 2]  # Value channel represents brightness\n",
        "\n",
        "            # 基本的亮度統計\n",
        "            avg_brightness = float(np.mean(v_channel))\n",
        "            brightness_std = float(np.std(v_channel))\n",
        "\n",
        "            # Pixel ratio calculations\n",
        "            dark_threshold = self.config_manager.feature_thresholds.dark_pixel_threshold\n",
        "            bright_threshold = self.config_manager.feature_thresholds.bright_pixel_threshold\n",
        "\n",
        "            total_pixels = height * width\n",
        "            dark_pixel_ratio = float(np.sum(v_channel < dark_threshold) / total_pixels)\n",
        "            bright_pixel_ratio = float(np.sum(v_channel > bright_threshold) / total_pixels)\n",
        "\n",
        "            # Brightness uniformity\n",
        "            brightness_uniformity = 1.0 - min(1.0, brightness_std / max(avg_brightness, 1e-5))\n",
        "\n",
        "            return {\n",
        "                \"avg_brightness\": avg_brightness,\n",
        "                \"brightness_std\": brightness_std,\n",
        "                \"dark_pixel_ratio\": dark_pixel_ratio,\n",
        "                \"bright_pixel_ratio\": bright_pixel_ratio,\n",
        "                \"brightness_uniformity\": brightness_uniformity\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing brightness features: {str(e)}\")\n",
        "            return {\n",
        "                \"avg_brightness\": 100.0,\n",
        "                \"brightness_std\": 50.0,\n",
        "                \"dark_pixel_ratio\": 0.0,\n",
        "                \"bright_pixel_ratio\": 0.0,\n",
        "                \"brightness_uniformity\": 0.5\n",
        "            }\n",
        "\n",
        "    def compute_color_features(self, hsv_img: np.ndarray, height: int, width: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Compute color-related features from HSV image.\n",
        "\n",
        "        Args:\n",
        "            hsv_img: Image in HSV color space.\n",
        "            height: Image height.\n",
        "            width: Image width.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing color features.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            h_channel, s_channel, v_channel = cv2.split(hsv_img)\n",
        "            total_pixels = height * width\n",
        "\n",
        "            # Color ratio calculations\n",
        "            color_features = {}\n",
        "\n",
        "            # Blue color detection (general and sky-specific)\n",
        "            blue_mask = ((h_channel >= 90) & (h_channel <= 140))\n",
        "            color_features[\"blue_ratio\"] = float(np.sum(blue_mask) / total_pixels)\n",
        "\n",
        "            # Sky-like blue detection\n",
        "            ft = self.config_manager.feature_thresholds\n",
        "            sky_blue_mask = (\n",
        "                (h_channel >= ft.sky_blue_hue_min) & (h_channel <= ft.sky_blue_hue_max) &\n",
        "                (s_channel > ft.sky_blue_sat_min) & (v_channel > ft.sky_blue_val_min)\n",
        "            )\n",
        "            color_features[\"sky_like_blue_ratio\"] = float(np.sum(sky_blue_mask) / total_pixels)\n",
        "\n",
        "            # Yellow-orange detection\n",
        "            yellow_orange_mask = ((h_channel >= 15) & (h_channel <= 45))\n",
        "            color_features[\"yellow_orange_ratio\"] = float(np.sum(yellow_orange_mask) / total_pixels)\n",
        "\n",
        "            # Gray detection\n",
        "            gray_mask = (\n",
        "                (s_channel < ft.gray_sat_max) &\n",
        "                (v_channel > ft.gray_val_min) &\n",
        "                (v_channel < ft.gray_val_max)\n",
        "            )\n",
        "            color_features[\"gray_ratio\"] = float(np.sum(gray_mask) / total_pixels)\n",
        "\n",
        "            # Saturation statistics\n",
        "            color_features[\"avg_saturation\"] = float(np.mean(s_channel))\n",
        "\n",
        "            # Sky region analysis\n",
        "            sky_region_features = self._analyze_sky_region(h_channel, s_channel, v_channel, height)\n",
        "            color_features.update(sky_region_features)\n",
        "\n",
        "            # Color atmosphere analysis\n",
        "            atmosphere_features = self._analyze_color_atmosphere(h_channel, s_channel, total_pixels)\n",
        "            color_features.update(atmosphere_features)\n",
        "\n",
        "            return color_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing color features: {str(e)}\")\n",
        "            return self._get_default_color_features()\n",
        "\n",
        "    def compute_texture_features(self, small_gray: np.ndarray, gray_img: np.ndarray,\n",
        "                                height: int, width: int) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute texture and gradient features.\n",
        "\n",
        "        Args:\n",
        "            small_gray: Downscaled grayscale image for efficient processing.\n",
        "            gray_img: Full-resolution grayscale image.\n",
        "            height: Original image height.\n",
        "            width: Original image width.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing texture features.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Compute gradients on small image for efficiency\n",
        "            gx = cv2.Sobel(small_gray, cv2.CV_32F, 1, 0, ksize=3)\n",
        "            gy = cv2.Sobel(small_gray, cv2.CV_32F, 0, 1, ksize=3)\n",
        "\n",
        "            avg_abs_gx = float(np.mean(np.abs(gx)))\n",
        "            avg_abs_gy = float(np.mean(np.abs(gy)))\n",
        "\n",
        "            # Gradient ratio (vertical to horizontal)\n",
        "            gradient_ratio_vertical_horizontal = avg_abs_gy / max(avg_abs_gx, 1e-5)\n",
        "\n",
        "            # Top region texture complexity\n",
        "            small_top_third_height = small_gray.shape[0] // 3\n",
        "            small_sky_region_gray = small_gray[:small_top_third_height, :]\n",
        "\n",
        "            if small_sky_region_gray.size > 0:\n",
        "                laplacian_var_sky = cv2.Laplacian(small_sky_region_gray, cv2.CV_64F).var()\n",
        "                top_region_texture_complexity = min(1.0, laplacian_var_sky / 1000.0)\n",
        "            else:\n",
        "                top_region_texture_complexity = 0.5\n",
        "\n",
        "            # Shadow clarity estimation\n",
        "            brightness_std = float(np.std(gray_img))\n",
        "            avg_brightness = float(np.mean(gray_img))\n",
        "            dark_pixel_ratio = float(np.sum(gray_img < 50) / (height * width))\n",
        "\n",
        "            if brightness_std > 60 and dark_pixel_ratio < 0.15 and avg_brightness > 100:\n",
        "                shadow_clarity_score = 0.7\n",
        "            elif brightness_std < 30 and dark_pixel_ratio > 0.1:\n",
        "                shadow_clarity_score = 0.3\n",
        "            else:\n",
        "                shadow_clarity_score = 0.5\n",
        "\n",
        "            # Edge density\n",
        "            edges_density = min(1.0, (avg_abs_gx + avg_abs_gy) / 100.0)\n",
        "\n",
        "            return {\n",
        "                \"gradient_ratio_vertical_horizontal\": gradient_ratio_vertical_horizontal,\n",
        "                \"top_region_texture_complexity\": top_region_texture_complexity,\n",
        "                \"shadow_clarity_score\": shadow_clarity_score,\n",
        "                \"vertical_strength\": avg_abs_gy,\n",
        "                \"horizontal_strength\": avg_abs_gx,\n",
        "                \"edges_density\": edges_density\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing texture features: {str(e)}\")\n",
        "            return {\n",
        "                \"gradient_ratio_vertical_horizontal\": 1.0,\n",
        "                \"top_region_texture_complexity\": 0.5,\n",
        "                \"shadow_clarity_score\": 0.5,\n",
        "                \"vertical_strength\": 0.0,\n",
        "                \"horizontal_strength\": 0.0,\n",
        "                \"edges_density\": 0.0\n",
        "            }\n",
        "\n",
        "    def compute_structure_features(self, small_gray: np.ndarray, gray_img: np.ndarray,\n",
        "                                  hsv_img: np.ndarray, height: int, width: int,\n",
        "                                  scale_factor: int) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute structural features including ceiling likelihood and boundary clarity.\n",
        "\n",
        "        Args:\n",
        "            small_gray: Downscaled grayscale image.\n",
        "            gray_img: Full-resolution grayscale image.\n",
        "            hsv_img: HSV image for brightness analysis.\n",
        "            height: Original image height.\n",
        "            width: Original image width.\n",
        "            scale_factor: Downscaling factor used.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing structural features.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Compute gradients\n",
        "            gx = cv2.Sobel(small_gray, cv2.CV_32F, 1, 0, ksize=3)\n",
        "            gy = cv2.Sobel(small_gray, cv2.CV_32F, 0, 1, ksize=3)\n",
        "            avg_abs_gx = float(np.mean(np.abs(gx)))\n",
        "            avg_abs_gy = float(np.mean(np.abs(gy)))\n",
        "\n",
        "            # Ceiling likelihood analysis\n",
        "            ceiling_features = self._analyze_ceiling_likelihood(\n",
        "                small_gray, hsv_img, gx, avg_abs_gx, height, scale_factor\n",
        "            )\n",
        "\n",
        "            # Boundary clarity analysis\n",
        "            boundary_clarity = self._compute_boundary_clarity(small_gray, avg_abs_gx, avg_abs_gy)\n",
        "\n",
        "            # Openness analysis\n",
        "            openness_top_edge = self._compute_openness_top_edge(gy, avg_abs_gy)\n",
        "\n",
        "            # Legacy compatibility features\n",
        "            legacy_structure = self._compute_legacy_structure_features(gray_img, height)\n",
        "\n",
        "            structure_features = {\n",
        "                \"ceiling_likelihood\": ceiling_features[\"ceiling_likelihood\"],\n",
        "                \"boundary_clarity\": boundary_clarity,\n",
        "                \"openness_top_edge\": openness_top_edge,\n",
        "                **legacy_structure\n",
        "            }\n",
        "\n",
        "            return structure_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing structure features: {str(e)}\")\n",
        "            return {\n",
        "                \"ceiling_likelihood\": 0.0,\n",
        "                \"boundary_clarity\": 0.0,\n",
        "                \"openness_top_edge\": 0.5,\n",
        "                \"ceiling_uniformity\": 0.5,\n",
        "                \"horizontal_line_ratio\": 0.0\n",
        "            }\n",
        "\n",
        "    def _analyze_sky_region(self, h_channel: np.ndarray, s_channel: np.ndarray,\n",
        "                           v_channel: np.ndarray, height: int) -> Dict[str, float]:\n",
        "        \"\"\"Analyze features specific to the sky region (top third of image).\"\"\"\n",
        "        try:\n",
        "            top_third_height = height // 3\n",
        "            sky_region_v = v_channel[:top_third_height, :]\n",
        "            sky_region_s = s_channel[:top_third_height, :]\n",
        "            sky_region_h = h_channel[:top_third_height, :]\n",
        "\n",
        "            if sky_region_v.size == 0:\n",
        "                return self._get_default_sky_features()\n",
        "\n",
        "            # Sky region brightness analysis\n",
        "            sky_region_avg_brightness = float(np.mean(sky_region_v))\n",
        "            overall_avg_brightness = float(np.mean(v_channel))\n",
        "            sky_region_brightness_ratio = sky_region_avg_brightness / max(overall_avg_brightness, 1e-5)\n",
        "            sky_region_saturation = float(np.mean(sky_region_s))\n",
        "\n",
        "            # Sky blue dominance in sky region\n",
        "            ft = self.config_manager.feature_thresholds\n",
        "            sky_region_blue_pixels = np.sum(\n",
        "                (sky_region_h >= ft.sky_blue_hue_min) & (sky_region_h <= ft.sky_blue_hue_max) &\n",
        "                (sky_region_s > ft.sky_blue_sat_min) & (sky_region_v > ft.sky_blue_val_min)\n",
        "            )\n",
        "            sky_region_blue_dominance = float(sky_region_blue_pixels / max(1, sky_region_v.size))\n",
        "\n",
        "            return {\n",
        "                \"sky_region_brightness_ratio\": sky_region_brightness_ratio,\n",
        "                \"sky_region_saturation\": sky_region_saturation,\n",
        "                \"sky_region_blue_dominance\": sky_region_blue_dominance,\n",
        "                \"sky_brightness\": sky_region_avg_brightness\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error analyzing sky region: {str(e)}\")\n",
        "            return self._get_default_sky_features()\n",
        "\n",
        "    def _analyze_color_atmosphere(self, h_channel: np.ndarray, s_channel: np.ndarray,\n",
        "                                 total_pixels: int) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze warm/cool color atmosphere.\"\"\"\n",
        "        try:\n",
        "            cr = self.config_manager.color_ranges\n",
        "\n",
        "            # Warm colors detection\n",
        "            warm_mask = np.zeros_like(h_channel, dtype=bool)\n",
        "            for h_min, h_max in cr.warm_hue_ranges:\n",
        "                warm_mask |= ((h_channel >= h_min) & (h_channel <= h_max))\n",
        "            warm_ratio = float(np.sum(warm_mask & (s_channel > 30)) / total_pixels)\n",
        "\n",
        "            # Cool colors detection\n",
        "            cool_mask = np.zeros_like(h_channel, dtype=bool)\n",
        "            for h_min, h_max in cr.cool_hue_ranges:\n",
        "                cool_mask |= ((h_channel >= h_min) & (h_channel <= h_max))\n",
        "            cool_ratio = float(np.sum(cool_mask & (s_channel > 30)) / total_pixels)\n",
        "\n",
        "            # Determine overall atmosphere\n",
        "            if warm_ratio > cool_ratio and warm_ratio > 0.3:\n",
        "                color_atmosphere = \"warm\"\n",
        "            elif cool_ratio > warm_ratio and cool_ratio > 0.3:\n",
        "                color_atmosphere = \"cool\"\n",
        "            else:\n",
        "                color_atmosphere = \"neutral\"\n",
        "\n",
        "            return {\n",
        "                \"warm_ratio\": warm_ratio,\n",
        "                \"cool_ratio\": cool_ratio,\n",
        "                \"color_atmosphere\": color_atmosphere\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error analyzing color atmosphere: {str(e)}\")\n",
        "            return {\n",
        "                \"warm_ratio\": 0.0,\n",
        "                \"cool_ratio\": 0.0,\n",
        "                \"color_atmosphere\": \"neutral\"\n",
        "            }\n",
        "\n",
        "    def _analyze_ceiling_likelihood(self, small_gray: np.ndarray, hsv_img: np.ndarray,\n",
        "                                   gx: np.ndarray, avg_abs_gx: float, height: int,\n",
        "                                   scale_factor: int) -> Dict[str, float]:\n",
        "        \"\"\"Analyze likelihood of ceiling presence.\"\"\"\n",
        "        try:\n",
        "            ceiling_likelihood = 0.0\n",
        "            config = self.config_manager.indoor_outdoor_thresholds\n",
        "\n",
        "            # Get sky region brightness for analysis\n",
        "            v_channel = hsv_img[:, :, 2]\n",
        "            top_third_height = height // 3\n",
        "            sky_region_v = v_channel[:top_third_height, :]\n",
        "            sky_region_avg_brightness = float(np.mean(sky_region_v)) if sky_region_v.size > 0 else 0\n",
        "\n",
        "            # Get top region texture complexity\n",
        "            small_top_third_height = small_gray.shape[0] // 3\n",
        "            small_sky_region_gray = small_gray[:small_top_third_height, :]\n",
        "\n",
        "            if small_sky_region_gray.size > 0:\n",
        "                laplacian_var = cv2.Laplacian(small_sky_region_gray, cv2.CV_64F).var()\n",
        "                top_region_texture_complexity = min(1.0, laplacian_var / 1000.0)\n",
        "            else:\n",
        "                top_region_texture_complexity = 0.5\n",
        "\n",
        "            # Condition 1: Simple texture and moderate brightness\n",
        "            ceiling_texture_thresh = getattr(config, 'ceiling_texture_thresh', 0.4)\n",
        "            ceiling_brightness_min = getattr(config, 'ceiling_brightness_min', 60)\n",
        "            ceiling_brightness_max = getattr(config, 'ceiling_brightness_max', 230)\n",
        "\n",
        "            if (top_region_texture_complexity < ceiling_texture_thresh and\n",
        "                ceiling_brightness_min < sky_region_avg_brightness < ceiling_brightness_max):\n",
        "                ceiling_likelihood += 0.45\n",
        "\n",
        "            # Condition 2: Horizontal line strength\n",
        "            top_horizontal_lines_strength = float(np.mean(np.abs(gx[:small_gray.shape[0]//3, :])))\n",
        "            ceiling_horizontal_line_factor = getattr(config, 'ceiling_horizontal_line_factor', 1.15)\n",
        "\n",
        "            if top_horizontal_lines_strength > avg_abs_gx * ceiling_horizontal_line_factor:\n",
        "                ceiling_likelihood += 0.35\n",
        "\n",
        "            # Condition 3: Central bright spot (lamp detection)\n",
        "            center_y_sm, center_x_sm = small_gray.shape[0]//2, small_gray.shape[1]//2\n",
        "            lamp_check_radius_y = small_gray.shape[0] // 8\n",
        "            lamp_check_radius_x = small_gray.shape[1] // 8\n",
        "\n",
        "            center_region = small_gray[\n",
        "                max(0, center_y_sm - lamp_check_radius_y):min(small_gray.shape[0], center_y_sm + lamp_check_radius_y),\n",
        "                max(0, center_x_sm - lamp_check_radius_x):min(small_gray.shape[1], center_x_sm + lamp_check_radius_x)\n",
        "            ]\n",
        "\n",
        "            if center_region.size > 0:\n",
        "                avg_brightness = float(np.mean(small_gray))\n",
        "                center_brightness = float(np.mean(center_region))\n",
        "                ceiling_center_bright_factor = getattr(config, 'ceiling_center_bright_factor', 1.25)\n",
        "\n",
        "                if center_brightness > avg_brightness * ceiling_center_bright_factor:\n",
        "                    ceiling_likelihood += 0.30\n",
        "\n",
        "            # Sky dominance analysis for penalty\n",
        "            sky_region_blue_dominance = self._compute_sky_blue_dominance(hsv_img, height)\n",
        "            sky_region_brightness_ratio = sky_region_avg_brightness / max(float(np.mean(v_channel)), 1e-5)\n",
        "\n",
        "            # Penalties for strong sky signals\n",
        "            ceiling_max_sky_blue_thresh = getattr(config, 'ceiling_max_sky_blue_thresh', 0.08)\n",
        "            ceiling_max_sky_brightness_ratio = getattr(config, 'ceiling_max_sky_brightness_ratio', 1.15)\n",
        "\n",
        "            if (sky_region_blue_dominance < ceiling_max_sky_blue_thresh and\n",
        "                sky_region_brightness_ratio < ceiling_max_sky_brightness_ratio):\n",
        "                ceiling_likelihood += 0.15\n",
        "\n",
        "            # Strong sky override\n",
        "            sky_blue_dominance_strong_thresh = getattr(config, 'sky_blue_dominance_strong_thresh', 0.25)\n",
        "            sky_brightness_strong_thresh = getattr(config, 'sky_brightness_strong_thresh', 1.25)\n",
        "            ceiling_sky_override_factor = getattr(config, 'ceiling_sky_override_factor', 0.1)\n",
        "\n",
        "            if (sky_region_blue_dominance > sky_blue_dominance_strong_thresh and\n",
        "                sky_region_brightness_ratio > sky_brightness_strong_thresh):\n",
        "                ceiling_likelihood *= ceiling_sky_override_factor\n",
        "\n",
        "            ceiling_likelihood = min(1.0, ceiling_likelihood)\n",
        "\n",
        "            return {\"ceiling_likelihood\": ceiling_likelihood}\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error analyzing ceiling likelihood: {str(e)}\")\n",
        "            return {\"ceiling_likelihood\": 0.0}\n",
        "\n",
        "    def _compute_sky_blue_dominance(self, hsv_img: np.ndarray, height: int) -> float:\n",
        "        \"\"\"Compute blue dominance in sky region.\"\"\"\n",
        "        try:\n",
        "            h_channel, s_channel, v_channel = cv2.split(hsv_img)\n",
        "            top_third_height = height // 3\n",
        "            sky_region_h = h_channel[:top_third_height, :]\n",
        "            sky_region_s = s_channel[:top_third_height, :]\n",
        "            sky_region_v = v_channel[:top_third_height, :]\n",
        "\n",
        "            if sky_region_h.size == 0:\n",
        "                return 0.0\n",
        "\n",
        "            ft = self.config_manager.feature_thresholds\n",
        "            sky_region_blue_pixels = np.sum(\n",
        "                (sky_region_h >= ft.sky_blue_hue_min) & (sky_region_h <= ft.sky_blue_hue_max) &\n",
        "                (sky_region_s > ft.sky_blue_sat_min) & (sky_region_v > ft.sky_blue_val_min)\n",
        "            )\n",
        "\n",
        "            return float(sky_region_blue_pixels / max(1, sky_region_h.size))\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing sky blue dominance: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _compute_boundary_clarity(self, small_gray: np.ndarray, avg_abs_gx: float,\n",
        "                                 avg_abs_gy: float) -> float:\n",
        "        \"\"\"Compute boundary clarity score.\"\"\"\n",
        "        try:\n",
        "            edge_width_sm = max(1, small_gray.shape[1] // 10)\n",
        "            edge_height_sm = max(1, small_gray.shape[0] // 10)\n",
        "\n",
        "            # Edge gradients\n",
        "            left_edge_grad_x = 0.0\n",
        "            right_edge_grad_x = 0.0\n",
        "            top_edge_grad_y = 0.0\n",
        "\n",
        "            if small_gray.shape[1] > edge_width_sm:\n",
        "                left_edge = small_gray[:, :edge_width_sm]\n",
        "                right_edge = small_gray[:, -edge_width_sm:]\n",
        "                left_edge_grad_x = float(np.mean(np.abs(cv2.Sobel(left_edge, cv2.CV_32F, 1, 0, ksize=3))))\n",
        "                right_edge_grad_x = float(np.mean(np.abs(cv2.Sobel(right_edge, cv2.CV_32F, 1, 0, ksize=3))))\n",
        "\n",
        "            if small_gray.shape[0] > edge_height_sm:\n",
        "                top_edge = small_gray[:edge_height_sm, :]\n",
        "                top_edge_grad_y = float(np.mean(np.abs(cv2.Sobel(top_edge, cv2.CV_32F, 0, 1, ksize=3))))\n",
        "\n",
        "            # Normalize against average gradients\n",
        "            boundary_clarity = (left_edge_grad_x + right_edge_grad_x + top_edge_grad_y) / (\n",
        "                3 * max(avg_abs_gx, avg_abs_gy, 1e-5)\n",
        "            )\n",
        "            boundary_clarity = min(1.0, boundary_clarity / 1.5)\n",
        "\n",
        "            return boundary_clarity\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing boundary clarity: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _compute_openness_top_edge(self, gy: np.ndarray, avg_abs_gy: float) -> float:\n",
        "        \"\"\"Compute openness of top edge.\"\"\"\n",
        "        try:\n",
        "            top_edge_strip_gy = float(np.mean(np.abs(gy[:max(1, gy.shape[0]//20), :])))\n",
        "            openness_top_edge = 1.0 - min(1.0, top_edge_strip_gy / max(avg_abs_gy, 1e-5) / 0.5)\n",
        "            return openness_top_edge\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing top edge openness: {str(e)}\")\n",
        "            return 0.5\n",
        "\n",
        "    def _compute_legacy_compatibility_features(self, hsv_img: np.ndarray, small_gray: np.ndarray,\n",
        "                                             features: Dict[str, Any], scale_factor: int) -> Dict[str, Any]:\n",
        "        \"\"\"Compute additional features for backward compatibility.\"\"\"\n",
        "        try:\n",
        "            v_channel = hsv_img[:, :, 2]\n",
        "\n",
        "            # Light source detection\n",
        "            light_features = self._detect_light_sources(v_channel, features[\"avg_brightness\"],\n",
        "                                                       features[\"brightness_std\"], scale_factor)\n",
        "\n",
        "            # Street line detection\n",
        "            street_score = self._compute_street_line_score(small_gray)\n",
        "\n",
        "            # Additional legacy features\n",
        "            legacy_features = {\n",
        "                **light_features,\n",
        "                \"street_line_score\": street_score,\n",
        "                \"sky_blue_ratio\": features.get(\"sky_like_blue_ratio\", 0.0),  # Alias\n",
        "                \"gradient_ratio\": features.get(\"gradient_ratio_vertical_horizontal\", 1.0)  # Alias\n",
        "            }\n",
        "\n",
        "            return legacy_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing legacy compatibility features: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def _detect_light_sources(self, v_channel: np.ndarray, avg_brightness: float,\n",
        "                             brightness_std: float, scale_factor: int) -> Dict[str, float]:\n",
        "        \"\"\"Detect artificial light sources in the image.\"\"\"\n",
        "        try:\n",
        "            # Sample pixels for efficiency\n",
        "            sampled_v = v_channel[::scale_factor*2, ::scale_factor*2]\n",
        "\n",
        "            # Light threshold\n",
        "            light_threshold = min(\n",
        "                self.config_manager.feature_thresholds.light_source_abs_thresh,\n",
        "                avg_brightness + 2 * brightness_std\n",
        "            )\n",
        "\n",
        "            is_bright_spots = sampled_v > light_threshold\n",
        "            bright_spot_count = int(np.sum(is_bright_spots))\n",
        "\n",
        "            # Initialize light features\n",
        "            circular_light_count = 0\n",
        "            indoor_light_score = 0.0\n",
        "            light_distribution_uniformity = 0.5\n",
        "\n",
        "            # Analyze light distribution if spots are found\n",
        "            if 1 < bright_spot_count < 20:\n",
        "                bright_y, bright_x = np.where(is_bright_spots)\n",
        "                if len(bright_y) > 1:\n",
        "                    mean_x, mean_y = np.mean(bright_x), np.mean(bright_y)\n",
        "                    dist_from_center = np.sqrt((bright_x - mean_x)**2 + (bright_y - mean_y)**2)\n",
        "\n",
        "                    if np.std(dist_from_center) < np.mean(dist_from_center):\n",
        "                        circular_light_count = min(3, len(bright_y) // 2)\n",
        "                        light_distribution_uniformity = 0.7\n",
        "\n",
        "                    if np.mean(bright_y) < sampled_v.shape[0] / 2:\n",
        "                        indoor_light_score = 0.6\n",
        "                    else:\n",
        "                        indoor_light_score = 0.3\n",
        "\n",
        "            return {\n",
        "                \"bright_spot_count\": bright_spot_count,\n",
        "                \"circular_light_count\": circular_light_count,\n",
        "                \"indoor_light_score\": indoor_light_score,\n",
        "                \"light_distribution_uniformity\": light_distribution_uniformity\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error detecting light sources: {str(e)}\")\n",
        "            return {\n",
        "                \"bright_spot_count\": 0,\n",
        "                \"circular_light_count\": 0,\n",
        "                \"indoor_light_score\": 0.0,\n",
        "                \"light_distribution_uniformity\": 0.5\n",
        "            }\n",
        "\n",
        "    def _compute_street_line_score(self, small_gray: np.ndarray) -> float:\n",
        "        \"\"\"Compute street line detection score.\"\"\"\n",
        "        try:\n",
        "            street_line_score = 0.0\n",
        "            bottom_half_sm = small_gray[small_gray.shape[0]//2:, :]\n",
        "\n",
        "            if bottom_half_sm.size > 0:\n",
        "                bottom_vert_gradient = cv2.Sobel(bottom_half_sm, cv2.CV_32F, 0, 1, ksize=3)\n",
        "                strong_vert_lines = np.abs(bottom_vert_gradient) > 50\n",
        "\n",
        "                if np.sum(strong_vert_lines) > (bottom_half_sm.size * 0.05):\n",
        "                    street_line_score = 0.7\n",
        "\n",
        "            return street_line_score\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing street line score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _compute_legacy_structure_features(self, gray_img: np.ndarray, height: int) -> Dict[str, float]:\n",
        "        \"\"\"Compute legacy structure features for backward compatibility.\"\"\"\n",
        "        try:\n",
        "            # Top region analysis for ceiling uniformity\n",
        "            top_region = gray_img[:height//4, :]\n",
        "            top_region_std = float(np.std(top_region)) if top_region.size > 0 else 0.0\n",
        "            ceiling_uniformity = 1.0 - min(1.0, top_region_std / max(float(np.mean(top_region)) if top_region.size > 0 else 1e-5, 1e-5))\n",
        "\n",
        "            # Horizontal line detection in top region\n",
        "            if top_region.size > 0:\n",
        "                top_gradients = np.abs(cv2.Sobel(top_region, cv2.CV_32F, 0, 1, ksize=3))\n",
        "                horizontal_lines_strength = float(np.mean(top_gradients))\n",
        "                horizontal_line_ratio = min(1.0, horizontal_lines_strength / 40.0)\n",
        "            else:\n",
        "                horizontal_line_ratio = 0.0\n",
        "\n",
        "            # Boundary edge score computation\n",
        "            boundary_edge_score = self._compute_legacy_boundary_score(gray_img)\n",
        "\n",
        "            return {\n",
        "                \"ceiling_uniformity\": ceiling_uniformity,\n",
        "                \"horizontal_line_ratio\": horizontal_line_ratio,\n",
        "                \"top_region_std\": top_region_std,\n",
        "                \"boundary_edge_score\": boundary_edge_score\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing legacy structure features: {str(e)}\")\n",
        "            return {\n",
        "                \"ceiling_uniformity\": 0.5,\n",
        "                \"horizontal_line_ratio\": 0.0,\n",
        "                \"top_region_std\": 0.0,\n",
        "                \"boundary_edge_score\": 0.0\n",
        "            }\n",
        "\n",
        "    def _compute_legacy_boundary_score(self, gray_img: np.ndarray) -> float:\n",
        "        \"\"\"Compute legacy boundary edge score.\"\"\"\n",
        "        try:\n",
        "            height, width = gray_img.shape\n",
        "\n",
        "            # Create small version for boundary analysis\n",
        "            small_height, small_width = height // 4, width // 4\n",
        "            small_gray = cv2.resize(gray_img, (small_width, small_height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            # Edge regions\n",
        "            left_edge_sm = small_gray[:, :small_width//6] if small_width > 6 else small_gray\n",
        "            right_edge_sm = small_gray[:, 5*small_width//6:] if small_width > 6 else small_gray\n",
        "            top_edge_sm = small_gray[:small_height//6, :] if small_height > 6 else small_gray\n",
        "\n",
        "            # Compute gradients for each edge\n",
        "            left_gradient = float(np.mean(np.abs(cv2.Sobel(left_edge_sm, cv2.CV_32F, 1, 0, ksize=3)))) if left_edge_sm.size > 0 else 0\n",
        "            right_gradient = float(np.mean(np.abs(cv2.Sobel(right_edge_sm, cv2.CV_32F, 1, 0, ksize=3)))) if right_edge_sm.size > 0 else 0\n",
        "            top_gradient = float(np.mean(np.abs(cv2.Sobel(top_edge_sm, cv2.CV_32F, 0, 1, ksize=3)))) if top_edge_sm.size > 0 else 0\n",
        "\n",
        "            # Combine and normalize\n",
        "            boundary_edge_score = (min(1.0, left_gradient/50) + min(1.0, right_gradient/50) + min(1.0, top_gradient/50)) / 3\n",
        "\n",
        "            return boundary_edge_score\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error computing legacy boundary score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _validate_image(self, image_rgb: np.ndarray) -> bool:\n",
        "        \"\"\"Validate input image format and dimensions.\"\"\"\n",
        "        try:\n",
        "            if not isinstance(image_rgb, np.ndarray):\n",
        "                self.logger.error(\"Input is not a numpy array\")\n",
        "                return False\n",
        "\n",
        "            if len(image_rgb.shape) != 3 or image_rgb.shape[2] != 3:\n",
        "                self.logger.error(f\"Invalid image shape: {image_rgb.shape}. Expected (H, W, 3)\")\n",
        "                return False\n",
        "\n",
        "            height, width = image_rgb.shape[:2]\n",
        "            if height == 0 or width == 0:\n",
        "                self.logger.error(f\"Invalid image dimensions: {height}x{width}\")\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error validating image: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _calculate_scale_factor(self, height: int, width: int) -> int:\n",
        "        \"\"\"Calculate appropriate scale factor for image processing efficiency.\"\"\"\n",
        "        try:\n",
        "            base_scale = 4\n",
        "            scale_factor = base_scale + min(8, max(0, int((height * width) / (1000 * 1000)) if height * width > 0 else 0))\n",
        "            return max(1, scale_factor)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating scale factor: {str(e)}\")\n",
        "            return 4\n",
        "\n",
        "    def _get_default_features(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return default feature values in case of processing errors.\"\"\"\n",
        "        return {\n",
        "            \"avg_brightness\": 100.0,\n",
        "            \"brightness_std\": 50.0,\n",
        "            \"dark_pixel_ratio\": 0.0,\n",
        "            \"bright_pixel_ratio\": 0.0,\n",
        "            \"brightness_uniformity\": 0.5,\n",
        "            \"blue_ratio\": 0.0,\n",
        "            \"sky_like_blue_ratio\": 0.0,\n",
        "            \"yellow_orange_ratio\": 0.0,\n",
        "            \"gray_ratio\": 0.0,\n",
        "            \"avg_saturation\": 100.0,\n",
        "            \"sky_region_brightness_ratio\": 1.0,\n",
        "            \"sky_region_saturation\": 0.0,\n",
        "            \"sky_region_blue_dominance\": 0.0,\n",
        "            \"sky_brightness\": 100.0,\n",
        "            \"warm_ratio\": 0.0,\n",
        "            \"cool_ratio\": 0.0,\n",
        "            \"color_atmosphere\": \"neutral\",\n",
        "            \"gradient_ratio_vertical_horizontal\": 1.0,\n",
        "            \"top_region_texture_complexity\": 0.5,\n",
        "            \"shadow_clarity_score\": 0.5,\n",
        "            \"vertical_strength\": 0.0,\n",
        "            \"horizontal_strength\": 0.0,\n",
        "            \"edges_density\": 0.0,\n",
        "            \"ceiling_likelihood\": 0.0,\n",
        "            \"boundary_clarity\": 0.0,\n",
        "            \"openness_top_edge\": 0.5,\n",
        "            \"ceiling_uniformity\": 0.5,\n",
        "            \"horizontal_line_ratio\": 0.0,\n",
        "            \"top_region_std\": 0.0,\n",
        "            \"boundary_edge_score\": 0.0,\n",
        "            \"bright_spot_count\": 0,\n",
        "            \"circular_light_count\": 0,\n",
        "            \"indoor_light_score\": 0.0,\n",
        "            \"light_distribution_uniformity\": 0.5,\n",
        "            \"street_line_score\": 0.0,\n",
        "            \"sky_blue_ratio\": 0.0,\n",
        "            \"gradient_ratio\": 1.0\n",
        "        }\n",
        "\n",
        "    def _get_default_color_features(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return default color feature values.\"\"\"\n",
        "        return {\n",
        "            \"blue_ratio\": 0.0,\n",
        "            \"sky_like_blue_ratio\": 0.0,\n",
        "            \"yellow_orange_ratio\": 0.0,\n",
        "            \"gray_ratio\": 0.0,\n",
        "            \"avg_saturation\": 100.0,\n",
        "            \"sky_region_brightness_ratio\": 1.0,\n",
        "            \"sky_region_saturation\": 0.0,\n",
        "            \"sky_region_blue_dominance\": 0.0,\n",
        "            \"sky_brightness\": 100.0,\n",
        "            \"warm_ratio\": 0.0,\n",
        "            \"cool_ratio\": 0.0,\n",
        "            \"color_atmosphere\": \"neutral\"\n",
        "        }\n",
        "\n",
        "    def _get_default_sky_features(self) -> Dict[str, float]:\n",
        "        \"\"\"Return default sky region feature values.\"\"\"\n",
        "        return {\n",
        "            \"sky_region_brightness_ratio\": 1.0,\n",
        "            \"sky_region_saturation\": 0.0,\n",
        "            \"sky_region_blue_dominance\": 0.0,\n",
        "            \"sky_brightness\": 100.0\n",
        "        }"
      ],
      "metadata": {
        "id": "moJU9zlctJqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e51673-b560-42b1-ee2c-358094062f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feature_extractor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile indoor_outdoor_classifier.py\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Optional, List\n",
        "# from configuration_manager import ConfigurationManager\n",
        "\n",
        "\n",
        "class IndoorOutdoorClassifier:\n",
        "    \"\"\"\n",
        "    Classifies scenes as indoor or outdoor based on visual features and Places365 context.(判斷室內室外)\n",
        "    此class會融入PLACES365，使判斷更準確\n",
        "\n",
        "    This class implements sophisticated decision logic that combines multiple evidence sources\n",
        "    including visual scene analysis, structural features, and external scene classification\n",
        "    data to determine whether a scene is indoor or outdoor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_manager: ConfigurationManager):\n",
        "        \"\"\"\n",
        "        Initialize the indoor/outdoor classifier.\n",
        "\n",
        "        Args:\n",
        "            config_manager: Configuration manager instance for accessing thresholds and weights.\n",
        "        \"\"\"\n",
        "        self.config_manager = config_manager\n",
        "        self.logger = self._setup_logger()\n",
        "\n",
        "        # Internal threshold constants for Places365 confidence levels\n",
        "        self.P365_HIGH_CONF_THRESHOLD = 0.65\n",
        "        self.P365_MODERATE_CONF_THRESHOLD = 0.4\n",
        "\n",
        "        # 以下是絕對室內/室外的基本情況\n",
        "        self.DEFINITELY_OUTDOOR_KEYWORDS_P365 = [\n",
        "            \"street\", \"road\", \"highway\", \"park\", \"beach\", \"mountain\", \"forest\", \"field\",\n",
        "            \"outdoor\", \"sky\", \"coast\", \"courtyard\", \"square\", \"plaza\", \"bridge\",\n",
        "            \"parking_lot\", \"playground\", \"stadium\", \"construction_site\", \"river\", \"ocean\",\n",
        "            \"desert\", \"garden\", \"trail\", \"intersection\", \"crosswalk\", \"sidewalk\", \"pathway\",\n",
        "            \"avenue\", \"boulevard\", \"downtown\", \"city_center\", \"market_outdoor\"\n",
        "        ]\n",
        "\n",
        "        self.DEFINITELY_INDOOR_KEYWORDS_P365 = [\n",
        "            \"bedroom\", \"office\", \"kitchen\", \"library\", \"classroom\", \"conference_room\", \"living_room\",\n",
        "            \"bathroom\", \"hospital\", \"hotel_room\", \"cabin\", \"interior\", \"museum\", \"gallery\",\n",
        "            \"mall\", \"market_indoor\", \"basement\", \"corridor\", \"lobby\", \"restaurant_indoor\",\n",
        "            \"bar_indoor\", \"shop_indoor\", \"gym_indoor\"\n",
        "        ]\n",
        "\n",
        "    def _setup_logger(self) -> logging.Logger:\n",
        "        \"\"\"Set up logger for classification operations.\"\"\"\n",
        "        logger = logging.getLogger(f\"{__name__}.IndoorOutdoorClassifier\")\n",
        "        if not logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "            logger.setLevel(logging.INFO)\n",
        "        return logger\n",
        "\n",
        "    def classify(self, features: Dict[str, Any], places365_info: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Classify scene as indoor or outdoor based on features and Places365 context.\n",
        "\n",
        "        Args:\n",
        "            features: Dictionary containing extracted image features.\n",
        "            places365_info: Optional Places365 classification information.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing classification results including decision, probability,\n",
        "            feature contributions, and diagnostic information.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Starting indoor/outdoor classification\")\n",
        "\n",
        "            # Initialize classification components\n",
        "            visual_score = 0.0\n",
        "            feature_contributions = {}\n",
        "            diagnostics = {}\n",
        "\n",
        "            # Extract Places365 information\n",
        "            p365_context = self._extract_places365_context(places365_info, diagnostics)\n",
        "\n",
        "            # Compute visual evidence score\n",
        "            visual_analysis = self._analyze_visual_evidence(features, diagnostics)\n",
        "            visual_score = visual_analysis[\"visual_score\"]\n",
        "            feature_contributions.update(visual_analysis[\"contributions\"])\n",
        "\n",
        "            # Incorporate Places365 influence\n",
        "            p365_analysis = self._analyze_places365_influence(\n",
        "                p365_context, visual_analysis.get(\"strong_sky_signal\", False), diagnostics\n",
        "            )\n",
        "            p365_influence_score = p365_analysis[\"influence_score\"]\n",
        "            if abs(p365_influence_score) > 0.01:\n",
        "                feature_contributions[\"places365_influence_score\"] = round(p365_influence_score, 2)\n",
        "\n",
        "            # Calculate final score and probability\n",
        "            final_indoor_score = visual_score + p365_influence_score\n",
        "            classification_result = self._compute_final_classification(\n",
        "                final_indoor_score, visual_score, p365_influence_score, diagnostics\n",
        "            )\n",
        "\n",
        "            # Apply Places365 override if conditions are met\n",
        "            override_result = self._apply_places365_override(\n",
        "                classification_result, p365_context, diagnostics\n",
        "            )\n",
        "\n",
        "            # Ensure default values for missing contributions\n",
        "            self._ensure_default_contributions(feature_contributions)\n",
        "\n",
        "            # 最終結果\n",
        "            result = {\n",
        "                \"is_indoor\": override_result[\"is_indoor\"],\n",
        "                \"indoor_probability\": override_result[\"indoor_probability\"],\n",
        "                \"indoor_score_raw\": override_result[\"final_score\"],\n",
        "                \"feature_contributions\": feature_contributions,\n",
        "                \"diagnostics\": diagnostics\n",
        "            }\n",
        "\n",
        "            self.logger.debug(f\"Classification complete: indoor={result['is_indoor']}, \"\n",
        "                            f\"probability={result['indoor_probability']:.3f}\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in indoor/outdoor classification: {str(e)}\")\n",
        "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "            return self._get_default_classification_result()\n",
        "\n",
        "    def _extract_places365_context(self, places365_info: Optional[Dict],\n",
        "                                  diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract and validate Places365 context information.\"\"\"\n",
        "        context = {\n",
        "            \"mapped_scene\": \"unknown\",\n",
        "            \"is_indoor_from_classification\": None,\n",
        "            \"attributes\": [],\n",
        "            \"confidence\": 0.0,\n",
        "            \"is_indoor\": None\n",
        "        }\n",
        "\n",
        "        if places365_info:\n",
        "            context[\"mapped_scene\"] = places365_info.get('mapped_scene_type', 'unknown').lower()\n",
        "            context[\"attributes\"] = [attr.lower() for attr in places365_info.get('attributes', [])]\n",
        "            context[\"confidence\"] = places365_info.get('confidence', 0.0)\n",
        "            context[\"is_indoor_from_classification\"] = places365_info.get('is_indoor_from_classification', None)\n",
        "            context[\"is_indoor\"] = places365_info.get('is_indoor', None)\n",
        "\n",
        "            diagnostics[\"p365_context_received\"] = (\n",
        "                f\"P365 Scene: {context['mapped_scene']}, P365 SceneConf: {context['confidence']:.2f}, \"\n",
        "                f\"P365 DirectIndoor: {context['is_indoor_from_classification']}, \"\n",
        "                f\"P365 Attrs: {context['attributes']}\"\n",
        "            )\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _analyze_visual_evidence(self, features: Dict[str, Any],\n",
        "                                diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze visual evidence for indoor/outdoor classification.\"\"\"\n",
        "        visual_score = 0.0\n",
        "        contributions = {}\n",
        "        strong_sky_signal = False\n",
        "\n",
        "        # Sky and openness analysis\n",
        "        sky_analysis = self._analyze_sky_evidence(features, diagnostics)\n",
        "        visual_score += sky_analysis[\"score\"]\n",
        "        if sky_analysis[\"score\"] != 0:\n",
        "            contributions[\"sky_openness_features_visual\"] = round(sky_analysis[\"score\"], 2)\n",
        "        strong_sky_signal = sky_analysis[\"strong_signal\"]\n",
        "\n",
        "        # Enclosure and structural analysis\n",
        "        enclosure_analysis = self._analyze_enclosure_evidence(features, strong_sky_signal, diagnostics)\n",
        "        visual_score += enclosure_analysis[\"score\"]\n",
        "        if enclosure_analysis[\"score\"] != 0:\n",
        "            contributions[\"enclosure_features\"] = round(enclosure_analysis[\"score\"], 2)\n",
        "\n",
        "        # Brightness uniformity analysis\n",
        "        uniformity_analysis = self._analyze_brightness_uniformity(features, strong_sky_signal, diagnostics)\n",
        "        visual_score += uniformity_analysis[\"score\"]\n",
        "        if uniformity_analysis[\"score\"] != 0:\n",
        "            contributions[\"brightness_uniformity_contribution\"] = round(uniformity_analysis[\"score\"], 2)\n",
        "\n",
        "        # Light source analysis\n",
        "        light_analysis = self._analyze_light_sources(features, strong_sky_signal, diagnostics)\n",
        "        visual_score += light_analysis[\"score\"]\n",
        "        if light_analysis[\"score\"] != 0:\n",
        "            contributions[\"light_source_features\"] = round(light_analysis[\"score\"], 2)\n",
        "\n",
        "        # Color atmosphere analysis\n",
        "        atmosphere_analysis = self._analyze_color_atmosphere(features, strong_sky_signal, diagnostics)\n",
        "        visual_score += atmosphere_analysis[\"score\"]\n",
        "        if atmosphere_analysis[\"score\"] != 0:\n",
        "            contributions[\"warm_atmosphere_indoor_visual_contrib\"] = round(atmosphere_analysis[\"score\"], 2)\n",
        "\n",
        "        # Home environment pattern analysis\n",
        "        home_analysis = self._analyze_home_environment_pattern(features, strong_sky_signal, diagnostics)\n",
        "        visual_score += home_analysis[\"score\"]\n",
        "        if home_analysis[\"score\"] != 0:\n",
        "            contributions[\"home_environment_pattern_visual\"] = round(home_analysis[\"score\"], 2)\n",
        "\n",
        "        # Aerial street pattern analysis\n",
        "        aerial_analysis = self._analyze_aerial_street_pattern(features, strong_sky_signal, contributions, diagnostics)\n",
        "        visual_score += aerial_analysis[\"score\"]\n",
        "        if aerial_analysis[\"score\"] != 0:\n",
        "            contributions[\"aerial_street_pattern_visual\"] = round(aerial_analysis[\"score\"], 2)\n",
        "\n",
        "        diagnostics[\"visual_indoor_score_subtotal\"] = round(visual_score, 3)\n",
        "\n",
        "        return {\n",
        "            \"visual_score\": visual_score,\n",
        "            \"contributions\": contributions,\n",
        "            \"strong_sky_signal\": strong_sky_signal\n",
        "        }\n",
        "\n",
        "    def _analyze_sky_evidence(self, features: Dict[str, Any],\n",
        "                             diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze sky-related evidence for outdoor classification.\"\"\"\n",
        "        sky_evidence_score = 0.0\n",
        "        strong_sky_signal = False\n",
        "\n",
        "        # Extract relevant features\n",
        "        sky_blue_dominance = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        texture_complexity = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        openness_top_edge = features.get(\"openness_top_edge\", 0.5)\n",
        "\n",
        "        # Get thresholds\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "\n",
        "        # Strong blue sky signal\n",
        "        if sky_blue_dominance > thresholds.sky_blue_dominance_thresh:\n",
        "            sky_evidence_score -= weights.sky_blue_dominance_w * sky_blue_dominance\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = f\"Visual: Strong sky-like blue ({sky_blue_dominance:.2f})\"\n",
        "            strong_sky_signal = True\n",
        "\n",
        "        # Bright top region with low texture\n",
        "        elif (sky_brightness_ratio > getattr(thresholds, 'sky_brightness_ratio_strong_thresh', 1.35) and\n",
        "              texture_complexity < getattr(thresholds, 'sky_texture_complexity_clear_thresh', 0.25)):\n",
        "            outdoor_push = weights.sky_brightness_ratio_w * (sky_brightness_ratio - 1.0)\n",
        "            sky_evidence_score -= outdoor_push\n",
        "            sky_evidence_score -= weights.sky_texture_w\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = (\n",
        "                f\"Visual: Top brighter (ratio:{sky_brightness_ratio:.2f}) & low texture.\"\n",
        "            )\n",
        "            strong_sky_signal = True\n",
        "\n",
        "        # High top edge openness\n",
        "        elif openness_top_edge > getattr(thresholds, 'openness_top_strong_thresh', 0.80):\n",
        "            sky_evidence_score -= weights.openness_top_w * openness_top_edge\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = (\n",
        "                f\"Visual: Very high top edge openness ({openness_top_edge:.2f}).\"\n",
        "            )\n",
        "            strong_sky_signal = True\n",
        "\n",
        "        # Weak sky signal (cloudy conditions)\n",
        "        elif (not strong_sky_signal and\n",
        "              texture_complexity < getattr(thresholds, 'sky_texture_complexity_cloudy_thresh', 0.20) and\n",
        "              sky_brightness_ratio > getattr(thresholds, 'sky_brightness_ratio_cloudy_thresh', 0.95)):\n",
        "            sky_evidence_score -= weights.sky_texture_w * (1.0 - texture_complexity) * 0.5\n",
        "            diagnostics[\"sky_detection_reason_visual\"] = (\n",
        "                f\"Visual: Weak sky signal (low texture, brightish top: {texture_complexity:.2f}), less weight.\"\n",
        "            )\n",
        "\n",
        "        if strong_sky_signal:\n",
        "            diagnostics[\"strong_sky_signal_visual_detected\"] = True\n",
        "\n",
        "        return {\n",
        "            \"score\": sky_evidence_score,\n",
        "            \"strong_signal\": strong_sky_signal\n",
        "        }\n",
        "\n",
        "    def _analyze_enclosure_evidence(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                                   diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze enclosure evidence for indoor classification.\"\"\"\n",
        "        enclosure_score = 0.0\n",
        "\n",
        "        # Extract features\n",
        "        ceiling_likelihood = features.get(\"ceiling_likelihood\", 0.0)\n",
        "        boundary_clarity = features.get(\"boundary_clarity\", 0.0)\n",
        "        texture_complexity = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        openness_top_edge = features.get(\"openness_top_edge\", 0.5)\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "        override_factors = self.config_manager.override_factors\n",
        "\n",
        "        # Ceiling likelihood analysis\n",
        "        if ceiling_likelihood > thresholds.ceiling_likelihood_thresh:\n",
        "            current_ceiling_score = weights.ceiling_likelihood_w * ceiling_likelihood\n",
        "            if strong_sky_signal:\n",
        "                current_ceiling_score *= override_factors.sky_override_factor_ceiling\n",
        "            enclosure_score += current_ceiling_score\n",
        "            diagnostics[\"indoor_reason_ceiling_visual\"] = (\n",
        "                f\"Visual Ceiling: {ceiling_likelihood:.2f}, ScoreCont: {current_ceiling_score:.2f}\"\n",
        "            )\n",
        "\n",
        "        # Boundary clarity analysis\n",
        "        if boundary_clarity > thresholds.boundary_clarity_thresh:\n",
        "            current_boundary_score = weights.boundary_clarity_w * boundary_clarity\n",
        "            if strong_sky_signal:\n",
        "                current_boundary_score *= override_factors.sky_override_factor_boundary\n",
        "            enclosure_score += current_boundary_score\n",
        "            diagnostics[\"indoor_reason_boundary_visual\"] = (\n",
        "                f\"Visual Boundary: {boundary_clarity:.2f}, ScoreCont: {current_boundary_score:.2f}\"\n",
        "            )\n",
        "\n",
        "        # Complex urban top detection\n",
        "        if (not strong_sky_signal and texture_complexity > 0.7 and\n",
        "            openness_top_edge < 0.3 and ceiling_likelihood < 0.35):\n",
        "            diagnostics[\"complex_urban_top_visual\"] = True\n",
        "            if boundary_clarity > 0.5:\n",
        "                enclosure_score *= 0.5\n",
        "                diagnostics[\"reduced_enclosure_for_urban_top_visual\"] = True\n",
        "\n",
        "        return {\"score\": enclosure_score}\n",
        "\n",
        "    def _analyze_brightness_uniformity(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                                      diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze brightness uniformity patterns.\"\"\"\n",
        "        uniformity_score = 0.0\n",
        "\n",
        "        # Calculate brightness uniformity\n",
        "        brightness_std = features.get(\"brightness_std\", 50.0)\n",
        "        avg_brightness = features.get(\"avg_brightness\", 100.0)\n",
        "        brightness_uniformity = 1.0 - min(1.0, brightness_std / max(avg_brightness, 1e-5))\n",
        "        shadow_clarity = features.get(\"shadow_clarity_score\", 0.5)\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "        override_factors = self.config_manager.override_factors\n",
        "\n",
        "        # High uniformity (indoor indicator)\n",
        "        if brightness_uniformity > thresholds.brightness_uniformity_thresh_indoor:\n",
        "            uniformity_score = weights.brightness_uniformity_w * brightness_uniformity\n",
        "            if strong_sky_signal:\n",
        "                uniformity_score *= override_factors.sky_override_factor_uniformity\n",
        "\n",
        "        # Low uniformity (potential outdoor indicator)\n",
        "        elif brightness_uniformity < thresholds.brightness_uniformity_thresh_outdoor:\n",
        "            if shadow_clarity > 0.65:\n",
        "                uniformity_score = -weights.brightness_non_uniformity_outdoor_w * (1.0 - brightness_uniformity)\n",
        "            elif not strong_sky_signal:\n",
        "                uniformity_score = weights.brightness_non_uniformity_indoor_penalty_w * (1.0 - brightness_uniformity)\n",
        "\n",
        "        return {\"score\": uniformity_score}\n",
        "\n",
        "    def _analyze_light_sources(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                              diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze artificial light source patterns.\"\"\"\n",
        "        light_score = 0.0\n",
        "\n",
        "        # Extract light features\n",
        "        indoor_light_score = features.get(\"indoor_light_score\", 0.0)\n",
        "        circular_light_count = features.get(\"circular_light_count\", 0)\n",
        "        bright_spot_count = features.get(\"bright_spot_count\", 0)\n",
        "        avg_brightness = features.get(\"avg_brightness\", 100.0)\n",
        "        gradient_ratio = features.get(\"gradient_ratio_vertical_horizontal\", 1.0)\n",
        "        edges_density = features.get(\"edges_density\", 0.0)\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "        override_factors = self.config_manager.override_factors\n",
        "\n",
        "        # Circular lights detection\n",
        "        if circular_light_count >= 1 and not strong_sky_signal:\n",
        "            light_score += weights.circular_lights_w * circular_light_count\n",
        "\n",
        "        # Indoor light score\n",
        "        elif indoor_light_score > 0.55 and not strong_sky_signal:\n",
        "            light_score += weights.indoor_light_score_w * indoor_light_score\n",
        "\n",
        "        # Many bright spots in dim scenes\n",
        "        elif (bright_spot_count > thresholds.many_bright_spots_thresh and\n",
        "              avg_brightness < thresholds.dim_scene_for_spots_thresh and\n",
        "              not strong_sky_signal):\n",
        "            light_score += weights.many_bright_spots_indoor_w * min(bright_spot_count / 10.0, 1.5)\n",
        "\n",
        "        # Street structure detection\n",
        "        is_likely_street_structure = (0.7 < gradient_ratio < 1.5) and edges_density > 0.15\n",
        "\n",
        "        if is_likely_street_structure and bright_spot_count > 3 and not strong_sky_signal:\n",
        "            light_score *= 0.2\n",
        "            diagnostics[\"street_lights_heuristic_visual\"] = True\n",
        "        elif strong_sky_signal:\n",
        "            light_score *= override_factors.sky_override_factor_lights\n",
        "\n",
        "        return {\"score\": light_score}\n",
        "\n",
        "    def _analyze_color_atmosphere(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                                 diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze color atmosphere patterns.\"\"\"\n",
        "        atmosphere_score = 0.0\n",
        "\n",
        "        # Extract features\n",
        "        color_atmosphere = features.get(\"color_atmosphere\", \"neutral\")\n",
        "        avg_brightness = features.get(\"avg_brightness\", 100.0)\n",
        "        avg_saturation = features.get(\"avg_saturation\", 100.0)\n",
        "        gradient_ratio = features.get(\"gradient_ratio_vertical_horizontal\", 1.0)\n",
        "        edges_density = features.get(\"edges_density\", 0.0)\n",
        "        indoor_light_score = features.get(\"indoor_light_score\", 0.0)\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "\n",
        "        # Warm atmosphere analysis\n",
        "        if (color_atmosphere == \"warm\" and\n",
        "            avg_brightness < thresholds.warm_indoor_max_brightness_thresh):\n",
        "\n",
        "            # Check exclusion conditions\n",
        "            is_likely_street_structure = (0.7 < gradient_ratio < 1.5) and edges_density > 0.15\n",
        "            is_complex_urban_top = diagnostics.get(\"complex_urban_top_visual\", False)\n",
        "\n",
        "            if (not strong_sky_signal and not is_complex_urban_top and\n",
        "                not (is_likely_street_structure and avg_brightness > 80) and\n",
        "                avg_saturation < 160):\n",
        "\n",
        "                if indoor_light_score > 0.05:\n",
        "                    atmosphere_score = weights.warm_atmosphere_indoor_w\n",
        "\n",
        "        return {\"score\": atmosphere_score}\n",
        "\n",
        "    def _analyze_home_environment_pattern(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                                         diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze home/residential environment patterns.\"\"\"\n",
        "        home_score = 0.0\n",
        "\n",
        "        if strong_sky_signal:\n",
        "            diagnostics[\"skipped_home_env_visual_due_to_sky\"] = True\n",
        "            return {\"score\": 0.0}\n",
        "\n",
        "        # Calculate bedroom/home indicators\n",
        "        bedroom_indicators = 0.0\n",
        "        brightness_uniformity = features.get(\"brightness_uniformity\", 0.0)\n",
        "        boundary_clarity = features.get(\"boundary_clarity\", 0.0)\n",
        "        ceiling_likelihood = features.get(\"ceiling_likelihood\", 0.0)\n",
        "        bright_spot_count = features.get(\"bright_spot_count\", 0)\n",
        "        circular_light_count = features.get(\"circular_light_count\", 0)\n",
        "        warm_ratio = features.get(\"warm_ratio\", 0.0)\n",
        "        avg_saturation = features.get(\"avg_saturation\", 100.0)\n",
        "\n",
        "        # Accumulate indicators\n",
        "        if brightness_uniformity > 0.65 and boundary_clarity > 0.40:\n",
        "            bedroom_indicators += 1.1\n",
        "\n",
        "        if ceiling_likelihood > 0.35 and (bright_spot_count > 0 or circular_light_count > 0):\n",
        "            bedroom_indicators += 1.1\n",
        "\n",
        "        if warm_ratio > 0.55 and brightness_uniformity > 0.65:\n",
        "            bedroom_indicators += 1.0\n",
        "\n",
        "        if brightness_uniformity > 0.70 and avg_saturation < 60:\n",
        "            bedroom_indicators += 0.7\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "\n",
        "        # Apply scoring based on indicator strength\n",
        "        if bedroom_indicators >= thresholds.home_pattern_thresh_strong:\n",
        "            home_score = weights.home_env_strong_w\n",
        "        elif bedroom_indicators >= thresholds.home_pattern_thresh_moderate:\n",
        "            home_score = weights.home_env_moderate_w\n",
        "\n",
        "        if bedroom_indicators > 0:\n",
        "            diagnostics[\"home_environment_pattern_visual_indicators\"] = round(bedroom_indicators, 1)\n",
        "\n",
        "        return {\"score\": home_score}\n",
        "\n",
        "    def _analyze_aerial_street_pattern(self, features: Dict[str, Any], strong_sky_signal: bool,\n",
        "                                      contributions: Dict[str, float],\n",
        "                                      diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze aerial view street patterns.\"\"\"\n",
        "        aerial_score = 0.0\n",
        "\n",
        "        # Extract features\n",
        "        sky_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        texture_complexity = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        avg_brightness = features.get(\"avg_brightness\", 100.0)\n",
        "\n",
        "        # Get configuration\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        weights = self.config_manager.weighting_factors\n",
        "\n",
        "        # Aerial street pattern detection\n",
        "        if (sky_brightness_ratio < thresholds.aerial_top_dark_ratio_thresh and\n",
        "            texture_complexity > thresholds.aerial_top_complex_thresh and\n",
        "            avg_brightness > thresholds.aerial_min_avg_brightness_thresh and\n",
        "            not strong_sky_signal):\n",
        "\n",
        "            aerial_score = -weights.aerial_street_w\n",
        "            diagnostics[\"aerial_street_pattern_visual_detected\"] = True\n",
        "\n",
        "            # Reduce enclosure features if aerial pattern detected\n",
        "            if (\"enclosure_features\" in contributions and\n",
        "                contributions[\"enclosure_features\"] > 0):\n",
        "\n",
        "                reduction_factor = self.config_manager.override_factors.aerial_enclosure_reduction_factor\n",
        "                positive_enclosure_score = max(0, contributions[\"enclosure_features\"])\n",
        "                reduction_amount = positive_enclosure_score * reduction_factor\n",
        "\n",
        "                contributions[\"enclosure_features_reduced_by_aerial\"] = round(-reduction_amount, 2)\n",
        "                contributions[\"enclosure_features\"] = round(\n",
        "                    contributions[\"enclosure_features\"] - reduction_amount, 2\n",
        "                )\n",
        "\n",
        "        return {\"score\": aerial_score}\n",
        "\n",
        "    def _analyze_places365_influence(self, p365_context: Dict[str, Any],\n",
        "                                    strong_sky_signal: bool,\n",
        "                                    diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze Places365 influence on classification.\"\"\"\n",
        "        p365_influence_score = 0.0\n",
        "\n",
        "        if not p365_context or p365_context[\"confidence\"] < self.P365_MODERATE_CONF_THRESHOLD:\n",
        "            return {\"influence_score\": 0.0}\n",
        "\n",
        "        # Places365 direct classification influence\n",
        "        if p365_context[\"is_indoor_from_classification\"] is not None:\n",
        "            p365_influence_score += self._compute_direct_classification_influence(\n",
        "                p365_context, strong_sky_signal, diagnostics\n",
        "            )\n",
        "\n",
        "        # Places365 scene context influence\n",
        "        elif p365_context[\"confidence\"] >= self.P365_MODERATE_CONF_THRESHOLD:\n",
        "            p365_influence_score += self._compute_scene_context_influence(\n",
        "                p365_context, strong_sky_signal, diagnostics\n",
        "            )\n",
        "\n",
        "        # Places365 attributes influence\n",
        "        if p365_context[\"attributes\"] and p365_context[\"confidence\"] > 0.5:\n",
        "            p365_influence_score += self._compute_attributes_influence(\n",
        "                p365_context, strong_sky_signal, diagnostics\n",
        "            )\n",
        "\n",
        "        # High confidence street scene boost\n",
        "        if (p365_context[\"confidence\"] >= 0.85 and\n",
        "            any(kw in p365_context[\"mapped_scene\"] for kw in [\"intersection\", \"crosswalk\", \"street\", \"road\"])):\n",
        "\n",
        "            additional_outdoor_push = -3.0 * p365_context[\"confidence\"]\n",
        "            p365_influence_score += additional_outdoor_push\n",
        "            diagnostics[\"p365_street_scene_boost\"] = (\n",
        "                f\"Additional outdoor push: {additional_outdoor_push:.2f} for street scene: \"\n",
        "                f\"{p365_context['mapped_scene']}\"\n",
        "            )\n",
        "            self.logger.debug(f\"High confidence street scene detected - \"\n",
        "                            f\"{p365_context['mapped_scene']} with confidence {p365_context['confidence']:.3f}\")\n",
        "\n",
        "        return {\"influence_score\": p365_influence_score}\n",
        "\n",
        "    def _compute_direct_classification_influence(self, p365_context: Dict[str, Any],\n",
        "                                               strong_sky_signal: bool,\n",
        "                                               diagnostics: Dict[str, Any]) -> float:\n",
        "        \"\"\"Compute influence from Places365 direct indoor/outdoor classification.\"\"\"\n",
        "        P365_DIRECT_INDOOR_WEIGHT = 3.5\n",
        "        P365_DIRECT_OUTDOOR_WEIGHT = 4.0\n",
        "\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        is_indoor = p365_context[\"is_indoor_from_classification\"]\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "\n",
        "        if is_indoor is True:\n",
        "            current_contrib = P365_DIRECT_INDOOR_WEIGHT * confidence\n",
        "            diagnostics[\"p365_influence_source\"] = (\n",
        "                f\"P365_DirectIndoor(True,Conf:{confidence:.2f},Scene:{mapped_scene})\"\n",
        "            )\n",
        "        else:\n",
        "            current_contrib = -P365_DIRECT_OUTDOOR_WEIGHT * confidence\n",
        "            diagnostics[\"p365_influence_source\"] = (\n",
        "                f\"P365_DirectIndoor(False,Conf:{confidence:.2f},Scene:{mapped_scene})\"\n",
        "            )\n",
        "\n",
        "        # Apply sky override for indoor predictions\n",
        "        if strong_sky_signal and current_contrib > 0:\n",
        "            sky_override_factor = self.config_manager.override_factors.sky_override_factor_p365_indoor_decision\n",
        "            current_contrib *= sky_override_factor\n",
        "            diagnostics[\"p365_indoor_push_reduced_by_visual_sky\"] = f\"Reduced to {current_contrib:.2f}\"\n",
        "\n",
        "        return current_contrib\n",
        "\n",
        "    def _compute_scene_context_influence(self, p365_context: Dict[str, Any],\n",
        "                                        strong_sky_signal: bool,\n",
        "                                        diagnostics: Dict[str, Any]) -> float:\n",
        "        \"\"\"Compute influence from Places365 scene context.\"\"\"\n",
        "        P365_SCENE_CONTEXT_INDOOR_WEIGHT = 2.0\n",
        "        P365_SCENE_CONTEXT_OUTDOOR_WEIGHT = 2.5\n",
        "\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "\n",
        "        is_def_indoor = any(kw in mapped_scene for kw in self.DEFINITELY_INDOOR_KEYWORDS_P365)\n",
        "        is_def_outdoor = any(kw in mapped_scene for kw in self.DEFINITELY_OUTDOOR_KEYWORDS_P365)\n",
        "\n",
        "        current_contrib = 0.0\n",
        "\n",
        "        if is_def_indoor and not is_def_outdoor:\n",
        "            current_contrib = P365_SCENE_CONTEXT_INDOOR_WEIGHT * confidence\n",
        "            diagnostics[\"p365_influence_source\"] = (\n",
        "                f\"P365_SceneContext(Indoor: {mapped_scene}, Conf:{confidence:.2f})\"\n",
        "            )\n",
        "        elif is_def_outdoor and not is_def_indoor:\n",
        "            current_contrib = -P365_SCENE_CONTEXT_OUTDOOR_WEIGHT * confidence\n",
        "            diagnostics[\"p365_influence_source\"] = (\n",
        "                f\"P365_SceneContext(Outdoor: {mapped_scene}, Conf:{confidence:.2f})\"\n",
        "            )\n",
        "\n",
        "        # Apply sky override for indoor predictions\n",
        "        if strong_sky_signal and current_contrib > 0:\n",
        "            sky_override_factor = self.config_manager.override_factors.sky_override_factor_p365_indoor_decision\n",
        "            current_contrib *= sky_override_factor\n",
        "            diagnostics[\"p365_context_indoor_push_reduced_by_visual_sky\"] = f\"Reduced to {current_contrib:.2f}\"\n",
        "\n",
        "        return current_contrib\n",
        "\n",
        "    def _compute_attributes_influence(self, p365_context: Dict[str, Any],\n",
        "                                     strong_sky_signal: bool,\n",
        "                                     diagnostics: Dict[str, Any]) -> float:\n",
        "        \"\"\"Compute influence from Places365 attributes.\"\"\"\n",
        "        P365_ATTRIBUTE_INDOOR_WEIGHT = 1.0\n",
        "        P365_ATTRIBUTE_OUTDOOR_WEIGHT = 1.5\n",
        "\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        attributes = p365_context[\"attributes\"]\n",
        "\n",
        "        attr_contrib = 0.0\n",
        "\n",
        "        if \"indoor\" in attributes and \"outdoor\" not in attributes:\n",
        "            attr_contrib += P365_ATTRIBUTE_INDOOR_WEIGHT * (confidence * 0.5)\n",
        "            diagnostics[\"p365_attr_influence\"] = f\"+{attr_contrib:.2f} (indoor attr)\"\n",
        "        elif \"outdoor\" in attributes and \"indoor\" not in attributes:\n",
        "            attr_contrib -= P365_ATTRIBUTE_OUTDOOR_WEIGHT * (confidence * 0.5)\n",
        "            diagnostics[\"p365_attr_influence\"] = f\"{attr_contrib:.2f} (outdoor attr)\"\n",
        "\n",
        "        # Apply sky override for indoor attributes\n",
        "        if strong_sky_signal and attr_contrib > 0:\n",
        "            sky_override_factor = self.config_manager.override_factors.sky_override_factor_p365_indoor_decision\n",
        "            attr_contrib *= sky_override_factor\n",
        "\n",
        "        return attr_contrib\n",
        "\n",
        "    def _compute_final_classification(self, final_indoor_score: float, visual_score: float,\n",
        "                                     p365_influence_score: float, diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Compute final classification probability and decision.\"\"\"\n",
        "        # Record score breakdown\n",
        "        diagnostics[\"final_indoor_score_value\"] = round(final_indoor_score, 3)\n",
        "        diagnostics[\"final_score_breakdown\"] = (\n",
        "            f\"VisualScore: {visual_score:.2f}, P365Influence: {p365_influence_score:.2f}\"\n",
        "        )\n",
        "\n",
        "        # Apply sigmoid transformation\n",
        "        sigmoid_scale = self.config_manager.algorithm_parameters.indoor_score_sigmoid_scale\n",
        "        indoor_probability = 1 / (1 + np.exp(-final_indoor_score * sigmoid_scale))\n",
        "\n",
        "        # Make decision\n",
        "        decision_threshold = self.config_manager.algorithm_parameters.indoor_decision_threshold\n",
        "        is_indoor = indoor_probability > decision_threshold\n",
        "\n",
        "        return {\n",
        "            \"is_indoor\": is_indoor,\n",
        "            \"indoor_probability\": indoor_probability,\n",
        "            \"final_score\": final_indoor_score\n",
        "        }\n",
        "\n",
        "    def _apply_places365_override(self, classification_result: Dict[str, Any],\n",
        "                                 p365_context: Dict[str, Any],\n",
        "                                 diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Apply Places365 high-confidence override if conditions are met.\"\"\"\n",
        "        is_indoor = classification_result[\"is_indoor\"]\n",
        "        indoor_probability = classification_result[\"indoor_probability\"]\n",
        "        final_score = classification_result[\"final_score\"]\n",
        "\n",
        "        # Check for override conditions\n",
        "        if not p365_context or p365_context[\"confidence\"] < 0.5:\n",
        "            diagnostics[\"final_indoor_probability_calculated\"] = round(indoor_probability, 3)\n",
        "            diagnostics[\"final_is_indoor_decision\"] = bool(is_indoor)\n",
        "            return classification_result\n",
        "\n",
        "        p365_is_indoor_decision = p365_context.get(\"is_indoor\", None)\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "\n",
        "        self.logger.debug(f\"Override check: is_indoor={is_indoor}, p365_conf={confidence}, \"\n",
        "                         f\"p365_raw_is_indoor={p365_is_indoor_decision}\")\n",
        "\n",
        "        # Apply override for high confidence Places365 decisions\n",
        "        if p365_is_indoor_decision is not None:\n",
        "            if p365_is_indoor_decision == False:\n",
        "                self.logger.debug(f\"Applying outdoor override. Original: {is_indoor}\")\n",
        "                original_decision = f\"Indoor:{is_indoor}, Prob:{indoor_probability:.3f}, Score:{final_score:.2f}\"\n",
        "\n",
        "                is_indoor = False\n",
        "                indoor_probability = 0.02\n",
        "                final_score = -8.0\n",
        "\n",
        "                diagnostics[\"p365_force_override_applied\"] = (\n",
        "                    f\"P365 FORCED OUTDOOR (is_indoor: {p365_is_indoor_decision}, Conf: {confidence:.3f})\"\n",
        "                )\n",
        "                diagnostics[\"p365_override_original_decision\"] = original_decision\n",
        "                self.logger.info(f\"Places365 FORCED OUTDOOR override applied. New is_indoor: {is_indoor}\")\n",
        "\n",
        "            elif p365_is_indoor_decision == True:\n",
        "                self.logger.debug(f\"Applying indoor override. Original: {is_indoor}\")\n",
        "                original_decision = f\"Indoor:{is_indoor}, Prob:{indoor_probability:.3f}, Score:{final_score:.2f}\"\n",
        "\n",
        "                is_indoor = True\n",
        "                indoor_probability = 0.98\n",
        "                final_score = 8.0\n",
        "\n",
        "                diagnostics[\"p365_force_override_applied\"] = (\n",
        "                    f\"P365 FORCED INDOOR (is_indoor: {p365_is_indoor_decision}, Conf: {confidence:.3f})\"\n",
        "                )\n",
        "                diagnostics[\"p365_override_original_decision\"] = original_decision\n",
        "                self.logger.info(f\"Places365 FORCED INDOOR override applied. New is_indoor: {is_indoor}\")\n",
        "\n",
        "        # Record final values\n",
        "        diagnostics[\"final_indoor_probability_calculated\"] = round(indoor_probability, 3)\n",
        "        diagnostics[\"final_is_indoor_decision\"] = bool(is_indoor)\n",
        "\n",
        "        self.logger.debug(f\"Final classification: is_indoor={is_indoor}, score={final_score}, prob={indoor_probability}\")\n",
        "\n",
        "        return {\n",
        "            \"is_indoor\": is_indoor,\n",
        "            \"indoor_probability\": indoor_probability,\n",
        "            \"final_score\": final_score\n",
        "        }\n",
        "\n",
        "    def _ensure_default_contributions(self, feature_contributions: Dict[str, float]) -> None:\n",
        "        \"\"\"Ensure all expected feature contribution keys have default values.\"\"\"\n",
        "        default_keys = [\n",
        "            \"sky_openness_features\", \"enclosure_features\",\n",
        "            \"brightness_uniformity_contribution\", \"light_source_features\"\n",
        "        ]\n",
        "\n",
        "        for key in default_keys:\n",
        "            if key not in feature_contributions:\n",
        "                feature_contributions[key] = 0.0\n",
        "\n",
        "    def _get_default_classification_result(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return default classification result in case of errors.\"\"\"\n",
        "        return {\n",
        "            \"is_indoor\": False,\n",
        "            \"indoor_probability\": 0.5,\n",
        "            \"indoor_score_raw\": 0.0,\n",
        "            \"feature_contributions\": {\n",
        "                \"sky_openness_features\": 0.0,\n",
        "                \"enclosure_features\": 0.0,\n",
        "                \"brightness_uniformity_contribution\": 0.0,\n",
        "                \"light_source_features\": 0.0\n",
        "            },\n",
        "            \"diagnostics\": {\n",
        "                \"error\": \"Classification failed, using default values\"\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "o0THZpTbtJoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635e95f1-3651-4d09-eb4e-97e0e96f14c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing indoor_outdoor_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile lighting_condition_analyzer.py\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Optional, List, Tuple\n",
        "# from configuration_manager import ConfigurationManager\n",
        "\n",
        "\n",
        "class LightingConditionAnalyzer:\n",
        "    \"\"\"\n",
        "    Determines specific lighting conditions and time of day based on scene analysis.\n",
        "    此class 會判斷一些光線的特定場景\n",
        "\n",
        "    This class analyzes lighting characteristics including natural and artificial illumination,\n",
        "    color temperature patterns, and temporal indicators to classify scenes into specific\n",
        "    lighting categories such as day clear, night with lights, indoor artificial, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_manager: ConfigurationManager):\n",
        "        \"\"\"\n",
        "        Initialize the lighting condition analyzer.\n",
        "\n",
        "        Args:\n",
        "            config_manager: Configuration manager instance for accessing thresholds and parameters.\n",
        "        \"\"\"\n",
        "        self.config_manager = config_manager\n",
        "        self.logger = self._setup_logger()\n",
        "\n",
        "        # Internal threshold constants for Places365 analysis\n",
        "        self.P365_ATTRIBUTE_CONF_THRESHOLD = 0.60\n",
        "        self.P365_SCENE_MODERATE_CONF_THRESHOLD = 0.45\n",
        "        self.P365_SCENE_HIGH_CONF_THRESHOLD = 0.70\n",
        "\n",
        "        # Scene type keyword definitions\n",
        "        self.P365_OUTDOOR_SCENE_KEYWORDS = [\n",
        "            \"street\", \"road\", \"highway\", \"park\", \"beach\", \"mountain\", \"forest\", \"field\",\n",
        "            \"outdoor\", \"sky\", \"coast\", \"courtyard\", \"square\", \"plaza\", \"bridge\",\n",
        "            \"parking\", \"playground\", \"stadium\", \"construction\", \"river\", \"ocean\", \"desert\",\n",
        "            \"garden\", \"trail\", \"natural_landmark\", \"airport_outdoor\", \"train_station_outdoor\",\n",
        "            \"bus_station_outdoor\", \"intersection\", \"crosswalk\", \"sidewalk\", \"pathway\"\n",
        "        ]\n",
        "\n",
        "        self.P365_INDOOR_RESTAURANT_KEYWORDS = [\n",
        "            \"restaurant\", \"bar\", \"cafe\", \"dining_room\", \"pub\", \"bistro\", \"eatery\"\n",
        "        ]\n",
        "\n",
        "    def _setup_logger(self) -> logging.Logger:\n",
        "        \"\"\"Set up logger for lighting condition analysis operations.\"\"\"\n",
        "        logger = logging.getLogger(f\"{__name__}.LightingConditionAnalyzer\")\n",
        "        if not logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "            logger.setLevel(logging.INFO)\n",
        "        return logger\n",
        "\n",
        "    def analyze_lighting_conditions(self, features: Dict[str, Any], is_indoor: bool,\n",
        "                                   places365_info: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Determine specific lighting conditions based on features and scene context.\n",
        "\n",
        "        Args:\n",
        "            features: Dictionary containing extracted image features.\n",
        "            is_indoor: Boolean indicating whether the scene is indoor (from previous classification).\n",
        "            places365_info: Optional Places365 classification information.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing lighting analysis results including time_of_day, confidence,\n",
        "            and diagnostic information.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(f\"Starting lighting analysis for {'indoor' if is_indoor else 'outdoor'} scene\")\n",
        "\n",
        "            # Initialize analysis results\n",
        "            time_of_day = \"unknown\"\n",
        "            confidence = 0.5\n",
        "            diagnostics = {}\n",
        "\n",
        "            # Extract Places365 context\n",
        "            p365_context = self._extract_places365_context(places365_info, diagnostics)\n",
        "\n",
        "            # Priority 1: Use Places365 attributes if highly confident\n",
        "            attribute_result = self._analyze_places365_attributes(\n",
        "                p365_context, is_indoor, features, diagnostics\n",
        "            )\n",
        "\n",
        "            if attribute_result[\"determined\"] and attribute_result[\"confidence\"] >= 0.75:\n",
        "                self.logger.debug(f\"High-confidence Places365 attribute determination: {attribute_result['time_of_day']}\")\n",
        "                return {\n",
        "                    \"time_of_day\": attribute_result[\"time_of_day\"],\n",
        "                    \"confidence\": attribute_result[\"confidence\"],\n",
        "                    \"diagnostics\": diagnostics\n",
        "                }\n",
        "\n",
        "            # Priority 2: Visual feature analysis with Places365 scene context\n",
        "            visual_result = self._analyze_visual_features(\n",
        "                features, is_indoor, p365_context, diagnostics\n",
        "            )\n",
        "\n",
        "            time_of_day = visual_result[\"time_of_day\"]\n",
        "            confidence = visual_result[\"confidence\"]\n",
        "\n",
        "            # Combine with attribute result if it exists but wasn't decisive\n",
        "            if attribute_result[\"determined\"]:\n",
        "                combined_result = self._combine_attribute_and_visual_results(\n",
        "                    attribute_result, visual_result, diagnostics\n",
        "                )\n",
        "                time_of_day = combined_result[\"time_of_day\"]\n",
        "                confidence = combined_result[\"confidence\"]\n",
        "\n",
        "            # Priority 3: Special lighting refinement (neon, sodium vapor)\n",
        "            refined_result = self._apply_special_lighting_refinement(\n",
        "                time_of_day, confidence, features, is_indoor, p365_context, diagnostics\n",
        "            )\n",
        "\n",
        "            time_of_day = refined_result[\"time_of_day\"]\n",
        "            confidence = refined_result[\"confidence\"]\n",
        "\n",
        "            # Final confidence clamping\n",
        "            confidence = min(0.95, max(0.50, confidence))\n",
        "\n",
        "            # Record final results\n",
        "            diagnostics[\"final_lighting_time_of_day\"] = time_of_day\n",
        "            diagnostics[\"final_lighting_confidence\"] = round(confidence, 3)\n",
        "\n",
        "            self.logger.debug(f\"Lighting analysis complete: {time_of_day} (confidence: {confidence:.3f})\")\n",
        "\n",
        "            return {\n",
        "                \"time_of_day\": time_of_day,\n",
        "                \"confidence\": confidence,\n",
        "                \"diagnostics\": diagnostics\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in lighting condition analysis: {str(e)}\")\n",
        "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "            return self._get_default_lighting_result()\n",
        "\n",
        "    def _extract_places365_context(self, places365_info: Optional[Dict],\n",
        "                                  diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract and validate Places365 context information for lighting analysis.\"\"\"\n",
        "        context = {\n",
        "            \"mapped_scene\": \"unknown\",\n",
        "            \"attributes\": [],\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "\n",
        "        if places365_info:\n",
        "            context[\"mapped_scene\"] = places365_info.get('mapped_scene_type', 'unknown').lower()\n",
        "            context[\"attributes\"] = [attr.lower() for attr in places365_info.get('attributes', [])]\n",
        "            context[\"confidence\"] = places365_info.get('confidence', 0.0)\n",
        "\n",
        "            diagnostics[\"p365_context_for_lighting\"] = (\n",
        "                f\"P365 Scene: {context['mapped_scene']}, Attrs: {context['attributes']}, \"\n",
        "                f\"Conf: {context['confidence']:.2f}\"\n",
        "            )\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _analyze_places365_attributes(self, p365_context: Dict[str, Any], is_indoor: bool,\n",
        "                                     features: Dict[str, Any], diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze Places365 attributes for lighting condition determination.\"\"\"\n",
        "        if (not p365_context[\"attributes\"] or\n",
        "            p365_context[\"confidence\"] <= self.P365_ATTRIBUTE_CONF_THRESHOLD):\n",
        "            return {\"determined\": False, \"time_of_day\": \"unknown\", \"confidence\": 0.5}\n",
        "\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        attributes = p365_context[\"attributes\"]\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "\n",
        "        # Outdoor attribute analysis\n",
        "        if not is_indoor:\n",
        "            outdoor_result = self._analyze_outdoor_attributes(\n",
        "                attributes, mapped_scene, confidence, diagnostics\n",
        "            )\n",
        "            if outdoor_result[\"determined\"]:\n",
        "                return outdoor_result\n",
        "\n",
        "        # Indoor attribute analysis\n",
        "        if is_indoor:\n",
        "            indoor_result = self._analyze_indoor_attributes(\n",
        "                attributes, mapped_scene, features, confidence, diagnostics\n",
        "            )\n",
        "            if indoor_result[\"determined\"]:\n",
        "                return indoor_result\n",
        "\n",
        "        return {\"determined\": False, \"time_of_day\": \"unknown\", \"confidence\": 0.5}\n",
        "\n",
        "    def _analyze_outdoor_attributes(self, attributes: List[str], mapped_scene: str,\n",
        "                                   confidence: float, diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze Places365 attributes for outdoor lighting conditions.\"\"\"\n",
        "        base_confidence_boost = (confidence - self.P365_ATTRIBUTE_CONF_THRESHOLD) * 0.25\n",
        "\n",
        "        if \"sunny\" in attributes or \"clear sky\" in attributes:\n",
        "            final_confidence = 0.85 + base_confidence_boost\n",
        "            diagnostics[\"reason\"] = \"P365 attribute: sunny/clear sky (Outdoor).\"\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": \"day_clear\",\n",
        "                \"confidence\": final_confidence\n",
        "            }\n",
        "\n",
        "        elif \"nighttime\" in attributes or \"night\" in attributes:\n",
        "            if (\"artificial lighting\" in attributes or \"man-made lighting\" in attributes or\n",
        "                any(kw in mapped_scene for kw in [\"street\", \"city\", \"road\", \"urban\", \"downtown\"])):\n",
        "                final_confidence = 0.82 + base_confidence_boost * 0.8\n",
        "                diagnostics[\"reason\"] = \"P365 attribute: nighttime with artificial/street lights (Outdoor).\"\n",
        "                return {\n",
        "                    \"determined\": True,\n",
        "                    \"time_of_day\": \"night_with_lights\",\n",
        "                    \"confidence\": final_confidence\n",
        "                }\n",
        "            else:\n",
        "                final_confidence = 0.78 + base_confidence_boost * 0.8\n",
        "                diagnostics[\"reason\"] = \"P365 attribute: nighttime, dark (Outdoor).\"\n",
        "                return {\n",
        "                    \"determined\": True,\n",
        "                    \"time_of_day\": \"night_dark\",\n",
        "                    \"confidence\": final_confidence\n",
        "                }\n",
        "\n",
        "        elif \"cloudy\" in attributes or \"overcast\" in attributes:\n",
        "            final_confidence = 0.80 + base_confidence_boost\n",
        "            diagnostics[\"reason\"] = \"P365 attribute: cloudy/overcast (Outdoor).\"\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": \"day_cloudy_overcast\",\n",
        "                \"confidence\": final_confidence\n",
        "            }\n",
        "\n",
        "        return {\"determined\": False, \"time_of_day\": \"unknown\", \"confidence\": 0.5}\n",
        "\n",
        "    def _analyze_indoor_attributes(self, attributes: List[str], mapped_scene: str,\n",
        "                                  features: Dict[str, Any], confidence: float,\n",
        "                                  diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze Places365 attributes for indoor lighting conditions.\"\"\"\n",
        "        base_confidence_boost = (confidence - self.P365_ATTRIBUTE_CONF_THRESHOLD) * 0.20\n",
        "        avg_brightness = features.get(\"avg_brightness\", 128.0)\n",
        "\n",
        "        if \"artificial lighting\" in attributes or \"man-made lighting\" in attributes:\n",
        "            base_indoor_conf = 0.70 + base_confidence_boost\n",
        "            thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "            if avg_brightness > thresholds.indoor_bright_thresh:\n",
        "                time_of_day = \"indoor_bright_artificial\"\n",
        "                final_confidence = base_indoor_conf + 0.10\n",
        "            elif avg_brightness > thresholds.indoor_moderate_thresh:\n",
        "                time_of_day = \"indoor_moderate_artificial\"\n",
        "                final_confidence = base_indoor_conf\n",
        "            else:\n",
        "                time_of_day = \"indoor_dim_artificial\"\n",
        "                final_confidence = base_indoor_conf - 0.05\n",
        "\n",
        "            diagnostics[\"reason\"] = (\n",
        "                f\"P365 attribute: artificial lighting (Indoor), \"\n",
        "                f\"brightness based category: {time_of_day}.\"\n",
        "            )\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": time_of_day,\n",
        "                \"confidence\": final_confidence\n",
        "            }\n",
        "\n",
        "        elif \"natural lighting\" in attributes:\n",
        "            is_applicable_scene = (\n",
        "                self._check_home_environment_pattern(features) or\n",
        "                any(kw in mapped_scene for kw in [\"living_room\", \"bedroom\", \"sunroom\"])\n",
        "            )\n",
        "            if is_applicable_scene:\n",
        "                final_confidence = 0.80 + base_confidence_boost\n",
        "                diagnostics[\"reason\"] = \"P365 attribute: natural lighting in residential/applicable indoor scene.\"\n",
        "                return {\n",
        "                    \"determined\": True,\n",
        "                    \"time_of_day\": \"indoor_residential_natural\",\n",
        "                    \"confidence\": final_confidence\n",
        "                }\n",
        "\n",
        "        return {\"determined\": False, \"time_of_day\": \"unknown\", \"confidence\": 0.5}\n",
        "\n",
        "    def _analyze_visual_features(self, features: Dict[str, Any], is_indoor: bool,\n",
        "                                p365_context: Dict[str, Any], diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze visual features for lighting condition determination.\"\"\"\n",
        "        if is_indoor:\n",
        "            return self._analyze_indoor_visual_features(features, p365_context, diagnostics)\n",
        "        else:\n",
        "            return self._analyze_outdoor_visual_features(features, p365_context, diagnostics)\n",
        "\n",
        "    def _analyze_indoor_visual_features(self, features: Dict[str, Any], p365_context: Dict[str, Any],\n",
        "                                       diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze visual features for indoor lighting conditions.\"\"\"\n",
        "        avg_brightness = features.get(\"avg_brightness\", 128.0)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # Extract relevant features\n",
        "        sky_blue_in_sky_region = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_region_is_brighter = features.get(\"sky_region_brightness_ratio\", 1.0) > 1.05\n",
        "        is_likely_home_environment = self._check_home_environment_pattern(features)\n",
        "\n",
        "        # Lighting and structural features\n",
        "        circular_lights = features.get(\"circular_light_count\", 0)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "        brightness_uniformity = features.get(\"brightness_uniformity\", 0.0)\n",
        "        warm_ratio = features.get(\"warm_ratio\", 0.0)\n",
        "\n",
        "        # Natural light hints calculation\n",
        "        natural_light_hints = 0.0\n",
        "        if sky_blue_in_sky_region > 0.05 and sky_region_is_brighter:\n",
        "            natural_light_hints += 1.0\n",
        "        if brightness_uniformity > 0.65 and features.get(\"brightness_std\", 100.0) < 70:\n",
        "            natural_light_hints += 1.0\n",
        "        if warm_ratio > 0.15 and avg_brightness > 110:\n",
        "            natural_light_hints += 0.5\n",
        "\n",
        "        # Designer lighting detection\n",
        "        is_designer_lit = (\n",
        "            (circular_lights > 0 or bright_spots_overall > 2) and\n",
        "            brightness_uniformity > 0.6 and warm_ratio > 0.2 and avg_brightness > 90\n",
        "        )\n",
        "\n",
        "        # Brightness-based classification\n",
        "        if avg_brightness > thresholds.indoor_bright_thresh:\n",
        "            return self._classify_bright_indoor(\n",
        "                features, natural_light_hints, is_designer_lit, is_likely_home_environment,\n",
        "                p365_context, diagnostics\n",
        "            )\n",
        "        elif avg_brightness > thresholds.indoor_moderate_thresh:\n",
        "            return self._classify_moderate_indoor(\n",
        "                features, is_designer_lit, is_likely_home_environment, p365_context, diagnostics\n",
        "            )\n",
        "        else:\n",
        "            return self._classify_dim_indoor(features, diagnostics)\n",
        "\n",
        "    def _classify_bright_indoor(self, features: Dict[str, Any], natural_light_hints: float,\n",
        "                               is_designer_lit: bool, is_likely_home_environment: bool,\n",
        "                               p365_context: Dict[str, Any], diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify bright indoor lighting conditions.\"\"\"\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        sky_blue_in_sky_region = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_region_is_brighter = features.get(\"sky_region_brightness_ratio\", 1.0) > 1.05\n",
        "\n",
        "        # Natural residential lighting\n",
        "        if (natural_light_hints >= 1.5 and\n",
        "            (is_likely_home_environment or any(kw in mapped_scene for kw in [\"home\", \"residential\", \"living\", \"bedroom\"]))):\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_residential_natural\",\n",
        "                \"confidence\": 0.82\n",
        "            }\n",
        "\n",
        "        # Designer residential lighting\n",
        "        elif (is_designer_lit and\n",
        "              (is_likely_home_environment or any(kw in mapped_scene for kw in [\"home\", \"designer\", \"modern_interior\"]))):\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_designer_residential\",\n",
        "                \"confidence\": 0.85\n",
        "            }\n",
        "\n",
        "        # Mixed natural/artificial lighting\n",
        "        elif sky_blue_in_sky_region > 0.03 and sky_region_is_brighter:\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_bright_natural_mix\",\n",
        "                \"confidence\": 0.78\n",
        "            }\n",
        "\n",
        "        # Pure artificial lighting\n",
        "        else:\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_bright_artificial\",\n",
        "                \"confidence\": 0.75\n",
        "            }\n",
        "\n",
        "    def _classify_moderate_indoor(self, features: Dict[str, Any], is_designer_lit: bool,\n",
        "                                 is_likely_home_environment: bool, p365_context: Dict[str, Any],\n",
        "                                 diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify moderate brightness indoor lighting conditions.\"\"\"\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        warm_ratio = features.get(\"warm_ratio\", 0.0)\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "\n",
        "        # Designer residential lighting\n",
        "        if (is_designer_lit and\n",
        "            (is_likely_home_environment or any(kw in mapped_scene for kw in [\"home\", \"designer\"]))):\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_designer_residential\",\n",
        "                \"confidence\": 0.78\n",
        "            }\n",
        "\n",
        "        # Restaurant/bar lighting\n",
        "        elif warm_ratio > 0.35 and yellow_orange_ratio > 0.1:\n",
        "            return self._classify_restaurant_bar_lighting(\n",
        "                p365_context, features, diagnostics\n",
        "            )\n",
        "\n",
        "        # Standard moderate artificial\n",
        "        else:\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_moderate_artificial\",\n",
        "                \"confidence\": 0.70\n",
        "            }\n",
        "\n",
        "    def _classify_restaurant_bar_lighting(self, p365_context: Dict[str, Any],\n",
        "                                         features: Dict[str, Any],\n",
        "                                         diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify restaurant/bar specific lighting conditions.\"\"\"\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "\n",
        "        # Strong P365 restaurant/bar confirmation\n",
        "        if (any(kw in mapped_scene for kw in self.P365_INDOOR_RESTAURANT_KEYWORDS) and\n",
        "            confidence > self.P365_SCENE_MODERATE_CONF_THRESHOLD):\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Moderate warm tones. P365 context confirms restaurant/bar.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_restaurant_bar\",\n",
        "                \"confidence\": 0.80 + confidence * 0.15\n",
        "            }\n",
        "\n",
        "        # P365 outdoor conflict detection\n",
        "        elif (any(kw in mapped_scene for kw in self.P365_OUTDOOR_SCENE_KEYWORDS) and\n",
        "              confidence > self.P365_SCENE_MODERATE_CONF_THRESHOLD):\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Moderate warm. CONFLICT: LA says indoor but P365 scene is outdoor. \"\n",
        "                \"Defaulting to general indoor artificial.\"\n",
        "            )\n",
        "            diagnostics[\"conflict_is_indoor_vs_p365_scene_for_restaurant_bar\"] = True\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_moderate_artificial\",\n",
        "                \"confidence\": 0.55\n",
        "            }\n",
        "\n",
        "        # Neutral P365 context\n",
        "        else:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Moderate warm tones, typical of restaurant/bar. P365 context neutral or weak.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_restaurant_bar\",\n",
        "                \"confidence\": 0.70\n",
        "            }\n",
        "\n",
        "    def _classify_dim_indoor(self, features: Dict[str, Any],\n",
        "                            diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify dim indoor lighting conditions.\"\"\"\n",
        "        warm_ratio = features.get(\"warm_ratio\", 0.0)\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "\n",
        "        if warm_ratio > 0.45 and yellow_orange_ratio > 0.15:\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_dim_warm\",\n",
        "                \"confidence\": 0.75\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_dim_general\",\n",
        "                \"confidence\": 0.70\n",
        "            }\n",
        "\n",
        "    def _analyze_outdoor_visual_features(self, features: Dict[str, Any], p365_context: Dict[str, Any],\n",
        "                                        diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze visual features for outdoor lighting conditions.\"\"\"\n",
        "        avg_brightness = features.get(\"avg_brightness\", 128.0)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # P365 enhanced street scene analysis\n",
        "        street_result = self._analyze_p365_enhanced_street_scenes(\n",
        "            features, p365_context, diagnostics\n",
        "        )\n",
        "        if street_result[\"determined\"]:\n",
        "            return street_result\n",
        "\n",
        "        # Brightness-based outdoor classification\n",
        "        if avg_brightness < thresholds.outdoor_night_thresh_brightness:\n",
        "            return self._classify_night_outdoor(features, diagnostics)\n",
        "        elif (avg_brightness < thresholds.outdoor_dusk_dawn_thresh_brightness and\n",
        "              self._check_warm_sunset_conditions(features)):\n",
        "            return self._classify_sunset_sunrise(features, p365_context, diagnostics)\n",
        "        elif avg_brightness > thresholds.outdoor_day_bright_thresh:\n",
        "            return self._classify_bright_day_outdoor(features, diagnostics)\n",
        "        elif avg_brightness > thresholds.outdoor_day_cloudy_thresh:\n",
        "            return self._classify_cloudy_day_outdoor(features, diagnostics)\n",
        "        else:\n",
        "            return self._classify_general_outdoor(features, diagnostics)\n",
        "\n",
        "    def _analyze_p365_enhanced_street_scenes(self, features: Dict[str, Any], p365_context: Dict[str, Any],\n",
        "                                            diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze outdoor scenes with Places365 street context enhancement.\"\"\"\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        confidence = p365_context[\"confidence\"]\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # Check for street scene with warm lighting\n",
        "        is_street_scene = (\n",
        "            any(kw in mapped_scene for kw in [\"street\", \"city\", \"road\", \"urban\", \"downtown\", \"intersection\"]) and\n",
        "            confidence > self.P365_SCENE_MODERATE_CONF_THRESHOLD and\n",
        "            features.get(\"color_atmosphere\") == \"warm\"\n",
        "        )\n",
        "\n",
        "        if not is_street_scene:\n",
        "            return {\"determined\": False, \"time_of_day\": \"unknown\", \"confidence\": 0.5}\n",
        "\n",
        "        avg_brightness = features.get(\"avg_brightness\", 128.0)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "\n",
        "        # Night with street lights\n",
        "        if (avg_brightness < thresholds.outdoor_night_thresh_brightness and\n",
        "            bright_spots_overall > thresholds.outdoor_night_lights_thresh):\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                f\"P365 outdoor scene '{mapped_scene}' + visual low-warm light with spots -> night_with_lights.\"\n",
        "            )\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": \"night_with_lights\",\n",
        "                \"confidence\": 0.88 + confidence * 0.1\n",
        "            }\n",
        "\n",
        "        # Sunset/sunrise conditions\n",
        "        elif avg_brightness >= thresholds.outdoor_night_thresh_brightness:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                f\"P365 outdoor scene '{mapped_scene}' + visual moderate-warm light -> sunset/sunrise.\"\n",
        "            )\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": \"sunset_sunrise\",\n",
        "                \"confidence\": 0.88 + confidence * 0.1\n",
        "            }\n",
        "\n",
        "        # Very dark conditions\n",
        "        else:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                f\"P365 outdoor scene '{mapped_scene}' + visual very low light -> night_dark.\"\n",
        "            )\n",
        "            return {\n",
        "                \"determined\": True,\n",
        "                \"time_of_day\": \"night_dark\",\n",
        "                \"confidence\": 0.75 + confidence * 0.1\n",
        "            }\n",
        "\n",
        "    def _classify_night_outdoor(self, features: Dict[str, Any],\n",
        "                               diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify nighttime outdoor conditions.\"\"\"\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "        dark_pixel_ratio = features.get(\"dark_pixel_ratio\", 0.0)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        if bright_spots_overall > thresholds.outdoor_night_lights_thresh:\n",
        "            confidence = 0.82 + min(0.13, dark_pixel_ratio / 2.5)\n",
        "            diagnostics[\"visual_analysis_reason\"] = \"Visual: Low brightness with light sources (street/car lights).\"\n",
        "            return {\n",
        "                \"time_of_day\": \"night_with_lights\",\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "        else:\n",
        "            confidence = 0.78 + min(0.17, dark_pixel_ratio / 1.8)\n",
        "            diagnostics[\"visual_analysis_reason\"] = \"Visual: Very low brightness outdoor, deep night.\"\n",
        "            return {\n",
        "                \"time_of_day\": \"night_dark\",\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "\n",
        "    def _classify_sunset_sunrise(self, features: Dict[str, Any], p365_context: Dict[str, Any],\n",
        "                                diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify sunset/sunrise outdoor conditions.\"\"\"\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "        confidence = 0.75 + min(0.20, yellow_orange_ratio / 1.5)\n",
        "\n",
        "        diagnostics[\"visual_analysis_reason\"] = \"Visual: Moderate brightness, warm tones -> sunset/sunrise.\"\n",
        "\n",
        "        # P365 natural scene boost\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        p365_confidence = p365_context[\"confidence\"]\n",
        "\n",
        "        if (any(kw in mapped_scene for kw in [\"beach\", \"mountain\", \"lake\", \"ocean\", \"desert\", \"field\", \"natural_landmark\", \"sky\"]) and\n",
        "            p365_confidence > self.P365_SCENE_MODERATE_CONF_THRESHOLD):\n",
        "            confidence = min(0.95, confidence + 0.15)\n",
        "            diagnostics[\"visual_analysis_reason\"] += f\" P365 natural scene '{mapped_scene}' supports.\"\n",
        "\n",
        "        return {\n",
        "            \"time_of_day\": \"sunset_sunrise\",\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "\n",
        "    def _classify_bright_day_outdoor(self, features: Dict[str, Any],\n",
        "                                    diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify bright daytime outdoor conditions.\"\"\"\n",
        "        sky_like_blue_in_sky_region = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "        sky_region_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        texture_complexity = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # Clear sky conditions\n",
        "        if (sky_like_blue_in_sky_region > thresholds.outdoor_day_blue_thresh or\n",
        "            (sky_region_brightness_ratio > 1.05 and texture_complexity < 0.4)):\n",
        "\n",
        "            confidence = 0.80 + min(0.15, sky_like_blue_in_sky_region * 2 +\n",
        "                                  (sky_like_blue_in_sky_region * 1.5 if sky_region_brightness_ratio > 1.05 else 0))\n",
        "            diagnostics[\"visual_analysis_reason\"] = \"Visual: High brightness with blue/sky tones or bright smooth top.\"\n",
        "\n",
        "            return {\n",
        "                \"time_of_day\": \"day_clear\",\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "\n",
        "        # Stadium/floodlit detection\n",
        "        brightness_uniformity = features.get(\"brightness_uniformity\", 0.0)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "\n",
        "        if (brightness_uniformity > 0.70 and\n",
        "            bright_spots_overall > thresholds.stadium_min_spots_thresh):\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Very bright, uniform lighting with multiple sources, suggests floodlights (Outdoor).\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"stadium_or_floodlit_area\",\n",
        "                \"confidence\": 0.78\n",
        "            }\n",
        "\n",
        "        # General bright day\n",
        "        diagnostics[\"visual_analysis_reason\"] = \"Visual: High brightness outdoor, specific sky features unclear.\"\n",
        "        return {\n",
        "            \"time_of_day\": \"day_bright_general\",\n",
        "            \"confidence\": 0.68\n",
        "        }\n",
        "\n",
        "    def _classify_cloudy_day_outdoor(self, features: Dict[str, Any],\n",
        "                                    diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify cloudy daytime outdoor conditions.\"\"\"\n",
        "        sky_region_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "        texture_complexity = features.get(\"top_region_texture_complexity\", 0.5)\n",
        "        avg_saturation = features.get(\"avg_saturation\", 100.0)\n",
        "        gray_ratio = features.get(\"gray_ratio\", 0.0)\n",
        "        brightness_uniformity = features.get(\"brightness_uniformity\", 0.0)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # Overcast conditions\n",
        "        if (sky_region_brightness_ratio > 1.05 and texture_complexity < 0.45 and avg_saturation < 70):\n",
        "            confidence = 0.75 + min(0.20, gray_ratio / 1.5 + (brightness_uniformity - 0.5) / 1.5)\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Good brightness, uniform bright top, lower saturation -> overcast.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"day_cloudy_overcast\",\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "\n",
        "        # Gray cloudy conditions\n",
        "        elif gray_ratio > thresholds.outdoor_day_gray_thresh:\n",
        "            confidence = 0.72 + min(0.23, gray_ratio / 1.8)\n",
        "            diagnostics[\"visual_analysis_reason\"] = \"Visual: Good brightness with higher gray tones.\"\n",
        "            return {\n",
        "                \"time_of_day\": \"day_cloudy_gray\",\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "\n",
        "        # General bright outdoor\n",
        "        else:\n",
        "            diagnostics[\"visual_analysis_reason\"] = \"Visual: Bright outdoor, specific type less clear.\"\n",
        "            return {\n",
        "                \"time_of_day\": \"day_bright_general\",\n",
        "                \"confidence\": 0.68\n",
        "            }\n",
        "\n",
        "    def _classify_general_outdoor(self, features: Dict[str, Any],\n",
        "                                 diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Classify general outdoor conditions when specific patterns are unclear.\"\"\"\n",
        "        color_atmosphere = features.get(\"color_atmosphere\", \"neutral\")\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "        sky_like_blue_in_sky_region = features.get(\"sky_region_blue_dominance\", 0.0)\n",
        "\n",
        "        # Potential sunset/sunrise with low confidence\n",
        "        if color_atmosphere == \"warm\" and yellow_orange_ratio > 0.08:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Outdoor, specific conditions less clear; broader visual cues suggest warm lighting.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"sunset_sunrise_low_confidence\",\n",
        "                \"confidence\": 0.62\n",
        "            }\n",
        "\n",
        "        # Potential hazy day conditions\n",
        "        elif sky_like_blue_in_sky_region > 0.02:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Outdoor, specific conditions less clear; some blue tones suggest daylight.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"day_hazy_or_partly_cloudy\",\n",
        "                \"confidence\": 0.62\n",
        "            }\n",
        "\n",
        "        # Unknown outdoor daylight\n",
        "        else:\n",
        "            diagnostics[\"visual_analysis_reason\"] = (\n",
        "                \"Visual: Outdoor, specific conditions less clear; broader visual cues.\"\n",
        "            )\n",
        "            return {\n",
        "                \"time_of_day\": \"outdoor_unknown_daylight\",\n",
        "                \"confidence\": 0.58\n",
        "            }\n",
        "\n",
        "    def _apply_commercial_indoor_refinement(self, features: Dict[str, Any], p365_context: Dict[str, Any],\n",
        "                                           time_of_day: str, confidence: float) -> Dict[str, Any]:\n",
        "        \"\"\"Apply commercial indoor lighting refinement if conditions are met.\"\"\"\n",
        "        # Skip if already classified as residential, restaurant, or bar\n",
        "        if any(category in time_of_day for category in [\"residential\", \"restaurant\", \"bar\"]):\n",
        "            return {\"time_of_day\": time_of_day, \"confidence\": confidence}\n",
        "\n",
        "        # Skip if P365 suggests home environment\n",
        "        mapped_scene = p365_context[\"mapped_scene\"]\n",
        "        if any(kw in mapped_scene for kw in [\"home\", \"residential\"]):\n",
        "            return {\"time_of_day\": time_of_day, \"confidence\": confidence}\n",
        "\n",
        "        # Check commercial lighting indicators\n",
        "        avg_brightness = features.get(\"avg_brightness\", 100.0)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "        light_dist_uniformity = features.get(\"light_distribution_uniformity\", 0.5)\n",
        "        ceiling_likelihood = features.get(\"ceiling_likelihood\", 0.0)\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        if (avg_brightness > thresholds.commercial_min_brightness_thresh and\n",
        "            bright_spots_overall > thresholds.commercial_min_spots_thresh and\n",
        "            (light_dist_uniformity > 0.5 or ceiling_likelihood > 0.4)):\n",
        "\n",
        "            refined_confidence = 0.70 + min(0.2, bright_spots_overall * 0.02)\n",
        "            return {\n",
        "                \"time_of_day\": \"indoor_commercial\",\n",
        "                \"confidence\": refined_confidence\n",
        "            }\n",
        "\n",
        "        return {\"time_of_day\": time_of_day, \"confidence\": confidence}\n",
        "\n",
        "    def _apply_special_lighting_refinement(self, time_of_day: str, confidence: float,\n",
        "                                          features: Dict[str, Any], is_indoor: bool,\n",
        "                                          p365_context: Dict[str, Any],\n",
        "                                          diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Apply special lighting refinement for neon and sodium vapor lighting.\"\"\"\n",
        "        # Apply commercial refinement for indoor scenes first\n",
        "        if is_indoor:\n",
        "            commercial_result = self._apply_commercial_indoor_refinement(\n",
        "                features, p365_context, time_of_day, confidence\n",
        "            )\n",
        "            time_of_day = commercial_result[\"time_of_day\"]\n",
        "            confidence = commercial_result[\"confidence\"]\n",
        "\n",
        "        # Check for neon/sodium vapor lighting conditions\n",
        "        is_current_night_or_dim_warm = \"night\" in time_of_day or time_of_day == \"indoor_dim_warm\"\n",
        "\n",
        "        if not is_current_night_or_dim_warm:\n",
        "            return {\"time_of_day\": time_of_day, \"confidence\": confidence}\n",
        "\n",
        "        # Extract features for neon detection\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "        bright_spots_overall = features.get(\"bright_spot_count\", 0)\n",
        "        color_atmosphere = features.get(\"color_atmosphere\", \"neutral\")\n",
        "        avg_saturation = features.get(\"avg_saturation\", 0.0)\n",
        "\n",
        "        # Get neon detection thresholds\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "\n",
        "        # Check neon lighting conditions\n",
        "        if (yellow_orange_ratio > thresholds.neon_yellow_orange_thresh and\n",
        "            bright_spots_overall > thresholds.neon_bright_spots_thresh and\n",
        "            color_atmosphere == \"warm\" and\n",
        "            avg_saturation > thresholds.neon_avg_saturation_thresh):\n",
        "\n",
        "            old_time_of_day = time_of_day\n",
        "            old_confidence = confidence\n",
        "\n",
        "            # Check P365 context for neon scenes\n",
        "            mapped_scene = p365_context[\"mapped_scene\"]\n",
        "            attributes = p365_context[\"attributes\"]\n",
        "            is_p365_neon_context = (\n",
        "                any(kw in mapped_scene for kw in [\"neon\", \"nightclub\", \"bar_neon\"]) or\n",
        "                \"neon\" in attributes\n",
        "            )\n",
        "\n",
        "            if is_indoor:\n",
        "                if (is_p365_neon_context or\n",
        "                    any(kw in mapped_scene for kw in self.P365_INDOOR_RESTAURANT_KEYWORDS)):\n",
        "                    time_of_day = \"indoor_neon_lit\"\n",
        "                    confidence = max(confidence, 0.80)\n",
        "                else:\n",
        "                    time_of_day = \"indoor_dim_warm_neon_accent\"\n",
        "                    confidence = max(confidence, 0.77)\n",
        "            else:\n",
        "                if (is_p365_neon_context or\n",
        "                    any(kw in mapped_scene for kw in [\"street_night\", \"city_night\", \"downtown_night\"])):\n",
        "                    time_of_day = \"neon_or_sodium_vapor_night\"\n",
        "                    confidence = max(confidence, 0.82)\n",
        "                else:\n",
        "                    time_of_day = \"night_with_neon_lights\"\n",
        "                    confidence = max(confidence, 0.79)\n",
        "\n",
        "            # Record the refinement\n",
        "            diagnostics[\"special_lighting_detected\"] = (\n",
        "                f\"Refined from {old_time_of_day} (Conf:{old_confidence:.2f}) \"\n",
        "                f\"to {time_of_day} (Conf:{confidence:.2f}) due to neon/sodium vapor light characteristics. \"\n",
        "                f\"P365 Context: {mapped_scene if is_p365_neon_context else 'N/A'}.\"\n",
        "            )\n",
        "\n",
        "        return {\"time_of_day\": time_of_day, \"confidence\": confidence}\n",
        "\n",
        "    def _combine_attribute_and_visual_results(self, attribute_result: Dict[str, Any],\n",
        "                                             visual_result: Dict[str, Any],\n",
        "                                             diagnostics: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Combine Places365 attribute and visual analysis results.\"\"\"\n",
        "        # If visual analysis provided a different and potentially more nuanced result\n",
        "        if (attribute_result[\"time_of_day\"] != visual_result[\"time_of_day\"] and\n",
        "            visual_result[\"confidence\"] > 0.65):\n",
        "\n",
        "            diagnostics[\"final_decision_source\"] = \"Visual features (potentially P365-context-refined).\"\n",
        "            diagnostics[\"p365_attr_overridden_by_visual\"] = (\n",
        "                f\"P365 Attr ToD {attribute_result['time_of_day']} \"\n",
        "                f\"(Conf {attribute_result['confidence']:.2f}) was less certain or overridden by \"\n",
        "                f\"visual logic result {visual_result['time_of_day']} (Conf {visual_result['confidence']:.2f}).\"\n",
        "            )\n",
        "            return visual_result\n",
        "\n",
        "        # Use attribute result if it was more confident\n",
        "        elif attribute_result[\"confidence\"] >= visual_result[\"confidence\"]:\n",
        "            diagnostics[\"final_decision_source\"] = \"High-confidence P365 attribute.\"\n",
        "            return attribute_result\n",
        "\n",
        "        # Use visual result\n",
        "        else:\n",
        "            diagnostics[\"final_decision_source\"] = \"Visual features (potentially P365-context-refined).\"\n",
        "            return visual_result\n",
        "\n",
        "    def _check_home_environment_pattern(self, features: Dict[str, Any]) -> bool:\n",
        "        \"\"\"Check if features indicate a home/residential environment pattern.\"\"\"\n",
        "        thresholds = self.config_manager.indoor_outdoor_thresholds\n",
        "        return features.get(\"home_environment_pattern\", 0.0) > thresholds.home_pattern_thresh_moderate * 0.7\n",
        "\n",
        "    def _check_warm_sunset_conditions(self, features: Dict[str, Any]) -> bool:\n",
        "        \"\"\"Check if features indicate warm sunset/sunrise lighting conditions.\"\"\"\n",
        "        thresholds = self.config_manager.lighting_thresholds\n",
        "        yellow_orange_ratio = features.get(\"yellow_orange_ratio\", 0.0)\n",
        "        color_atmosphere = features.get(\"color_atmosphere\", \"neutral\")\n",
        "        sky_brightness_ratio = features.get(\"sky_region_brightness_ratio\", 1.0)\n",
        "\n",
        "        return (yellow_orange_ratio > thresholds.outdoor_dusk_dawn_color_thresh and\n",
        "                color_atmosphere == \"warm\" and\n",
        "                sky_brightness_ratio < 1.5)\n",
        "\n",
        "    def _get_default_lighting_result(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return default lighting analysis result in case of errors.\"\"\"\n",
        "        return {\n",
        "            \"time_of_day\": \"unknown\",\n",
        "            \"confidence\": 0.5,\n",
        "            \"diagnostics\": {\n",
        "                \"error\": \"Lighting analysis failed, using default values\"\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "ebRkfK4RtJlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf8323e-781c-4e34-8835-5f79e71f784b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lighting_condition_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile lighting_analyzer.py\n",
        "import numpy as np\n",
        "import cv2\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "# from configuration_manager import ConfigurationManager\n",
        "# from feature_extractor import FeatureExtractor\n",
        "# from indoor_outdoor_classifier import IndoorOutdoorClassifier\n",
        "# from lighting_condition_analyzer import LightingConditionAnalyzer\n",
        "\n",
        "\n",
        "class LightingAnalyzer:\n",
        "    \"\"\"\n",
        "    Comprehensive lighting analysis system facade that coordinates feature extraction,\n",
        "    indoor/outdoor classification, and lighting condition determination.\n",
        "    此class是一個總窗口，主要匯總各式光線分析相關的class\n",
        "\n",
        "    This facade class maintains the original interface while internally delegating\n",
        "    work to specialized components for improved maintainability and modularity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Optional[Dict[str, Any]] = None):\n",
        "        \"\"\"\n",
        "        Initialize the lighting analyzer with configuration.\n",
        "\n",
        "        Args:\n",
        "            config: Optional configuration dictionary. If None, uses default configuration.\n",
        "        \"\"\"\n",
        "        self.logger = self._setup_logger()\n",
        "\n",
        "        try:\n",
        "            # Initialize configuration manager\n",
        "            self.config_manager = ConfigurationManager()\n",
        "\n",
        "            # Override default configuration if provided\n",
        "            if config is not None:\n",
        "                self._update_configuration(config)\n",
        "\n",
        "            # Initialize specialized components\n",
        "            self.feature_extractor = FeatureExtractor(self.config_manager)\n",
        "            self.indoor_outdoor_classifier = IndoorOutdoorClassifier(self.config_manager)\n",
        "            self.lighting_condition_analyzer = LightingConditionAnalyzer(self.config_manager)\n",
        "\n",
        "            # Legacy configuration access for backward compatibility\n",
        "            self.config = self.config_manager.get_legacy_config_dict()\n",
        "\n",
        "            self.logger.info(\"LightingAnalyzer initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error initializing LightingAnalyzer: {str(e)}\")\n",
        "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "            raise\n",
        "\n",
        "    def _setup_logger(self) -> logging.Logger:\n",
        "        \"\"\"Set up logger for lighting analysis operations.\"\"\"\n",
        "        logger = logging.getLogger(f\"{__name__}.LightingAnalyzer\")\n",
        "        if not logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "            logger.setLevel(logging.INFO)\n",
        "        return logger\n",
        "\n",
        "    def _update_configuration(self, config: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Update configuration manager with provided configuration dictionary.\n",
        "\n",
        "        Args:\n",
        "            config: Configuration dictionary to update existing configuration.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Update configuration through the manager's internal method\n",
        "            self.config_manager._update_from_dict(config)\n",
        "            self.logger.debug(\"Configuration updated successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error updating configuration: {str(e)}\")\n",
        "            self.logger.warning(\"Continuing with default configuration\")\n",
        "\n",
        "    def analyze(self, image, places365_info: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze lighting conditions of an image.\n",
        "\n",
        "        This is the main entry point that maintains compatibility with the original interface\n",
        "        while leveraging the new modular architecture internally.\n",
        "\n",
        "        Args:\n",
        "            image: Input image (numpy array or PIL Image).\n",
        "            places365_info: Optional Places365 classification information containing\n",
        "                          scene type, confidence, attributes, and indoor/outdoor classification.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing comprehensive lighting analysis results including:\n",
        "            - time_of_day: Specific lighting condition classification\n",
        "            - confidence: Confidence score for the classification\n",
        "            - is_indoor: Boolean indicating indoor/outdoor classification\n",
        "            - indoor_probability: Probability score for indoor classification\n",
        "            - brightness: Brightness analysis metrics\n",
        "            - color_info: Color characteristic analysis\n",
        "            - texture_info: Texture and gradient analysis\n",
        "            - structure_info: Structural feature analysis\n",
        "            - diagnostics: Detailed diagnostic information (if enabled)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Starting comprehensive lighting analysis\")\n",
        "\n",
        "            # Step 1: Validate and preprocess input image\n",
        "            processed_image = self._preprocess_image(image)\n",
        "            if processed_image is None:\n",
        "                return self._get_error_result(\"Invalid image input\")\n",
        "\n",
        "            # Step 2: Extract comprehensive features\n",
        "            self.logger.debug(\"Extracting image features\")\n",
        "            features = self.feature_extractor.extract_features(processed_image)\n",
        "\n",
        "            if not features or \"avg_brightness\" not in features:\n",
        "                return self._get_error_result(\"Feature extraction failed\")\n",
        "\n",
        "            # Step 3: Classify indoor/outdoor with Places365 integration\n",
        "            self.logger.debug(\"Performing indoor/outdoor classification\")\n",
        "            indoor_outdoor_result = self.indoor_outdoor_classifier.classify(\n",
        "                features, places365_info\n",
        "            )\n",
        "\n",
        "            is_indoor = indoor_outdoor_result[\"is_indoor\"]\n",
        "            indoor_probability = indoor_outdoor_result[\"indoor_probability\"]\n",
        "\n",
        "            # Step 4: Determine specific lighting conditions\n",
        "            self.logger.debug(f\"Analyzing lighting conditions for {'indoor' if is_indoor else 'outdoor'} scene\")\n",
        "            lighting_result = self.lighting_condition_analyzer.analyze_lighting_conditions(\n",
        "                features, is_indoor, places365_info\n",
        "            )\n",
        "\n",
        "            # Step 5: Consolidate comprehensive results\n",
        "            result = self._consolidate_analysis_results(\n",
        "                lighting_result, indoor_outdoor_result, features\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"Analysis complete: {result['time_of_day']} \"\n",
        "                           f\"({'indoor' if result['is_indoor'] else 'outdoor'}) \"\n",
        "                           f\"confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in lighting analysis: {str(e)}\")\n",
        "            self.logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "            return self._get_error_result(str(e))\n",
        "\n",
        "    def _preprocess_image(self, image) -> Optional[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Preprocess input image to ensure consistent format for analysis.\n",
        "\n",
        "        Args:\n",
        "            image: Input image in various possible formats.\n",
        "\n",
        "        Returns:\n",
        "            Preprocessed image as RGB numpy array, or None if preprocessing failed.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert to numpy array if needed\n",
        "            if not isinstance(image, np.ndarray):\n",
        "                image_np = np.array(image)\n",
        "            else:\n",
        "                image_np = image.copy()\n",
        "\n",
        "            # Validate basic image properties\n",
        "            if len(image_np.shape) < 2:\n",
        "                self.logger.error(\"Image must have at least 2 dimensions\")\n",
        "                return None\n",
        "\n",
        "            height, width = image_np.shape[:2]\n",
        "            if height == 0 or width == 0:\n",
        "                self.logger.error(f\"Invalid image dimensions: {height}x{width}\")\n",
        "                return None\n",
        "\n",
        "            # Handle different color formats and convert to RGB\n",
        "            if len(image_np.shape) == 2:\n",
        "                # 灰階 to RGB\n",
        "                image_rgb = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)\n",
        "            elif image_np.shape[2] == 3:\n",
        "                # Handle BGR vs RGB\n",
        "                if not isinstance(image, np.ndarray):\n",
        "                    # PIL images are typically RGB\n",
        "                    image_rgb = image_np\n",
        "                else:\n",
        "                    # OpenCV arrays are typically BGR, convert to RGB\n",
        "                    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
        "            elif image_np.shape[2] == 4:\n",
        "                # RGBA to RGB\n",
        "                if not isinstance(image, np.ndarray):\n",
        "                    # PIL RGBA to RGB\n",
        "                    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)\n",
        "                else:\n",
        "                    # OpenCV BGRA to RGB\n",
        "                    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGRA2RGB)\n",
        "            else:\n",
        "                self.logger.error(f\"Unsupported image format with shape: {image_np.shape}\")\n",
        "                return None\n",
        "\n",
        "            # Ensure uint8 data type\n",
        "            if image_rgb.dtype != np.uint8:\n",
        "                if image_rgb.dtype in [np.float32, np.float64]:\n",
        "                    # Assume normalized float values\n",
        "                    if image_rgb.max() <= 1.0:\n",
        "                        image_rgb = (image_rgb * 255).astype(np.uint8)\n",
        "                    else:\n",
        "                        image_rgb = image_rgb.astype(np.uint8)\n",
        "                else:\n",
        "                    image_rgb = image_rgb.astype(np.uint8)\n",
        "\n",
        "            self.logger.debug(f\"Preprocessed image: {image_rgb.shape}, dtype: {image_rgb.dtype}\")\n",
        "            return image_rgb\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error preprocessing image: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _consolidate_analysis_results(self, lighting_result: Dict[str, Any],\n",
        "                                     indoor_outdoor_result: Dict[str, Any],\n",
        "                                     features: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Consolidate results from all analysis components into final output format.\n",
        "\n",
        "        Args:\n",
        "            lighting_result: Results from lighting condition analysis.\n",
        "            indoor_outdoor_result: Results from indoor/outdoor classification.\n",
        "            features: Extracted image features.\n",
        "\n",
        "        Returns:\n",
        "            Consolidated analysis results in the expected output format.\n",
        "        \"\"\"\n",
        "        # Extract core results\n",
        "        time_of_day = lighting_result[\"time_of_day\"]\n",
        "        confidence = lighting_result[\"confidence\"]\n",
        "        is_indoor = indoor_outdoor_result[\"is_indoor\"]\n",
        "        indoor_probability = indoor_outdoor_result[\"indoor_probability\"]\n",
        "\n",
        "        # Organize brightness information\n",
        "        brightness_info = {\n",
        "            \"average\": float(features.get(\"avg_brightness\", 0.0)),\n",
        "            \"std_dev\": float(features.get(\"brightness_std\", 0.0)),\n",
        "            \"dark_ratio\": float(features.get(\"dark_pixel_ratio\", 0.0)),\n",
        "            \"bright_ratio\": float(features.get(\"bright_pixel_ratio\", 0.0))\n",
        "        }\n",
        "\n",
        "        # Organize color information\n",
        "        color_info = {\n",
        "            \"blue_ratio\": float(features.get(\"blue_ratio\", 0.0)),\n",
        "            \"sky_like_blue_ratio\": float(features.get(\"sky_like_blue_ratio\", 0.0)),\n",
        "            \"yellow_orange_ratio\": float(features.get(\"yellow_orange_ratio\", 0.0)),\n",
        "            \"gray_ratio\": float(features.get(\"gray_ratio\", 0.0)),\n",
        "            \"avg_saturation\": float(features.get(\"avg_saturation\", 0.0)),\n",
        "            \"sky_region_brightness_ratio\": float(features.get(\"sky_region_brightness_ratio\", 1.0)),\n",
        "            \"sky_region_saturation\": float(features.get(\"sky_region_saturation\", 0.0)),\n",
        "            \"sky_region_blue_dominance\": float(features.get(\"sky_region_blue_dominance\", 0.0)),\n",
        "            \"color_atmosphere\": features.get(\"color_atmosphere\", \"neutral\"),\n",
        "            \"warm_ratio\": float(features.get(\"warm_ratio\", 0.0)),\n",
        "            \"cool_ratio\": float(features.get(\"cool_ratio\", 0.0))\n",
        "        }\n",
        "\n",
        "        # Organize texture information\n",
        "        texture_info = {\n",
        "            \"gradient_ratio_vertical_horizontal\": float(features.get(\"gradient_ratio_vertical_horizontal\", 0.0)),\n",
        "            \"top_region_texture_complexity\": float(features.get(\"top_region_texture_complexity\", 0.0)),\n",
        "            \"shadow_clarity_score\": float(features.get(\"shadow_clarity_score\", 0.5))\n",
        "        }\n",
        "\n",
        "        # Organize structure information\n",
        "        structure_info = {\n",
        "            \"ceiling_likelihood\": float(features.get(\"ceiling_likelihood\", 0.0)),\n",
        "            \"boundary_clarity\": float(features.get(\"boundary_clarity\", 0.0)),\n",
        "            \"openness_top_edge\": float(features.get(\"openness_top_edge\", 0.5))\n",
        "        }\n",
        "\n",
        "        # Compile final result\n",
        "        result = {\n",
        "            \"time_of_day\": time_of_day,\n",
        "            \"confidence\": float(confidence),\n",
        "            \"is_indoor\": is_indoor,\n",
        "            \"indoor_probability\": float(indoor_probability),\n",
        "            \"brightness\": brightness_info,\n",
        "            \"color_info\": color_info,\n",
        "            \"texture_info\": texture_info,\n",
        "            \"structure_info\": structure_info\n",
        "        }\n",
        "\n",
        "        # Add diagnostic information if enabled\n",
        "        if self.config_manager.algorithm_parameters.include_diagnostics:\n",
        "            diagnostics = {}\n",
        "\n",
        "            # Combine diagnostics from all components\n",
        "            if \"diagnostics\" in lighting_result:\n",
        "                diagnostics[\"lighting_diagnostics\"] = lighting_result[\"diagnostics\"]\n",
        "\n",
        "            if \"diagnostics\" in indoor_outdoor_result:\n",
        "                diagnostics[\"indoor_outdoor_diagnostics\"] = indoor_outdoor_result[\"diagnostics\"]\n",
        "\n",
        "            if \"feature_contributions\" in indoor_outdoor_result:\n",
        "                diagnostics[\"feature_contributions\"] = indoor_outdoor_result[\"feature_contributions\"]\n",
        "\n",
        "            result[\"diagnostics\"] = diagnostics\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _get_error_result(self, error_message: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate standardized error result format.\n",
        "\n",
        "        Args:\n",
        "            error_message: Description of the error that occurred.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing error result with safe default values.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"time_of_day\": \"unknown\",\n",
        "            \"confidence\": 0.0,\n",
        "            \"is_indoor\": False,\n",
        "            \"indoor_probability\": 0.5,\n",
        "            \"brightness\": {\n",
        "                \"average\": 100.0,\n",
        "                \"std_dev\": 50.0,\n",
        "                \"dark_ratio\": 0.0,\n",
        "                \"bright_ratio\": 0.0\n",
        "            },\n",
        "            \"color_info\": {\n",
        "                \"blue_ratio\": 0.0,\n",
        "                \"sky_like_blue_ratio\": 0.0,\n",
        "                \"yellow_orange_ratio\": 0.0,\n",
        "                \"gray_ratio\": 0.0,\n",
        "                \"avg_saturation\": 100.0,\n",
        "                \"sky_region_brightness_ratio\": 1.0,\n",
        "                \"sky_region_saturation\": 0.0,\n",
        "                \"sky_region_blue_dominance\": 0.0,\n",
        "                \"color_atmosphere\": \"neutral\",\n",
        "                \"warm_ratio\": 0.0,\n",
        "                \"cool_ratio\": 0.0\n",
        "            },\n",
        "            \"texture_info\": {\n",
        "                \"gradient_ratio_vertical_horizontal\": 1.0,\n",
        "                \"top_region_texture_complexity\": 0.5,\n",
        "                \"shadow_clarity_score\": 0.5\n",
        "            },\n",
        "            \"structure_info\": {\n",
        "                \"ceiling_likelihood\": 0.0,\n",
        "                \"boundary_clarity\": 0.0,\n",
        "                \"openness_top_edge\": 0.5\n",
        "            },\n",
        "            \"error\": error_message\n",
        "        }\n",
        "\n",
        "    def get_configuration(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get current configuration as dictionary for backward compatibility.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all current configuration parameters.\n",
        "        \"\"\"\n",
        "        return self.config_manager.get_legacy_config_dict()\n",
        "\n",
        "    def update_configuration(self, config_updates: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Update configuration parameters.\n",
        "\n",
        "        Args:\n",
        "            config_updates: Dictionary containing configuration parameters to update.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.config_manager._update_from_dict(config_updates)\n",
        "            # Update legacy config reference\n",
        "            self.config = self.config_manager.get_legacy_config_dict()\n",
        "            self.logger.info(\"Configuration updated successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error updating configuration: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def validate_configuration(self) -> bool:\n",
        "        \"\"\"\n",
        "        Validate current configuration for logical consistency.\n",
        "\n",
        "        Returns:\n",
        "            True if configuration is valid, False otherwise.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            validation_errors = self.config_manager.validate_configuration()\n",
        "\n",
        "            if validation_errors:\n",
        "                self.logger.error(\"Configuration validation failed:\")\n",
        "                for error in validation_errors:\n",
        "                    self.logger.error(f\"  - {error}\")\n",
        "                return False\n",
        "\n",
        "            self.logger.info(\"Configuration validation passed\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error during configuration validation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_configuration(self, filepath: str) -> None:\n",
        "        \"\"\"\n",
        "        Save current configuration to file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path where to save the configuration file.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.config_manager.save_to_file(filepath)\n",
        "            self.logger.info(f\"Configuration saved to {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error saving configuration: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_configuration(self, filepath: str) -> None:\n",
        "        \"\"\"\n",
        "        Load configuration from file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to the configuration file to load.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.config_manager.load_from_file(filepath)\n",
        "            # Update legacy config reference\n",
        "            self.config = self.config_manager.get_legacy_config_dict()\n",
        "            self.logger.info(f\"Configuration loaded from {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading configuration: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "k-slcek4tY1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44922ae6-32cd-4ec3-e6e6-72dca68497e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lighting_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClX1q_9rW_TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fc4738-7476-4a37-f413-249eeae7588d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_description.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile scene_description.py\n",
        "import os\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from scene_detail_templates import SCENE_DETAIL_TEMPLATES\n",
        "# from object_template_fillers import OBJECT_TEMPLATE_FILLERS\n",
        "# from activity_templates import ACTIVITY_TEMPLATES\n",
        "# from safety_templates import SAFETY_TEMPLATES\n",
        "# from confidence_templates import CONFIDENCE_TEMPLATES\n",
        "\n",
        "class SceneDescriptor:\n",
        "    \"\"\"\n",
        "    Generates natural language descriptions of scenes.\n",
        "    Handles scene descriptions, activity inference, and safety concerns identification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scene_types=None, object_categories=None):\n",
        "        \"\"\"\n",
        "        Initialize the scene descriptor\n",
        "\n",
        "        Args:\n",
        "            scene_types: Dictionary of scene type definitions\n",
        "        \"\"\"\n",
        "        self.scene_types = scene_types or {}\n",
        "        self.SCENE_TYPES = scene_types or {}\n",
        "\n",
        "        if object_categories:\n",
        "            self.OBJECT_CATEGORIES = object_categories\n",
        "        else:\n",
        "            # 從 JSON 加載或使用默認值\n",
        "            self.OBJECT_CATEGORIES = self._load_json_data(\"object_categories\") or {\n",
        "                \"furniture\": [56, 57, 58, 59, 60, 61],\n",
        "                \"electronics\": [62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "                \"kitchen_items\": [39, 40, 41, 42, 43, 44, 45],\n",
        "                \"food\": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
        "                \"vehicles\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "                \"personal_items\": [24, 25, 26, 27, 28, 73, 78, 79]\n",
        "            }\n",
        "\n",
        "        # 加載所有模板數據\n",
        "        self._load_templates()\n",
        "\n",
        "    def _load_templates(self):\n",
        "        \"\"\"Load all template data from script or fallback to imported defaults\"\"\"\n",
        "        self.confidence_templates = CONFIDENCE_TEMPLATES\n",
        "        self.scene_detail_templates = SCENE_DETAIL_TEMPLATES\n",
        "        self.object_template_fillers = OBJECT_TEMPLATE_FILLERS\n",
        "        self.safety_templates = SAFETY_TEMPLATES\n",
        "        self.activity_templates = ACTIVITY_TEMPLATES\n",
        "\n",
        "\n",
        "    def _initialize_fallback_templates(self):\n",
        "        \"\"\"Initialize fallback templates when no external data is available\"\"\"\n",
        "        # 只在無法從文件或導入加載時使用\n",
        "        self.confidence_templates = {\n",
        "            \"high\": \"{description} {details}\",\n",
        "            \"medium\": \"This appears to be {description} {details}\",\n",
        "            \"low\": \"This might be {description}, but the confidence is low. {details}\"\n",
        "        }\n",
        "\n",
        "        # 只提供最基本的模板作為後備\n",
        "        self.scene_detail_templates = {\n",
        "            \"default\": [\"A space with various objects.\"]\n",
        "        }\n",
        "\n",
        "        self.object_template_fillers = {\n",
        "            \"default\": [\"various items\"]\n",
        "        }\n",
        "\n",
        "        self.safety_templates = {\n",
        "            \"general\": \"Pay attention to {safety_element}.\"\n",
        "        }\n",
        "\n",
        "        self.activity_templates = {\n",
        "            \"default\": [\"General activity\"]\n",
        "        }\n",
        "\n",
        "    def _get_alternative_scenes(self, scene_scores: Dict[str, float],\n",
        "                            threshold: float, top_k: int = 2) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get alternative scene interpretations with their scores.\n",
        "\n",
        "        Args:\n",
        "            scene_scores: Dictionary of scene type scores\n",
        "            threshold: Minimum confidence threshold\n",
        "            top_k: Number of alternatives to return\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries with alternative scenes\n",
        "        \"\"\"\n",
        "        # Sort scenes by score in descending order\n",
        "        sorted_scenes = sorted(scene_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Skip the first one (best match) and take the next top_k\n",
        "        alternatives = []\n",
        "        for scene_type, score in sorted_scenes[1:1+top_k]:\n",
        "            if score >= threshold:\n",
        "                alternatives.append({\n",
        "                    \"type\": scene_type,\n",
        "                    \"name\": self.SCENE_TYPES.get(scene_type, {}).get(\"name\", \"Unknown\"),\n",
        "                    \"confidence\": score\n",
        "                })\n",
        "\n",
        "        return alternatives\n",
        "\n",
        "\n",
        "    def _infer_possible_activities(self, scene_type: str, detected_objects: List[Dict], enable_landmark: bool = True, scene_scores: Optional[Dict] = None) -> List[str]:\n",
        "        \"\"\"\n",
        "        Infer possible activities based on scene type and detected objects.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type\n",
        "            detected_objects: List of detected objects\n",
        "            enable_landmark: Whether landmark detection is enabled\n",
        "            scene_scores: Optional dictionary of scene type scores\n",
        "\n",
        "        Returns:\n",
        "            List of possible activities\n",
        "        \"\"\"\n",
        "        activities = []\n",
        "\n",
        "        # Dynamically replace landmark scene types when landmark detection is disabled\n",
        "        if not enable_landmark and scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "            alternative_scene_type = self._get_alternative_scene_type(scene_type, detected_objects, scene_scores)\n",
        "            print(f\"Replacing landmark scene type '{scene_type}' with '{alternative_scene_type}' for activity inference\")\n",
        "            scene_type = alternative_scene_type\n",
        "\n",
        "        # Process aerial view scenes\n",
        "        if scene_type.startswith(\"aerial_view_\"):\n",
        "            if scene_type == \"aerial_view_intersection\":\n",
        "                # Use predefined intersection activities\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_intersection\", []))\n",
        "\n",
        "                # Add pedestrian and vehicle specific activities\n",
        "                pedestrians = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "                vehicles = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 5, 7]]  # Car, bus, truck\n",
        "\n",
        "                if pedestrians and vehicles:\n",
        "                    activities.append(\"Waiting for an opportunity to cross the street\")\n",
        "                    activities.append(\"Obeying traffic signals\")\n",
        "\n",
        "            elif scene_type == \"aerial_view_commercial_area\":\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_commercial_area\", []))\n",
        "\n",
        "            elif scene_type == \"aerial_view_plaza\":\n",
        "                activities.extend(self.activity_templates.get(\"aerial_view_plaza\", []))\n",
        "\n",
        "            else:\n",
        "                # Handle other undefined aerial view scenes\n",
        "                aerial_activities = [\n",
        "                    \"Street crossing\",\n",
        "                    \"Waiting for signals\",\n",
        "                    \"Following traffic rules\",\n",
        "                    \"Pedestrian movement\"\n",
        "                ]\n",
        "                activities.extend(aerial_activities)\n",
        "\n",
        "        # Add scene-specific activities from templates\n",
        "        if scene_type in self.activity_templates:\n",
        "            activities.extend(self.activity_templates[scene_type])\n",
        "        elif \"default\" in self.activity_templates:\n",
        "            activities.extend(self.activity_templates[\"default\"])\n",
        "\n",
        "        # Filter out landmark-related activities when landmark detection is disabled\n",
        "        if not enable_landmark:\n",
        "            filtered_activities = []\n",
        "            landmark_keywords = [\"sightseeing\", \"landmark\", \"tourist\", \"monument\", \"historical\",\n",
        "                                \"guided tour\", \"photography\", \"cultural tourism\", \"heritage\"]\n",
        "\n",
        "            for activity in activities:\n",
        "                if not any(keyword in activity.lower() for keyword in landmark_keywords):\n",
        "                    filtered_activities.append(activity)\n",
        "\n",
        "            activities = filtered_activities\n",
        "\n",
        "        # If we filtered out all activities, add some generic ones based on scene type\n",
        "        if not activities:\n",
        "            generic_activities = {\n",
        "                \"city_street\": [\"Walking\", \"Commuting\", \"Shopping\"],\n",
        "                \"intersection\": [\"Crossing the street\", \"Waiting for traffic signals\"],\n",
        "                \"commercial_district\": [\"Shopping\", \"Walking\", \"Dining\"],\n",
        "                \"pedestrian_area\": [\"Walking\", \"Socializing\", \"Shopping\"],\n",
        "                \"park_area\": [\"Relaxing\", \"Walking\", \"Exercise\"],\n",
        "                \"outdoor_natural_area\": [\"Walking\", \"Nature observation\", \"Relaxation\"],\n",
        "                \"urban_architecture\": [\"Walking\", \"Urban exploration\", \"Photography\"]\n",
        "            }\n",
        "\n",
        "            activities.extend(generic_activities.get(scene_type, [\"Walking\", \"Observing surroundings\"]))\n",
        "\n",
        "        # Add activities based on detected objects\n",
        "        detected_class_ids = [obj[\"class_id\"] for obj in detected_objects]\n",
        "\n",
        "        # Add activities based on specific object combinations\n",
        "        if 62 in detected_class_ids and 57 in detected_class_ids:  # TV and sofa\n",
        "            activities.append(\"Watching shows or movies\")\n",
        "\n",
        "        if 63 in detected_class_ids:  # laptop\n",
        "            activities.append(\"Using a computer/laptop\")\n",
        "\n",
        "        if 67 in detected_class_ids:  # cell phone\n",
        "            activities.append(\"Using a mobile phone\")\n",
        "\n",
        "        if 73 in detected_class_ids:  # book\n",
        "            activities.append(\"Reading\")\n",
        "\n",
        "        if any(food_id in detected_class_ids for food_id in [46, 47, 48, 49, 50, 51, 52, 53, 54, 55]):\n",
        "            activities.append(\"Eating or preparing food\")\n",
        "\n",
        "        # Person-specific activities\n",
        "        if 0 in detected_class_ids:  # Person\n",
        "            if any(vehicle in detected_class_ids for vehicle in [1, 2, 3, 5, 7]):  # Vehicles\n",
        "                activities.append(\"Commuting or traveling\")\n",
        "\n",
        "            if 16 in detected_class_ids:  # Dog\n",
        "                activities.append(\"Walking a dog\")\n",
        "\n",
        "            if 24 in detected_class_ids or 26 in detected_class_ids:  # Backpack or handbag\n",
        "                activities.append(\"Carrying personal items\")\n",
        "\n",
        "            # Add more person count-dependent activities\n",
        "            person_count = detected_class_ids.count(0)\n",
        "            if person_count > 3:\n",
        "                activities.append(\"Group gathering\")\n",
        "            elif person_count > 1:\n",
        "                activities.append(\"Social interaction\")\n",
        "\n",
        "        # Add additional activities based on significant objects\n",
        "        if 43 in detected_class_ids:  # cup\n",
        "            activities.append(\"Drinking beverages\")\n",
        "\n",
        "        if 32 in detected_class_ids:  # sports ball\n",
        "            activities.append(\"Playing sports\")\n",
        "\n",
        "        if 25 in detected_class_ids:  # umbrella\n",
        "            activities.append(\"Sheltering from weather\")\n",
        "\n",
        "        # Add location-specific activities based on environment objects\n",
        "        if any(furniture in detected_class_ids for furniture in [56, 57, 58, 59, 60]):  # furniture items\n",
        "            activities.append(\"Using indoor facilities\")\n",
        "\n",
        "        if any(outdoor_item in detected_class_ids for outdoor_item in [13, 14, 15]):  # bench, outdoor items\n",
        "            activities.append(\"Enjoying outdoor spaces\")\n",
        "\n",
        "        # Remove duplicates and ensure reasonable number of activities\n",
        "        unique_activities = list(set(activities))\n",
        "\n",
        "        # Limit to reasonable number (maximum 8 activities)\n",
        "        if len(unique_activities) > 8:\n",
        "            # Prioritize more specific activities over general ones\n",
        "            general_activities = [\"Walking\", \"Observing surroundings\", \"Commuting\", \"Using indoor facilities\"]\n",
        "            specific_activities = [a for a in unique_activities if a not in general_activities]\n",
        "\n",
        "            # Take all specific activities first, then fill with general ones if needed\n",
        "            if len(specific_activities) <= 8:\n",
        "                result = specific_activities + general_activities[:8-len(specific_activities)]\n",
        "            else:\n",
        "                result = specific_activities[:8]\n",
        "        else:\n",
        "            result = unique_activities\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _identify_safety_concerns(self, detected_objects: List[Dict], scene_type: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Identify potential safety concerns based on objects and scene type.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects\n",
        "            scene_type: Identified scene type\n",
        "\n",
        "        Returns:\n",
        "            List of potential safety concerns\n",
        "        \"\"\"\n",
        "        concerns = []\n",
        "        detected_class_ids = [obj[\"class_id\"] for obj in detected_objects]\n",
        "\n",
        "        # General safety concerns\n",
        "        if 42 in detected_class_ids or 43 in detected_class_ids:  # Fork or knife\n",
        "            concerns.append(\"Sharp utensils present\")\n",
        "\n",
        "        if 76 in detected_class_ids:  # Scissors\n",
        "            concerns.append(\"Cutting tools present\")\n",
        "\n",
        "        # Traffic-related concerns\n",
        "        if scene_type in [\"city_street\", \"parking_lot\"]:\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                if any(vehicle in detected_class_ids for vehicle in [2, 3, 5, 7, 8]):  # Vehicles\n",
        "                    concerns.append(\"Pedestrians near vehicles\")\n",
        "\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Monitor traffic signals\")\n",
        "\n",
        "        # Identify crowded scenes\n",
        "        person_count = detected_class_ids.count(0)\n",
        "        if person_count > 5:\n",
        "            concerns.append(f\"Crowded area with multiple people ({person_count})\")\n",
        "\n",
        "        # Scene-specific concerns\n",
        "        if scene_type == \"kitchen\":\n",
        "            if 68 in detected_class_ids or 69 in detected_class_ids:  # Microwave or oven\n",
        "                concerns.append(\"Hot cooking equipment\")\n",
        "\n",
        "        # Potentially unstable objects\n",
        "        for obj in detected_objects:\n",
        "            if obj[\"class_id\"] in [39, 40, 41, 45]:  # Bottle, wine glass, cup, bowl\n",
        "                if obj[\"region\"] in [\"top_left\", \"top_center\", \"top_right\"] and obj[\"normalized_area\"] > 0.05:\n",
        "                    concerns.append(f\"Elevated {obj['class_name']} might be unstable\")\n",
        "\n",
        "        # Upscale dining safety concerns\n",
        "        if scene_type == \"upscale_dining\":\n",
        "            # Check for fragile items\n",
        "            if 40 in detected_class_ids:  # Wine glass\n",
        "                concerns.append(\"Fragile glassware present\")\n",
        "\n",
        "            # Check for lit candles (can't directly detect but can infer from context)\n",
        "            # Look for small bright spots that might be candles\n",
        "            if any(obj[\"class_id\"] == 41 for obj in detected_objects):  # Cup (which might include candle holders)\n",
        "                # We can't reliably detect candles, but if the scene appears to be formal dining,\n",
        "                # we can suggest this as a possibility\n",
        "                concerns.append(\"Possible lit candles or decorative items requiring care\")\n",
        "\n",
        "            # Check for overcrowded table\n",
        "            table_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 60]  # Dining table\n",
        "            if table_objs:\n",
        "                table_region = table_objs[0][\"region\"]\n",
        "                items_on_table = 0\n",
        "\n",
        "                for obj in detected_objects:\n",
        "                    if obj[\"class_id\"] in [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]:\n",
        "                        if obj[\"region\"] == table_region:\n",
        "                            items_on_table += 1\n",
        "\n",
        "                if items_on_table > 8:\n",
        "                    concerns.append(\"Dining table has multiple items which should be handled with care\")\n",
        "\n",
        "        # Asian commercial street safety concerns\n",
        "        elif scene_type == \"asian_commercial_street\":\n",
        "            # Check for crowded walkways\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 3:\n",
        "                    # Calculate person density (simplified)\n",
        "                    person_positions = []\n",
        "                    for obj in detected_objects:\n",
        "                        if obj[\"class_id\"] == 0:\n",
        "                            person_positions.append(obj[\"normalized_center\"])\n",
        "\n",
        "                    if len(person_positions) >= 2:\n",
        "                        # Calculate average distance between people\n",
        "                        total_distance = 0\n",
        "                        count = 0\n",
        "                        for i in range(len(person_positions)):\n",
        "                            for j in range(i+1, len(person_positions)):\n",
        "                                p1 = person_positions[i]\n",
        "                                p2 = person_positions[j]\n",
        "                                distance = ((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)**0.5\n",
        "                                total_distance += distance\n",
        "                                count += 1\n",
        "\n",
        "                        if count > 0:\n",
        "                            avg_distance = total_distance / count\n",
        "                            if avg_distance < 0.1:  # Close proximity\n",
        "                                concerns.append(\"Crowded walkway with limited personal space\")\n",
        "\n",
        "            # Check for motorcycles/bicycles near pedestrians\n",
        "            if (1 in detected_class_ids or 3 in detected_class_ids) and 0 in detected_class_ids:  # Bicycle/motorcycle and person\n",
        "                concerns.append(\"Two-wheeled vehicles in pedestrian areas\")\n",
        "\n",
        "            # Check for potential trip hazards\n",
        "            if scene_type == \"asian_commercial_street\" and \"bottom\" in \" \".join([obj[\"region\"] for obj in detected_objects if obj[\"class_id\"] == 0]):\n",
        "                # If people are in bottom regions, they might be walking on uneven surfaces\n",
        "                concerns.append(\"Potential uneven walking surfaces in commercial area\")\n",
        "\n",
        "        # Financial district safety concerns\n",
        "        elif scene_type == \"financial_district\":\n",
        "            # Check for heavy traffic conditions\n",
        "            vehicle_count = sum(1 for obj_id in detected_class_ids if obj_id in [2, 5, 7])  # Car, bus, truck\n",
        "            if vehicle_count > 5:\n",
        "                concerns.append(\"Heavy vehicle traffic in urban area\")\n",
        "\n",
        "            # Check for pedestrians crossing busy streets\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                vehicle_nearby = any(vehicle in detected_class_ids for vehicle in [2, 3, 5, 7])\n",
        "\n",
        "                if person_count > 0 and vehicle_nearby:\n",
        "                    concerns.append(\"Pedestrians navigating busy urban traffic\")\n",
        "\n",
        "            # Check for traffic signals\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Observe traffic signals when navigating this area\")\n",
        "            else:\n",
        "                # If no traffic lights detected but it's a busy area, it's worth noting\n",
        "                if vehicle_count > 3:\n",
        "                    concerns.append(\"Busy traffic area potentially without visible traffic signals in view\")\n",
        "\n",
        "            # Time of day considerations\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 5, 7]]\n",
        "            if vehicle_objs and any(\"lighting_conditions\" in obj for obj in detected_objects):\n",
        "                # If vehicles are present and it might be evening/night\n",
        "                concerns.append(\"Reduced visibility conditions during evening commute\")\n",
        "\n",
        "        # Urban intersection safety concerns\n",
        "        elif scene_type == \"urban_intersection\":\n",
        "            # Check for pedestrians in crosswalks\n",
        "            pedestrian_objs = [obj for obj in detected_objects if obj[\"class_id\"] == 0]\n",
        "            vehicle_objs = [obj for obj in detected_objects if obj[\"class_id\"] in [2, 3, 5, 7]]\n",
        "\n",
        "            if pedestrian_objs:\n",
        "                # Calculate distribution of pedestrians to see if they're crossing\n",
        "                pedestrian_positions = [obj[\"normalized_center\"] for obj in pedestrian_objs]\n",
        "\n",
        "                # Simplified check for pedestrians in crossing pattern\n",
        "                if len(pedestrian_positions) >= 3:\n",
        "                    # Check if pedestrians are distributed across different regions\n",
        "                    pedestrian_regions = set(obj[\"region\"] for obj in pedestrian_objs)\n",
        "                    if len(pedestrian_regions) >= 2:\n",
        "                        concerns.append(\"Multiple pedestrians crossing the intersection\")\n",
        "\n",
        "            # Check for traffic signal observation\n",
        "            if 9 in detected_class_ids:  # Traffic light\n",
        "                concerns.append(\"Observe traffic signals when crossing\")\n",
        "\n",
        "            # Check for busy intersection\n",
        "            if len(vehicle_objs) > 3:\n",
        "                concerns.append(\"Busy intersection with multiple vehicles\")\n",
        "\n",
        "            # Check for pedestrians potentially jay-walking\n",
        "            if pedestrian_objs and not 9 in detected_class_ids:  # People but no traffic lights\n",
        "                concerns.append(\"Pedestrians should use designated crosswalks\")\n",
        "\n",
        "            # Visibility concerns based on lighting\n",
        "            # This would be better with actual lighting data\n",
        "            pedestrian_count = len(pedestrian_objs)\n",
        "            if pedestrian_count > 5:\n",
        "                concerns.append(\"High pedestrian density at crossing points\")\n",
        "\n",
        "        # Transit hub safety concerns\n",
        "        elif scene_type == \"transit_hub\":\n",
        "            # These would be for transit areas like train stations or bus terminals\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 8:\n",
        "                    concerns.append(\"Crowded transit area requiring careful navigation\")\n",
        "\n",
        "            # Check for luggage/bags that could be trip hazards\n",
        "            if 24 in detected_class_ids or 28 in detected_class_ids:  # Backpack or suitcase\n",
        "                concerns.append(\"Luggage and personal items may create obstacles\")\n",
        "\n",
        "            # Public transportation vehicles\n",
        "            if any(vehicle in detected_class_ids for vehicle in [5, 6, 7]):  # Bus, train, truck\n",
        "                concerns.append(\"Stay clear of arriving and departing transit vehicles\")\n",
        "\n",
        "        # Shopping district safety concerns\n",
        "        elif scene_type == \"shopping_district\":\n",
        "            # Check for crowded shopping areas\n",
        "            if 0 in detected_class_ids:  # Person\n",
        "                person_count = detected_class_ids.count(0)\n",
        "                if person_count > 5:\n",
        "                    concerns.append(\"Crowded shopping area with multiple people\")\n",
        "\n",
        "            # Check for shopping bags and personal items\n",
        "            if 24 in detected_class_ids or 26 in detected_class_ids:  # Backpack or handbag\n",
        "                concerns.append(\"Mind personal belongings in busy retail environment\")\n",
        "\n",
        "            # Check for store entrances/exits which might have automatic doors\n",
        "            # We can't directly detect this, but can infer from context\n",
        "            if scene_type == \"shopping_district\" and 0 in detected_class_ids:\n",
        "                concerns.append(\"Be aware of store entrances and exits with potential automatic doors\")\n",
        "\n",
        "        return concerns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOZv19OLEu6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7786c5-2b92-4d59-8774-b0605def2c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing clip_prompts.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile clip_prompts.py\n",
        "\n",
        "# 場景類型提示\n",
        "SCENE_TYPE_PROMPTS = {\n",
        "    # 基本室內場景\n",
        "    \"living_room\": \"A photo of a living room with furniture and entertainment systems.\",\n",
        "    \"bedroom\": \"A photo of a bedroom with a bed and personal items.\",\n",
        "    \"dining_area\": \"A photo of a dining area with a table and chairs for meals.\",\n",
        "    \"kitchen\": \"A photo of a kitchen with cooking appliances and food preparation areas.\",\n",
        "    \"office_workspace\": \"A photo of an office workspace with desk, computer and work equipment.\",\n",
        "    \"meeting_room\": \"A photo of a meeting room with a conference table and multiple chairs.\",\n",
        "\n",
        "    # 基本室外/城市場景\n",
        "    \"city_street\": \"A photo of a city street with traffic, pedestrians and urban buildings.\",\n",
        "    \"parking_lot\": \"A photo of a parking lot with multiple parked vehicles.\",\n",
        "    \"park_area\": \"A photo of a park or recreational area with greenery and outdoor facilities.\",\n",
        "    \"retail_store\": \"A photo of a retail store with merchandise displays and shopping areas.\",\n",
        "    \"supermarket\": \"A photo of a supermarket with food items, aisles and shopping carts.\",\n",
        "\n",
        "    # 特殊室內場景\n",
        "    \"upscale_dining\": \"A photo of an upscale dining area with elegant furniture and refined decor.\",\n",
        "    \"conference_room\": \"A photo of a professional conference room with presentation equipment and seating.\",\n",
        "    \"classroom\": \"A photo of a classroom with desks, chairs and educational equipment.\",\n",
        "    \"library\": \"A photo of a library with bookshelves, reading areas and study spaces.\",\n",
        "\n",
        "    # 亞洲特色場景\n",
        "    \"asian_commercial_street\": \"A photo of an Asian commercial street with dense signage, shops and pedestrians.\",\n",
        "    \"asian_night_market\": \"A photo of an Asian night market with food stalls, crowds and colorful lights.\",\n",
        "    \"asian_temple_area\": \"A photo of an Asian temple with traditional architecture and cultural elements.\",\n",
        "\n",
        "    # 交通相關場景\n",
        "    \"financial_district\": \"A photo of a financial district with tall office buildings and business activity.\",\n",
        "    \"urban_intersection\": \"A photo of an urban intersection with crosswalks, traffic lights and pedestrians crossing.\",\n",
        "    \"transit_hub\": \"A photo of a transportation hub with multiple modes of public transit and passengers.\",\n",
        "    \"bus_stop\": \"A photo of a bus stop with people waiting and buses arriving or departing.\",\n",
        "    \"bus_station\": \"A photo of a bus terminal with multiple buses and traveler facilities.\",\n",
        "    \"train_station\": \"A photo of a train station with platforms, trains and passenger activity.\",\n",
        "    \"airport\": \"A photo of an airport with planes, terminals and traveler activity.\",\n",
        "\n",
        "    # 商業場景\n",
        "    \"shopping_district\": \"A photo of a shopping district with multiple retail stores and consumer activity.\",\n",
        "    \"cafe\": \"A photo of a cafe with coffee service, seating and casual dining.\",\n",
        "    \"restaurant\": \"A photo of a restaurant with dining tables, food service and eating areas.\",\n",
        "\n",
        "    # 空中視角場景\n",
        "    \"aerial_view_intersection\": \"An aerial view of an intersection showing crosswalks and traffic patterns from above.\",\n",
        "    \"aerial_view_commercial_area\": \"An aerial view of a commercial area showing shopping districts from above.\",\n",
        "    \"aerial_view_plaza\": \"An aerial view of a public plaza or square showing patterns of people movement from above.\",\n",
        "\n",
        "    # 娛樂場景\n",
        "    \"zoo\": \"A photo of a zoo with animal enclosures, exhibits and visitors.\",\n",
        "    \"playground\": \"A photo of a playground with recreational equipment and children playing.\",\n",
        "    \"sports_field\": \"A photo of a sports field with playing surfaces and athletic equipment.\",\n",
        "    \"sports_stadium\": \"A photo of a sports stadium with spectator seating and athletic facilities.\",\n",
        "\n",
        "    # 水相關場景\n",
        "    \"harbor\": \"A photo of a harbor with boats, docks and waterfront activity.\",\n",
        "    \"beach_water_recreation\": \"A photo of a beach area with water activities, sand and recreational equipment like surfboards.\",\n",
        "\n",
        "    # 文化時間特定場景\n",
        "    \"nighttime_street\": \"A photo of a street at night with artificial lighting and evening activity.\",\n",
        "    \"nighttime_commercial_district\": \"A photo of a commercial district at night with illuminated signs and evening shopping.\",\n",
        "    \"european_plaza\": \"A photo of a European-style plaza with historic architecture and public gathering spaces.\",\n",
        "\n",
        "    # 混合環境場景\n",
        "    \"indoor_outdoor_cafe\": \"A photo of a cafe with both indoor seating and outdoor patio areas.\",\n",
        "    \"transit_station_platform\": \"A photo of a transit station platform with waiting areas and arriving vehicles.\",\n",
        "\n",
        "    # 工作場景\n",
        "    \"construction_site\": \"A photo of a construction site with building materials, equipment and workers.\",\n",
        "    \"medical_facility\": \"A photo of a medical facility with healthcare equipment and professional staff.\",\n",
        "    \"educational_setting\": \"A photo of an educational setting with learning spaces and academic resources.\",\n",
        "    \"professional_kitchen\": \"A photo of a professional commercial kitchen with industrial cooking equipment and food preparation stations.\"\n",
        "}\n",
        "\n",
        "# 文化特定場景提示\n",
        "CULTURAL_SCENE_PROMPTS = {\n",
        "    \"asian_commercial_street\": [\n",
        "        \"A busy Asian shopping street with neon signs and dense storefronts.\",\n",
        "        \"A commercial street in Asia with multi-level signage and narrow walkways.\",\n",
        "        \"A street scene in Taiwan or Hong Kong with vertical signage and compact shops.\",\n",
        "        \"A crowded commercial alley in an Asian city with signs in Chinese characters.\",\n",
        "        \"A narrow shopping street in Asia with small shops on both sides.\",\n",
        "        \"An outdoor shopping district in an East Asian city with electronic billboards.\",\n",
        "        \"A bustling commercial street in Taiwan with food vendors and retail shops.\",\n",
        "        \"A pedestrian shopping area with Korean or Chinese signs and storefronts.\",\n",
        "        \"A daytime shopping street in an Asian urban center with vertical development.\"\n",
        "    ],\n",
        "    \"asian_night_market\": [\n",
        "        \"A vibrant night market in Asia with food stalls and large crowds.\",\n",
        "        \"An evening street market in Taiwan with street food vendors and bright lights.\",\n",
        "        \"A busy night bazaar in Asia with illuminated stalls and local food.\",\n",
        "        \"A crowded night street food market in an Asian city with vendor carts.\",\n",
        "        \"An Asian night market with steam from cooking food and hanging lanterns.\",\n",
        "        \"A nocturnal food street in East Asia with vendor canopies and neon lights.\",\n",
        "        \"A bustling evening market with rows of food stalls and plastic stools.\",\n",
        "        \"A lively Asian street food scene at night with cooking stations and crowds.\"\n",
        "    ],\n",
        "    \"asian_temple_area\": [\n",
        "        \"A traditional Asian temple with ornate roof details and religious symbols.\",\n",
        "        \"A Buddhist temple complex in East Asia with multiple pavilions and prayer areas.\",\n",
        "        \"A sacred site in Asia with incense burners and ceremonial elements.\",\n",
        "        \"A temple courtyard with stone statues and traditional Asian architecture.\",\n",
        "        \"A spiritual center in East Asia with pagoda-style structures and visitors.\",\n",
        "        \"An ancient temple site with Asian architectural elements and cultural symbols.\",\n",
        "        \"A religious compound with characteristic Asian roof curves and decorative features.\"\n",
        "    ],\n",
        "    \"european_plaza\": [\n",
        "        \"A historic European city square with classical architecture and cafes.\",\n",
        "        \"An old-world plaza in Europe with cobblestone paving and historic buildings.\",\n",
        "        \"A public square in a European city with fountains and surrounding architecture.\",\n",
        "        \"A central plaza in Europe with outdoor seating areas and historic monuments.\",\n",
        "        \"A traditional European town square with surrounding shops and restaurants.\",\n",
        "        \"A historic gathering space in Europe with distinctive architecture and pedestrians.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 對比類別提示\n",
        "COMPARATIVE_PROMPTS = {\n",
        "    \"indoor_vs_outdoor\": [\n",
        "        \"An indoor shopping mall corridor with controlled lighting and storefronts.\",\n",
        "        \"An outdoor commercial street with natural lighting and urban storefronts.\",\n",
        "        \"An enclosed shopping gallery with artificial lighting and climate control.\",\n",
        "        \"An open-air market street with natural light and weather exposure.\"\n",
        "    ],\n",
        "    \"professional_vs_home\": [\n",
        "        \"A professional commercial kitchen with stainless steel equipment and workstations.\",\n",
        "        \"A home kitchen with residential appliances and family cooking space.\",\n",
        "        \"A restaurant kitchen with multiple cooking stations and chef activity.\",\n",
        "        \"A family kitchen with standard household equipment and personal touches.\"\n",
        "    ],\n",
        "    \"sports_venue_vs_park\": [\n",
        "        \"A professional sports stadium with designated playing areas and audience seating.\",\n",
        "        \"A public park with casual recreation space and community greenery.\",\n",
        "        \"An athletic venue with specialized sports equipment and competitive playing surfaces.\",\n",
        "        \"An outdoor community space with general purpose areas and natural elements.\"\n",
        "    ],\n",
        "    \"asian_vs_western_commercial\": [\n",
        "        \"An Asian shopping street with vertical signage and compact multi-level shops.\",\n",
        "        \"A Western commercial street with horizontal storefronts and wider sidewalks.\",\n",
        "        \"An East Asian retail area with dense signage in Asian scripts and narrow walkways.\"\n",
        "        \"A Western shopping district with uniform building heights and Latin alphabetic signs.\"\n",
        "    ],\n",
        "    \"daytime_vs_nighttime\": [\n",
        "        \"A daytime urban scene with natural sunlight illuminating streets and buildings.\",\n",
        "        \"A nighttime city scene with artificial lighting from stores, signs and streetlights.\",\n",
        "        \"A commercial district during daylight hours with natural shadows and visibility.\",\n",
        "        \"An evening urban setting with illuminated storefronts and light patterns on streets.\"\n",
        "    ],\n",
        "    \"aerial_vs_street_level\": [\n",
        "        \"An aerial view showing urban patterns and layouts from above.\",\n",
        "        \"A street-level view showing pedestrian perspective and immediate surroundings.\",\n",
        "        \"A bird's-eye view of city organization and movement patterns from high above.\",\n",
        "        \"An eye-level perspective showing direct human interaction with urban elements.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 環境條件文本提示\n",
        "LIGHTING_CONDITION_PROMPTS = {\n",
        "    \"day_clear\": \"A photo taken during daytime with clear skies and direct sunlight.\",\n",
        "    \"day_cloudy\": \"A photo taken during daytime with overcast conditions and diffused light.\",\n",
        "    \"sunset/sunrise\": \"A photo taken during sunset or sunrise with warm golden lighting and long shadows.\",\n",
        "    \"night\": \"A photo taken at night with minimal natural light and artificial illumination.\",\n",
        "    \"indoor_bright\": \"An indoor photo with bright, even artificial lighting throughout the space.\",\n",
        "    \"indoor_moderate\": \"An indoor photo with moderate lighting creating a balanced indoor atmosphere.\",\n",
        "    \"indoor_dim\": \"An indoor photo with low lighting levels creating a subdued environment.\",\n",
        "    \"neon_night\": \"A night scene with colorful neon lighting creating vibrant illumination patterns.\",\n",
        "    \"indoor_commercial\": \"An indoor retail environment with directed display lighting highlighting products.\",\n",
        "    \"indoor_restaurant\": \"An indoor dining space with ambient mood lighting for atmosphere.\",\n",
        "    \"stadium_lighting\": \"A sports venue with powerful floodlights creating intense, even illumination.\",\n",
        "    \"mixed_lighting\": \"A scene with combined natural and artificial light sources creating transition zones.\",\n",
        "    \"beach_daylight\": \"A photo taken at a beach with bright natural sunlight and reflections from water.\",\n",
        "    \"sports_arena_lighting\": \"A photo of a sports venue illuminated by powerful overhead lighting systems.\",\n",
        "    \"kitchen_task_lighting\": \"A photo of a kitchen with focused lighting concentrated on work surfaces.\"\n",
        "}\n",
        "\n",
        "# 針對新場景類型的特殊提示\n",
        "SPECIALIZED_SCENE_PROMPTS = {\n",
        "    \"beach_water_recreation\": [\n",
        "        \"A coastal beach scene with people surfing and sunbathing on sandy shores.\",\n",
        "        \"Active water sports participants at a beach with surfboards and swimming areas.\",\n",
        "        \"A sunny beach destination with recreational water equipment and beachgoers.\",\n",
        "        \"A shoreline recreation area with surf gear and coastal activities.\",\n",
        "        \"An oceanfront scene with people engaging in water sports and beach leisure.\",\n",
        "        \"A popular beach spot with swimming areas and surfing zones.\",\n",
        "        \"A coastal recreation setting with beach umbrellas and water activities.\"\n",
        "    ],\n",
        "    \"sports_venue\": [\n",
        "        \"An indoor sports arena with professional equipment and competition spaces.\",\n",
        "        \"A sports stadium with marked playing areas and spectator seating arrangement.\",\n",
        "        \"A specialized athletic venue with competition equipment and performance areas.\",\n",
        "        \"A professional sports facility with game-related apparatus and audience zones.\",\n",
        "        \"An organized sports center with competitive play areas and athletic equipment.\",\n",
        "        \"A competition venue with sport-specific markings and professional setup.\",\n",
        "        \"A formal athletic facility with standardized equipment and playing surfaces.\"\n",
        "    ],\n",
        "    \"professional_kitchen\": [\n",
        "        \"A commercial restaurant kitchen with multiple cooking stations and food prep areas.\",\n",
        "        \"A professional culinary workspace with industrial appliances and chef activity.\",\n",
        "        \"A busy restaurant back-of-house with stainless steel equipment and meal preparation.\",\n",
        "        \"A commercial food service kitchen with chef workstations and specialized zones.\",\n",
        "        \"An industrial kitchen facility with specialized cooking equipment and prep surfaces.\",\n",
        "        \"A high-volume food production kitchen with professional-grade appliances.\",\n",
        "        \"A restaurant kitchen with distinct cooking areas and culinary workflow design.\"\n",
        "    ],\n",
        "    \"urban_intersection\": [\n",
        "        \"A city intersection with crosswalks and traffic signals controlling movement.\",\n",
        "        \"A busy urban crossroad with pedestrian crossings and vehicle traffic.\",\n",
        "        \"A regulated street intersection with crosswalk markings and waiting pedestrians.\",\n",
        "        \"A metropolitan junction with traffic lights and pedestrian crossing zones.\",\n",
        "        \"A city street crossing with safety features for pedestrians and traffic flow.\",\n",
        "        \"A controlled urban intersection with movement patterns for vehicles and people.\",\n",
        "        \"A city center crossroad with traffic management features and pedestrian areas.\"\n",
        "    ],\n",
        "    \"financial_district\": [\n",
        "        \"A downtown business area with tall office buildings and commercial activity.\",\n",
        "        \"An urban financial center with skyscrapers and professional environment.\",\n",
        "        \"A city's business district with corporate headquarters and office towers.\",\n",
        "        \"A metropolitan financial zone with high-rise buildings and business traffic.\",\n",
        "        \"A corporate district in a city center with professional architecture.\",\n",
        "        \"An urban area dominated by office buildings and business establishments.\",\n",
        "        \"A city's economic center with banking institutions and corporate offices.\"\n",
        "    ],\n",
        "    \"aerial_view_intersection\": [\n",
        "        \"A bird's-eye view of a city intersection showing crossing patterns from above.\",\n",
        "        \"An overhead perspective of an urban crossroad showing traffic organization.\",\n",
        "        \"A top-down view of a street intersection revealing pedestrian crosswalks.\",\n",
        "        \"An aerial shot of a city junction showing the layout of roads and crossings.\",\n",
        "        \"A high-angle view of an intersection showing traffic and pedestrian flow patterns.\",\n",
        "        \"A drone perspective of urban crossing design viewed from directly above.\",\n",
        "        \"A vertical view of a street intersection showing crossing infrastructure.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "VIEWPOINT_PROMPTS = {\n",
        "    \"eye_level\": \"A photo taken from normal human eye level showing a direct frontal perspective.\",\n",
        "    \"aerial\": \"A photo taken from high above looking directly down at the scene below.\",\n",
        "    \"elevated\": \"A photo taken from a higher than normal position looking down at an angle.\",\n",
        "    \"low_angle\": \"A photo taken from a low position looking upward at the scene.\",\n",
        "    \"bird_eye\": \"A photo taken from very high above showing a complete overhead perspective.\",\n",
        "    \"street_level\": \"A photo taken from the perspective of someone standing on the street.\",\n",
        "    \"interior\": \"A photo taken from inside a building showing the internal environment.\",\n",
        "    \"vehicular\": \"A photo taken from inside or mounted on a moving vehicle.\"\n",
        "}\n",
        "\n",
        "OBJECT_COMBINATION_PROMPTS = {\n",
        "    \"dining_setting\": \"A scene with tables, chairs, plates, and eating utensils arranged for meals.\",\n",
        "    \"office_setup\": \"A scene with desks, chairs, computers, and office supplies for work.\",\n",
        "    \"living_space\": \"A scene with sofas, coffee tables, TVs, and comfortable seating arrangements.\",\n",
        "    \"transportation_hub\": \"A scene with vehicles, waiting areas, passengers, and transit information.\",\n",
        "    \"retail_environment\": \"A scene with merchandise displays, shoppers, and store fixtures.\",\n",
        "    \"crosswalk_scene\": \"A scene with street markings, pedestrians crossing, and traffic signals.\",\n",
        "    \"cooking_area\": \"A scene with stoves, prep surfaces, cooking utensils, and food items.\",\n",
        "    \"recreational_space\": \"A scene with sports equipment, play areas, and activity participants.\"\n",
        "}\n",
        "\n",
        "ACTIVITY_PROMPTS = {\n",
        "    \"shopping\": \"People looking at merchandise, carrying shopping bags, and browsing stores.\",\n",
        "    \"dining\": \"People eating food, sitting at tables, and using dining utensils.\",\n",
        "    \"commuting\": \"People waiting for transportation, boarding vehicles, and traveling.\",\n",
        "    \"working\": \"People using computers, attending meetings, and engaged in professional tasks.\",\n",
        "    \"exercising\": \"People engaged in physical activities, using sports equipment, and training.\",\n",
        "    \"cooking\": \"People preparing food, using kitchen equipment, and creating meals.\",\n",
        "    \"crossing_street\": \"People walking across designated crosswalks and navigating intersections.\",\n",
        "    \"recreational_activity\": \"People engaged in leisure activities, games, and social recreation.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LTmls2hz4bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788fa955-c94f-43ba-d0fe-1c4fcbc8f5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing clip_analyzer.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile clip_analyzer.py\n",
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple, Any, Optional, Union\n",
        "\n",
        "# from clip_prompts import (\n",
        "#     SCENE_TYPE_PROMPTS,\n",
        "#     CULTURAL_SCENE_PROMPTS,\n",
        "#     COMPARATIVE_PROMPTS,\n",
        "#     LIGHTING_CONDITION_PROMPTS,\n",
        "#     SPECIALIZED_SCENE_PROMPTS,\n",
        "#     VIEWPOINT_PROMPTS,\n",
        "#     OBJECT_COMBINATION_PROMPTS,\n",
        "#     ACTIVITY_PROMPTS\n",
        "# )\n",
        "\n",
        "class CLIPAnalyzer:\n",
        "    \"\"\"\n",
        "    Use Clip to intergrate scene understanding function\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"ViT-B/16\", device: str = None):\n",
        "        \"\"\"\n",
        "        初始化 CLIP 分析器。\n",
        "\n",
        "        Args:\n",
        "            model_name: CLIP Model name, 默認 \"ViT-B/16\"\n",
        "            device: Use GPU if it can use\n",
        "        \"\"\"\n",
        "        # 自動選擇設備\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        print(f\"Loading CLIP model {model_name} on {self.device}...\")\n",
        "        try:\n",
        "            self.model, self.preprocess = clip.load(model_name, device=self.device)\n",
        "            print(f\"CLIP model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CLIP model: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.scene_type_prompts = SCENE_TYPE_PROMPTS\n",
        "        self.cultural_scene_prompts = CULTURAL_SCENE_PROMPTS\n",
        "        self.comparative_prompts = COMPARATIVE_PROMPTS\n",
        "        self.lighting_condition_prompts = LIGHTING_CONDITION_PROMPTS\n",
        "        self.specialized_scene_prompts = SPECIALIZED_SCENE_PROMPTS\n",
        "        self.viewpoint_prompts = VIEWPOINT_PROMPTS\n",
        "        self.object_combination_prompts = OBJECT_COMBINATION_PROMPTS\n",
        "        self.activity_prompts = ACTIVITY_PROMPTS\n",
        "\n",
        "        # turn to CLIP format\n",
        "        self._prepare_text_prompts()\n",
        "\n",
        "    def _prepare_text_prompts(self):\n",
        "        \"\"\"準備所有文本提示的 CLIP 特徵並存儲到 self.text_features_cache 中\"\"\"\n",
        "        self.text_features_cache = {}\n",
        "\n",
        "        # 處理基礎場景類型 (SCENE_TYPE_PROMPTS)\n",
        "        if hasattr(self, 'scene_type_prompts') and self.scene_type_prompts:\n",
        "            scene_texts = [prompt for scene_type, prompt in self.scene_type_prompts.items()]\n",
        "            if scene_texts:\n",
        "                self.text_features_cache[\"scene_type_keys\"] = list(self.scene_type_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"scene_type_tokens\"] = clip.tokenize(scene_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing scene_type_prompts: {e}\")\n",
        "                    self.text_features_cache[\"scene_type_tokens\"] = None # 標記錯誤或空\n",
        "            else:\n",
        "                self.text_features_cache[\"scene_type_keys\"] = []\n",
        "                self.text_features_cache[\"scene_type_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"scene_type_keys\"] = []\n",
        "            self.text_features_cache[\"scene_type_tokens\"] = None\n",
        "\n",
        "        # 處理文化場景 (CULTURAL_SCENE_PROMPTS)\n",
        "        # cultural_tokens_dict 存儲的是 tokenized prompts\n",
        "        cultural_tokens_dict_val = {}\n",
        "        if hasattr(self, 'cultural_scene_prompts') and self.cultural_scene_prompts:\n",
        "            for scene_type, prompts in self.cultural_scene_prompts.items():\n",
        "                if prompts and isinstance(prompts, list) and all(isinstance(p, str) for p in prompts):\n",
        "                    try:\n",
        "                        cultural_tokens_dict_val[scene_type] = clip.tokenize(prompts).to(self.device)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Error tokenizing cultural_scene_prompts for {scene_type}: {e}\")\n",
        "                        cultural_tokens_dict_val[scene_type] = None # 標記錯誤或空\n",
        "                else:\n",
        "                    cultural_tokens_dict_val[scene_type] = None # prompts 不合規\n",
        "        self.text_features_cache[\"cultural_tokens_dict\"] = cultural_tokens_dict_val\n",
        "\n",
        "        # 處理光照條件 (LIGHTING_CONDITION_PROMPTS)\n",
        "        if hasattr(self, 'lighting_condition_prompts') and self.lighting_condition_prompts:\n",
        "            lighting_texts = [prompt for cond, prompt in self.lighting_condition_prompts.items()]\n",
        "            if lighting_texts:\n",
        "                self.text_features_cache[\"lighting_condition_keys\"] = list(self.lighting_condition_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"lighting_tokens\"] = clip.tokenize(lighting_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing lighting_condition_prompts: {e}\")\n",
        "                    self.text_features_cache[\"lighting_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"lighting_condition_keys\"] = []\n",
        "                self.text_features_cache[\"lighting_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"lighting_condition_keys\"] = []\n",
        "            self.text_features_cache[\"lighting_tokens\"] = None\n",
        "\n",
        "        # 處理特殊場景 (SPECIALIZED_SCENE_PROMPTS)\n",
        "        specialized_tokens_dict_val = {}\n",
        "        if hasattr(self, 'specialized_scene_prompts') and self.specialized_scene_prompts:\n",
        "            for scene_type, prompts in self.specialized_scene_prompts.items():\n",
        "                if prompts and isinstance(prompts, list) and all(isinstance(p, str) for p in prompts):\n",
        "                    try:\n",
        "                        specialized_tokens_dict_val[scene_type] = clip.tokenize(prompts).to(self.device)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Error tokenizing specialized_scene_prompts for {scene_type}: {e}\")\n",
        "                        specialized_tokens_dict_val[scene_type] = None\n",
        "                else:\n",
        "                    specialized_tokens_dict_val[scene_type] = None\n",
        "        self.text_features_cache[\"specialized_tokens_dict\"] = specialized_tokens_dict_val\n",
        "\n",
        "        # 處理視角 (VIEWPOINT_PROMPTS)\n",
        "        if hasattr(self, 'viewpoint_prompts') and self.viewpoint_prompts:\n",
        "            viewpoint_texts = [prompt for viewpoint, prompt in self.viewpoint_prompts.items()]\n",
        "            if viewpoint_texts:\n",
        "                self.text_features_cache[\"viewpoint_keys\"] = list(self.viewpoint_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"viewpoint_tokens\"] = clip.tokenize(viewpoint_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing viewpoint_prompts: {e}\")\n",
        "                    self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"viewpoint_keys\"] = []\n",
        "                self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"viewpoint_keys\"] = []\n",
        "            self.text_features_cache[\"viewpoint_tokens\"] = None\n",
        "\n",
        "        # 處理物件組合 (OBJECT_COMBINATION_PROMPTS)\n",
        "        if hasattr(self, 'object_combination_prompts') and self.object_combination_prompts:\n",
        "            object_combination_texts = [prompt for combo, prompt in self.object_combination_prompts.items()]\n",
        "            if object_combination_texts:\n",
        "                self.text_features_cache[\"object_combination_keys\"] = list(self.object_combination_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"object_combination_tokens\"] = clip.tokenize(object_combination_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing object_combination_prompts: {e}\")\n",
        "                    self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"object_combination_keys\"] = []\n",
        "                self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"object_combination_keys\"] = []\n",
        "            self.text_features_cache[\"object_combination_tokens\"] = None\n",
        "\n",
        "        # 處理活動 (ACTIVITY_PROMPTS)\n",
        "        if hasattr(self, 'activity_prompts') and self.activity_prompts:\n",
        "            activity_texts = [prompt for activity, prompt in self.activity_prompts.items()]\n",
        "            if activity_texts:\n",
        "                self.text_features_cache[\"activity_keys\"] = list(self.activity_prompts.keys())\n",
        "                try:\n",
        "                    self.text_features_cache[\"activity_tokens\"] = clip.tokenize(activity_texts).to(self.device)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error tokenizing activity_prompts: {e}\")\n",
        "                    self.text_features_cache[\"activity_tokens\"] = None\n",
        "            else:\n",
        "                self.text_features_cache[\"activity_keys\"] = []\n",
        "                self.text_features_cache[\"activity_tokens\"] = None\n",
        "        else:\n",
        "            self.text_features_cache[\"activity_keys\"] = []\n",
        "            self.text_features_cache[\"activity_tokens\"] = None\n",
        "\n",
        "        self.scene_type_tokens = self.text_features_cache[\"scene_type_tokens\"]\n",
        "        self.lighting_tokens = self.text_features_cache[\"lighting_tokens\"]\n",
        "        self.viewpoint_tokens = self.text_features_cache[\"viewpoint_tokens\"]\n",
        "        self.object_combination_tokens = self.text_features_cache[\"object_combination_tokens\"]\n",
        "        self.activity_tokens = self.text_features_cache[\"activity_tokens\"]\n",
        "        self.cultural_tokens_dict = self.text_features_cache[\"cultural_tokens_dict\"]\n",
        "        self.specialized_tokens_dict = self.text_features_cache[\"specialized_tokens_dict\"]\n",
        "\n",
        "        print(\"CLIP text_features_cache prepared.\")\n",
        "\n",
        "    def analyze_image(self, image, include_cultural_analysis=True, exclude_categories=None, enable_landmark=True, places365_guidance=None):\n",
        "        \"\"\"\n",
        "        分析圖像，預測場景類型和光照條件。\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像 (PIL Image 或 numpy array)\n",
        "            include_cultural_analysis: 是否包含文化場景的詳細分析\n",
        "            exclude_categories: 要排除的類別列表\n",
        "            enable_landmark: 是否啟用地標檢測功能\n",
        "            places365_guidance: Places365 提供的場景指導信息 (可選)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含場景類型預測和光照條件的分析結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.enable_landmark = enable_landmark # 更新實例的 enable_landmark 狀態\n",
        "            # 確保圖像是 PIL 格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 預處理圖像\n",
        "            image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "            # 獲取圖像特徵\n",
        "            with torch.no_grad():\n",
        "                image_features = self.model.encode_image(image_input)\n",
        "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            places365_focus_areas = []\n",
        "            places365_scene_context = \"\" # 用於存儲 Places365 提供的場景描述\n",
        "\n",
        "            if places365_guidance and isinstance(places365_guidance, dict) and places365_guidance.get('confidence', 0) > 0.4:\n",
        "                mapped_scene = places365_guidance.get('mapped_scene_type', '')\n",
        "                scene_label = places365_guidance.get('scene_label', '')\n",
        "                # is_indoor = places365_guidance.get('is_indoor', None) # 未使用，可註釋\n",
        "                attributes = places365_guidance.get('attributes', [])\n",
        "\n",
        "                places365_scene_context = f\"Scene identified by Places365 as {scene_label}\" # 更新上下文描述\n",
        "\n",
        "                # Adjust CLIP analysis focus based on Places365 scene type\n",
        "                if mapped_scene in ['kitchen', 'dining_area', 'restaurant']:\n",
        "                    places365_focus_areas.extend(['food preparation', 'dining setup', 'kitchen appliances'])\n",
        "                elif mapped_scene in ['office_workspace', 'educational_setting', 'library', 'conference_room']:\n",
        "                    places365_focus_areas.extend(['work environment', 'professional setting', 'learning space', 'study area'])\n",
        "                elif mapped_scene in ['retail_store', 'shopping_mall', 'market', 'supermarket']: # 擴展匹配\n",
        "                    places365_focus_areas.extend(['commercial space', 'shopping environment', 'retail display', 'goods for sale'])\n",
        "                elif mapped_scene in ['park_area', 'beach', 'natural_outdoor_area', 'playground', 'sports_field']: # 擴展匹配\n",
        "                    places365_focus_areas.extend(['outdoor recreation', 'natural environment', 'leisure activity', 'open space'])\n",
        "\n",
        "                # 根據屬性添加更通用的 focus areas\n",
        "                if isinstance(attributes, list): # 確保 attributes 是列表\n",
        "                    if 'commercial' in attributes:\n",
        "                        places365_focus_areas.append('business activity')\n",
        "                    if 'recreational' in attributes:\n",
        "                        places365_focus_areas.append('entertainment or leisure')\n",
        "                    if 'residential' in attributes:\n",
        "                        places365_focus_areas.append('living space')\n",
        "\n",
        "                # 去重\n",
        "                places365_focus_areas = list(set(places365_focus_areas))\n",
        "\n",
        "                if places365_focus_areas: # 只有在確實有 focus areas 時才打印\n",
        "                    print(f\"CLIP analysis guided by Places365: {places365_scene_context}, focus areas: {places365_focus_areas}\")\n",
        "\n",
        "            # 分析場景類型，傳遞 enable_landmark 參數和 Places365 指導\n",
        "            scene_scores = self._analyze_scene_type(image_features,\n",
        "                                                  enable_landmark=self.enable_landmark, # 使用更新後的實例屬性\n",
        "                                                  places365_focus=places365_focus_areas)\n",
        "\n",
        "            # 如果禁用地標功能，確保排除地標相關類別\n",
        "            current_exclude_categories = list(exclude_categories) if exclude_categories is not None else []\n",
        "            if not self.enable_landmark: # 使用更新後的實例屬性\n",
        "                landmark_related_terms = [\"landmark\", \"monument\", \"tower\", \"tourist\", \"attraction\", \"historical\", \"famous\", \"iconic\"]\n",
        "                for term in landmark_related_terms:\n",
        "                    if term not in current_exclude_categories:\n",
        "                        current_exclude_categories.append(term)\n",
        "\n",
        "            if current_exclude_categories:\n",
        "                filtered_scores = {}\n",
        "                for scene, score in scene_scores.items():\n",
        "                    # 檢查 scene 的鍵名（通常是英文）是否包含任何排除詞彙\n",
        "                    if not any(cat.lower() in scene.lower() for cat in current_exclude_categories):\n",
        "                        filtered_scores[scene] = score\n",
        "\n",
        "                if filtered_scores:\n",
        "                    total_score = sum(filtered_scores.values())\n",
        "                    if total_score > 1e-5: # 避免除以零或非常小的數\n",
        "                        scene_scores = {k: v / total_score for k, v in filtered_scores.items()}\n",
        "                    else: # 如果總分趨近於0，則保持原樣或設為0\n",
        "                        scene_scores = {k: 0.0 for k in filtered_scores.keys()} # 或者 scene_scores = filtered_scores\n",
        "                else: # 如果過濾後沒有場景了\n",
        "                    scene_scores = {k: (0.0 if any(cat.lower() in k.lower() for cat in current_exclude_categories) else v) for k,v in scene_scores.items()}\n",
        "                    if not any(s > 1e-5 for s in scene_scores.values()): # 如果還是全0\n",
        "                         scene_scores = {\"unknown\": 1.0} # 給一個默認值避免空字典\n",
        "\n",
        "            lighting_scores = self._analyze_lighting_condition(image_features)\n",
        "            cultural_analysis = {}\n",
        "            if include_cultural_analysis and self.enable_landmark: # 使用更新後的實例屬性\n",
        "                for scene_type_cultural_key in self.text_features_cache.get(\"cultural_tokens_dict\", {}).keys():\n",
        "                     # 確保 scene_type_cultural_key 是 SCENE_TYPE_PROMPTS 中的鍵，或者有一個映射關係\n",
        "                    if scene_type_cultural_key in scene_scores and scene_scores[scene_type_cultural_key] > 0.2:\n",
        "                        cultural_analysis[scene_type_cultural_key] = self._analyze_cultural_scene(\n",
        "                            image_features, scene_type_cultural_key\n",
        "                        )\n",
        "\n",
        "            specialized_analysis = {}\n",
        "            for scene_type_specialized_key in self.text_features_cache.get(\"specialized_tokens_dict\", {}).keys():\n",
        "                if scene_type_specialized_key in scene_scores and scene_scores[scene_type_specialized_key] > 0.2:\n",
        "                    specialized_analysis[scene_type_specialized_key] = self._analyze_specialized_scene(\n",
        "                        image_features, scene_type_specialized_key\n",
        "                    )\n",
        "\n",
        "            viewpoint_scores = self._analyze_viewpoint(image_features)\n",
        "            object_combination_scores = self._analyze_object_combinations(image_features)\n",
        "            activity_scores = self._analyze_activities(image_features)\n",
        "\n",
        "            if scene_scores: # 確保 scene_scores 不是空的\n",
        "                top_scene = max(scene_scores.items(), key=lambda x: x[1])\n",
        "                 # 如果禁用地標，再次確認 top_scene 不是地標相關\n",
        "                if not self.enable_landmark and any(cat.lower() in top_scene[0].lower() for cat in current_exclude_categories):\n",
        "                    non_excluded_scores = {k:v for k,v in scene_scores.items() if not any(cat.lower() in k.lower() for cat in current_exclude_categories)}\n",
        "                    if non_excluded_scores:\n",
        "                        top_scene = max(non_excluded_scores.items(), key=lambda x: x[1])\n",
        "                    else:\n",
        "                        top_scene = (\"unknown\", 0.0) # 或其他合適的默認值\n",
        "            else:\n",
        "                top_scene = (\"unknown\", 0.0)\n",
        "\n",
        "\n",
        "            result = {\n",
        "                \"scene_scores\": scene_scores,\n",
        "                \"top_scene\": top_scene,\n",
        "                \"lighting_condition\": max(lighting_scores.items(), key=lambda x: x[1]) if lighting_scores else (\"unknown\", 0.0),\n",
        "                \"embedding\": image_features.cpu().numpy().tolist()[0], # 簡化\n",
        "                \"viewpoint\": max(viewpoint_scores.items(), key=lambda x: x[1]) if viewpoint_scores else (\"unknown\", 0.0),\n",
        "                \"object_combinations\": sorted(object_combination_scores.items(), key=lambda x: x[1], reverse=True)[:3] if object_combination_scores else [],\n",
        "                \"activities\": sorted(activity_scores.items(), key=lambda x: x[1], reverse=True)[:3] if activity_scores else []\n",
        "            }\n",
        "\n",
        "            if places365_guidance and isinstance(places365_guidance, dict) and places365_focus_areas: # 檢查 places365_focus_areas 是否被填充\n",
        "                result[\"places365_guidance\"] = {\n",
        "                    \"scene_context\": places365_scene_context,\n",
        "                    \"focus_areas\": places365_focus_areas, # 現在這個會包含基於 guidance 的內容\n",
        "                    \"guided_analysis\": True,\n",
        "                    \"original_places365_scene\": places365_guidance.get('scene_label', 'N/A'),\n",
        "                    \"original_places365_confidence\": places365_guidance.get('confidence', 0.0)\n",
        "                }\n",
        "\n",
        "            if cultural_analysis and self.enable_landmark:\n",
        "                result[\"cultural_analysis\"] = cultural_analysis\n",
        "\n",
        "            if specialized_analysis:\n",
        "                result[\"specialized_analysis\"] = specialized_analysis\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing image with CLIP: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\"error\": str(e), \"scene_scores\": {}, \"top_scene\": (\"error\", 0.0)}\n",
        "\n",
        "    def _analyze_scene_type(self, image_features: torch.Tensor, enable_landmark: bool = True, places365_focus: List[str] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        分析圖像特徵與各場景類型的相似度，並可選擇性地排除地標相關場景\n",
        "\n",
        "        Args:\n",
        "            image_features: 經過 CLIP 編碼的圖像特徵\n",
        "            enable_landmark: 是否啟用地標識別功能\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 各場景類型的相似度分數字典\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算場景類型文本特徵\n",
        "            text_features = self.model.encode_text(self.scene_type_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # Apply Places365 guidance if available\n",
        "            if places365_focus and len(places365_focus) > 0:\n",
        "                # Create enhanced prompts that incorporate Places365 guidance\n",
        "                enhanced_prompts = []\n",
        "                for scene_type in self.scene_type_prompts.keys():\n",
        "                    base_prompt = self.scene_type_prompts[scene_type]\n",
        "\n",
        "                    # Check if this scene type should be emphasized based on Places365 guidance\n",
        "                    scene_lower = scene_type.lower()\n",
        "                    should_enhance = False\n",
        "\n",
        "                    for focus_area in places365_focus:\n",
        "                        if any(keyword in scene_lower for keyword in focus_area.split()):\n",
        "                            should_enhance = True\n",
        "                            enhanced_prompts.append(f\"{base_prompt} with {focus_area}\")\n",
        "                            break\n",
        "\n",
        "                    if not should_enhance:\n",
        "                        enhanced_prompts.append(base_prompt)\n",
        "\n",
        "                # Re-tokenize and encode enhanced prompts\n",
        "                enhanced_tokens = clip.tokenize(enhanced_prompts).to(self.device)\n",
        "                text_features = self.model.encode_text(enhanced_tokens)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立場景分數字典\n",
        "            scene_scores = {}\n",
        "            for i, scene_type in enumerate(self.scene_type_prompts.keys()):\n",
        "                # 如果未啟用地標功能，則跳過地標相關場景類型\n",
        "                if not enable_landmark and scene_type in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                    scene_scores[scene_type] = 0.0  # 將地標場景分數設為零\n",
        "                else:\n",
        "                    base_score = float(similarity[i])\n",
        "\n",
        "                    # Apply Places365 guidance boost if applicable\n",
        "                    if places365_focus:\n",
        "                        scene_lower = scene_type.lower()\n",
        "                        boost_factor = 1.0\n",
        "\n",
        "                        for focus_area in places365_focus:\n",
        "                            if any(keyword in scene_lower for keyword in focus_area.split()):\n",
        "                                boost_factor = 1.15  # 15% boost for matching scenes\n",
        "                                break\n",
        "\n",
        "                        scene_scores[scene_type] = base_score * boost_factor\n",
        "                    else:\n",
        "                        scene_scores[scene_type] = base_score\n",
        "\n",
        "            # 如果禁用地標功能，確保重新歸一化剩餘場景分數\n",
        "            if not enable_landmark:\n",
        "                # 獲取所有非零分數\n",
        "                non_zero_scores = {k: v for k, v in scene_scores.items() if v > 0}\n",
        "                if non_zero_scores:\n",
        "                    # 計算總和並歸一化\n",
        "                    total_score = sum(non_zero_scores.values())\n",
        "                    if total_score > 0:\n",
        "                        for scene_type in non_zero_scores:\n",
        "                            scene_scores[scene_type] = non_zero_scores[scene_type] / total_score\n",
        "\n",
        "            return scene_scores\n",
        "\n",
        "    def _analyze_lighting_condition(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像的光照條件\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算光照條件文本特徵\n",
        "            text_features = self.model.encode_text(self.lighting_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立光照條件分數字典\n",
        "            lighting_scores = {}\n",
        "            for i, lighting_type in enumerate(self.lighting_condition_prompts.keys()):\n",
        "                lighting_scores[lighting_type] = float(similarity[i])\n",
        "\n",
        "            return lighting_scores\n",
        "\n",
        "    def _analyze_cultural_scene(self, image_features: torch.Tensor, scene_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"針對特定文化場景進行深入分析\"\"\"\n",
        "        if scene_type not in self.cultural_tokens_dict:\n",
        "            return {\"error\": f\"No cultural analysis available for {scene_type}\"}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 獲取特定文化場景的文本特徵\n",
        "            cultural_tokens = self.cultural_tokens_dict[scene_type]\n",
        "            text_features = self.model.encode_text(cultural_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 找到最匹配的文化描述\n",
        "            prompts = self.cultural_scene_prompts[scene_type]\n",
        "            scores = [(prompts[i], float(similarity[i])) for i in range(len(prompts))]\n",
        "            scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            return {\n",
        "                \"best_description\": scores[0][0],\n",
        "                \"confidence\": scores[0][1],\n",
        "                \"all_matches\": scores\n",
        "            }\n",
        "\n",
        "    def _analyze_specialized_scene(self, image_features: torch.Tensor, scene_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"針對特定專門場景進行深入分析\"\"\"\n",
        "        if scene_type not in self.specialized_tokens_dict:\n",
        "            return {\"error\": f\"No specialized analysis available for {scene_type}\"}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 獲取特定專門場景的文本特徵\n",
        "            specialized_tokens = self.specialized_tokens_dict[scene_type]\n",
        "            text_features = self.model.encode_text(specialized_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 找到最匹配的專門描述\n",
        "            prompts = self.specialized_scene_prompts[scene_type]\n",
        "            scores = [(prompts[i], float(similarity[i])) for i in range(len(prompts))]\n",
        "            scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            return {\n",
        "                \"best_description\": scores[0][0],\n",
        "                \"confidence\": scores[0][1],\n",
        "                \"all_matches\": scores\n",
        "            }\n",
        "\n",
        "    def _analyze_viewpoint(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像的拍攝視角\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算視角文本特徵\n",
        "            text_features = self.model.encode_text(self.viewpoint_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立視角分數字典\n",
        "            viewpoint_scores = {}\n",
        "            for i, viewpoint in enumerate(self.viewpoint_prompts.keys()):\n",
        "                viewpoint_scores[viewpoint] = float(similarity[i])\n",
        "\n",
        "            return viewpoint_scores\n",
        "\n",
        "    def _analyze_object_combinations(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像中的物體組合\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算物體組合文本特徵\n",
        "            text_features = self.model.encode_text(self.object_combination_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立物體組合分數字典\n",
        "            combination_scores = {}\n",
        "            for i, combination in enumerate(self.object_combination_prompts.keys()):\n",
        "                combination_scores[combination] = float(similarity[i])\n",
        "\n",
        "            return combination_scores\n",
        "\n",
        "    def _analyze_activities(self, image_features: torch.Tensor) -> Dict[str, float]:\n",
        "        \"\"\"分析圖像中的活動\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # 計算活動文本特徵\n",
        "            text_features = self.model.encode_text(self.activity_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            # 計算相似度分數\n",
        "            similarity = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "            # 建立活動分數字典\n",
        "            activity_scores = {}\n",
        "            for i, activity in enumerate(self.activity_prompts.keys()):\n",
        "                activity_scores[activity] = float(similarity[i])\n",
        "\n",
        "            return activity_scores\n",
        "\n",
        "    def get_image_embedding(self, image) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        獲取圖像的 CLIP 嵌入表示\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy array\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: 圖像的 CLIP 特徵向量\n",
        "        \"\"\"\n",
        "        # 確保圖像是 PIL 格式\n",
        "        if not isinstance(image, Image.Image):\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image = Image.fromarray(image)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "        # 預處理並編碼\n",
        "        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_input)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # 轉換為 numpy 並返回\n",
        "        return image_features.cpu().numpy()[0] if self.device == \"cuda\" else image_features.numpy()[0]\n",
        "\n",
        "    def text_to_embedding(self, text: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        將文本轉換為 CLIP 嵌入表示\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: 文本的 CLIP 特徵向量\n",
        "        \"\"\"\n",
        "        text_token = clip.tokenize([text]).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_features = self.model.encode_text(text_token)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        return text_features.cpu().numpy()[0] if self.device == \"cuda\" else text_features.numpy()[0]\n",
        "\n",
        "    def calculate_similarity(self, image, text_queries: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        計算圖像與多個文本查詢的相似度\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy array\n",
        "            text_queries: 文本查詢列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 每個查詢的相似度分數\n",
        "        \"\"\"\n",
        "        # 獲取圖像嵌入\n",
        "        if isinstance(image, np.ndarray) and len(image.shape) == 1:\n",
        "            # 已經是嵌入向量\n",
        "            image_features = torch.tensor(image).unsqueeze(0).to(self.device)\n",
        "        else:\n",
        "            # 是圖像，需要提取嵌入\n",
        "            image_features = torch.tensor(self.get_image_embedding(image)).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # calulate similarity\n",
        "        text_tokens = clip.tokenize(text_queries).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_features = self.model.encode_text(text_tokens)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            similarity = similarity.cpu().numpy()[0] if self.device == \"cuda\" else similarity.numpy()[0]\n",
        "\n",
        "        # display results\n",
        "        result = {}\n",
        "        for i, query in enumerate(text_queries):\n",
        "            result[query] = float(similarity[i])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_clip_instance(self):\n",
        "        \"\"\"\n",
        "        獲取初始化好的CLIP模型實例，便於其他模組重用\n",
        "\n",
        "        Returns:\n",
        "            tuple: (模型實例, 預處理函數, 設備名稱)\n",
        "        \"\"\"\n",
        "        return self.model, self.preprocess, self.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pQfOjOABhs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9c7589-02a4-48f3-af95-4e3d7f220503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing landmark_data.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile landmark_data.py\n",
        "\n",
        "\"\"\"\n",
        "Landmark database for zero-shot classification using CLIP\n",
        "\"\"\"\n",
        "\n",
        "LANDMARK_DATA = {\n",
        "    # 亞洲地標\n",
        "    \"asia\": {\n",
        "        \"taipei_101\": {\n",
        "            \"name\": \"Taipei 101\",\n",
        "            \"aliases\": [\"Taipei 101 Tower\", \"Taipei Financial Center\", \"台北101大樓\", \"Taipei World Financial Center\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic green bamboo-shaped Taipei 101 skyscraper against city skyline\",\n",
        "                \"Taipei 101 tower with its distinctive stacked pagoda design and vibrant green glass facade\",\n",
        "                \"world-famous Taipei 101 skyscraper with its segmented exterior resembling a bamboo stalk and prominent observation deck\",\n",
        "                \"close-up of Taipei 101's architectural details showing the ruyi-inspired motifs and bamboo-inspired segments\",\n",
        "                \"aerial view of Taipei 101 standing tall as a landmark in Taipei's urban landscape\",\n",
        "                \"Taipei 101 illuminated at night with a spectrum of colorful light displays, often themed for holidays\",\n",
        "                \"Taipei 101 seen from street level, emphasizing its immense height and unique green-tinted curtain wall\",\n",
        "                \"the 508-meter tall Taipei 101 tower, an engineering marvel with its unique tiered design and spire\",\n",
        "                \"Taipei 101's distinctive green glass exterior reflecting the sky, with visible bamboo segment patterns\",\n",
        "                \"famous Taipei skyscraper, its characteristic pagoda-like stacked sections symbolizing growth and prosperity\",\n",
        "                \"Taipei 101 featuring its massive tuned mass damper, visible through architectural openings, designed to counteract wind and seismic activity\",\n",
        "                \"modern Asian skyscraper Taipei 101, showcasing a fusion of contemporary architecture and traditional Asian symbolism\",\n",
        "                \"Taipei's iconic 101-story skyscraper with its tapered pinnacle reaching towards the sky, often against a backdrop of mountains or blue sky\",\n",
        "                \"Taipei 101 viewed from Elephant Mountain, offering a classic panoramic shot of the tower and city\",\n",
        "                \"close view of Taipei 101's signature green glass exterior with its intricate geometric patterns and reflective surface\",\n",
        "                \"Taipei 101 with its distinct floor segments that resemble ancient Chinese ingots or a blossoming bamboo\",\n",
        "                \"Taiwan's tallest building, Taipei 101, with its square base, tapered form, and prominent antenna\",\n",
        "                \"the tall, slender green Taipei 101 skyscraper, a prominent feature in the city's skyline, day or night\",\n",
        "                \"Taipei 101 with its unique green segmented tower design, a masterpiece of modern engineering and cultural symbolism, against a clear blue sky\",\n",
        "                \"distinctive green glass Taipei 101 tower, a symbol of Taiwan's modernity, dominating the city view\",\n",
        "                \"Taipei 101's iconic green tiered skyscraper structure with its high-speed elevators and 360-degree observation deck\"\n",
        "            ]\n",
        "        },\n",
        "        \"taroko_gorge\": {\n",
        "            \"name\": \"Taroko Gorge\",\n",
        "            \"aliases\": [\"Taroko National Park\", \"太魯閣國家公園\"],\n",
        "            \"location\": \"Hualien, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Taroko Gorge in Taiwan, showcasing its deep marble canyons and the Liwu River\",\n",
        "                \"sheer marble cliffs of Taroko Gorge, with tunnels carved through the rock like the Tunnel of Nine Turns\",\n",
        "                \"Taroko Gorge national park landscape with turquoise river, lush vegetation, and towering rock walls\",\n",
        "                \"Swallow Grotto (Yanzikou) trail in Taroko Gorge, with views of the river and cliff formations\",\n",
        "                \"the Cihmu Bridge, a distinctive red suspension bridge within Taroko Gorge\"\n",
        "            ]\n",
        "        },\n",
        "        \"sun_moon_lake\": {\n",
        "            \"name\": \"Sun Moon Lake\",\n",
        "            \"aliases\": [\"日月潭\", \"Lake Candidius\"],\n",
        "            \"location\": \"Nantou, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Sun Moon Lake in Taiwan, showing its calm, clear waters and surrounding mountains\",\n",
        "                \"the serene Sun Moon Lake with Lalu Island, its sacred ancestral ground, dividing the lake into sun and moon shapes\",\n",
        "                \"Sun Moon Lake surrounded by mist-covered mountains, with traditional temples like Wenwu Temple or Ci En Pagoda visible\",\n",
        "                \"boats and ferries on Sun Moon Lake, with cyclists on lakeside paths\",\n",
        "                \"aerial view of Sun Moon Lake highlighting its unique shape and the lush greenery of the region\"\n",
        "            ]\n",
        "        },\n",
        "        \"jiufen_old_street\": {\n",
        "            \"name\": \"Jiufen Old Street\",\n",
        "            \"aliases\": [\"九份老街\", \"Chiufen\"],\n",
        "            \"location\": \"New Taipei City, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"narrow, winding alleys of Jiufen Old Street, lined with glowing red lanterns, traditional teahouses, and local food stalls\",\n",
        "                \"atmospheric Jiufen Old Street at dusk or night, with countless red lanterns illuminating the historic hillside town and views of the coast\",\n",
        "                \"historic gold mining town architecture in Jiufen, with wooden buildings and steep staircases, reminiscent of scenes from 'Spirited Away'\",\n",
        "                \"A-Mei Tea House in Jiufen, a famous landmark with its traditional facade and lantern decorations\",\n",
        "                \"street food and bustling crowds in the vibrant Jiufen Old Street market\"\n",
        "            ]\n",
        "        },\n",
        "        \"kenting_national_park\": {\n",
        "            \"name\": \"Kenting National Park\",\n",
        "            \"aliases\": [\"墾丁國家公園\"],\n",
        "            \"location\": \"Pingtung, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"tropical beaches with white sand and clear blue water in Kenting National Park, southern Taiwan\",\n",
        "                \"Eluanbi Lighthouse, the iconic white lighthouse at Taiwan's southernmost point, within Kenting National Park\",\n",
        "                \"diverse coastal landscapes of Kenting, including coral reefs, rock formations like Sail Rock (Chuanfanshi), and lush forests\",\n",
        "                \"vibrant marine life and water activities like snorkeling or surfing in Kenting National Park\",\n",
        "                \"Longpan Park in Kenting, featuring dramatic grassy cliffs and coastline views\"\n",
        "            ]\n",
        "        },\n",
        "        \"national_palace_museum_tw\": { # Added _tw to differentiate from Beijing's\n",
        "            \"name\": \"National Palace Museum (Taipei)\",\n",
        "            \"aliases\": [\"國立故宮博物院\", \"Taipei Palace Museum\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"the grand exterior of the National Palace Museum in Taipei, a traditional Chinese palace-style building housing a vast collection of imperial artifacts\",\n",
        "                \"iconic exhibits like the Jadeite Cabbage, Meat-shaped Stone, and Mao Gong Ding at the National Palace Museum in Taipei\",\n",
        "                \"classical Chinese palace architecture of the National Palace Museum building in Taipei, with green tiled roofs and moon gates\",\n",
        "                \"interior halls of the National Palace Museum displaying ancient Chinese ceramics, bronzes, and calligraphy\",\n",
        "                \"gardens surrounding the National Palace Museum in Taipei, such as Zhishan Garden\"\n",
        "            ]\n",
        "        },\n",
        "        \"alishan_national_scenic_area\": {\n",
        "            \"name\": \"Alishan National Scenic Area\",\n",
        "            \"aliases\": [\"阿里山國家風景區\", \"Mount Ali\"],\n",
        "            \"location\": \"Chiayi, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"sea of clouds phenomenon at Alishan National Scenic Area, viewed from high mountain peaks at sunrise or sunset\",\n",
        "                \"Alishan Forest Railway trains, with their distinctive red carriages, winding through misty forests of ancient cypress and cedar trees\",\n",
        "                \"sunrise views over Yushan (Jade Mountain), Taiwan's highest peak, from Alishan's Chushan or Ogasawara Mountain observation points\",\n",
        "                \"tea plantations on the rolling hills of Alishan, known for its high-mountain oolong tea\",\n",
        "                \"hiking trails through Alishan's giant tree groves and serene forests, like the Sister Ponds\"\n",
        "            ]\n",
        "        },\n",
        "        \"shilin_night_market\": {\n",
        "            \"name\": \"Shilin Night Market\",\n",
        "            \"aliases\": [\"士林夜市\"],\n",
        "            \"location\": \"Taipei, Taiwan\",\n",
        "            \"prompts\": [\n",
        "                \"bustling and vibrant atmosphere of Shilin Night Market in Taipei, one of Taiwan's largest and most famous night markets, packed with people\",\n",
        "                \"a wide variety of Taiwanese street food stalls offering delicacies like oyster omelets, stinky tofu, and giant fried chicken cutlets at Shilin Night Market\",\n",
        "                \"crowds of people exploring the maze-like alleys of Shilin Night Market, filled with food vendors, game stalls, and small shops\",\n",
        "                \"brightly lit signs and food aromas filling the air at the lively Shilin Night Market\",\n",
        "                \"underground food court area of Shilin Night Market offering a diverse range of local dishes\"\n",
        "            ]\n",
        "        },\n",
        "        \"tokyo_tower\": {\n",
        "            \"name\": \"Tokyo Tower\",\n",
        "            \"aliases\": [\"東京タワー\", \"Tokyo Tower Landmark\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Tokyo Tower in Japan, its distinctive red and white lattice structure inspired by the Eiffel Tower\",\n",
        "                \"Tokyo Tower with its vibrant orange and white paint scheme, standing out against the Tokyo skyline\",\n",
        "                \"the iconic Tokyo Tower illuminated at night, often with seasonal or special light displays\",\n",
        "                \"view from Tokyo Tower's observation deck overlooking the sprawling metropolis of Tokyo\",\n",
        "                \"Tokyo Tower as a symbol of post-war Japan's rebirth and a prominent communications tower\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_fuji\": {\n",
        "            \"name\": \"Mount Fuji\",\n",
        "            \"aliases\": [\"富士山\", \"Fujisan\"],\n",
        "            \"location\": \"Honshu, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mount Fuji in Japan, its perfectly symmetrical snow-capped conical volcanic peak\",\n",
        "                \"the snow-capped peak of Mount Fuji, often with a clear blue sky or surrounded by clouds\",\n",
        "                \"Mount Fuji with cherry blossoms (sakura) in the foreground during spring, or reflected in one of the Fuji Five Lakes (Fujigoko)\",\n",
        "                \"iconic view of Mount Fuji from the Chureito Pagoda\",\n",
        "                \"Mount Fuji, Japan's highest mountain and an active stratovolcano, a symbol of Japan\"\n",
        "            ]\n",
        "        },\n",
        "        \"kinkaku_ji\": {\n",
        "            \"name\": \"Kinkaku-ji\",\n",
        "            \"aliases\": [\"Golden Pavilion\", \"金閣寺\", \"Rokuon-ji\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Kinkaku-ji temple (Golden Pavilion) in Kyoto, its top two floors completely covered in gold leaf\",\n",
        "                \"the Golden Pavilion Kinkaku-ji reflected perfectly in the Mirror Pond (Kyōko-chi) surrounding it\",\n",
        "                \"Kinkaku-ji, a Zen Buddhist temple in Kyoto, set within a beautiful Japanese stroll garden\",\n",
        "                \"the three-tiered structure of Kinkaku-ji, each floor representing a different architectural style\",\n",
        "                \"Kinkaku-ji in autumn with colorful foliage, or in winter dusted with snow\"\n",
        "            ]\n",
        "        },\n",
        "        \"fushimi_inari_shrine\": {\n",
        "            \"name\": \"Fushimi Inari Shrine\",\n",
        "            \"aliases\": [\"伏見稲荷大社\", \"Thousand Torii Gates\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Fushimi Inari Shrine in Kyoto, famous for its thousands of vibrant red/orange torii gates\",\n",
        "                \"thousands of vermilion torii gates forming tunnels along a network of trails at Fushimi Inari Taisha\",\n",
        "                \"pathways lined with densely packed red torii gates winding up a mountainside at Fushimi Inari Shrine\",\n",
        "                \"fox statues (kitsune), messengers of Inari, found throughout Fushimi Inari Shrine\",\n",
        "                \"the main shrine buildings of Fushimi Inari at the base of the mountain, with more torii gates leading upwards\"\n",
        "            ]\n",
        "        },\n",
        "        \"shibuya_crossing\": {\n",
        "            \"name\": \"Shibuya Crossing\",\n",
        "            \"aliases\": [\"Shibuya Scramble Crossing\", \"澀谷十字路口\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"massive pedestrian scramble at Shibuya Crossing, Tokyo, with crowds of people crossing from all directions, surrounded by neon signs and large video screens\",\n",
        "                \"bird's-eye view of the crowded Shibuya intersection with its iconic starburst pedestrian walkways and Hachiko statue nearby\",\n",
        "                \"throngs of people crossing the multi-directional Shibuya intersection surrounded by modern buildings, department stores, and vibrant advertisements\",\n",
        "                \"Shibuya Crossing at night with dazzling, vibrant lights from billboards and a continuous sea of people\",\n",
        "                \"the energetic and iconic Shibuya Crossing, a symbol of modern Tokyo and urban life\"\n",
        "            ]\n",
        "        },\n",
        "        \"tokyo_skytree\": {\n",
        "            \"name\": \"Tokyo Skytree\",\n",
        "            \"aliases\": [\"東京晴空塔\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the slender, futuristic Tokyo Skytree, a broadcasting and observation tower in Sumida, Tokyo, with its lattice steel structure\",\n",
        "                \"Tokyo Skytree illuminated in its signature pale blue (Iki) or purple (Miyabi) lights against the night sky\",\n",
        "                \"modern lattice structure of the Tokyo Skytree, the world's tallest freestanding tower, dominating the city's skyline\",\n",
        "                \"panoramic view from Tokyo Skytree's Tembo Deck or Tembo Galleria overlooking the sprawling city of Tokyo and beyond\",\n",
        "                \"Tokyo Skytree with the Sumida River and surrounding urban landscape\"\n",
        "            ]\n",
        "        },\n",
        "        \"senso_ji_temple\": {\n",
        "            \"name\": \"Senso-ji Temple\",\n",
        "            \"aliases\": [\"淺草寺\", \"Asakusa Kannon Temple\"],\n",
        "            \"location\": \"Tokyo, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the vibrant red Senso-ji Temple in Asakusa, Tokyo, with its iconic Kaminarimon (Thunder Gate) featuring a massive red paper lantern\",\n",
        "                \"traditional Japanese temple architecture of Senso-ji, Tokyo's oldest temple, including its five-story pagoda and main hall\",\n",
        "                \"incense smoke billowing from a large cauldron and worshippers at Senso-ji Temple\",\n",
        "                \"Nakamise-dori, the bustling market street leading to Senso-ji Temple, lined with traditional souvenir stalls and food vendors\",\n",
        "                \"the Hozomon Gate with its giant waraji (straw sandals) at Senso-ji Temple\"\n",
        "            ]\n",
        "        },\n",
        "        \"osaka_castle\": {\n",
        "            \"name\": \"Osaka Castle\",\n",
        "            \"aliases\": [\"大阪城\", \"Osaka-jo\"],\n",
        "            \"location\": \"Osaka, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic Osaka Castle with its distinctive white walls, green tiled roofs, golden embellishments, and surrounding moat and massive stone walls\",\n",
        "                \"Osaka Castle Park with the imposing castle keep (tenshukaku) in the background, especially beautiful during cherry blossom season or autumn foliage\",\n",
        "                \"historic Japanese castle, Osaka Castle, reconstructed with modern interiors, showcasing its historical significance\",\n",
        "                \"Osaka Castle illuminated at night, reflecting in its expansive moat, creating a stunning visual\",\n",
        "                \"view of Osaka Castle from Nishinomaru Garden, offering a picturesque perspective\"\n",
        "            ]\n",
        "        },\n",
        "        \"dotonbori\": {\n",
        "            \"name\": \"Dotonbori\",\n",
        "            \"aliases\": [\"道頓堀\"],\n",
        "            \"location\": \"Osaka, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the vibrant and eclectic Dotonbori entertainment district in Osaka, famous for its extravagant, oversized 3D signage like the Glico Running Man and Kani Doraku crab\",\n",
        "                \"canal view of Dotonbori at night with a dazzling array of neon lights from billboards and signs reflecting on the Dotonbori River\",\n",
        "                \"colorful and brightly lit billboards, including the iconic Glico Running Man, lining the Dotonbori canal, a symbol of Osaka's energy\",\n",
        "                \"bustling atmosphere of Dotonbori with street food stalls offering takoyaki and okonomiyaki, and throngs of people\",\n",
        "                \"the Ebisu Bridge over the Dotonbori canal, a popular meeting spot and photo location\"\n",
        "            ]\n",
        "        },\n",
        "        \"arashiyama_bamboo_grove\": {\n",
        "            \"name\": \"Arashiyama Bamboo Grove\",\n",
        "            \"aliases\": [\"嵐山竹林\", \"Sagano Bamboo Forest\"],\n",
        "            \"location\": \"Kyoto, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"towering stalks of green bamboo creating a dense, immersive canopy over a pathway in Arashiyama Bamboo Grove, Kyoto\",\n",
        "                \"sunlight filtering magically through the leaves of the tall, closely packed bamboo forest in Arashiyama\",\n",
        "                \"serene and tranquil walking path through the iconic Arashiyama Bamboo Grove, with the distinctive sound of rustling bamboo leaves\",\n",
        "                \"people in traditional kimono or yukata walking through the Arashiyama Bamboo Grove\",\n",
        "                \"the unique, otherworldly atmosphere of the Arashiyama Bamboo Grove, a natural wonder\"\n",
        "            ]\n",
        "        },\n",
        "        \"itsukushima_shrine\": {\n",
        "            \"name\": \"Itsukushima Shrine\",\n",
        "            \"aliases\": [\"嚴島神社\", \"Miyajima Shrine\"],\n",
        "            \"location\": \"Miyajima Island, Hiroshima, Japan\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic vermilion 'floating' torii gate of Itsukushima Shrine in Miyajima, appearing to float on the water during high tide\",\n",
        "                \"Itsukushima Shrine complex, a UNESCO World Heritage site, built on stilts over the sea, with its distinctive red-lacquered corridors and halls\",\n",
        "                \"sacred wild deer roaming freely around Miyajima Island with the Itsukushima Shrine and its torii gate in the background\",\n",
        "                \"Itsukushima Shrine and its torii gate illuminated at night, creating a mystical scene\",\n",
        "                \"view of Itsukushima Shrine from Mount Misen or from a ferry approaching Miyajima Island\"\n",
        "            ]\n",
        "        },\n",
        "        \"gyeongbokgung_palace\": {\n",
        "            \"name\": \"Gyeongbokgung Palace\",\n",
        "            \"aliases\": [\"경복궁\", \"Gyeongbok Palace\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Gyeongbokgung Palace in Seoul, the largest and most stunning of Seoul's five grand Joseon Dynasty palaces\",\n",
        "                \"the main royal palace of the Joseon dynasty, Gyeongbokgung, with its grand Gwanghwamun Gate and Heungnyemun Gate\",\n",
        "                \"traditional Korean architecture at Gyeongbokgung Palace, featuring intricate Dancheong (colorful painted patterns) on wooden structures and elegant curved roofs\",\n",
        "                \"the impressive Geunjeongjeon Hall (Imperial Throne Hall) and the picturesque Gyeonghoeru Pavilion (Royal Banquet Hall) on a pond at Gyeongbokgung Palace\",\n",
        "                \"Changing of the Royal Guard ceremony (Sumunjang Gyedaeui) taking place at Gyeongbokgung Palace\"\n",
        "            ]\n",
        "        },\n",
        "        \"n_seoul_tower\": {\n",
        "            \"name\": \"N Seoul Tower\",\n",
        "            \"aliases\": [\"N서울타워\", \"YTN Seoul Tower\", \"Namsan Tower\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of N Seoul Tower perched atop Namsan Mountain, offering panoramic views of Seoul\",\n",
        "                \"N Seoul Tower illuminated with vibrant LED lights at night, changing colors and patterns, visible from across the city\",\n",
        "                \"the iconic N Seoul Tower in South Korea, a popular landmark with its observation deck and 'love locks' fences\",\n",
        "                \"view from the N Seoul Tower looking down on the sprawling cityscape of Seoul, day or night\",\n",
        "                \"cable car ascending Namsan Mountain towards the N Seoul Tower\"\n",
        "            ]\n",
        "        },\n",
        "        \"bukchon_hanok_village\": {\n",
        "            \"name\": \"Bukchon Hanok Village\",\n",
        "            \"aliases\": [\"북촌한옥마을\", \"Traditional Korean Village\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Bukchon Hanok Village in Seoul, a preserved traditional Korean village with hundreds of hanok (traditional Korean houses)\",\n",
        "                \"traditional Korean houses (hanok) in Bukchon Village, featuring distinctive tiled roofs, wooden beams, and courtyards, nestled on a hillside\",\n",
        "                \"narrow, winding alleyways and cobblestone streets of Bukchon Hanok Village, offering glimpses into historic Seoul\",\n",
        "                \"view of modern Seoul skyline contrasting with the traditional rooftops of Bukchon Hanok Village\",\n",
        "                \"people wearing Hanbok (traditional Korean attire) walking through Bukchon Hanok Village\"\n",
        "            ]\n",
        "        },\n",
        "        \"myeongdong_shopping_street\": {\n",
        "            \"name\": \"Myeongdong Shopping Street\",\n",
        "            \"aliases\": [\"명동 쇼핑거리\", \"Myeong-dong\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"bustling Myeongdong shopping street in Seoul, a paradise for cosmetics, fashion, and K-pop merchandise, packed with shoppers and vibrant storefronts\",\n",
        "                \"crowds of shoppers navigating the pedestrian-friendly streets of Myeongdong, with bright neon signs and music from stores creating a lively atmosphere, especially at night\",\n",
        "                \"vibrant street food scene in Myeongdong, Seoul, with numerous stalls offering popular Korean snacks like tteokbokki, gyeranppang, and tornado potatoes\",\n",
        "                \"Myeongdong Cathedral, a historic Gothic-style church, standing amidst the bustling modern shopping district\",\n",
        "                \"large department stores and international brands alongside local boutiques in Myeongdong\"\n",
        "            ]\n",
        "        },\n",
        "        \"dmz_korea\": {\n",
        "            \"name\": \"DMZ (Korean Demilitarized Zone)\",\n",
        "            \"aliases\": [\"韓國非軍事區\", \"Panmunjom\", \"JSA\"],\n",
        "            \"location\": \"Gyeonggi-do, South Korea / North Korea\",\n",
        "            \"prompts\": [\n",
        "                \"the heavily fortified Korean Demilitarized Zone (DMZ) separating North and South Korea, with barbed wire fences and guard posts\",\n",
        "                \"Joint Security Area (JSA) or Panmunjom at the DMZ, with soldiers from North and South Korea facing each other across the Military Demarcation Line\",\n",
        "                \"the iconic blue conference buildings straddling the border within the JSA at the DMZ\",\n",
        "                \"tense and somber atmosphere of the DMZ, a symbol of the Korean War and the divided peninsula\",\n",
        "                \"observation posts like Dora Observatory overlooking North Korean territory from the DMZ\"\n",
        "            ]\n",
        "        },\n",
        "        \"busan_gamcheon_culture_village\": {\n",
        "            \"name\": \"Busan Gamcheon Culture Village\",\n",
        "            \"aliases\": [\"부산 감천문화마을\", \"Machu Picchu of Busan\", \"Taegukdo Village\"],\n",
        "            \"location\": \"Busan, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"colorful houses built in terraced fashion on a steep hillside in Gamcheon Culture Village, Busan, often called the 'Machu Picchu of Busan'\",\n",
        "                \"narrow, winding alleyways adorned with vibrant street art, colorful murals, and art installations in Gamcheon Culture Village\",\n",
        "                \"panoramic view of the brightly painted houses of Gamcheon Culture Village cascading down to the sea, creating a unique urban landscape\",\n",
        "                \"sculptures like 'The Little Prince and the Desert Fox' overlooking the village in Gamcheon Culture Village\",\n",
        "                \"artistic and quirky atmosphere of Gamcheon Culture Village, a regenerated slum transformed into an art hub\"\n",
        "            ]\n",
        "        },\n",
        "        \"jeju_island\": {\n",
        "            \"name\": \"Jeju Island\",\n",
        "            \"aliases\": [\"제주도\", \"Jejudo\"],\n",
        "            \"location\": \"Jeju Province, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"volcanic landscape of Jeju Island, South Korea, a UNESCO World Heritage site, featuring black basalt rock formations (like Jusangjeolli Cliff) and lush greenery\",\n",
        "                \"Seongsan Ilchulbong (Sunrise Peak), a dramatic tuff cone crater rising from the sea on the eastern coast of Jeju Island\",\n",
        "                \"beautiful sandy beaches like Hyeopjae Beach, waterfalls such as Cheonjeyeon Falls, and lava tubes like Manjanggul Cave on Jeju Island\",\n",
        "                \"Hallasan National Park, home to South Korea's highest mountain, Hallasan, a dormant shield volcano, on Jeju Island\",\n",
        "                \"Dol Hareubang (stone grandfathers), iconic black lava stone statues found throughout Jeju Island\"\n",
        "            ]\n",
        "        },\n",
        "        \"changdeokgung_palace_secret_garden\": {\n",
        "            \"name\": \"Changdeokgung Palace & Secret Garden\",\n",
        "            \"aliases\": [\"창덕궁과 후원\", \"Donggwol (East Palace)\"],\n",
        "            \"location\": \"Seoul, South Korea\",\n",
        "            \"prompts\": [\n",
        "                \"the beautiful Changdeokgung Palace, a UNESCO World Heritage site in Seoul, known for its harmonious design that blends with the natural landscape\",\n",
        "                \"traditional Korean palace architecture of Changdeokgung, including the Injeongjeon (main throne hall) and Donhwamun (main gate)\",\n",
        "                \"the serene and picturesque Secret Garden (Huwon) of Changdeokgung Palace, a vast rear garden with pavilions, ponds, and ancient trees, requiring a guided tour\",\n",
        "                \"Buyongjeong Pavilion and Buyongji Pond in the Secret Garden of Changdeokgung Palace\",\n",
        "                \"Changdeokgung Palace as one of the best-preserved Joseon Dynasty palaces\"\n",
        "            ]\n",
        "        },\n",
        "        \"great_wall\": {\n",
        "            \"name\": \"Great Wall of China\",\n",
        "            \"aliases\": [\"长城\", \"The Great Wall\", \"萬里長城\"],\n",
        "            \"location\": \"China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Great Wall of China, the massive ancient fortification winding across rugged mountains and diverse terrains\",\n",
        "                \"the Great Wall stretching for thousands of miles, with watchtowers and battlements, a testament to ancient Chinese engineering\",\n",
        "                \"sections of the Great Wall like Badaling or Mutianyu, showing its impressive scale and historical significance\",\n",
        "                \"the Great Wall of China snaking along steep mountain ridges, often covered in snow or surrounded by lush greenery\",\n",
        "                \"iconic man-made structure, the Great Wall, visible from afar, symbolizing China's strength and history\"\n",
        "            ]\n",
        "        },\n",
        "        \"forbidden_city\": {\n",
        "            \"name\": \"Forbidden City\",\n",
        "            \"aliases\": [\"紫禁城\", \"Palace Museum\", \"故宫博物院\"],\n",
        "            \"location\": \"Beijing, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Forbidden City in Beijing, the vast imperial palace complex with its iconic red walls and yellow-tiled roofs\",\n",
        "                \"the imperial palace complex of the Forbidden City, former home to Chinese emperors, showcasing classical Chinese palatial architecture\",\n",
        "                \"courtyards, halls, and gates of the Forbidden City, such as the Hall of Supreme Harmony, arranged along a central axis\",\n",
        "                \"intricate details and symbolic ornamentation of the Forbidden City's buildings, reflecting imperial power and Chinese cosmology\",\n",
        "                \"the Meridian Gate (Wumen), the main entrance to the Forbidden City, or the Corner Towers with their complex roof structures\"\n",
        "            ]\n",
        "        },\n",
        "        \"terracotta_army\": {\n",
        "            \"name\": \"Terracotta Army\",\n",
        "            \"aliases\": [\"兵马俑\", \"Terracotta Warriors and Horses\"],\n",
        "            \"location\": \"Xi'an, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Terracotta Army in Xi'an, rows of life-sized terracotta warriors, archers, and chariots in vast pits\",\n",
        "                \"thousands of life-sized terracotta warriors and horses, each with unique facial expressions and armor, part of Qin Shi Huang's mausoleum\",\n",
        "                \"archaeological site of the Terracotta Army, a UNESCO World Heritage site, showcasing the incredible artistry and scale of ancient Chinese burial practices\",\n",
        "                \"close-up of the detailed faces and uniforms of the Terracotta Warriors\",\n",
        "                \"excavation pits containing the Terracotta Army, demonstrating the ongoing discovery and preservation efforts\"\n",
        "            ]\n",
        "        },\n",
        "        \"the_bund\": {\n",
        "            \"name\": \"The Bund\",\n",
        "            \"aliases\": [\"外滩\", \"Waitan\"],\n",
        "            \"location\": \"Shanghai, China\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of The Bund waterfront in Shanghai, with its impressive collection of historic colonial-era buildings in various architectural styles\",\n",
        "                \"skyline of The Bund featuring iconic early 20th-century buildings, contrasting with the modern skyscrapers of Pudong across the Huangpu River\",\n",
        "                \"The Bund overlooking the Huangpu River, with boats and ferries, and the Oriental Pearl Tower and Shanghai Tower visible on the Pudong side\",\n",
        "                \"pedestrian promenade along The Bund, a popular spot for tourists and locals to view Shanghai's historic and modern skylines\",\n",
        "                \"The Bund at night, with both the historic buildings and the Pudong skyline brilliantly illuminated\"\n",
        "            ]\n",
        "        },\n",
        "        \"li_river_guilin\": {\n",
        "            \"name\": \"Li River, Guilin\",\n",
        "            \"aliases\": [\"漓江\", \"Guilin Karst Landscape\"],\n",
        "            \"location\": \"Guilin, Guangxi, China\",\n",
        "            \"prompts\": [\n",
        "                \"surreal karst mountain landscape along the Li River in Guilin, China, with picturesque limestone peaks rising dramatically from the flat terrain\",\n",
        "                \"bamboo rafts and cruise boats navigating the scenic Li River, surrounded by mist-shrouded, unusually shaped karst formations\",\n",
        "                \"iconic view of the Li River, often depicted in traditional Chinese landscape paintings, particularly the scene on the 20 Yuan banknote (Yellow Cloth Shoal)\",\n",
        "                \"cormorant fishermen on bamboo rafts on the Li River\",\n",
        "                \"lush green vegetation covering the steep karst hills along the banks of the winding Li River\"\n",
        "            ]\n",
        "        },\n",
        "        \"potala_palace\": {\n",
        "            \"name\": \"Potala Palace\",\n",
        "            \"aliases\": [\"布達拉宮\"],\n",
        "            \"location\": \"Lhasa, Tibet, China\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic Potala Palace, former winter residence of the Dalai Lama, dramatically situated on Red Hill (Marpo Ri) in Lhasa, Tibet\",\n",
        "                \"distinctive white (White Palace) and red (Red Palace) architecture of the Potala Palace against a clear blue sky and surrounding mountains\",\n",
        "                \"the imposing Potala Palace, a UNESCO World Heritage site, a symbol of Tibetan Buddhism and a marvel of Tibetan architecture with its many chapels and statues\",\n",
        "                \"Potala Palace with prayer flags fluttering in the foreground\",\n",
        "                \"view of Potala Palace from afar, showcasing its grand scale and dominant position over Lhasa\"\n",
        "            ]\n",
        "        },\n",
        "        \"zhangjiajie_national_forest_park\": {\n",
        "            \"name\": \"Zhangjiajie National Forest Park\",\n",
        "            \"aliases\": [\"張家界國家森林公園\", \"Avatar Mountains\"],\n",
        "            \"location\": \"Hunan, China\",\n",
        "            \"prompts\": [\n",
        "                \"tall, pillar-like quartz-sandstone formations, often shrouded in mist, in Zhangjiajie National Forest Park, inspiration for the 'Avatar Hallelujah Mountains'\",\n",
        "                \"the 'Avatar Hallelujah Mountains' (formerly Southern Sky Column) in Zhangjiajie, known for their gravity-defying appearance and lush vegetation\",\n",
        "                \"glass bridges like the Zhangjiajie Grand Canyon Glass Bridge, and cable cars offering stunning, vertigo-inducing views of the unique landscape of Zhangjiajie\",\n",
        "                \"Bailong Elevator (Hundred Dragons Elevator), a massive glass elevator built onto the side of a cliff in Zhangjiajie\",\n",
        "                \"dense forests and deep ravines characterize the otherworldly scenery of Zhangjiajie National Forest Park\"\n",
        "            ]\n",
        "        },\n",
        "        \"west_lake_hangzhou\": {\n",
        "            \"name\": \"West Lake, Hangzhou\",\n",
        "            \"aliases\": [\"西湖\"],\n",
        "            \"location\": \"Hangzhou, China\",\n",
        "            \"prompts\": [\n",
        "                \"the serene and beautiful West Lake in Hangzhou, China, a UNESCO World Heritage site, famous for its scenic beauty, pagodas, islands, and causeways\",\n",
        "                \"iconic landmarks of West Lake such as the Broken Bridge (Duan Qiao), Leifeng Pagoda, Su Causeway, and Bai Causeway\",\n",
        "                \"traditional Chinese pavilions, arched bridges, and gardens surrounding West Lake, often depicted in Chinese art and poetry\",\n",
        "                \"boats gently gliding on West Lake, with willow trees lining its shores and lotus flowers blooming in summer\",\n",
        "                \"Three Ponds Mirroring the Moon, one of the most famous sights of West Lake\"\n",
        "            ]\n",
        "        },\n",
        "        \"summer_palace_beijing\": {\n",
        "            \"name\": \"Summer Palace, Beijing\",\n",
        "            \"aliases\": [\"頤和園\", \"Yiheyuan\"],\n",
        "            \"location\": \"Beijing, China\",\n",
        "            \"prompts\": [\n",
        "                \"the vast imperial garden of the Summer Palace in Beijing, a UNESCO World Heritage site, featuring Kunming Lake and Longevity Hill\",\n",
        "                \"ornate palaces, temples, bridges, and pavilions within the Summer Palace, such as the Marble Boat, the Long Corridor (Chang Lang), and the Tower of Buddhist Incense (Foxiang Ge)\",\n",
        "                \"traditional Chinese landscape garden design of the Summer Palace, showcasing harmony between man-made structures and nature\",\n",
        "                \"Kunming Lake in the Summer Palace, with the Seventeen-Arch Bridge leading to Nanhu Island\",\n",
        "                \"Longevity Hill at the Summer Palace, crowned by impressive imperial buildings\"\n",
        "            ]\n",
        "        },\n",
        "        \"petronas_towers\": {\n",
        "            \"name\": \"Petronas Twin Towers\",\n",
        "            \"aliases\": [\"KLCC Twin Towers\", \"Menara Petronas\", \"Petronas Towers\"],\n",
        "            \"location\": \"Kuala Lumpur, Malaysia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Petronas Twin Towers in Kuala Lumpur, the world's tallest twin skyscrapers with their distinctive postmodern Islamic architectural motifs\",\n",
        "                \"the iconic Petronas Towers connected by a double-decker skybridge on the 41st and 42nd floors\",\n",
        "                \"Petronas Twin Towers brilliantly illuminated at night, a striking landmark in Kuala Lumpur's skyline\",\n",
        "                \"the multi-faceted, tapering design of the Petronas Twin Towers, inspired by Islamic geometric patterns\",\n",
        "                \"view of the Petronas Twin Towers from KLCC Park, with its fountains and gardens\"\n",
        "            ]\n",
        "        },\n",
        "        \"marina_bay_sands\": {\n",
        "            \"name\": \"Marina Bay Sands\",\n",
        "            \"aliases\": [\"MBS\", \"Singapore Skypark\"],\n",
        "            \"location\": \"Singapore\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Marina Bay Sands in Singapore, the iconic integrated resort featuring three soaring hotel towers topped by a massive cantilevered SkyPark\",\n",
        "                \"the Marina Bay Sands resort with its distinctive three towers and the ship-like Sands SkyPark housing an infinity pool, observation deck, and gardens\",\n",
        "                \"Marina Bay Sands overlooking the Singapore skyline and Marina Bay, often seen with the ArtScience Museum in the foreground\",\n",
        "                \"the impressive architecture of Marina Bay Sands, a symbol of modern Singapore, illuminated at night\",\n",
        "                \"Spectra light and water show in front of Marina Bay Sands\"\n",
        "            ]\n",
        "        },\n",
        "        \"gardens_by_the_bay\": {\n",
        "            \"name\": \"Gardens by the Bay\",\n",
        "            \"aliases\": [\"Singapore Gardens\", \"Supertree Grove\"],\n",
        "            \"location\": \"Singapore\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Gardens by the Bay in Singapore, a futuristic nature park known for its iconic Supertree Grove\",\n",
        "                \"the towering Supertree Grove at Gardens by the Bay, tree-like vertical gardens that light up spectacularly during the Garden Rhapsody show at night\",\n",
        "                \"Flower Dome and Cloud Forest, two massive cooled conservatories at Gardens by the Bay, housing diverse plant life from around the world\",\n",
        "                \"the OCBC Skyway, an aerial walkway offering panoramic views of the Supertrees and surrounding gardens\",\n",
        "                \"lush landscapes and innovative horticultural displays within Gardens by the Bay\"\n",
        "            ]\n",
        "        },\n",
        "        \"taj_mahal\": {\n",
        "            \"name\": \"Taj Mahal\",\n",
        "            \"aliases\": [\"Crown of Palaces\", \"Mumtaz Mahal\"],\n",
        "            \"location\": \"Agra, India\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Taj Mahal in Agra, the iconic ivory-white marble mausoleum renowned for its beauty and symmetry\",\n",
        "                \"the ivory-white marble mausoleum of the Taj Mahal, a UNESCO World Heritage site, built by Mughal emperor Shah Jahan\",\n",
        "                \"Taj Mahal reflected perfectly in its long सामने (frontal) water feature (reflecting pool), flanked by symmetrical gardens\",\n",
        "                \"the intricate marble inlay work (pietra dura) and calligraphy on the facade of the Taj Mahal\",\n",
        "                \"the central dome and four minarets of the Taj Mahal, a masterpiece of Mughal architecture\"\n",
        "            ]\n",
        "        },\n",
        "        \"angkor_wat\": {\n",
        "            \"name\": \"Angkor Wat\",\n",
        "            \"aliases\": [\"吳哥窟\", \"City of Temples\"],\n",
        "            \"location\": \"Siem Reap, Cambodia\",\n",
        "            \"prompts\": [\n",
        "                \"the magnificent temple complex of Angkor Wat in Cambodia, a UNESCO World Heritage site, with its iconic five lotus-bud shaped towers reflecting in a surrounding moat\",\n",
        "                \"intricate bas-reliefs and stone carvings depicting Hindu epics like the Ramayana and Mahabharata, and apsaras (celestial dancers) at Angkor Wat\",\n",
        "                \"sunrise over Angkor Wat, casting a golden glow on its ancient stone structures, the world's largest religious monument\",\n",
        "                \"the grand scale and symmetrical design of Angkor Wat, an architectural marvel of the Khmer Empire\",\n",
        "                \"causeway leading to the main entrance of Angkor Wat, often with monks in saffron robes\"\n",
        "            ]\n",
        "        },\n",
        "        \"ha_long_bay\": {\n",
        "            \"name\": \"Ha Long Bay\",\n",
        "            \"aliases\": [\"下龍灣\", \"Vịnh Hạ Long\"],\n",
        "            \"location\": \"Quảng Ninh Province, Vietnam\",\n",
        "            \"prompts\": [\n",
        "                \"thousands of towering limestone karsts and islets rising dramatically from the emerald green waters of Ha Long Bay, Vietnam, a UNESCO World Heritage site\",\n",
        "                \"traditional Vietnamese junk boats sailing majestically through the stunning seascape of Ha Long Bay\",\n",
        "                \"caves and grottoes, such as Thien Cung Cave or Dau Go Cave, hidden within the limestone islands of Ha Long Bay\",\n",
        "                \"floating fishing villages and pearl farms nestled among the karsts in Ha Long Bay\",\n",
        "                \"misty and ethereal atmosphere of Ha Long Bay, especially at dawn or dusk\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_everest\": {\n",
        "            \"name\": \"Mount Everest\",\n",
        "            \"aliases\": [\"聖母峰\", \"Sagarmatha\", \"Chomolungma\"],\n",
        "            \"location\": \"Mahalangur Himal, Nepal/China border\",\n",
        "            \"prompts\": [\n",
        "                \"the snow-covered, pyramid-shaped peak of Mount Everest, the world's highest mountain, towering above the Himalayan range\",\n",
        "                \"climbers and expeditions at Mount Everest Base Camp, with prayer flags and views of the Khumbu Icefall\",\n",
        "                \"majestic and formidable landscape of Mount Everest and surrounding Himalayan peaks like Lhotse and Nuptse, often with wispy clouds\",\n",
        "                \"the challenging south face or north face routes leading to the summit of Mount Everest\",\n",
        "                \"breathtaking aerial view of Mount Everest, highlighting its immense scale and icy terrain\"\n",
        "            ]\n",
        "        },\n",
        "        \"bagan\": {\n",
        "            \"name\": \"Bagan\",\n",
        "            \"aliases\": [\"蒲甘\", \"Pagan\"],\n",
        "            \"location\": \"Mandalay Region, Myanmar\",\n",
        "            \"prompts\": [\n",
        "                \"thousands of ancient Buddhist temples, pagodas, and stupas, mostly in reddish-brown brick, spread across the plains of Bagan, Myanmar, a UNESCO World Heritage site\",\n",
        "                \"hot air balloons drifting gracefully over the temple-studded landscape of Bagan at sunrise or sunset, creating a magical scene\",\n",
        "                \"archaeological zone of Bagan with its diverse stupas (like Shwezigon Pagoda) and temples (like Ananda Temple) dating back to the 9th-13th centuries\",\n",
        "                \"sunlight illuminating the ancient temples of Bagan, with intricate carvings and Buddha statues inside\",\n",
        "                \"view from a high temple in Bagan, offering a panoramic vista of countless religious structures\"\n",
        "            ]\n",
        "        },\n",
        "        \"grand_palace_wat_phra_kaew\": {\n",
        "            \"name\": \"The Grand Palace & Wat Phra Kaew\",\n",
        "            \"aliases\": [\"曼谷大皇宮與玉佛寺\", \"Royal Palace Bangkok\"],\n",
        "            \"location\": \"Bangkok, Thailand\",\n",
        "            \"prompts\": [\n",
        "                \"ornate and glittering architecture of the Grand Palace in Bangkok, former residence of the Kings of Siam, with its intricate details and golden spires\",\n",
        "                \"Wat Phra Kaew (Temple of the Emerald Buddha) within the Grand Palace complex, housing the highly revered Emerald Buddha statue carved from a single jade stone\",\n",
        "                \"intricate details, golden chedis (stupas), colorful mosaics made of glass and porcelain, and mythical guardian statues (yakshas) of Thai traditional architecture at the Grand Palace\",\n",
        "                \"the dazzling exteriors of the royal halls and temples within the Grand Palace grounds\",\n",
        "                \"crowds of visitors and worshippers at the magnificent Grand Palace and Wat Phra Kaew\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 歐洲地標\n",
        "    \"europe\": {\n",
        "        \"eiffel_tower\": {\n",
        "            \"name\": \"Eiffel Tower\",\n",
        "            \"aliases\": [\"Tour Eiffel\", \"The Iron Lady\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Eiffel Tower in Paris, the iconic wrought-iron lattice tower on the Champ de Mars\",\n",
        "                \"the iconic Eiffel Tower structure, its intricate ironwork and graceful curves against the Paris skyline\",\n",
        "                \"Eiffel Tower illuminated at night with its sparkling light show, a beacon in the City of Lights\",\n",
        "                \"view from the top of the Eiffel Tower overlooking Paris, including the Seine River and landmarks like the Arc de Triomphe\",\n",
        "                \"Eiffel Tower seen from the Trocadéro, providing a classic photographic angle\"\n",
        "            ]\n",
        "        },\n",
        "        \"louvre_museum\": {\n",
        "            \"name\": \"Louvre Museum\",\n",
        "            \"aliases\": [\"Musée du Louvre\", \"The Louvre Pyramid\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Louvre Museum in Paris, with its iconic glass pyramid designed by I. M. Pei contrasting with the historic Louvre Palace\",\n",
        "                \"the Louvre Pyramid at the entrance of the museum, reflecting the sky and surrounding palace wings\",\n",
        "                \"exterior of the historic Louvre Palace, a former royal palace, now one of the world's largest art museums\",\n",
        "                \"crowds of visitors entering the Louvre Museum through the pyramid or its underground entrance\",\n",
        "                \"the Louvre Museum at night, with the pyramid and palace illuminated\"\n",
        "            ]\n",
        "        },\n",
        "        \"mont_saint_michel\": {\n",
        "            \"name\": \"Mont Saint-Michel\",\n",
        "            \"aliases\": [\"Saint Michael's Mount (France)\", \"Abbaye du Mont-Saint-Michel\"],\n",
        "            \"location\": \"Normandy, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mont Saint-Michel in France, the stunning tidal island commune topped by a medieval Benedictine abbey\",\n",
        "                \"the tidal island and abbey of Mont Saint-Michel rising dramatically from the bay, surrounded by water at high tide or sand flats at low tide\",\n",
        "                \"Mont Saint-Michel at high tide, appearing as a fairytale castle floating on the water\",\n",
        "                \"the Gothic architecture of the Abbey of Mont Saint-Michel, with its towering spire and fortified walls\",\n",
        "                \"narrow winding streets and historic buildings leading up to the abbey on Mont Saint-Michel\"\n",
        "            ]\n",
        "        },\n",
        "        \"arc_de_triomphe\": {\n",
        "            \"name\": \"Arc de Triomphe\",\n",
        "            \"aliases\": [\"Triumphal Arch of the Star\", \"Arc de Triomphe de l'Étoile\"],\n",
        "            \"location\": \"Paris, France\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Arc de Triomphe in Paris, the monumental triumphal arch at the center of Place Charles de Gaulle (Place de l'Étoile)\",\n",
        "                \"the iconic Arc de Triomphe at the western end of the Champs-Élysées, adorned with intricate sculptures depicting Napoleonic victories\",\n",
        "                \"view from the top of the Arc de Triomphe, looking down the twelve radiating avenues, including the Champs-Élysées towards the Louvre\",\n",
        "                \"the Eternal Flame burning beneath the Arc de Triomphe at the Tomb of the Unknown Soldier\",\n",
        "                \"Arc de Triomphe illuminated at night, a symbol of French national pride\"\n",
        "            ]\n",
        "        },\n",
        "        \"big_ben\": {\n",
        "            \"name\": \"Big Ben (Elizabeth Tower)\", # Clarified name\n",
        "            \"aliases\": [\"Elizabeth Tower\", \"Westminster Clock Tower\", \"Clock Tower, Palace of Westminster\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Big Ben (Elizabeth Tower) clock tower with the Houses of Parliament (Palace of Westminster) in London, on the bank of the River Thames\",\n",
        "                \"the iconic Gothic Revival clock tower Big Ben with its four massive, illuminated clock faces in London\",\n",
        "                \"Big Ben tower with its distinctive golden clock face, intricate stonework, and cast-iron spire, a symbol of London and the UK\",\n",
        "                \"the famous Westminster clock tower Big Ben in Gothic revival style, meticulously restored with its original blue clock hands\",\n",
        "                \"close-up of Big Ben's clock face showing the Roman numerals and detailed craftsmanship\"\n",
        "            ]\n",
        "        },\n",
        "        \"stonehenge\": {\n",
        "            \"name\": \"Stonehenge\",\n",
        "            \"aliases\": [\"Prehistoric Monument\", \"Ring of Stones\"],\n",
        "            \"location\": \"Wiltshire, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Stonehenge in the UK, the mysterious prehistoric monument of massive standing stones arranged in a circular formation\",\n",
        "                \"the prehistoric stone circle of Stonehenge, a UNESCO World Heritage site, with its sarsens and bluestones\",\n",
        "                \"Stonehenge at sunset or sunrise, with dramatic lighting casting long shadows over the ancient stones\",\n",
        "                \"the unique trilithons (two upright stones topped by a lintel) of Stonehenge\",\n",
        "                \"the enigmatic landscape surrounding Stonehenge on Salisbury Plain\"\n",
        "            ]\n",
        "        },\n",
        "        \"tower_of_london\": {\n",
        "            \"name\": \"Tower of London\",\n",
        "            \"aliases\": [\"His Majesty's Royal Palace and Fortress of the Tower of London\", \"The Tower\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Tower of London, the historic medieval castle on the north bank of the River Thames\",\n",
        "                \"the imposing White Tower, the central keep of the Tower of London, with its Norman architecture\",\n",
        "                \"Crown Jewels of the United Kingdom on display within the Tower of London\",\n",
        "                \"Yeoman Warders ('Beefeaters') in their traditional Tudor uniforms at the Tower of London\",\n",
        "                \"Traitors' Gate at the Tower of London, a famous water gate leading from the Thames\"\n",
        "            ]\n",
        "        },\n",
        "        \"buckingham_palace\": {\n",
        "            \"name\": \"Buckingham Palace\",\n",
        "            \"aliases\": [\"British Royal Residence\", \"The Palace\"],\n",
        "            \"location\": \"London, UK\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Buckingham Palace in London, the official residence and administrative headquarters of the monarch of the United Kingdom\",\n",
        "                \"the iconic facade of Buckingham Palace with the Queen's Guard (King's Guard) in their red tunics and bearskin hats\",\n",
        "                \"Changing of the Guard ceremony taking place in the forecourt of Buckingham Palace, a popular tourist attraction\",\n",
        "                \"the Victoria Memorial statue in front of Buckingham Palace\",\n",
        "                \"Buckingham Palace with the Royal Standard flag flying, indicating the monarch is in residence\"\n",
        "            ]\n",
        "        },\n",
        "        \"colosseum\": {\n",
        "            \"name\": \"Colosseum\",\n",
        "            \"aliases\": [\"Roman Colosseum\", \"Flavian Amphitheatre\", \"Colosseo\"],\n",
        "            \"location\": \"Rome, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Colosseum in Rome, the massive ancient Roman amphitheater, an icon of Imperial Rome\",\n",
        "                \"the ancient Roman Colosseum structure, with its elliptical shape, tiered seating, and arched exterior, partly in ruins\",\n",
        "                \"historic Colosseum amphitheater in Italy, where gladiatorial contests and public spectacles were held\",\n",
        "                \"the interior of the Colosseum, showing the hypogeum (underground structures) and remaining seating areas\",\n",
        "                \"the Colosseum illuminated at night, a powerful symbol of Roman history\"\n",
        "            ]\n",
        "        },\n",
        "        \"leaning_tower_of_pisa\": {\n",
        "            \"name\": \"Leaning Tower of Pisa\",\n",
        "            \"aliases\": [\"Torre pendente di Pisa\", \"Tower of Pisa\"],\n",
        "            \"location\": \"Pisa, Tuscany, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Leaning Tower of Pisa in Italy, the iconic white marble freestanding bell tower (campanile) of Pisa Cathedral, famous for its significant unintended tilt\",\n",
        "                \"the world-famous leaning cylindrical campanile of Pisa Cathedral, built of white marble with Romanesque architecture and multiple tiers of arched colonnades, noticeably tilted to one side\",\n",
        "                \"tourists taking humorous forced perspective photos with the Leaning Tower of Pisa\",\n",
        "                \"the Leaning Tower of Pisa located in the Piazza dei Miracoli (Square of Miracles), alongside the Duomo (cathedral) and Baptistery\",\n",
        "                \"the white marble cylindrical structure of the Leaning Tower of Pisa with its distinctive arched galleries, showing its dramatic lean\",\n",
        "                \"the iconic leaning cylindrical bell tower with six tiers of open galleries with arches and columns, against a blue sky, in Pisa, Italy\",\n",
        "                \"a global tourist landmark: Italy's Leaning Tower of Pisa, a tilted white marble tower with intricate Romanesque arcades\",\n",
        "                \"side view emphasizing the dramatic four-degree angle of the Leaning Tower's tilt, showcasing its unique structural imbalance\",\n",
        "                \"ornate white marble cylindrical tower with multiple levels of columns, visibly leaning to one side, a masterpiece of medieval engineering\",\n",
        "                \"the famous tilted bell tower of Pisa with its many columned galleries viewed from below, highlighting its precarious stance\",\n",
        "                \"detailed close-up of the Leaning Tower of Pisa's distinctive multi-tiered arched colonnades and ornate architectural details in white marble\",\n",
        "                \"the freestanding belltower of Pisa Cathedral set on the green grass of Piazza dei Miracoli, with its visible foundation on the low side where it sinks into the ground\",\n",
        "                \"a photo of the white marble Leaning Tower of Pisa, known for its nearly four-degree lean, a UNESCO World Heritage Site in Tuscany\"\n",
        "            ]\n",
        "        },\n",
        "        \"trevi_fountain\": {\n",
        "            \"name\": \"Trevi Fountain\",\n",
        "            \"aliases\": [\"Fontana di Trevi\"],\n",
        "            \"location\": \"Rome, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Trevi Fountain in Rome, the largest Baroque fountain in the city and one of the most famous fountains in the world\",\n",
        "                \"the spectacular Baroque Trevi Fountain with its grand sculptures, including Oceanus, tritons, and horses, set against the Palazzo Poli\",\n",
        "                \"people throwing coins over their shoulders into the Trevi Fountain, a tradition said to ensure a return to Rome\",\n",
        "                \"the Trevi Fountain illuminated at night, showcasing its dramatic statues and cascading water\",\n",
        "                \"the vibrant turquoise water of the Trevi Fountain contrasting with its white travertine stone\"\n",
        "            ]\n",
        "        },\n",
        "        \"st_peters_basilica\": {\n",
        "            \"name\": \"St. Peter's Basilica\",\n",
        "            \"aliases\": [\"Basilica di San Pietro\", \"Vatican Basilica\"],\n",
        "            \"location\": \"Vatican City\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of St. Peter's Basilica in Vatican City, the immense Renaissance church, one of the largest and most renowned churches in the world\",\n",
        "                \"the magnificent dome of St. Peter's Basilica, designed by Michelangelo, dominating the skyline of Rome and Vatican City\",\n",
        "                \"St. Peter's Square (Piazza San Pietro), designed by Bernini, with its grand colonnades, obelisk, and fountains, leading to the basilica\",\n",
        "                \"the lavish interior of St. Peter's Basilica, featuring masterpieces like Michelangelo's Pietà and Bernini's Baldachin\",\n",
        "                \"St. Peter's Basilica viewed from Via della Conciliazione or from the top of its dome\"\n",
        "            ]\n",
        "        },\n",
        "        \"sagrada_familia\": {\n",
        "            \"name\": \"Sagrada Familia\",\n",
        "            \"aliases\": [\"Basílica de la Sagrada Família\", \"Gaudi's Church\"],\n",
        "            \"location\": \"Barcelona, Spain\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Sagrada Familia in Barcelona, Antoni Gaudí's unfinished masterpiece of Catalan Modernism, a Roman Catholic minor basilica\",\n",
        "                \"the unique and highly ornate architecture of Gaudí's Sagrada Familia, with its towering spires, intricate facades (Nativity, Passion, Glory), and organic forms\",\n",
        "                \"construction cranes still present on the perpetually evolving Sagrada Familia\",\n",
        "                \"the stunning interior of Sagrada Familia, with its tree-like columns and vibrant stained-glass windows creating a forest of light\",\n",
        "                \"close-up details of the sculptural elements and symbolic decorations on the facades of Sagrada Familia\"\n",
        "            ]\n",
        "        },\n",
        "        \"alhambra\": {\n",
        "            \"name\": \"Alhambra\",\n",
        "            \"aliases\": [\"Alhambra Palace\", \"The Red Fortress\", \"Alhambra of Granada\"],\n",
        "            \"location\": \"Granada, Spain\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Alhambra palace and fortress complex in Granada, Spain, a stunning example of Moorish architecture\",\n",
        "                \"exquisite Moorish architecture of the Alhambra, featuring intricate stucco work, geometric tile patterns (azulejos), and delicate courtyards like the Court of the Lions\",\n",
        "                \"courtyards, palaces (Nasrid Palaces), and gardens (Generalife) of the Alhambra, showcasing Islamic art and design\",\n",
        "                \"the Alhambra perched on a hill overlooking the city of Granada, with the Sierra Nevada mountains in the background\",\n",
        "                \"the red-hued walls of the Alcazaba fortress within the Alhambra complex\"\n",
        "            ]\n",
        "        },\n",
        "        \"brandenburg_gate\": {\n",
        "            \"name\": \"Brandenburg Gate\",\n",
        "            \"aliases\": [\"Brandenburger Tor\", \"Berlin Gate\"],\n",
        "            \"location\": \"Berlin, Germany\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Brandenburg Gate in Berlin, the iconic neoclassical triumphal arch, a symbol of German reunification and peace\",\n",
        "                \"the neoclassical Brandenburg Gate monument, with its Doric columns and the Quadriga (a chariot drawn by four horses) скульптура наверху\",\n",
        "                \"Brandenburg Gate illuminated at night, standing at the end of Unter den Linden boulevard\",\n",
        "                \"historical significance of the Brandenburg Gate, once a symbol of division during the Cold War\",\n",
        "                \"Pariser Platz in front of the Brandenburg Gate, a lively public square\"\n",
        "            ]\n",
        "        },\n",
        "        \"neuschwanstein_castle\": {\n",
        "            \"name\": \"Neuschwanstein Castle\",\n",
        "            \"aliases\": [\"Schloss Neuschwanstein\", \"Fairy Tale Castle\", \"Mad King Ludwig's Castle\"],\n",
        "            \"location\": \"Bavaria, Germany\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Neuschwanstein Castle in Germany, the quintessential fairytale castle with its white limestone facade and blue turrets, inspiring Disney's Sleeping Beauty Castle\",\n",
        "                \"the fairytale Neuschwanstein Castle dramatically nestled in the Bavarian Alps, perched on a rugged hill overlooking the Hohenschwangau valley\",\n",
        "                \"Neuschwanstein Castle on a hill, often viewed from Marienbrücke (Mary's Bridge) for a classic postcard shot\",\n",
        "                \"the Romanesque Revival architecture of Neuschwanstein Castle, commissioned by King Ludwig II of Bavaria\",\n",
        "                \"Neuschwanstein Castle surrounded by autumn foliage or dusted with snow in winter\"\n",
        "            ]\n",
        "        },\n",
        "        \"acropolis_of_athens\": {\n",
        "            \"name\": \"Acropolis of Athens\",\n",
        "            \"aliases\": [\"Ακρόπολη Αθηνών\", \"Parthenon\", \"Sacred Rock\"],\n",
        "            \"location\": \"Athens, Greece\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Acropolis of Athens in Greece, the ancient citadel located on a rocky outcrop above the city, crowned by the Parthenon\",\n",
        "                \"the Parthenon, the iconic Doric temple dedicated to the goddess Athena, standing majestically on the Acropolis\",\n",
        "                \"ancient ruins of the Acropolis overlooking the sprawling city of Athens, including the Erechtheion with its Porch of the Caryatids, and the Propylaea\",\n",
        "                \"the Acropolis illuminated at night, a symbol of ancient Greek civilization and democracy\",\n",
        "                \"view of the Acropolis from Filopappou Hill or Lycabettus Hill\"\n",
        "            ]\n",
        "        },\n",
        "        \"santorini_oia\": { # Specified Oia for iconic view\n",
        "            \"name\": \"Santorini (Oia)\",\n",
        "            \"aliases\": [\"Thera\", \"Greek Islands\", \"Oia village Santorini\"],\n",
        "            \"location\": \"Cyclades, Greece\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Oia village in Santorini island, Greece, famous for its whitewashed cave houses and blue-domed churches clinging to cliffs above the Aegean Sea\",\n",
        "                \"iconic whitewashed villages with blue domes in Oia, Santorini, overlooking the volcanic caldera\",\n",
        "                \"breathtaking sunset over the caldera in Oia, Santorini, a world-famous romantic spectacle\",\n",
        "                \"narrow winding pathways and steps through the picturesque village of Oia\",\n",
        "                \"bougainvillea flowers adding splashes of color to the white buildings of Santorini\"\n",
        "            ]\n",
        "        },\n",
        "        \"canals_of_venice\": {\n",
        "            \"name\": \"Canals of Venice\",\n",
        "            \"aliases\": [\"Venetian Canals\", \"Rialto Bridge Venice\"],\n",
        "            \"location\": \"Venice, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"gondolas gliding gracefully through the narrow, winding canals of Venice, Italy, lined with historic, colorful buildings\",\n",
        "                \"the Grand Canal in Venice, its main waterway, bustling with vaporettos (water buses), water taxis, and gondolas, spanned by the iconic Rialto Bridge\",\n",
        "                \"romantic atmosphere of Venetian canals, reflecting the unique architecture of the sinking city, with smaller bridges connecting walkways\",\n",
        "                \"picturesque scenes of Venice's canals, often with laundry hanging between buildings or flower boxes on windowsills\",\n",
        "                \"Rio di Palazzo with the Bridge of Sighs connecting the Doge's Palace to the prisons\"\n",
        "            ]\n",
        "        },\n",
        "        \"florence_cathedral_duomo\": {\n",
        "            \"name\": \"Florence Cathedral (Duomo)\",\n",
        "            \"aliases\": [\"Cattedrale di Santa Maria del Fiore\", \"Il Duomo di Firenze\", \"Brunelleschi's Dome\"],\n",
        "            \"location\": \"Florence, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"Brunelleschi's massive, iconic red-tiled dome atop the Florence Cathedral (Santa Maria del Fiore), dominating the city skyline of Florence\",\n",
        "                \"the intricate Gothic and Renaissance facade of the Florence Duomo, made of white, green, and pink marble, alongside Giotto's Campanile (bell tower) and the Baptistery of St. John\",\n",
        "                \"panoramic view of Florence from the top of Brunelleschi's Dome or Giotto's Campanile, showcasing the sea of red-tiled roofs and the Arno River\",\n",
        "                \"the octagonal Florence Baptistery with its famous bronze doors, particularly Ghiberti's 'Gates of Paradise'\",\n",
        "                \"the grand interior of Florence Cathedral, with its vast nave and frescoes, including Vasari's 'Last Judgment' inside the dome\"\n",
        "            ]\n",
        "        },\n",
        "        \"anne_frank_house\": {\n",
        "            \"name\": \"Anne Frank House\",\n",
        "            \"aliases\": [\"Anne Frank Huis\", \"Secret Annex Amsterdam\"],\n",
        "            \"location\": \"Amsterdam, Netherlands\",\n",
        "            \"prompts\": [\n",
        "                \"the unassuming exterior of the Anne Frank House, a canal house on the Prinsengracht in Amsterdam, where Anne Frank and her family hid during WWII\",\n",
        "                \"the secret annex (Achterhuis) hidden behind a movable bookcase in the Anne Frank House, where the Frank family lived in hiding\",\n",
        "                \"poignant historical site of the Anne Frank House, now a biographical museum dedicated to Jewish wartime diarist Anne Frank and the Holocaust\",\n",
        "                \"long queues of visitors outside the Anne Frank House, waiting to enter the museum\",\n",
        "                \"the preserved rooms and exhibits within the Anne Frank House, telling the story of Anne's life and diary\"\n",
        "            ]\n",
        "        },\n",
        "        \"canals_of_amsterdam\": {\n",
        "            \"name\": \"Canals of Amsterdam\",\n",
        "            \"aliases\": [\"Grachtengordel Amsterdam\", \"Amsterdam Canal Ring\"],\n",
        "            \"location\": \"Amsterdam, Netherlands\",\n",
        "            \"prompts\": [\n",
        "                \"picturesque canals of Amsterdam, part of the Grachtengordel (canal belt), a UNESCO World Heritage site, lined with narrow, gabled canal houses and houseboats\",\n",
        "                \"bicycles parked along the charming bridges that cross Amsterdam's numerous canals, often adorned with flowers\",\n",
        "                \"canal cruise boats navigating the historic waterways of Amsterdam, offering views of 17th-century architecture\",\n",
        "                \"tree-lined canals of Amsterdam in different seasons, reflecting the elegant facades of the canal houses\",\n",
        "                \"the distinctive architecture of Amsterdam's canal houses, with their narrow fronts and decorative gables\"\n",
        "            ]\n",
        "        },\n",
        "        \"charles_bridge_prague\": {\n",
        "            \"name\": \"Charles Bridge\",\n",
        "            \"aliases\": [\"Karlův most\", \"Prague Stone Bridge\"],\n",
        "            \"location\": \"Prague, Czech Republic\",\n",
        "            \"prompts\": [\n",
        "                \"the historic Charles Bridge in Prague, a medieval stone arch bridge adorned with 30 statues of saints, crossing the Vltava River\",\n",
        "                \"view of Prague Castle and St. Vitus Cathedral from Charles Bridge, with artists, musicians, and vendors lining the bridge\",\n",
        "                \"Gothic Old Town Bridge Tower and Lesser Town Bridge Towers guarding both ends of Charles Bridge\",\n",
        "                \"Charles Bridge at dawn or dusk, with fewer crowds and atmospheric lighting, a symbol of Prague\",\n",
        "                \"statues on Charles Bridge, such as the statue of St. John of Nepomuk, often touched for good luck\"\n",
        "            ]\n",
        "        },\n",
        "        \"red_square_st_basils_cathedral\": {\n",
        "            \"name\": \"Red Square & St. Basil's Cathedral\",\n",
        "            \"aliases\": [\"Красная площадь\", \"Собор Василия Блаженного\", \"Moscow Kremlin\"],\n",
        "            \"location\": \"Moscow, Russia\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic, vibrantly colored onion domes of St. Basil's Cathedral (Cathedral of Vasily the Blessed) in Red Square, Moscow, a unique masterpiece of Russian architecture\",\n",
        "                \"Red Square, the historic central square of Moscow, with Lenin's Mausoleum, the fortified walls of the Kremlin, the State Historical Museum, and the GUM department store\",\n",
        "                \"historic and vast Red Square, a UNESCO World Heritage site, a focal point of Russian history and culture\",\n",
        "                \"St. Basil's Cathedral illuminated at night, its swirling patterns and bright colors standing out against the dark sky\",\n",
        "                \"the imposing Spasskaya Tower of the Moscow Kremlin overlooking Red Square\"\n",
        "            ]\n",
        "        },\n",
        "        \"edinburgh_castle\": {\n",
        "            \"name\": \"Edinburgh Castle\",\n",
        "            \"aliases\": [\"Castle Rock Edinburgh\"],\n",
        "            \"location\": \"Edinburgh, UK\",\n",
        "            \"prompts\": [\n",
        "                \"Edinburgh Castle perched dramatically atop Castle Rock, an extinct volcano, dominating the skyline of Edinburgh, Scotland\",\n",
        "                \"historic Scottish fortress, Edinburgh Castle, with its ancient ramparts, Crown Jewels of Scotland (Honours of Scotland), and St. Margaret's Chapel\",\n",
        "                \"view of the Royal Mile leading up to Edinburgh Castle, the historic heart of Edinburgh's Old Town\",\n",
        "                \"the One O'Clock Gun firing from Edinburgh Castle, a daily tradition\",\n",
        "                \"Edinburgh Castle illuminated at night, overlooking the city\"\n",
        "            ]\n",
        "        },\n",
        "        \"matterhorn\": {\n",
        "            \"name\": \"Matterhorn\",\n",
        "            \"aliases\": [\"Monte Cervino\", \"The Horn\"],\n",
        "            \"location\": \"Zermatt, Switzerland / Breuil-Cervinia, Italy\",\n",
        "            \"prompts\": [\n",
        "                \"the distinctive, sharply defined pyramidal peak of the Matterhorn mountain in the Pennine Alps on the border between Switzerland and Italy\",\n",
        "                \"snow-covered Matterhorn against a clear blue sky, often reflected in a tranquil alpine lake like Riffelsee or Stellisee\",\n",
        "                \"iconic alpine scenery surrounding the Matterhorn, a world-famous mountaineering challenge and symbol of the Alps\",\n",
        "                \"the village of Zermatt, Switzerland, with traditional chalets and views of the Matterhorn\",\n",
        "                \"Matterhorn at sunrise or sunset (alpenglow), when the peak is bathed in golden or reddish light\"\n",
        "            ]\n",
        "        },\n",
        "        \"palace_of_versailles\": {\n",
        "            \"name\": \"Palace of Versailles\",\n",
        "            \"aliases\": [\"Château de Versailles\", \"Versailles Palace\"],\n",
        "            \"location\": \"Versailles, France\",\n",
        "            \"prompts\": [\n",
        "                \"the opulent Palace of Versailles, former principal royal residence of France, with its grand Hall of Mirrors (Galerie des Glaces) and lavish state apartments\",\n",
        "                \"expansive formal gardens of Versailles designed by André Le Nôtre, featuring geometric patterns, fountains (like the Latona Fountain), canals, and groves\",\n",
        "                \"luxurious Baroque architecture and lavish interiors of the Palace of Versailles, a UNESCO World Heritage site symbolizing absolute monarchy\",\n",
        "                \"the Grand Trianon and Petit Trianon, smaller palaces within the estate of Versailles, and Marie Antoinette's Hamlet\",\n",
        "                \"the facade of the Palace of Versailles overlooking the Place d'Armes\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 北美地標\n",
        "    \"north_america\": {\n",
        "        \"statue_of_liberty\": {\n",
        "            \"name\": \"Statue of Liberty\",\n",
        "            \"aliases\": [\"Liberty Enlightening the World\", \"Lady Liberty\"],\n",
        "            \"location\": \"New York Harbor, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Statue of Liberty in New York, the colossal neoclassical sculpture on Liberty Island, a symbol of freedom and democracy\",\n",
        "                \"the iconic Statue of Liberty with her torch held high and tabula ansata (tablet), a gift from France to the USA\",\n",
        "                \"Statue of Liberty on Liberty Island, with the Manhattan skyline or Ellis Island in the background\",\n",
        "                \"close-up of Lady Liberty's crowned head or her copper-green patina\",\n",
        "                \"ferry approaching the Statue of Liberty, offering panoramic views\"\n",
        "            ]\n",
        "        },\n",
        "        \"golden_gate_bridge\": {\n",
        "            \"name\": \"Golden Gate Bridge\",\n",
        "            \"aliases\": [\"Golden Gate\", \"GGB\"],\n",
        "            \"location\": \"San Francisco, California, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Golden Gate Bridge in San Francisco, its iconic Art Deco suspension bridge painted in 'International Orange'\",\n",
        "                \"the vibrant red-orange Golden Gate Bridge spanning the Golden Gate strait, often partially shrouded in fog\",\n",
        "                \"Golden Gate Bridge with its distinctive twin towers, soaring cables, and views of Alcatraz Island or the San Francisco skyline\",\n",
        "                \"view of the Golden Gate Bridge from various vantage points like Battery Spencer, Vista Point, or Baker Beach\",\n",
        "                \"cyclists or pedestrians crossing the Golden Gate Bridge\"\n",
        "            ]\n",
        "        },\n",
        "        \"grand_canyon\": {\n",
        "            \"name\": \"Grand Canyon\",\n",
        "            \"aliases\": [\"Grand Canyon National Park\", \"The Canyon\"],\n",
        "            \"location\": \"Arizona, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Grand Canyon in Arizona, a massive, steep-sided canyon carved by the Colorado River, showcasing layers of colorful rock\",\n",
        "                \"vast, awe-inspiring landscape of the Grand Canyon, with its immense scale, depth, and intricate formations\",\n",
        "                \"Colorado River flowing through the bottom of the Grand Canyon, visible from viewpoints like Mather Point or Yavapai Point on the South Rim\",\n",
        "                \"sunset or sunrise over the Grand Canyon, painting the canyon walls in vibrant hues of red, orange, and purple\",\n",
        "                \"hiking trails along the rim or into the Grand Canyon, such as Bright Angel Trail\"\n",
        "            ]\n",
        "        },\n",
        "        \"hollywood_sign\": {\n",
        "            \"name\": \"Hollywood Sign\",\n",
        "            \"aliases\": [\"Hollywoodland Sign\"],\n",
        "            \"location\": \"Mount Lee, Los Angeles, California, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Hollywood Sign in Los Angeles, the iconic white capital letters spelling out 'HOLLYWOOD' on the side of Mount Lee\",\n",
        "                \"the iconic Hollywood Sign overlooking the sprawling cityscape of Hollywood and Los Angeles\",\n",
        "                \"view of the Hollywood Sign from Griffith Observatory, Lake Hollywood Park, or a helicopter tour\",\n",
        "                \"the large, distinctive letters of the Hollywood Sign, a symbol of the American film industry\",\n",
        "                \"Hollywood Sign against a clear blue sky or at sunset with city lights below\"\n",
        "            ]\n",
        "        },\n",
        "        \"white_house\": {\n",
        "            \"name\": \"White House\",\n",
        "            \"aliases\": [\"President's House\", \"Executive Mansion\", \"1600 Pennsylvania Avenue\"],\n",
        "            \"location\": \"Washington D.C., USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the White House in Washington D.C., the official residence and workplace of the President of the United States\",\n",
        "                \"the iconic neoclassical facade of the White House, with its white columns and porticoes (North Portico and South Portico)\",\n",
        "                \"the North Portico of the White House facing Pennsylvania Avenue, or the South Lawn with the Oval Office view\",\n",
        "                \"the White House surrounded by its meticulously manicured gardens and security fencing\",\n",
        "                \"Marine One helicopter landing on the South Lawn of the White House\"\n",
        "            ]\n",
        "        },\n",
        "        \"mount_rushmore\": {\n",
        "            \"name\": \"Mount Rushmore\",\n",
        "            \"aliases\": [\"Mount Rushmore National Memorial\", \"Presidents' Mountain\"],\n",
        "            \"location\": \"Keystone, South Dakota, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Mount Rushmore National Memorial, featuring the colossal carved faces of U.S. Presidents George Washington, Thomas Jefferson, Theodore Roosevelt, and Abraham Lincoln\",\n",
        "                \"the sculpted faces of four presidents carved into the granite face of Mount Rushmore in the Black Hills of South Dakota\",\n",
        "                \"Mount Rushmore with the Avenue of Flags leading to the Grand View Terrace\",\n",
        "                \"the immense scale and detailed carving of the presidential heads on Mount Rushmore\",\n",
        "                \"Mount Rushmore illuminated at night during the evening lighting ceremony\"\n",
        "            ]\n",
        "        },\n",
        "        \"times_square\": {\n",
        "            \"name\": \"Times Square\",\n",
        "            \"aliases\": [\"The Crossroads of the World\", \"The Great White Way\"],\n",
        "            \"location\": \"New York City, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Times Square in New York City, the bustling commercial intersection and entertainment hub, famous for its dazzling array of brightly lit billboards and advertisements\",\n",
        "                \"bright, massive digital billboards and flashing neon lights of Times Square at night, creating a vibrant and energetic atmosphere\",\n",
        "                \"bustling crowds of tourists and locals, yellow taxis, and costumed characters in Times Square\",\n",
        "                \"the New Year's Eve ball drop ceremony in Times Square\",\n",
        "                \"the TKTS booth with its red steps in Times Square, a popular spot for discounted Broadway tickets\"\n",
        "            ]\n",
        "        },\n",
        "        \"cn_tower\": {\n",
        "            \"name\": \"CN Tower\",\n",
        "            \"aliases\": [\"Canadian National Tower\", \"Toronto Tower\"],\n",
        "            \"location\": \"Toronto, Ontario, Canada\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the CN Tower in Toronto, the iconic slender communications and observation tower dominating the city's skyline\",\n",
        "                \"the tall, freestanding CN Tower with its distinctive main pod housing observation decks, a revolving restaurant, and the EdgeWalk\",\n",
        "                \"view from the top of the CN Tower, looking down through the glass floor or out at Lake Ontario and the Toronto Islands\",\n",
        "                \"CN Tower illuminated at night with programmable LED lights, often changing colors for special occasions\",\n",
        "                \"Toronto skyline featuring the CN Tower as its centerpiece\"\n",
        "            ]\n",
        "        },\n",
        "        \"chichen_itza\": {\n",
        "            \"name\": \"Chichen Itza\",\n",
        "            \"aliases\": [\"El Castillo\", \"Pyramid of Kukulcan\", \"Chichén Itzá\"],\n",
        "            \"location\": \"Yucatan Peninsula, Mexico\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Chichen Itza in Mexico, the ancient Mayan city and UNESCO World Heritage site, with its iconic El Castillo (Pyramid of Kukulcan)\",\n",
        "                \"the massive step-pyramid El Castillo at Chichen Itza, famous for the serpent shadow effect during the equinoxes\",\n",
        "                \"ancient ruins of Chichen Itza, including the Temple of Warriors, the Great Ball Court, and the Observatory (El Caracol)\",\n",
        "                \"intricate stone carvings and Mayan hieroglyphs found on the structures of Chichen Itza\",\n",
        "                \"the sacred cenote (sinkhole) at Chichen Itza, used for sacrifices\"\n",
        "            ]\n",
        "        },\n",
        "        \"niagara_falls\": {\n",
        "            \"name\": \"Niagara Falls\",\n",
        "            \"aliases\": [\"Horseshoe Falls\", \"American Falls\", \"Bridal Veil Falls\"],\n",
        "            \"location\": \"Ontario, Canada / New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"massive cascades of Niagara Falls, including the powerful Horseshoe Falls (Canadian Falls), the American Falls, and the smaller Bridal Veil Falls\",\n",
        "                \"mist rising dramatically from the thundering Niagara Falls, with tour boats like the Maid of the Mist or Hornblower navigating the turbulent waters below\",\n",
        "                \"Rainbow Bridge connecting Canada and the USA, with panoramic views of Niagara Falls\",\n",
        "                \"Niagara Falls illuminated with colorful lights at night, or with fireworks displays\",\n",
        "                \"Goat Island separating the American Falls and Horseshoe Falls, offering close-up views\"\n",
        "            ]\n",
        "        },\n",
        "        \"central_park\": {\n",
        "            \"name\": \"Central Park\",\n",
        "            \"aliases\": [\"Manhattan Central Park\"],\n",
        "            \"location\": \"New York City, New York, USA\",\n",
        "            \"prompts\": [\n",
        "                \"vast green expanse of Central Park in Manhattan, New York City, an urban oasis surrounded by the towering skyscrapers of the city skyline\",\n",
        "                \"iconic locations within Central Park such as Bethesda Terrace and Fountain, Strawberry Fields (John Lennon memorial), Wollman Rink (ice skating), or the Central Park Carousel\",\n",
        "                \"people enjoying recreational activities like picnicking, boating on The Lake, jogging, or horse-drawn carriage rides in Central Park\",\n",
        "                \"lush lawns, wooded areas, walking paths, and picturesque bridges (like Bow Bridge or Gapstow Bridge) within Central Park\",\n",
        "                \"aerial view of Central Park, highlighting its rectangular shape amidst the dense urban grid of Manhattan\"\n",
        "            ]\n",
        "        },\n",
        "        \"las_vegas_strip\": {\n",
        "            \"name\": \"Las Vegas Strip\",\n",
        "            \"aliases\": [\"The Strip Las Vegas\", \"Las Vegas Boulevard South\"],\n",
        "            \"location\": \"Las Vegas, Nevada, USA\",\n",
        "            \"prompts\": [\n",
        "                \"the dazzling Las Vegas Strip at night, a vibrant spectacle of illuminated mega-resorts, opulent casinos, and world-class entertainment venues\",\n",
        "                \"iconic landmarks and themed hotels on the Las Vegas Strip such as the Bellagio fountains, the Eiffel Tower replica at Paris Las Vegas, the High Roller observation wheel, or the Venetian's canals\",\n",
        "                \"bustling energy, flashing neon signs, and extravagant architecture characterizing the world-famous Las Vegas Strip\",\n",
        "                \"pedestrians walking along the crowded sidewalks of the Las Vegas Strip, taking in the sights and sounds\",\n",
        "                \"the Fountains of Bellagio water show on the Las Vegas Strip\"\n",
        "            ]\n",
        "        },\n",
        "        \"yellowstone_national_park\": {\n",
        "            \"name\": \"Yellowstone National Park\",\n",
        "            \"aliases\": [\"Old Faithful Yellowstone\", \"Grand Prismatic Spring\"],\n",
        "            \"location\": \"Wyoming, Montana, Idaho, USA\",\n",
        "            \"prompts\": [\n",
        "                \"geothermal features of Yellowstone National Park, including the iconic Old Faithful geyser erupting steam and hot water into the air\",\n",
        "                \"the vibrant, rainbow-like colors of the Grand Prismatic Spring, the largest hot spring in the United States, in Yellowstone's Midway Geyser Basin\",\n",
        "                \"wildlife such as bison herds, elk, bears, and wolves roaming freely in the diverse landscapes of Yellowstone National Park, including forests, meadows, and rivers\",\n",
        "                \"the Grand Canyon of the Yellowstone, a dramatic canyon with impressive waterfalls like the Lower Falls\",\n",
        "                \"Mammoth Hot Springs in Yellowstone, with its terraced travertine formations\"\n",
        "            ]\n",
        "        },\n",
        "        \"banff_national_park_lake_louise\": { # Specified Lake Louise\n",
        "            \"name\": \"Banff National Park (Lake Louise / Moraine Lake)\",\n",
        "            \"aliases\": [\"Lake Louise Banff\", \"Moraine Lake Banff\", \"Canadian Rockies\"],\n",
        "            \"location\": \"Alberta, Canada\",\n",
        "            \"prompts\": [\n",
        "                \"the stunning turquoise glacial waters of Lake Louise in Banff National Park, with the majestic Victoria Glacier and Fairmont Chateau Lake Louise in the background\",\n",
        "                \"the equally breathtaking Moraine Lake in Banff National Park, with its vivid blue water backed by the rugged Valley of the Ten Peaks\",\n",
        "                \"stunning Canadian Rockies mountain scenery in Banff National Park, a UNESCO World Heritage site, with snow-capped peaks, alpine meadows, and pristine forests\",\n",
        "                \"canoeing or hiking around Lake Louise or Moraine Lake\",\n",
        "                \"wildlife like elk or grizzly bears sometimes spotted in Banff National Park\"\n",
        "            ]\n",
        "        },\n",
        "        \"space_needle_seattle\": {\n",
        "            \"name\": \"Space Needle\",\n",
        "            \"aliases\": [\"Seattle Space Needle\"],\n",
        "            \"location\": \"Seattle, Washington, USA\",\n",
        "            \"prompts\": [\n",
        "                \"the futuristic Space Needle observation tower in Seattle, Washington, with its distinctive saucer-shaped top and slender hourglass silhouette\",\n",
        "                \"panoramic view of Seattle's skyline, Puget Sound, Elliott Bay, and surrounding mountains like Mount Rainier from the Space Needle's observation deck or revolving restaurant\",\n",
        "                \"Space Needle as an icon of the Pacific Northwest and a legacy of the 1962 World's Fair\",\n",
        "                \"the Space Needle illuminated at night, a prominent feature of Seattle's cityscape\",\n",
        "                \"Chihuly Garden and Glass exhibit located at the base of the Space Needle\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 南美地標\n",
        "    \"south_america\": {\n",
        "        \"machu_picchu\": {\n",
        "            \"name\": \"Machu Picchu\",\n",
        "            \"aliases\": [\"Lost City of the Incas\", \"Machu Pikchu\"],\n",
        "            \"location\": \"Cusco Region, Peru\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Machu Picchu in Peru, the breathtaking ancient Inca citadel set high in the Andes Mountains, often shrouded in mist\",\n",
        "                \"the well-preserved ruins of the Inca city of Machu Picchu, with its intricate stone masonry, temples, plazas, and agricultural terraces\",\n",
        "                \"panoramic view of Machu Picchu ruins with Huayna Picchu mountain rising prominently in the background\",\n",
        "                \"llamas grazing among the ancient stone structures of Machu Picchu\",\n",
        "                \"sunrise over Machu Picchu, revealing its mystical beauty and stunning mountain setting\"\n",
        "            ]\n",
        "        },\n",
        "        \"christ_the_redeemer\": {\n",
        "            \"name\": \"Christ the Redeemer\",\n",
        "            \"aliases\": [\"Cristo Redentor\", \"Rio Jesus Statue\", \"Corcovado Statue\"],\n",
        "            \"location\": \"Rio de Janeiro, Brazil\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Christ the Redeemer statue in Rio de Janeiro, the colossal Art Deco statue of Jesus Christ with outstretched arms, standing atop Corcovado Mountain\",\n",
        "                \"the iconic soapstone statue of Jesus Christ on Corcovado Mountain, overlooking the city of Rio de Janeiro, Sugarloaf Mountain, and Guanabara Bay\",\n",
        "                \"Christ the Redeemer as a symbol of Christianity and a global icon of Rio de Janeiro and Brazil\",\n",
        "                \"view from the base of Christ the Redeemer statue, offering breathtaking panoramic vistas\",\n",
        "                \"Christ the Redeemer statue illuminated at night or silhouetted against a vibrant sunset\"\n",
        "            ]\n",
        "        },\n",
        "        \"iguazu_falls\": {\n",
        "            \"name\": \"Iguazu Falls\",\n",
        "            \"aliases\": [\"Iguaçu Falls\", \"Cataratas del Iguazú\", \"Cataratas do Iguaçu\", \"Devil's Throat Iguazu\"],\n",
        "            \"location\": \"Misiones Province, Argentina / Paraná State, Brazil\",\n",
        "            \"prompts\": [\n",
        "                \"expansive network of hundreds of powerful waterfalls at Iguazu Falls, spanning the border of Argentina and Brazil, surrounded by lush subtropical rainforest\",\n",
        "                \"the immense and thunderous Devil's Throat (Garganta del Diablo / Garganta do Diabo), the largest and most dramatic cataract of Iguazu Falls\",\n",
        "                \"walkways and viewpoints offering close-up, immersive experiences of the mighty Iguazu Falls, often with rainbows forming in the mist\",\n",
        "                \"boat tours venturing near the base of the waterfalls at Iguazu Falls\",\n",
        "                \"diverse wildlife like coatis and colorful birds in the Iguazu National Park surrounding the falls\"\n",
        "            ]\n",
        "        },\n",
        "        \"galapagos_islands\": {\n",
        "            \"name\": \"Galapagos Islands\",\n",
        "            \"aliases\": [\"Archipiélago de Colón\", \"Darwin's Islands\"],\n",
        "            \"location\": \"Ecuador\",\n",
        "            \"prompts\": [\n",
        "                \"unique and fearless wildlife of the Galapagos Islands, such as giant tortoises roaming freely, marine iguanas basking on volcanic rocks, and blue-footed boobies performing their mating dance\",\n",
        "                \"pristine volcanic landscapes, lava fields, and beautiful beaches (like Tortuga Bay) of the Galapagos Islands, a UNESCO World Heritage site that inspired Charles Darwin's theory of evolution\",\n",
        "                \"snorkeling or diving with sea lions, penguins, and diverse marine life in the clear waters surrounding the Galapagos Islands\",\n",
        "                \"various endemic species found only in the Galapagos, like Darwin's finches or flightless cormorants\",\n",
        "                \"cruise ships or small yachts exploring the different islands of the Galapagos archipelago\"\n",
        "            ]\n",
        "        },\n",
        "        \"torres_del_paine_national_park\": {\n",
        "            \"name\": \"Torres del Paine National Park\",\n",
        "            \"aliases\": [\"Parque Nacional Torres del Paine\", \"Paine Towers\"],\n",
        "            \"location\": \"Patagonia, Chile\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic granite peaks (Horns or Towers of Paine) of the Torres del Paine massif in Chilean Patagonia, often reflecting in turquoise glacial lakes like Pehoé or Nordenskjöld\",\n",
        "                \"stunning and wild landscapes of glaciers (like Grey Glacier), vibrant blue lakes, rivers, and mountains in Torres del Paine National Park, a UNESCO Biosphere Reserve\",\n",
        "                \"hiking trails like the 'W' trek or 'O' circuit offering breathtaking views of the dramatic Patagonian scenery in Torres del Paine\",\n",
        "                \"guanacos, condors, and other Patagonian wildlife in their natural habitat within Torres del Paine\",\n",
        "                \"the dramatic, windswept environment of Torres del Paine, known for its unpredictable weather\"\n",
        "            ]\n",
        "        },\n",
        "        \"angel_falls\": {\n",
        "            \"name\": \"Angel Falls\",\n",
        "            \"aliases\": [\"Salto Ángel\", \"Kerepakupai Merú\"],\n",
        "            \"location\": \"Canaima National Park, Venezuela\",\n",
        "            \"prompts\": [\n",
        "                \"Angel Falls, the world's tallest uninterrupted waterfall, cascading spectacularly from the sheer cliff face of Auyán-Tepui, a massive table-top mountain (tepui) in Venezuela's Canaima National Park\",\n",
        "                \"remote and dramatic jungle landscape surrounding Angel Falls, with tepuis rising from the savanna and rainforest\",\n",
        "                \"aerial view of Angel Falls plunging thousands of feet down the Auyán-Tepui, often shrouded in mist\",\n",
        "                \"expeditions by boat and foot through the remote wilderness to reach the base of Angel Falls\",\n",
        "                \"the sheer scale and pristine, untouched beauty of Angel Falls, a natural wonder\"\n",
        "            ]\n",
        "        },\n",
        "        \"salar_de_uyuni\": {\n",
        "            \"name\": \"Salar de Uyuni\",\n",
        "            \"aliases\": [\"Uyuni Salt Flat\"],\n",
        "            \"location\": \"Potosí, Bolivia\",\n",
        "            \"prompts\": [\n",
        "                \"vast, seemingly endless white expanse of the Salar de Uyuni salt flat in Bolivia, the world's largest salt desert, creating a surreal and minimalist landscape\",\n",
        "                \"mirror-like reflections on Salar de Uyuni during the rainy season (December-April), transforming the salt flat into the world's largest natural mirror, blurring the horizon between sky and ground\",\n",
        "                \"Isla Incahuasi (Fish Island) with its giant ancient cacti standing starkly against the white salt crust of Salar de Uyuni\",\n",
        "                \"geometric patterns of salt polygons on the dry Salar de Uyuni\",\n",
        "                \"creative forced perspective photographs taken by tourists on the Salar de Uyuni\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 中東/非洲地標\n",
        "    \"middle_east_africa\": {\n",
        "        \"pyramids_of_giza\": {\n",
        "            \"name\": \"Pyramids of Giza\",\n",
        "            \"aliases\": [\"Great Pyramids\", \"Egyptian Pyramids\", \"Giza Necropolis\"],\n",
        "            \"location\": \"Giza, Egypt (near Cairo)\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Pyramids of Giza in Egypt, the ancient wonder of the world, with the Great Pyramid, Pyramid of Khafre, and Pyramid of Menkaure\",\n",
        "                \"the ancient Egyptian pyramids on the Giza plateau, with the enigmatic Great Sphinx guarding them, against a desert backdrop or the Cairo skyline\",\n",
        "                \"Great Pyramid of Giza, the largest of the three, with the smaller Queen's Pyramids nearby\",\n",
        "                \"camels and horses carrying tourists around the Giza pyramid complex\",\n",
        "                \"sunset or sunrise over the Pyramids of Giza, casting long shadows\"\n",
        "            ]\n",
        "        },\n",
        "        \"burj_khalifa\": {\n",
        "            \"name\": \"Burj Khalifa\",\n",
        "            \"aliases\": [\"Khalifa Tower\", \"Dubai Tower\", \"World's Tallest Building\"],\n",
        "            \"location\": \"Dubai, UAE\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Burj Khalifa in Dubai, the world's tallest building, a sleek, tapering skyscraper piercing the sky\",\n",
        "                \"the ultra-modern skyscraper Burj Khalifa dominating the Dubai skyline with its impressive height and futuristic design\",\n",
        "                \"Burj Khalifa skyscraper rising above the Dubai Fountain and surrounding modern architecture\",\n",
        "                \"view from the observation deck ('At the Top') of Burj Khalifa, offering panoramic views of Dubai and the desert\",\n",
        "                \"Burj Khalifa illuminated with spectacular light shows at night\"\n",
        "            ]\n",
        "        },\n",
        "        \"petra_jordan\": { # Added Jordan to differentiate from any other Petra\n",
        "            \"name\": \"Petra\",\n",
        "            \"aliases\": [\"Rose City\", \"Lost City of Petra\", \"Al-Khazneh Petra\"],\n",
        "            \"location\": \"Ma'an Governorate, Jordan\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Petra in Jordan, the ancient Nabataean city carved into rose-red sandstone cliffs, a UNESCO World Heritage site\",\n",
        "                \"the iconic Treasury (Al-Khazneh) in Petra, with its ornate facade intricately carved into a sandstone rock face, revealed at the end of the Siq (narrow gorge)\",\n",
        "                \"ancient city of Petra with its rock-cut architecture, including tombs, temples (like the Monastery, Ad Deir), and colonnaded streets\",\n",
        "                \"the Siq, a narrow, winding gorge that serves as the dramatic main entrance to the city of Petra\",\n",
        "                \"Bedouins with camels or donkeys in the ancient city of Petra\"\n",
        "            ]\n",
        "        },\n",
        "        \"table_mountain\": {\n",
        "            \"name\": \"Table Mountain\",\n",
        "            \"aliases\": [\"Tafelberg\", \"Cape Town Table Mountain\"],\n",
        "            \"location\": \"Cape Town, South Africa\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Table Mountain in Cape Town, the iconic flat-topped mountain majestically overlooking the city, Table Bay, and the Atlantic Ocean\",\n",
        "                \"the flat-topped Table Mountain, often covered by a 'tablecloth' of clouds, with Devil's Peak and Lion's Head adjacent to it\",\n",
        "                \"view from the rotating cable car ascending Table Mountain, or panoramic views from its summit\",\n",
        "                \"Cape Town city nestled at the foot of Table Mountain, with the V&A Waterfront visible\",\n",
        "                \"unique fynbos vegetation found on Table Mountain, part of the Cape Floral Kingdom\"\n",
        "            ]\n",
        "        },\n",
        "        \"sheikh_zayed_grand_mosque\": {\n",
        "            \"name\": \"Sheikh Zayed Grand Mosque\",\n",
        "            \"aliases\": [\"Grand Mosque Abu Dhabi\"],\n",
        "            \"location\": \"Abu Dhabi, UAE\",\n",
        "            \"prompts\": [\n",
        "                \"the stunning, pristine white marble Sheikh Zayed Grand Mosque in Abu Dhabi, with its numerous domes (82 of them) and four towering minarets\",\n",
        "                \"intricate floral designs inlaid with semi-precious stones, gold accents, and massive reflective pools surrounding the Sheikh Zayed Grand Mosque\",\n",
        "                \"the vast main prayer hall of Sheikh Zayed Grand Mosque, featuring the world's largest hand-knotted carpet and one of the world's largest Swarovski crystal chandeliers\",\n",
        "                \"the gleaming white exterior and symmetrical courtyards of Sheikh Zayed Grand Mosque, a masterpiece of modern Islamic architecture\",\n",
        "                \"Sheikh Zayed Grand Mosque illuminated at night with a unique lunar lighting system that changes with the phases of the moon\"\n",
        "            ]\n",
        "        },\n",
        "        \"masai_mara_national_reserve\": {\n",
        "            \"name\": \"Masai Mara National Reserve\",\n",
        "            \"aliases\": [\"Maasai Mara\", \"The Mara\"],\n",
        "            \"location\": \"Kenya\",\n",
        "            \"prompts\": [\n",
        "                \"vast, open savannas of the Masai Mara National Reserve in Kenya, teeming with iconic African wildlife like lions, elephants, giraffes, zebras, and wildebeest\",\n",
        "                \"the Great Migration of millions of wildebeest and zebras crossing the Mara River, often facing crocodiles, during their annual journey (July-October)\",\n",
        "                \"Masai people in their traditional vibrant red shuka robes, often seen near their villages or as safari guides in the Masai Mara\",\n",
        "                \"hot air balloons drifting over the plains of the Masai Mara at sunrise, offering a unique perspective on the landscape and wildlife\",\n",
        "                \"acacia trees silhouetted against a dramatic African sunset in the Masai Mara\"\n",
        "            ]\n",
        "        },\n",
        "        \"victoria_falls\": {\n",
        "            \"name\": \"Victoria Falls\",\n",
        "            \"aliases\": [\"Mosi-oa-Tunya\", \"The Smoke that Thunders\"],\n",
        "            \"location\": \"Livingstone, Zambia / Victoria Falls, Zimbabwe\",\n",
        "            \"prompts\": [\n",
        "                \"the spectacular, vast curtain of falling water at Victoria Falls, one of the largest waterfalls in the world by combined width and height, on the Zambezi River\",\n",
        "                \"a plume of mist (the 'smoke') rising high above Victoria Falls, visible for miles, and frequent rainbows forming in the spray\",\n",
        "                \"views of Victoria Falls from various viewpoints like the Knife-Edge Bridge, Danger Point, or from rainforest trails along the gorge\",\n",
        "                \"adventure activities at Victoria Falls, such as bungee jumping from the Victoria Falls Bridge or white-water rafting on the Zambezi\",\n",
        "                \"the Zambezi River plunging into the deep Batoka Gorge at Victoria Falls\"\n",
        "            ]\n",
        "        },\n",
        "        \"kilimanjaro\": {\n",
        "            \"name\": \"Mount Kilimanjaro\",\n",
        "            \"aliases\": [\"Uhuru Peak\", \"Kibo Kilimanjaro\", \"Africa's Highest Mountain\"],\n",
        "            \"location\": \"Tanzania\",\n",
        "            \"prompts\": [\n",
        "                \"the snow-capped, iconic peak of Mount Kilimanjaro, Africa's highest mountain and the world's tallest freestanding mountain, rising majestically from the plains of Tanzania\",\n",
        "                \"the distinctive flat-topped dormant volcano, Kilimanjaro, with its three volcanic cones (Kibo, Mawenzi, and Shira), a popular and challenging climbing destination\",\n",
        "                \"diverse ecosystems on the slopes of Kilimanjaro, transitioning from rainforest and moorland to alpine desert and arctic summit zones\",\n",
        "                \"porters and climbers on one of the routes (e.g., Machame, Lemosho) ascending Mount Kilimanjaro\",\n",
        "                \"Mount Kilimanjaro at sunrise or sunset, with its glaciers and snowfields gleaming\"\n",
        "            ]\n",
        "        },\n",
        "        \"dead_sea\": {\n",
        "            \"name\": \"Dead Sea\",\n",
        "            \"aliases\": [\"Salt Sea\"],\n",
        "            \"location\": \"Jordan / Israel / Palestine\",\n",
        "            \"prompts\": [\n",
        "                \"people floating effortlessly and buoyantly in the hyper-saline, turquoise waters of the Dead Sea, the lowest point on Earth's land surface\",\n",
        "                \"mineral-rich black mud from the Dead Sea being applied to the skin for therapeutic benefits, with salt formations along the shores\",\n",
        "                \"unique landscape of the Dead Sea, with its calm, dense waters reflecting the arid surrounding mountains and desert\",\n",
        "                \"evaporation ponds for mineral extraction at the southern end of the Dead Sea\",\n",
        "                \"salt crystals encrusting rocks and branches along the coastline of the Dead Sea\"\n",
        "            ]\n",
        "        },\n",
        "        \"dome_of_the_rock\": {\n",
        "            \"name\": \"Dome of the Rock\",\n",
        "            \"aliases\": [\"Qubbat as-Sakhrah\", \"Temple Mount Jerusalem\"],\n",
        "            \"location\": \"Old City of Jerusalem\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic, gleaming golden dome of the Dome of the Rock, an Islamic shrine located on the Temple Mount (Haram al-Sharif) in the Old City of Jerusalem\",\n",
        "                \"the octagonal structure of the Dome of the Rock, adorned with intricate blue and turquoise ceramic tilework, calligraphy, and mosaics\",\n",
        "                \"iconic religious landmark, the Dome of the Rock, a site of great significance in Islam, Judaism, and Christianity, within the historic walls of Jerusalem\",\n",
        "                \"view of the Dome of the Rock from the Mount of Olives, with the Old City in the background\",\n",
        "                \"the interior of the Dome of the Rock (if permissible to depict), showing the Foundation Stone\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # 大洋洲地標\n",
        "    \"oceania\": {\n",
        "        \"sydney_opera_house\": {\n",
        "            \"name\": \"Sydney Opera House\",\n",
        "            \"aliases\": [\"Opera House Sydney\", \"Sydney Landmark\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Sydney Opera House in Australia, its iconic white sail-shaped shells creating a distinctive silhouette on Sydney Harbour\",\n",
        "                \"the multi-venue performing arts centre, Sydney Opera House, with its unique shell-like roof structures, a masterpiece of modern architecture\",\n",
        "                \"Sydney Opera House with the Sydney Harbour Bridge in the background, a classic view of Sydney's landmarks\",\n",
        "                \"the Sydney Opera House illuminated at night, often with colorful projections for events like Vivid Sydney\",\n",
        "                \"close-up of the textured, chevron-patterned tiles covering the shells of the Sydney Opera House\"\n",
        "            ]\n",
        "        },\n",
        "        \"uluru\": {\n",
        "            \"name\": \"Uluru\",\n",
        "            \"aliases\": [\"Ayers Rock\", \"The Rock\", \"Uluru-Kata Tjuta National Park\"],\n",
        "            \"location\": \"Northern Territory, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of Uluru (Ayers Rock) in Australia, the massive, sacred sandstone monolith rising from the flat desert landscape of the Red Centre\",\n",
        "                \"the immense sandstone monolith of Uluru changing colors dramatically at sunrise or sunset, glowing in shades of red, orange, and purple\",\n",
        "                \"Uluru in the Red Centre of Australia, a significant spiritual site for Indigenous Anangu people, with visible rock caves and ancient rock art\",\n",
        "                \"the distinct shape and texture of Uluru, showing its weathered surface and gullies\",\n",
        "                \"Kata Tjuta (The Olgas) formations visible in the distance from Uluru\"\n",
        "            ]\n",
        "        },\n",
        "        \"great_barrier_reef\": {\n",
        "            \"name\": \"Great Barrier Reef\",\n",
        "            \"aliases\": [\"GBR\", \"World's Largest Coral Reef System\"],\n",
        "            \"location\": \"Queensland, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"an underwater photo of the Great Barrier Reef, showcasing its vibrant and diverse coral formations, colorful fish, and other marine life like sea turtles or manta rays\",\n",
        "                \"colorful hard and soft coral gardens thriving in the clear turquoise waters of the Great Barrier Reef, the world's largest coral reef system\",\n",
        "                \"aerial view of the Great Barrier Reef, revealing the intricate patterns of reefs, islands, and cays stretching along the Queensland coast\",\n",
        "                \"scuba divers or snorkelers exploring the rich biodiversity of the Great Barrier Reef\",\n",
        "                \"Heart Reef, a naturally formed heart-shaped coral formation in the Great Barrier Reef (often seen from the air)\"\n",
        "            ]\n",
        "        },\n",
        "        \"hobbiton_movie_set\": {\n",
        "            \"name\": \"Hobbiton Movie Set\",\n",
        "            \"aliases\": [\"The Shire Tour\", \"Lord of the Rings Set NZ\", \"Hobbiton New Zealand\"],\n",
        "            \"location\": \"Matamata, Waikato, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"a photo of the Hobbiton Movie Set in New Zealand, the picturesque movie set for The Shire from 'The Lord of the Rings' and 'The Hobbit' trilogies\",\n",
        "                \"charming, brightly colored circular Hobbit hole doors built into rolling green hills at the Hobbiton Movie Set, with meticulously tended gardens\",\n",
        "                \"the Green Dragon Inn at Hobbiton, a faithfully reconstructed pub where visitors can enjoy a drink\",\n",
        "                \"the Party Tree and Mill at Hobbiton, iconic locations from the movies, set within a lush pastoral landscape\",\n",
        "                \"guided tour groups exploring the whimsical and detailed Hobbiton Movie Set\"\n",
        "            ]\n",
        "        },\n",
        "        \"sydney_harbour_bridge\": {\n",
        "            \"name\": \"Sydney Harbour Bridge\",\n",
        "            \"aliases\": [\"The Coathanger Sydney\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"the iconic steel through arch of the Sydney Harbour Bridge, affectionately known as 'The Coathanger', spanning Sydney Harbour\",\n",
        "                \"people participating in the Sydney Harbour BridgeClimb, ascending the arch for panoramic views of the city and harbour\",\n",
        "                \"view of Sydney Harbour featuring both the Opera House and the Harbour Bridge together, a quintessential Sydney scene\",\n",
        "                \"ferries and sailboats passing under the massive Sydney Harbour Bridge\",\n",
        "                \"fireworks display over the Sydney Harbour Bridge during New Year's Eve celebrations\"\n",
        "            ]\n",
        "        },\n",
        "        \"fiordland_national_park_milford_sound\": { # Specified Milford Sound\n",
        "            \"name\": \"Fiordland National Park (Milford Sound / Doubtful Sound)\",\n",
        "            \"aliases\": [\"Milford Sound New Zealand\", \"Doubtful Sound Fiordland\"],\n",
        "            \"location\": \"South Island, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"dramatic fiords with sheer, towering cliffs and cascading waterfalls (like Stirling Falls or Bowen Falls) in Fiordland National Park, New Zealand, particularly Milford Sound\",\n",
        "                \"the iconic Mitre Peak rising sharply from the dark, reflective waters of Milford Sound in Fiordland, often shrouded in mist\",\n",
        "                \"boat cruises navigating through the stunning natural scenery of Milford Sound or the more remote Doubtful Sound, with seals, dolphins, or penguins sometimes spotted\",\n",
        "                \"lush rainforest clinging to the steep mountain sides of Fiordland National Park\",\n",
        "                \"the dramatic, moody atmosphere of Fiordland, known for its high rainfall and untouched wilderness\"\n",
        "            ]\n",
        "        },\n",
        "        \"bondi_beach\": {\n",
        "            \"name\": \"Bondi Beach\",\n",
        "            \"aliases\": [\"Bondi Sydney\"],\n",
        "            \"location\": \"Sydney, New South Wales, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"the famous crescent-shaped Bondi Beach in Sydney, a popular destination with golden sand, turquoise waves, surfers, and sunbathers\",\n",
        "                \"Bondi Icebergs Club swimming pool, an ocean pool with waves crashing into it, located at the southern end of Bondi Beach\",\n",
        "                \"vibrant beach culture, surf lifesavers in their distinctive red and yellow uniforms, and bustling cafes along the promenade at Bondi Beach\",\n",
        "                \"the Bondi to Coogee coastal walk, offering stunning ocean views starting from Bondi Beach\",\n",
        "                \"aerial view of Bondi Beach, showcasing its iconic shape and lively atmosphere\"\n",
        "            ]\n",
        "        },\n",
        "        \"aoraki_mount_cook_national_park\": {\n",
        "            \"name\": \"Aoraki / Mount Cook National Park\",\n",
        "            \"aliases\": [\"Mount Cook New Zealand\", \"Lake Pukaki Mount Cook\", \"Hooker Valley Track\"],\n",
        "            \"location\": \"South Island, New Zealand\",\n",
        "            \"prompts\": [\n",
        "                \"the majestic, snow-capped pyramid peak of Aoraki / Mount Cook, New Zealand's highest mountain, dominating the Southern Alps\",\n",
        "                \"glaciers like Tasman Glacier, alpine lakes with milky turquoise water (such as Lake Pukaki or Lake Tekapo often framed by colorful lupins in summer), and rugged mountain scenery in Aoraki / Mount Cook National Park\",\n",
        "                \"stargazing in the Aoraki Mackenzie International Dark Sky Reserve, with the silhouette of Aoraki / Mount Cook against a starry night sky\",\n",
        "                \"hiking trails like the Hooker Valley Track, offering spectacular views of Aoraki / Mount Cook, glaciers, and icebergs in Hooker Lake\",\n",
        "                \"the Hermitage Hotel or other alpine lodges with views of Aoraki / Mount Cook\"\n",
        "            ]\n",
        "        },\n",
        "        \"twelve_apostles_great_ocean_road\": { # Specified Great Ocean Road\n",
        "            \"name\": \"The Twelve Apostles, Great Ocean Road\",\n",
        "            \"aliases\": [\"Twelve Apostles Victoria\", \"Great Ocean Road Australia\"],\n",
        "            \"location\": \"Victoria, Australia\",\n",
        "            \"prompts\": [\n",
        "                \"limestone stacks known as The Twelve Apostles (though fewer than twelve remain) rising dramatically from the Southern Ocean along the scenic Great Ocean Road in Victoria, Australia\",\n",
        "                \"coastal scenery with rugged cliffs, powerful wave erosion, and the iconic sea stacks of The Twelve Apostles site, especially at sunrise or sunset\",\n",
        "                \"sunset or sunrise over The Twelve Apostles rock formations, casting golden light and long shadows\",\n",
        "                \"viewing platforms offering panoramic vistas of The Twelve Apostles and the surrounding coastline\",\n",
        "                \"other nearby rock formations along the Great Ocean Road, like Loch Ard Gorge or London Arch (formerly London Bridge)\"\n",
        "            ]\n",
        "        },\n",
        "         \"easter_island_moai\": {\n",
        "            \"name\": \"Moai Statues, Easter Island\",\n",
        "            \"aliases\": [\n",
        "                \"Easter Island Heads\",\n",
        "                \"Rapa Nui Moai\",\n",
        "                \"復活節島摩艾石像\",\n",
        "                \"拉帕努伊島石像\",\n",
        "                \"摩艾\"\n",
        "            ],\n",
        "            \"location\": \"Easter Island (Rapa Nui), Chile\",\n",
        "            \"prompts\": [\n",
        "                \"colossal monolithic human figures known as moai, carved from volcanic rock, standing on Easter Island (Rapa Nui)\",\n",
        "                \"iconic giant stone heads and torsos of the moai statues with long ears and stoic expressions, dotting the coastal and inland landscapes of Easter Island\",\n",
        "                \"the mysterious moai statues of Rapa Nui, some with red scoria topknots (pukao), on ceremonial platforms called ahu\",\n",
        "                \"Ahu Tongariki featuring a line-up of fifteen imposing moai statues against the Pacific Ocean, Easter Island\",\n",
        "                \"moai statues in the Rano Raraku quarry, where they were carved, some partially buried or appearing to emerge from the hillside\",\n",
        "                \"the unique archaeological site of Easter Island, showcasing hundreds of ancient monolithic moai, a testament to Rapa Nui culture\",\n",
        "                \"weathered stone giants of Easter Island, their distinct profiles silhouetted against the sky or ocean, conveying a sense of ancient mystery\",\n",
        "                \"close-up of a moai's characteristic features: heavy brow, elongated nose, thin lips, and often deep eye sockets, Easter Island\",\n",
        "                \"a line of massive moai statues on an ahu platform overlooking the sea, representing deified ancestors of Rapa Nui\",\n",
        "                \"the remote and windswept landscape of Easter Island, punctuated by the enigmatic presence of its ancient moai statues\"\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 方便直接查詢所有地標\n",
        "ALL_LANDMARKS = {}\n",
        "for region, landmarks in LANDMARK_DATA.items():\n",
        "    for landmark_id, landmark_info in landmarks.items():\n",
        "        ALL_LANDMARKS[landmark_id] = landmark_info\n",
        "\n",
        "# 獲取所有地標提示列表（用於CLIP分析）\n",
        "def get_all_landmark_prompts():\n",
        "    \"\"\"\n",
        "    返回所有地標的提示列表，用於CLIP分析\n",
        "\n",
        "    Returns:\n",
        "        list: 提示列表\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    for landmark_id, landmark_info in ALL_LANDMARKS.items():\n",
        "        # 使用第一個提示作為主要提示\n",
        "        prompts.append(landmark_info[\"prompts\"][0])\n",
        "    return prompts\n",
        "\n",
        "# 獲取地標名稱到ID的映射\n",
        "def get_landmark_name_to_id_map():\n",
        "    \"\"\"\n",
        "    返回地標名稱到ID的映射\n",
        "\n",
        "    Returns:\n",
        "        dict: {地標名稱: 地標ID}\n",
        "    \"\"\"\n",
        "    name_to_id = {}\n",
        "    for landmark_id, landmark_info in ALL_LANDMARKS.items():\n",
        "        name_to_id[landmark_info[\"name\"]] = landmark_id\n",
        "        # 也添加所有別名\n",
        "        for alias in landmark_info[\"aliases\"]:\n",
        "            name_to_id[alias] = landmark_id\n",
        "    return name_to_id\n",
        "\n",
        "# 獲取某個區域的所有地標ID\n",
        "def get_landmarks_by_region(region):\n",
        "    \"\"\"\n",
        "    返回指定區域的所有地標ID\n",
        "\n",
        "    Args:\n",
        "        region (str): 區域名稱\n",
        "\n",
        "    Returns:\n",
        "        list: 地標ID列表\n",
        "    \"\"\"\n",
        "    if region not in LANDMARK_DATA:\n",
        "        return []\n",
        "    return list(LANDMARK_DATA[region].keys())\n",
        "\n",
        "# 獲取每個地標的代表性提示\n",
        "def get_landmark_prompt(landmark_id):\n",
        "    \"\"\"\n",
        "    返回指定地標的代表性提示\n",
        "\n",
        "    Args:\n",
        "        landmark_id (str): 地標ID\n",
        "\n",
        "    Returns:\n",
        "        str: 提示文本\n",
        "    \"\"\"\n",
        "    if landmark_id not in ALL_LANDMARKS:\n",
        "        return None\n",
        "    return ALL_LANDMARKS[landmark_id][\"prompts\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKbGJYo_ESn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fead6c8-76f7-4f17-b764-7ac6d183e2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing landmark_activities.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile landmark_activities.py\n",
        "\n",
        "\"\"\"\n",
        "Activity suggestions for specific landmarks.\n",
        "This module provides custom activity recommendations for recognized landmarks.\n",
        "\"\"\"\n",
        "\n",
        "LANDMARK_ACTIVITIES = {\n",
        "    # 亞洲地標 (Asia)\n",
        "    \"taipei_101\": [\n",
        "        \"Visiting the observation deck (89F, 91F, 101F) for panoramic city and mountain views\",\n",
        "        \"Shopping at the luxury mall at the base (Taipei 101 Mall)\",\n",
        "        \"Photographing the cityscape, especially at sunset or during the New Year's Eve fireworks display\",\n",
        "        \"Dining at high-altitude restaurants within the tower (e.g., Din Tai Fung, Starbucks on 35F)\",\n",
        "        \"Learning about the engineering marvels, including the tuned mass damper, through exhibits\",\n",
        "        \"Admiring the public art installations around the building and mall\"\n",
        "    ],\n",
        "    \"taroko_gorge\": [\n",
        "        \"Hiking scenic trails like Shakadang Trail (Mysterious Valley Trail), Baiyang Waterfall Trail (Water Curtain Cave), or Lushui Trail\",\n",
        "        \"Photographing the sheer marble cliffs, tunnels, and the turquoise Liwu River\",\n",
        "        \"Visiting the Eternal Spring Shrine (Changchun Shrine) and Bell Tower\",\n",
        "        \"Exploring Swallow Grotto (Yanzikou) and the Tunnel of Nine Turns (Jiuqudong) for close-up gorge views\",\n",
        "        \"Learning about the geology, ecology, and indigenous Truku culture at the visitor center\",\n",
        "        \"Cycling along parts of the gorge road (with extreme caution due to traffic and tunnels)\"\n",
        "    ],\n",
        "    \"sun_moon_lake\": [\n",
        "        \"Taking a boat tour across the lake, visiting Lalu Island, Xuanguang Temple, and Ita Thao Pier\",\n",
        "        \"Cycling or walking on the dedicated bike paths encircling the lake (e.g., Xiangshan to Shuishe section)\",\n",
        "        \"Visiting Wenwu Temple and Ci'en Pagoda for stunning lake views and cultural insights\",\n",
        "        \"Riding the Sun Moon Lake Ropeway (cable car) for aerial views and access to the Formosan Aboriginal Culture Village\",\n",
        "        \"Enjoying local Thao aboriginal cuisine and street food at Ita Thao village\",\n",
        "        \"Photographing the serene lake landscapes, especially at sunrise, sunset, or when mist-covered\"\n",
        "    ],\n",
        "    \"jiufen_old_street\": [\n",
        "        \"Wandering through the narrow, lantern-lined alleyways of Jiufen Old Street, especially Shuqi Road\",\n",
        "        \"Sampling local Taiwanese snacks like taro balls, fish balls, and peanut ice cream rolls\",\n",
        "        \"Visiting traditional teahouses (e.g., A-Mei Tea House) for tea and panoramic coastal views\",\n",
        "        \"Photographing the nostalgic atmosphere, red lanterns, and views of Keelung Mountain and the coastline\",\n",
        "        \"Shopping for local crafts, souvenirs, and ocarinas\",\n",
        "        \"Learning about Jiufen's gold mining history at the Gold Museum in nearby Jinguashi (optional day trip extension)\"\n",
        "    ],\n",
        "    \"kenting_national_park\": [\n",
        "        \"Relaxing, swimming, or surfing at popular beaches like Nanwan (South Bay), Baishawan (White Sand Bay), or Little Bay (Xiaowan)\",\n",
        "        \"Visiting Eluanbi Park to see the iconic Eluanbi Lighthouse, Taiwan's southernmost point\",\n",
        "        \"Exploring unique geological formations like Sail Rock (Chuanfanshi), Longpan Park's limestone cliffs, and Maobitou's coastal terrain\",\n",
        "        \"Snorkeling or scuba diving in the coral-rich waters (e.g., Houbihu Marine Protected Area)\",\n",
        "        \"Hiking trails in Sheding Nature Park or Kenting Forest Recreation Area\",\n",
        "        \"Enjoying the vibrant atmosphere and street food at Kenting Night Market on Kenting Street\"\n",
        "    ],\n",
        "    \"national_palace_museum_tw\": [\n",
        "        \"Viewing renowned masterpieces like the Jadeite Cabbage, Meat-shaped Stone, and Mao Gong Ding\",\n",
        "        \"Exploring extensive collections of Chinese imperial artifacts, calligraphy, paintings, ceramics, and bronzes\",\n",
        "        \"Taking a guided tour or using an audio guide to understand the historical and cultural context of the exhibits\",\n",
        "        \"Admiring the classical Chinese palace-style architecture of the museum building\",\n",
        "        \"Visiting the serene Zhishan Garden, a traditional Chinese garden adjacent to the museum\",\n",
        "        \"Attending special exhibitions and cultural events hosted by the museum\"\n",
        "    ],\n",
        "    \"alishan_national_scenic_area\": [\n",
        "        \"Watching the famous sunrise over a sea of clouds from Chushan or Ogasawara Mountain viewing platforms\",\n",
        "        \"Riding the Alishan Forest Railway on one of its scenic mountain routes (e.g., to Shenmu 'Sacred Tree' Station)\",\n",
        "        \"Hiking through misty forests of ancient giant trees (Taiwan red cypress and cedar) along trails like the Giant Tree Plank Trail\",\n",
        "        \"Visiting the Sister Ponds (Jiemei Tan) and Shouzhen Temple\",\n",
        "        \"Learning about Alishan's tea culture and sampling high-mountain oolong tea at local plantations\",\n",
        "        \"Photographing the cherry blossoms in spring or fireflies in summer\"\n",
        "    ],\n",
        "    \"shilin_night_market\": [\n",
        "        \"Sampling a wide variety of iconic Taiwanese street foods like oyster omelets, stinky tofu, giant fried chicken cutlets, and bubble tea\",\n",
        "        \"Exploring the bustling maze of food stalls, clothing shops, and souvenir vendors in the outdoor and underground sections\",\n",
        "        \"Playing traditional night market games like claw machines, balloon darts, and shrimp fishing\",\n",
        "        \"Shopping for trendy apparel, accessories, and electronics at affordable prices\",\n",
        "        \"Experiencing the vibrant and energetic atmosphere of one of Taipei's largest and most famous night markets\",\n",
        "        \"Trying unique snacks like flame-torched beef cubes or cheese-filled potatoes\"\n",
        "    ],\n",
        "    \"tokyo_tower\": [\n",
        "        \"Ascending to the main (150m) and top (250m) observation decks for panoramic views of Tokyo, including Mount Fuji on clear days\",\n",
        "        \"Photographing the tower, especially when illuminated with its iconic orange lights or special seasonal displays\",\n",
        "        \"Visiting the official 'FootTown' at the base, featuring souvenir shops, cafes, an aquarium, and an e-sports park\",\n",
        "        \"Enjoying refreshments or a meal at the tower's cafes or restaurants with city views\",\n",
        "        \"Learning about the tower's history, construction, and its role as a broadcasting tower\",\n",
        "        \"Visiting nearby Zojoji Temple for a cultural contrast and photo opportunities with the tower in the background\"\n",
        "    ],\n",
        "    \"mount_fuji\": [\n",
        "        \"Climbing to the summit during the official climbing season (typically early July to early September) via one of the four main trails\",\n",
        "        \"Photographing the iconic snow-capped conical peak from various viewpoints like the Fuji Five Lakes (especially Lake Kawaguchiko or Lake Yamanakako), Chureito Pagoda, or Hakone\",\n",
        "        \"Visiting the Fuji Five Lakes region for activities like boating, fishing, hot springs (onsen), and museums (e.g., Itchiku Kubota Art Museum)\",\n",
        "        \"Hiking or nature walking around the lower slopes, Aokigahara forest (Jukai), or Oshino Hakkai (traditional village with eight spring ponds)\",\n",
        "        \"Visiting Fuji-Q Highland amusement park for thrill rides with views of Mount Fuji\",\n",
        "        \"Learning about its volcanic geology, cultural significance (UNESCO World Heritage site), and spiritual importance in Shintoism and Buddhism\"\n",
        "    ],\n",
        "    \"kinkaku_ji\": [\n",
        "        \"Admiring and photographing the stunning Golden Pavilion (Shariden) meticulously covered in gold leaf, reflected in the Mirror Pond (Kyōko-chi)\",\n",
        "        \"Strolling through the meticulously maintained Japanese Muromachi period stroll garden (kaiyū-shiki teien)\",\n",
        "        \"Learning about the Zen Buddhist history of the temple, originally a retirement villa for Shogun Ashikaga Yoshimitsu\",\n",
        "        \"Observing the distinct architectural styles of each of the three floors of the pavilion\",\n",
        "        \"Making a wish by tossing coins at designated spots for good luck\",\n",
        "        \"Enjoying matcha tea and traditional sweets at the Sekkatei Teahouse or nearby tea houses (check availability)\"\n",
        "    ],\n",
        "    \"fushimi_inari_shrine\": [\n",
        "        \"Walking through the thousands of vibrant vermilion (shu-iro) torii gates that form tunnels along the mountain trails\",\n",
        "        \"Hiking the entire 4km (2-3 hour) trail up the sacred Mount Inari, exploring the network of paths and smaller shrines\",\n",
        "        \"Photographing the iconic, seemingly endless tunnels of torii gates, a symbol of prosperity and good fortune\",\n",
        "        \"Visiting the main shrine buildings (Go-Honden) at the base and offering prayers to Inari, the Shinto god of rice, sake, and business\",\n",
        "        \"Exploring smaller sub-shrines (otsuka) and atmospheric graveyards along the mountain trails\",\n",
        "        \"Looking for numerous fox statues (kitsune), considered messengers of Inari, often holding keys or jewels in their mouths\"\n",
        "    ],\n",
        "    \"shibuya_crossing\": [\n",
        "        \"Experiencing the 'scramble' by walking across the multi-directional intersection with hundreds of other pedestrians\",\n",
        "        \"Photographing or video recording the iconic crossing from a high vantage point, such as the Starbucks in the Tsutaya building or Mag's Park rooftop at Magnet by Shibuya109\",\n",
        "        \"People-watching and soaking in the vibrant, energetic atmosphere of modern Tokyo\",\n",
        "        \"Visiting the Hachiko statue, a famous meeting spot dedicated to the loyal Akita dog, located outside Shibuya Station\",\n",
        "        \"Shopping at the numerous department stores (e.g., Shibuya 109, Shibuya Sky) and trendy boutiques in the surrounding area\",\n",
        "        \"Exploring nearby entertainment venues, restaurants, and nightlife options\"\n",
        "    ],\n",
        "    \"tokyo_skytree\": [\n",
        "        \"Ascending to the Tembo Deck (350m) and Tembo Galleria (450m) for breathtaking panoramic views of Tokyo and beyond, including Mount Fuji on clear days\",\n",
        "        \"Photographing the modern architectural marvel, especially when illuminated with its signature 'Iki' (sky blue) or 'Miyabi' (purple) lights\",\n",
        "        \"Walking on the glass floor section of the Tembo Deck for a thrilling view downwards\",\n",
        "        \"Shopping and dining at Tokyo Solamachi, the large entertainment complex at the base of the Skytree, which includes an aquarium and planetarium\",\n",
        "        \"Learning about the tower's earthquake-resistant design and construction\",\n",
        "        \"Visiting nearby Sumida River for a different perspective of the tower and leisurely walks\"\n",
        "    ],\n",
        "    \"senso_ji_temple\": [\n",
        "        \"Entering through the Kaminarimon (Thunder Gate) with its giant red lantern and statues of Raijin and Fujin\",\n",
        "        \"Walking along Nakamise-dori, the bustling market street leading to the temple, lined with stalls selling traditional snacks, crafts, and souvenirs\",\n",
        "        \"Visiting the main hall (Hondo) dedicated to Kannon Bosatsu (Bodhisattva of Compassion) and the five-story pagoda\",\n",
        "        \"Wafting incense smoke from the large cauldron (jokoro) over oneself for good health and luck\",\n",
        "        \"Photographing the vibrant temple complex, its traditional architecture, and the lively atmosphere\",\n",
        "        \"Exploring the quieter Asakusa Shrine (a Shinto shrine) located next to Senso-ji\"\n",
        "    ],\n",
        "    \"osaka_castle\": [\n",
        "        \"Exploring the interior of the reconstructed castle keep (tenshukaku), which now serves as a museum detailing the castle's history and Toyotomi Hideyoshi\",\n",
        "        \"Ascending to the observation deck on the top floor of the castle keep for panoramic views of Osaka city and Osaka Castle Park\",\n",
        "        \"Strolling through Osaka Castle Park, enjoying the vast green spaces, moats, stone walls, and seasonal blooms (especially cherry blossoms in spring and plum blossoms in late winter)\",\n",
        "        \"Photographing the majestic castle, its golden embellishments, and its reflection in the moat\",\n",
        "        \"Visiting Nishinomaru Garden within the park for beautiful views of the castle (especially during cherry blossom season, requires separate admission)\",\n",
        "        \"Learning about the historical sieges and significance of Osaka Castle in Japanese history\"\n",
        "    ],\n",
        "    \"dotonbori\": [\n",
        "        \"Taking iconic photos with the Glico Running Man billboard and other extravagant 3D signs (e.g., Kani Doraku crab, Zubora-ya pufferfish)\",\n",
        "        \"Strolling along the Dotonbori canal and its vibrant pedestrianized streets, especially at night when the neon lights are dazzling\",\n",
        "        \"Sampling famous Osakan street food (kuidaore) like takoyaki, okonomiyaki, kushikatsu, and ramen from numerous stalls and restaurants\",\n",
        "        \"Taking a Tonbori River Cruise for a different perspective of the district from the water\",\n",
        "        \"Shopping for souvenirs, fashion, and unique Japanese goods in the area\",\n",
        "        \"Experiencing the lively entertainment, including arcades, theaters (like Shochikuza for kabuki), and karaoke bars\"\n",
        "    ],\n",
        "    \"arashiyama_bamboo_grove\": [\n",
        "        \"Walking or cycling along the enchanting pathway through the towering stalks of the Sagano Bamboo Forest\",\n",
        "        \"Listening to the rustling sound of the bamboo leaves in the wind, a designated 'Soundscape of Japan'\",\n",
        "        \"Photographing the magical light filtering through the dense green bamboo canopy\",\n",
        "        \"Visiting nearby Tenryu-ji Temple (a UNESCO World Heritage site) with its beautiful garden that backs onto the bamboo grove\",\n",
        "        \"Crossing the Togetsukyo Bridge ('Moon Crossing Bridge') over the Hozugawa River for scenic views of Arashiyama\",\n",
        "        \"Renting a rowboat on the Hozugawa River or taking the Sagano Romantic Train for more scenic views of the area\"\n",
        "    ],\n",
        "    \"itsukushima_shrine\": [\n",
        "        \"Photographing the iconic 'floating' vermilion O-Torii Gate, especially during high tide when it appears to float on the water, and at sunset\",\n",
        "        \"Exploring the Itsukushima Shrine complex (a UNESCO World Heritage site), built on stilts over the water, with its distinctive red-lacquered corridors and halls\",\n",
        "        \"Walking out to the O-Torii Gate during low tide to see it up close (check tide schedules)\",\n",
        "        \"Interacting with the friendly wild sika deer that roam freely on Miyajima Island\",\n",
        "        \"Taking the Miyajima Ropeway up Mount Misen for panoramic views of the Seto Inland Sea and hiking its trails\",\n",
        "        \"Sampling local Miyajima delicacies like grilled oysters and momiji manju (maple leaf-shaped cakes)\"\n",
        "    ],\n",
        "    \"gyeongbokgung_palace\": [\n",
        "        \"Exploring the main halls like Geunjeongjeon (Throne Hall) and pavilions like Gyeonghoeru (Royal Banquet Hall on a pond)\",\n",
        "        \"Watching the impressive Royal Guard Changing Ceremony (Sumunjang Gyedaeui) held several times a day at Gwanghwamun and Heungnyemun Gates\",\n",
        "        \"Renting a Hanbok (traditional Korean attire) from nearby shops to enter the palace for free and for an immersive photo experience\",\n",
        "        \"Visiting the National Folk Museum of Korea and the National Palace Museum of Korea, both located within the palace grounds\",\n",
        "        \"Taking a guided tour (available in multiple languages) to learn about the Joseon Dynasty's history and palace architecture\",\n",
        "        \"Photographing the intricate Dancheong (colorful painted patterns) on the wooden structures and the serene Hyangwonjeong Pavilion\"\n",
        "    ],\n",
        "    \"n_seoul_tower\": [\n",
        "        \"Taking a scenic cable car ride up Namsan Mountain to reach the N Seoul Tower\",\n",
        "        \"Ascending to the observatory (digital and analog) for breathtaking 360-degree panoramic views of Seoul's cityscape, day and night\",\n",
        "        \"Attaching a 'love lock' with a personal message to the famous railings and tree-like structures on the tower's outdoor terrace\",\n",
        "        \"Dining at the revolving N.Grill restaurant or other cafes and eateries within the tower complex, enjoying the views\",\n",
        "        \"Photographing the city skyline, especially during sunset or when the city lights twinkle at night; the tower itself is also beautifully illuminated\",\n",
        "        \"Exploring Namsan Park surrounding the tower, enjoying its walking trails, botanical gardens, and the Namsan Beacon Mounds\"\n",
        "    ],\n",
        "    \"bukchon_hanok_village\": [\n",
        "        \"Walking respectfully through the narrow, hilly alleyways lined with hundreds of well-preserved traditional Korean houses (Hanoks)\",\n",
        "        \"Photographing the beautiful tiled roofs, wooden beams, and stone walls of the Hanoks, often with views of modern Seoul in the background\",\n",
        "        \"Visiting small, private museums, cultural centers, and craft workshops (e.g., for Gahoe Museum, Donglim Knot Museum, or embroidery workshops) within the village\",\n",
        "        \"Renting a Hanbok to enhance the experience and take memorable photos in the traditional setting\",\n",
        "        \"Observing the 'Eight Scenic Spots of Bukchon' for the best photo opportunities and views (look for photo spot markers)\",\n",
        "        \"Enjoying tea at a traditional Hanok teahouse or Browse unique artisan shops while being mindful of it being a residential area\"\n",
        "    ],\n",
        "    \"myeongdong_shopping_street\": [\n",
        "        \"Shopping for Korean cosmetics and skincare products from numerous flagship stores and local brands\",\n",
        "        \"Exploring trendy fashion boutiques, shoe stores, and accessory shops catering to K-fashion enthusiasts\",\n",
        "        \"Indulging in a wide variety of delicious Korean street food from bustling stalls (e.g., tteokbokki, gyeranppang, tornado potato, grilled cheese lobster)\",\n",
        "        \"Visiting large department stores like Lotte Department Store and Shinsegae Department Store for luxury goods and diverse shopping\",\n",
        "        \"Catching K-pop related events, Browse K-pop merchandise stores, or spotting advertisements featuring K-pop idols\",\n",
        "        \"Visiting Myeongdong Cathedral, a historic Gothic-style Catholic church, as a peaceful contrast to the shopping frenzy\"\n",
        "    ],\n",
        "    \"dmz_korea\": [\n",
        "        \"Taking a guided tour to the Korean Demilitarized Zone (DMZ), including the Joint Security Area (JSA/Panmunjom) if accessible\",\n",
        "        \"Visiting the Third Infiltration Tunnel, one of several tunnels dug by North Korea under the DMZ\",\n",
        "        \"Looking into North Korea from observation posts like Dora Observatory\",\n",
        "        \"Learning about the history of the Korean War, the division of Korea, and ongoing inter-Korean relations at the DMZ Exhibition Hall or Imjingak Park\",\n",
        "        \"Seeing the Bridge of No Return and the Freedom House (within JSA)\",\n",
        "        \"Reflecting on the poignant reminders of a divided nation and hopes for reunification\"\n",
        "    ],\n",
        "    \"busan_gamcheon_culture_village\": [\n",
        "        \"Exploring the maze-like alleyways adorned with vibrant street art, colorful murals, and whimsical art installations\",\n",
        "        \"Photographing the brightly painted terraced houses cascading down the hillside, often called the 'Machu Picchu of Busan' or 'Santorini of Korea'\",\n",
        "        \"Following a stamp tour map to discover hidden artworks and viewpoints throughout the village\",\n",
        "        \"Visiting small art galleries, quirky shops, and charming cafes run by local artists and residents\",\n",
        "        \"Taking photos with iconic sculptures like 'The Little Prince and the Desert Fox' overlooking the village\",\n",
        "        \"Enjoying panoramic views of the village and the port of Busan from various observation decks\"\n",
        "    ],\n",
        "    \"jeju_island\": [\n",
        "        \"Hiking Hallasan, South Korea's highest mountain and a dormant volcano, or exploring its surrounding national park trails\",\n",
        "        \"Visiting Seongsan Ilchulbong (Sunrise Peak), a UNESCO World Heritage tuff cone, especially for sunrise views\",\n",
        "        \"Exploring Manjanggul Cave, one of the longest lava tubes in the world (UNESCO site)\",\n",
        "        \"Relaxing on beautiful beaches like Hyeopjae Beach (with views of Biyangdo Island) or Jungmun Saekdal Beach (popular for surfing)\",\n",
        "        \"Chasing waterfalls such as Cheonjeyeon Falls ('Pond of God') or Jeongbang Falls (falls directly into the ocean)\",\n",
        "        \"Discovering unique geological formations like Jusangjeolli Cliffs (hexagonal lava pillars) and Yongduam Rock (Dragon Head Rock)\"\n",
        "    ],\n",
        "    \"changdeokgung_palace_secret_garden\": [\n",
        "        \"Taking a mandatory guided tour of the Huwon (Secret Garden), a stunningly beautiful and expansive rear garden of Changdeokgung Palace (UNESCO World Heritage site)\",\n",
        "        \"Admiring the harmonious blend of traditional Korean palace architecture (pavilions, halls) with the natural landscape (ponds, streams, ancient trees) within the Secret Garden\",\n",
        "        \"Exploring the main palace buildings of Changdeokgung, such as Injeongjeon (main throne hall) and Donhwamun Gate\",\n",
        "        \"Photographing the serene Buyongji Pond with Buyongjeong Pavilion and Juhamnu Pavilion in the Secret Garden\",\n",
        "        \"Learning about the lives of the Joseon Dynasty royal family who used this palace and garden for leisure and study\",\n",
        "        \"Appreciating the palace's design, which is considered more integrated with its natural surroundings than other Seoul palaces\"\n",
        "    ],\n",
        "    \"great_wall\": [\n",
        "        \"Hiking or walking along various restored sections like Mutianyu (family-friendly, cable car/chairlift options), Badaling (most famous, can be crowded), or Jinshanling and Simatai (more rugged, great for photography, partially restored)\",\n",
        "        \"Taking a cable car, chairlift, or toboggan ride at sections like Mutianyu for easier access and fun descent\",\n",
        "        \"Photographing the vast structure snaking across diverse mountainous landscapes, with its watchtowers and fortifications\",\n",
        "        \"Learning about the history of its construction (spanning many dynasties), its purpose as a defensive barrier, and the legends associated with it\",\n",
        "        \"Participating in guided tours to understand the historical context and logistical details of visiting specific sections\",\n",
        "        \"Considering a visit to less crowded, 'wild' sections (with caution and appropriate preparation) for a more adventurous experience\"\n",
        "    ],\n",
        "    \"forbidden_city\": [\n",
        "        \"Exploring the vast imperial palace complex, walking from the Meridian Gate (Wumen) through numerous courtyards and halls to the Gate of Divine Might (Shenwumen)\",\n",
        "        \"Admiring the magnificent traditional Chinese palatial architecture, intricate roof details, dragon motifs, and symbolic color schemes (yellow and red)\",\n",
        "        \"Visiting key structures like the Hall of Supreme Harmony (Taihedian), Hall of Central Harmony (Zhonghedian), and Hall of Preserving Harmony (Baohedian) on the Outer Court\",\n",
        "        \"Exploring the Inner Court, including the Palace of Heavenly Purity (Qianqinggong), Hall of Union (Jiaotaidian), and Palace of Earthly Tranquility (Kunninggong)\",\n",
        "        \"Visiting the Palace Museum's extensive collections of imperial treasures, including ceramics, paintings, jade, and clocks, housed in various side halls\",\n",
        "        \"Strolling through the Imperial Garden (Yuhuayuan) at the northern end of the complex\"\n",
        "    ],\n",
        "    \"terracotta_army\": [\n",
        "        \"Viewing the thousands of life-sized terracotta warriors, archers, chariots, and horses arranged in battle formation in the three main excavation pits (Pit 1, Pit 2, Pit 3)\",\n",
        "        \"Admiring the individual details of the soldiers, each with unique facial expressions, hairstyles, and armor, reflecting the incredible craftsmanship\",\n",
        "        \"Visiting the Exhibition Hall of Bronze Chariots to see the two remarkably preserved and intricate bronze chariots and horses\",\n",
        "        \"Learning about Emperor Qin Shi Huang, the first emperor of China, and his quest for immortality that led to the creation of this mausoleum army\",\n",
        "        \"Taking a guided tour or using an audio guide for in-depth historical context and insights into the archaeological discoveries\",\n",
        "        \"Photographing the impressive scale of the pits and the ranks of warriors (flash photography is usually prohibited)\"\n",
        "    ],\n",
        "    \"the_bund\": [\n",
        "        \"Strolling along the wide waterfront promenade (Zhongshan East First Road) to admire the grand colonial-era buildings in various architectural styles (e.g., Gothic, Baroque, Art Deco) – the 'museum of international architecture'\",\n",
        "        \"Photographing the spectacular modern skyline of Pudong across the Huangpu River, featuring the Oriental Pearl Tower, Shanghai Tower, and Shanghai World Financial Center, especially stunning at night\",\n",
        "        \"Taking a Huangpu River cruise (day or night) for panoramic views of both the historic Bund and the futuristic Pudong skyline\",\n",
        "        \"Visiting the interiors of some heritage buildings (many now house banks, hotels, or luxury shops) or admiring their detailed facades\",\n",
        "        \"Dining at upscale restaurants or enjoying drinks at rooftop bars within the Bund buildings, offering magnificent views\",\n",
        "        \"Observing locals engaging in morning tai chi, evening strolls, or public dancing along the promenade\"\n",
        "    ],\n",
        "    \"li_river_guilin\": [\n",
        "        \"Taking a scenic boat cruise along the Li River from Guilin to Yangshuo (or vice versa) to admire the stunning karst mountain landscapes\",\n",
        "        \"Photographing the picturesque limestone peaks, bamboo groves, rice paddies, and water buffalo along the riverbanks – scenes often depicted in traditional Chinese paintings\",\n",
        "        \"Opting for a traditional bamboo raft ride (motorized) on sections of the Li River or the Yulong River (a tributary near Yangshuo) for a closer experience with the scenery\",\n",
        "        \"Exploring the Reed Flute Cave or Seven Star Park in Guilin before or after the river cruise\",\n",
        "        \"Visiting Xingping Town along the Li River, known for the landscape depicted on the 20 RMB banknote\",\n",
        "        \"Cycling or hiking in the countryside around Yangshuo to further explore the karst scenery\"\n",
        "    ],\n",
        "    \"potala_palace\": [\n",
        "        \"Exploring the majestic Potala Palace, a UNESCO World Heritage site, former winter residence of the Dalai Lamas, with its White Palace (administrative) and Red Palace (religious sections)\",\n",
        "        \"Admiring the unique Tibetan architecture, including massive stone walls, golden roofs, intricate murals, thangkas, and numerous chapels and tombs of past Dalai Lamas\",\n",
        "        \"Ascending the numerous staircases (visitors need to be acclimatized to the high altitude of Lhasa)\",\n",
        "        \"Photographing the imposing palace from various viewpoints, such as Chakpori Hill (for sunrise/sunset views) or Potala Palace Square\",\n",
        "        \"Learning about Tibetan Buddhism, the history of the Dalai Lamas, and the cultural significance of the palace\",\n",
        "        \"Observing pilgrims performing kora (circumambulation) around the palace\"\n",
        "    ],\n",
        "    \"zhangjiajie_national_forest_park\": [\n",
        "        \"Admiring the towering quartz-sandstone pillars and peaks, often shrouded in mist, that inspired the 'Hallelujah Mountains' in the movie Avatar (especially in the Yuanjiajie area)\",\n",
        "        \"Riding the Bailong Elevator (Hundred Dragons Elevator), a massive glass elevator built onto the side of a cliff, for dramatic views\",\n",
        "        \"Walking across the Zhangjiajie Grand Canyon Glass Bridge (requires separate entry/location from the main park but often combined in tours) for a thrilling experience\",\n",
        "        \"Taking cable cars, like the one to Tianzi Mountain or Huangshizhai, for breathtaking panoramic vistas\",\n",
        "        \"Hiking along scenic trails, such as the Golden Whip Stream, to enjoy the lush forests, clear streams, and unique rock formations from below\",\n",
        "        \"Exploring other key areas like Tianmen Mountain (Heaven's Gate Mountain, often a separate visit) with its cable car, skywalk, and Tianmen Cave\"\n",
        "    ],\n",
        "    \"west_lake_hangzhou\": [\n",
        "        \"Taking a leisurely boat ride on the serene West Lake to enjoy its scenic beauty and visit islands like Xiaoyingzhou (Three Ponds Mirroring the Moon)\",\n",
        "        \"Walking or cycling along the Su Causeway (Sudi) and Bai Causeway (Baidi), lined with willow and peach trees\",\n",
        "        \"Admiring iconic landmarks such as Leifeng Pagoda (rebuilt), Broken Bridge (Duan Qiao, famous in legend), and the Mid-Lake Pavilion\",\n",
        "        \"Visiting traditional gardens and temples around the lake, like Lingyin Temple (Temple of the Soul's Retreat) and Guo's Villa\",\n",
        "        \"Watching the 'Impression West Lake' outdoor musical performance on the lake at night (seasonal, created by Zhang Yimou)\",\n",
        "        \"Photographing the picturesque landscapes, especially during different seasons (e.g., lotus blooms in summer, osmanthus in autumn)\"\n",
        "    ],\n",
        "    \"summer_palace_beijing\": [\n",
        "        \"Strolling through the vast imperial garden, a masterpiece of Chinese landscape garden design, centered around Longevity Hill and Kunming Lake\",\n",
        "        \"Taking a boat ride on Kunming Lake, especially a traditional dragon boat\",\n",
        "        \"Walking along the Long Corridor (Chang Lang), a covered walkway decorated with thousands of paintings\",\n",
        "        \"Visiting key structures like the Hall of Benevolence and Longevity (Renshoudian), Tower of Buddhist Incense (Foxiangge) on Longevity Hill, and the Marble Boat\",\n",
        "        \"Exploring Suzhou Street, a recreated canal-side shopping street from imperial times\",\n",
        "        \"Admiring the beautiful traditional Chinese architecture, bridges (like the Seventeen-Arch Bridge), and landscaped gardens\"\n",
        "    ],\n",
        "    \"petronas_towers\": [\n",
        "        \"Visiting the Skybridge, the double-decker bridge connecting the two towers on the 41st and 42nd floors, for close-up views and a unique perspective (book tickets in advance)\",\n",
        "        \"Ascending to the Observation Deck on the 86th floor of Tower 2 for breathtaking panoramic views of Kuala Lumpur's skyline\",\n",
        "        \"Photographing the iconic twin skyscrapers, an architectural marvel, especially when brilliantly illuminated at night\",\n",
        "        \"Shopping at the upscale Suria KLCC mall located at the base of the towers, featuring luxury brands and diverse retail options\",\n",
        "        \"Relaxing or strolling in the beautifully landscaped KLCC Park, which includes a man-made lake (Lake Symphony) with water fountain shows, a jogging track, and a children's playground\",\n",
        "        \"Visiting nearby attractions like Petrosains Discovery Centre (interactive science museum) or Aquaria KLCC (oceanarium)\"\n",
        "    ],\n",
        "    \"marina_bay_sands\": [\n",
        "        \"Visiting the Sands SkyPark Observation Deck on the 57th floor for stunning 360-degree panoramic views of Singapore's skyline, Gardens by the Bay, and the Singapore Strait\",\n",
        "        \"Swimming in the world-famous rooftop infinity pool (exclusive access for Marina Bay Sands hotel guests)\",\n",
        "        \"Shopping at The Shoppes at Marina Bay Sands, a luxury mall featuring international brands, a canal with sampan rides, and the Digital Light Canvas\",\n",
        "        \"Watching the 'Spectra – A Light & Water Show' in the evening, a spectacular outdoor multimedia presentation over Marina Bay\",\n",
        "        \"Visiting the ArtScience Museum, with its iconic lotus-inspired design, showcasing art, science, culture, and technology exhibitions\",\n",
        "        \"Dining at celebrity chef restaurants or exploring diverse culinary options within the integrated resort, and trying your luck at the casino\"\n",
        "    ],\n",
        "    \"gardens_by_the_bay\": [\n",
        "        \"Exploring the two massive cooled conservatories: the Flower Dome (showcasing exotic plants from Mediterranean and semi-arid regions) and the Cloud Forest (featuring a stunning indoor waterfall and plants from tropical highlands)\",\n",
        "        \"Walking along the OCBC Skyway, an aerial walkway suspended between two Supertrees, for panoramic views of the Supertree Grove and surrounding gardens\",\n",
        "        \"Watching the 'Garden Rhapsody' light and sound show at Supertree Grove in the evening, where the Supertrees come alive with dazzling lights synchronized to music\",\n",
        "        \"Strolling through the various outdoor themed gardens, such as the Heritage Gardens, Serene Garden, and the outdoor art sculptures\",\n",
        "        \"Photographing the unique horticultural displays, futuristic Supertrees, and innovative sustainable architecture\",\n",
        "        \"Letting children play at the Far East Organization Children's Garden with its water play areas and treehouses\"\n",
        "    ],\n",
        "    \"taj_mahal\": [\n",
        "        \"Admiring the breathtaking beauty and perfect symmetry of the ivory-white marble mausoleum, a UNESCO World Heritage site and a symbol of eternal love\",\n",
        "        \"Photographing the iconic structure from various angles, especially during sunrise or sunset when the light casts different hues on the marble, and its reflection in the central water channels\",\n",
        "        \"Strolling through the formal Mughal gardens (Charbagh) that surround the mausoleum, with their pathways, fountains, and reflecting pools\",\n",
        "        \"Learning about the poignant love story of Mughal emperor Shah Jahan and his wife Mumtaz Mahal, for whom the Taj Mahal was built\",\n",
        "        \"Observing the intricate marble inlay work (pietra dura) featuring semi-precious stones, and the detailed calligraphy on the monument's facade\",\n",
        "        \"Visiting the mosque and the guesthouse (jawab) that flank the main mausoleum, providing architectural balance\"\n",
        "    ],\n",
        "    \"angkor_wat\": [\n",
        "        \"Exploring the vast temple complex of Angkor Wat, the world's largest religious monument, admiring its iconic five lotus-bud towers and intricate bas-reliefs\",\n",
        "        \"Watching the sunrise over Angkor Wat, a magical experience as the temple silhouette emerges against the colorful sky (can be very crowded)\",\n",
        "        \"Taking a guided tour to understand the history of the Khmer Empire, the Hindu and Buddhist symbolism, and the architectural features of the temple\",\n",
        "        \"Examining the detailed stone carvings and extensive galleries depicting scenes from Hindu epics like the Ramayana and Mahabharata, and historical events\",\n",
        "        \"Photographing the temple's reflection in the surrounding moat and its grandeur from different perspectives\",\n",
        "        \"Visiting other nearby temples in the Angkor Archaeological Park, such as Angkor Thom (Bayon, Baphuon), Ta Prohm (Tomb Raider temple), and Banteay Srei\"\n",
        "    ],\n",
        "    \"ha_long_bay\": [\n",
        "        \"Taking an overnight cruise or a day boat trip to explore the stunning seascape of thousands of limestone karsts and islets rising from the emerald green waters (UNESCO World Heritage site)\",\n",
        "        \"Kayaking or taking a bamboo boat ride through hidden lagoons, caves, and around the towering rock formations for a closer experience\",\n",
        "        \"Visiting impressive caves and grottoes, such as Thien Cung Cave (Heavenly Palace Cave) or Dau Go Cave (Wooden Stakes Cave), with their stalactites and stalagmites\",\n",
        "        \"Swimming in the calm waters or relaxing on small, secluded beaches (e.g., Titop Island beach)\",\n",
        "        \"Photographing the breathtaking and often misty scenery, especially at sunrise or sunset\",\n",
        "        \"Learning about the local culture by visiting floating fishing villages or pearl farms\"\n",
        "    ],\n",
        "    \"mount_everest\": [\n",
        "        \"Trekking to Everest Base Camp (South Base Camp in Nepal or North Base Camp in Tibet) for close-up views of Mount Everest and the surrounding Himalayan giants (requires significant preparation and acclimatization)\",\n",
        "        \"Taking a scenic mountain flight from Kathmandu for breathtaking aerial views of Mount Everest and the Himalayan range (a popular option for non-trekkers)\",\n",
        "        \"Photographing the world's highest peak, especially during sunrise or sunset when alpenglow illuminates the summit\",\n",
        "        \"Learning about Sherpa culture and mountaineering history in villages like Namche Bazaar (on the Nepal EBC trek)\",\n",
        "        \"Visiting monasteries like Tengboche Monastery (Nepal) for spiritual insights and stunning mountain backdrops\",\n",
        "        \"For experienced mountaineers: attempting to summit Mount Everest (a highly challenging and expensive endeavor)\"\n",
        "    ],\n",
        "    \"bagan\": [\n",
        "        \"Exploring the vast archaeological zone, home to thousands of ancient Buddhist temples, pagodas, and stupas dating from the 9th to 13th centuries (UNESCO World Heritage site)\",\n",
        "        \"Renting an e-bike or horse cart to navigate the sandy tracks and discover both major temples (like Ananda, Shwezigon, Thatbyinnyu, Dhammayangyi) and smaller, hidden gems\",\n",
        "        \"Watching the sunrise or sunset over the temple-strewn plains from a high vantage point (e.g., a designated viewing mound or a temple terrace where permitted)\",\n",
        "        \"Taking a hot air balloon ride over Bagan at sunrise for an unforgettable panoramic view of the temples (seasonal, typically October to April)\",\n",
        "        \"Photographing the unique landscape of ancient religious structures against the backdrop of the Irrawaddy River and distant hills\",\n",
        "        \"Learning about the history of the Pagan Kingdom and Buddhist art and architecture through temple murals and local guides\"\n",
        "    ],\n",
        "    \"grand_palace_wat_phra_kaew\": [\n",
        "        \"Exploring the magnificent Grand Palace complex, the former official residence of the Kings of Siam (Thailand), with its stunning traditional Thai architecture\",\n",
        "        \"Visiting Wat Phra Kaew (Temple of the Emerald Buddha) within the palace grounds to see the highly revered Emerald Buddha statue, carved from a single jade stone\",\n",
        "        \"Admiring the intricate details of the golden spires (chedis), colorful mosaics made of glass and porcelain, ornate gables, and mythical guardian statues (yakshas and kinnaras)\",\n",
        "        \"Photographing the dazzling exteriors of the royal halls (e.g., Chakri Maha Prasat Hall), temples, and courtyards\",\n",
        "        \"Learning about Thai history, royal traditions, and Buddhist art and iconography (dressing respectfully is required: no shorts, sleeveless shirts)\",\n",
        "        \"Observing the Ramakien murals (Thai version of the Ramayana) that adorn the walls of the cloister surrounding Wat Phra Kaew\"\n",
        "    ],\n",
        "\n",
        "    # 歐洲地標 (Europe)\n",
        "    \"eiffel_tower\": [\n",
        "        \"Ascending to the different observation platforms (1st floor, 2nd floor, summit) for stunning panoramic views of Paris\",\n",
        "        \"Enjoying a romantic meal or champagne at Le Jules Verne restaurant (2nd floor) or other tower eateries\",\n",
        "        \"Picnicking on the Champ de Mars park with the Eiffel Tower as a magnificent backdrop\",\n",
        "        \"Photographing the iconic structure day and night, especially during the hourly sparkling lights show after sunset\",\n",
        "        \"Taking a Seine River cruise that offers unique perspectives of the tower from the water\",\n",
        "        \"Learning about its history, engineering, and construction at the first-floor exhibition or through guided tours\"\n",
        "    ],\n",
        "    \"louvre_museum\": [\n",
        "        \"Viewing iconic masterpieces like the Mona Lisa, Venus de Milo, Winged Victory of Samothrace, and Liberty Leading the People\",\n",
        "        \"Exploring diverse and extensive art collections spanning from ancient civilizations (Egyptian, Greek, Roman) to 19th-century European painting and sculpture\",\n",
        "        \"Taking a guided tour or using an audio guide to navigate the vast museum and focus on key exhibits or specific interests\",\n",
        "        \"Admiring the architecture of the former royal palace (Louvre Palace) and the modern glass Louvre Pyramid designed by I. M. Pei\",\n",
        "        \"Strolling through the Tuileries Garden (Jardin des Tuileries) adjacent to the museum, leading towards Place de la Concorde\",\n",
        "        \"Photographing the impressive exterior, the pyramid, and select artworks (where permitted without flash)\"\n",
        "    ],\n",
        "    \"mont_saint_michel\": [\n",
        "        \"Walking up the winding Grande Rue, lined with shops and restaurants, to reach the magnificent Benedictine Abbey at the summit\",\n",
        "        \"Taking a guided tour (or audio guide) of the Mont Saint-Michel Abbey to explore its Romanesque and Gothic sections, cloister, and refectory\",\n",
        "        \"Admiring the breathtaking views of the surrounding bay and tidal flats from the abbey terraces and ramparts\",\n",
        "        \"Photographing the island commune at different times of the day and tides, especially during high tide when it's completely surrounded by water, or at sunrise/sunset\",\n",
        "        \"Exploring the small museums, chapels, and historic houses within the village\",\n",
        "        \"Witnessing the dramatic tidal changes (some of the highest in Europe) from a safe vantage point on the island or the mainland causeway\"\n",
        "    ],\n",
        "    \"arc_de_triomphe\": [\n",
        "        \"Climbing the stairs (or taking the elevator part-way) to the rooftop observation deck for panoramic 360-degree views of Paris, including the Champs-Élysées, Eiffel Tower, Sacré-Cœur Basilica, and La Défense\",\n",
        "        \"Admiring the intricate Neoclassical sculptures and reliefs on the arch's facade, depicting scenes from French military history, particularly Napoleonic victories\",\n",
        "        \"Visiting the Tomb of the Unknown Soldier beneath the arch and witnessing the rekindling of the eternal flame each evening at 6:30 PM\",\n",
        "        \"Photographing the monument, the twelve avenues radiating from Place Charles de Gaulle (formerly Place de l'Étoile), and the surrounding cityscape\",\n",
        "        \"Learning about its historical significance and the events it commemorates through the small museum inside the arch\",\n",
        "        \"Observing major events like the Bastille Day military parade (July 14th) which passes through the arch\"\n",
        "    ],\n",
        "    \"big_ben\": [ # Elizabeth Tower\n",
        "        \"Photographing the iconic clock tower (officially Elizabeth Tower), the Great Bell (Big Ben), and the adjacent Houses of Parliament (Palace of Westminster) from Westminster Bridge or Parliament Square\",\n",
        "        \"Hearing the famous chimes of Big Ben, especially the distinctive Westminster Quarters\",\n",
        "        \"Taking a guided tour of the Houses of Parliament (when Parliament is not in session, book in advance) to see inside this historic building\",\n",
        "        \"Walking along the South Bank of the River Thames for classic views of Big Ben and the Houses of Parliament, especially at dusk or night when illuminated\",\n",
        "        \"Visiting nearby attractions such as Westminster Abbey, the Churchill War Rooms, and the London Eye\",\n",
        "        \"Learning about its history, recent restoration, and the workings of the UK Parliament\"\n",
        "    ],\n",
        "    \"stonehenge\": [\n",
        "        \"Walking the designated pathway around the prehistoric stone circle, observing the massive sarsen stones and smaller bluestones\",\n",
        "        \"Listening to the informative audio guide (available in multiple languages) to learn about the history, construction phases, and various theories about Stonehenge's purpose (e.g., astronomical observatory, burial site, ceremonial center)\",\n",
        "        \"Visiting the world-class exhibition and visitor centre to see archaeological finds, reconstructions of a Neolithic village, and interactive displays\",\n",
        "        \"Photographing the mysterious ancient monument against the backdrop of Salisbury Plain, especially during sunrise or sunset for dramatic lighting (special access may be required for inner circle access during these times)\",\n",
        "        \"Considering the astronomical alignments, particularly during the summer and winter solstices when special events are often held\",\n",
        "        \"Exploring the surrounding landscape, which is rich in other Neolithic and Bronze Age sites, including Woodhenge and Durrington Walls\"\n",
        "    ],\n",
        "    \"tower_of_london\": [\n",
        "        \"Taking a captivating tour led by a Yeoman Warder (Beefeater), who shares fascinating stories, historical anecdotes, and traditions of the Tower\",\n",
        "        \"Viewing the spectacular Crown Jewels, a dazzling collection of royal regalia including crowns, orbs, and sceptres, housed securely in the Jewel House\",\n",
        "        \"Exploring the White Tower, the oldest part of the castle (a Norman keep), which houses the Royal Armouries collection\",\n",
        "        \"Walking the ancient ramparts and learning about the Tower's multifaceted history as a royal palace, fortress, prison, and place of execution\",\n",
        "        \"Seeing the famous resident ravens and learning about the legend that the kingdom and Tower will fall if they leave\",\n",
        "        \"Visiting sites of historical significance such as Traitors' Gate, the Bloody Tower, and the execution site on Tower Green\"\n",
        "    ],\n",
        "    \"buckingham_palace\": [\n",
        "        \"Watching the iconic Changing of the Guard ceremony (check schedule and arrive early for a good view), a display of British pageantry with guards in red tunics and bearskin hats\",\n",
        "        \"Photographing the grand facade of Buckingham Palace, the official London residence of the UK monarch, and the impressive Victoria Memorial in front\",\n",
        "        \"Touring the magnificent State Rooms during the Summer Opening (typically July to September, when the King is not in residence, book tickets in advance)\",\n",
        "        \"Visiting the Queen's Gallery to see rotating exhibitions of artworks and treasures from the Royal Collection\",\n",
        "        \"Exploring the Royal Mews to see historic royal carriages and vehicles\",\n",
        "        \"Strolling through St. James's Park or Green Park, adjacent to the palace, for pleasant walks and views\"\n",
        "    ],\n",
        "    \"colosseum\": [\n",
        "        \"Taking a guided historical tour (or using an audio guide) to learn about the gladiatorial contests, wild animal hunts, public spectacles, and the lives of Roman citizens and emperors associated with the amphitheater\",\n",
        "        \"Exploring the different levels of the ancient Flavian Amphitheatre, including the arena floor (if accessible with your ticket), the hypogeum (underground tunnels and chambers), and the upper tiers for panoramic views\",\n",
        "        \"Photographing the imposing structure, a symbol of Imperial Rome, noting its architectural features like arches, columns, and the remaining sections of the outer wall\",\n",
        "        \"Visiting the adjacent Roman Forum (Foro Romano) and Palatine Hill (Colle Palatino), which are usually included in a combined ticket, to explore the heart of ancient Roman life, politics, and mythology\",\n",
        "        \"Learning about Roman engineering, architecture, and the social importance of the games held in the Colosseum\",\n",
        "        \"Imagining the roar of the crowds and the dramatic events that once unfolded within its ancient walls, especially when illuminated at night\"\n",
        "    ],\n",
        "    \"leaning_tower_of_pisa\": [\n",
        "        \"Climbing the spiral staircase of 294 steps to the top of the leaning bell tower (Torre Pendente di Pisa) for panoramic views of Pisa and the Piazza dei Miracoli (book tickets well in advance as numbers are limited)\",\n",
        "        \"Taking the classic and fun forced-perspective photo where you appear to be 'holding up' or 'pushing over' the Leaning Tower\",\n",
        "        \"Visiting the magnificent Pisa Cathedral (Duomo di Santa Maria Assunta) and the impressive Baptistery of St. John (Battistero di San Giovanni) located in the same Square of Miracles (Piazza dei Miracoli)\",\n",
        "        \"Admiring the beautiful Romanesque architecture of white marble that characterizes the entire complex\",\n",
        "        \"Strolling around the well-manicured lawns of the Piazza dei Miracoli and exploring the Camposanto Monumentale (monumental cemetery)\",\n",
        "        \"Learning about the history of the tower's construction, the reasons for its unintended tilt, and the centuries of efforts to stabilize it\"\n",
        "    ],\n",
        "    \"trevi_fountain\": [\n",
        "        \"Tossing a coin over your right shoulder with your left hand into the fountain – tradition holds that this ensures your return to Rome (toss two coins for a new romance, three for marriage)\",\n",
        "        \"Admiring the spectacular Baroque sculptures depicting Oceanus (god of the sea) on a shell-shaped chariot pulled by sea horses and tritons, set against the backdrop of Palazzo Poli\",\n",
        "        \"Photographing the magnificent fountain, one of the most famous in the world, especially beautiful when illuminated at night (be prepared for crowds)\",\n",
        "        \"Enjoying delicious Italian gelato from a nearby gelateria while people-watching and soaking in the lively atmosphere\",\n",
        "        \"Learning about the history and design of the fountain, completed by Nicola Salvi and Giuseppe Pannini, and its connection to ancient Roman aqueducts\",\n",
        "        \"Visiting at different times of day, such as early morning, to experience it with fewer crowds and different lighting conditions\"\n",
        "    ],\n",
        "    \"st_peters_basilica\": [\n",
        "        \"Exploring the vast and awe-inspiring interior of St. Peter's Basilica, the largest Christian church in the world and a masterpiece of Renaissance architecture\",\n",
        "        \"Admiring Michelangelo's magnificent dome from the inside and considering climbing to the top (cupola) for breathtaking panoramic views of St. Peter's Square, Vatican City, and Rome (requires a ticket, involves stairs and an elevator option for part of the way)\",\n",
        "        \"Viewing renowned masterpieces such as Michelangelo's Pietà (sculpture of Mary holding Christ's body), Bernini's bronze Baldachin over the papal altar, and various ornate chapels and papal tombs\",\n",
        "        \"Visiting the Vatican Grottoes (Papal Tombs) located beneath the basilica, where many popes are interred\",\n",
        "        \"Attending a Papal Mass, audience, or the Angelus prayer in St. Peter's Square if your visit coincides with these events (check Vatican schedules)\",\n",
        "        \"Strolling through the immense St. Peter's Square (Piazza San Pietro), designed by Bernini, with its grand colonnades, central obelisk, and twin fountains\"\n",
        "    ],\n",
        "    \"sagrada_familia\": [\n",
        "        \"Admiring the extraordinary and unique facades of Antoni Gaudí's unfinished masterpiece: the Nativity Facade (celebrating Christ's birth), the Passion Facade (depicting his suffering), and the still-under-construction Glory Facade\",\n",
        "        \"Exploring the breathtaking interior, a forest of tree-like columns that branch out to support the roof, illuminated by vibrant stained-glass windows that create an ethereal play of light and color\",\n",
        "        \"Taking a guided tour or using an audio guide (highly recommended) to understand Gaudí's visionary architectural concepts, complex symbolism, and the ongoing construction process (book tickets well in advance online)\",\n",
        "        \"Ascending one of the towers (Nativity or Passion, requires separate ticket and booking) for close-up views of the spires and panoramic vistas of Barcelona\",\n",
        "        \"Visiting the museum located underneath the basilica to learn about Gaudí's life, design models, construction techniques, and the history of the Sagrada Família\",\n",
        "        \"Photographing the incredibly detailed architectural elements, both inside and out, reflecting Gaudí's deep connection with nature and spirituality\"\n",
        "    ],\n",
        "    \"alhambra\": [\n",
        "        \"Exploring the Nasrid Palaces, the heart of the Alhambra, with their exquisite stucco work, intricate geometric tile mosaics (azulejos), delicate muqarnas (stalactite vaulting), and tranquil courtyards like the Court of the Lions and Court of the Myrtles (book tickets well in advance, as entry is timed and limited)\",\n",
        "        \"Wandering through the serene Generalife gardens, the summer palace of the Nasrid rulers, with its beautiful patios, fountains, flowerbeds, and scenic pathways\",\n",
        "        \"Visiting the Alcazaba, the oldest part of the Alhambra, a formidable fortress with towers offering panoramic views over the city of Granada and the surrounding landscape\",\n",
        "        \"Admiring the Palace of Charles V, a contrasting Renaissance-style building within the Alhambra complex, now housing museums\",\n",
        "        \"Photographing the stunning Moorish architecture, intricate details, and the interplay of light, water, and shadow throughout the complex\",\n",
        "        \"Learning about the history of the last Muslim emirs in Spain, the Reconquista, and the subsequent Christian modifications to the palace\"\n",
        "    ],\n",
        "    \"brandenburg_gate\": [\n",
        "        \"Walking through the iconic neoclassical triumphal arch, a potent symbol of German history, division, and reunification\",\n",
        "        \"Photographing the gate, especially when illuminated at night, and the Quadriga statue (a chariot drawn by four horses, driven by Victoria, the Roman goddess of victory) that crowns it\",\n",
        "        \"Visiting Pariser Platz, the grand square in front of the gate, which also houses embassies (e.g., US, French) and the Hotel Adlon\",\n",
        "        \"Learning about its historical significance, from its construction under King Frederick William II of Prussia to its role during the Napoleonic Wars, the Nazi era, the Cold War (when it stood near the Berlin Wall), and German reunification\",\n",
        "        \"Reflecting at nearby historical sites such as the Reichstag Building (German Parliament), the Memorial to the Murdered Jews of Europe, and the remnants of the Berlin Wall\",\n",
        "        \"Observing the bustling atmosphere and often, street performers or public events taking place in Pariser Platz\"\n",
        "    ],\n",
        "    \"neuschwanstein_castle\": [\n",
        "        \"Taking a mandatory guided tour of the fairytale-like interiors of King Ludwig II's dream castle, inspired by Richard Wagner's operas and medieval legends (tickets must be purchased in Hohenschwangau village and are timed; book online in advance to secure a spot)\",\n",
        "        \"Photographing the castle from Marienbrücke (Mary's Bridge), a pedestrian bridge offering the classic, breathtaking postcard view of Neuschwanstein perched on its rugged hill with the Bavarian Alps in the background\",\n",
        "        \"Hiking, taking a horse-drawn carriage, or riding a shuttle bus up the steep road from Hohenschwangau village to the castle entrance\",\n",
        "        \"Admiring the scenic beauty of the Bavarian Alps, forests, and nearby lakes (Alpsee and Schwansee) surrounding the castle\",\n",
        "        \"Learning about the eccentric 'Mad' King Ludwig II of Bavaria, his passion for art and architecture, and the romantic inspirations behind the castle's design\",\n",
        "        \"Visiting the nearby Hohenschwangau Castle, King Ludwig II's childhood home, for more royal history and contrasting architectural style\"\n",
        "    ],\n",
        "    \"acropolis_of_athens\": [\n",
        "        \"Exploring the Parthenon, the magnificent Doric temple dedicated to the goddess Athena Parthenos, an enduring symbol of Ancient Greece, democracy, and Western civilization\",\n",
        "        \"Visiting other significant ancient structures on the Sacred Rock, such as the Erechtheion (with its iconic Porch of the Caryatids), the Propylaea (the monumental gateway), and the Temple of Athena Nike\",\n",
        "        \"Walking to the ancient Theatre of Dionysus on the southern slope, considered the birthplace of Greek tragedy, and the well-preserved Odeon of Herodes Atticus (still used for performances)\",\n",
        "        \"Enjoying breathtaking panoramic views of Athens, including the Plaka district, Mount Lycabettus, and the Saronic Gulf, from the summit of the Acropolis\",\n",
        "        \"Visiting the Acropolis Museum, located at the foot of the Acropolis, to see original sculptures, friezes (including parts of the Parthenon Marbles), and artifacts found on the site, displayed in a modern architectural setting\",\n",
        "        \"Photographing the ancient ruins against the backdrop of the modern city, especially beautiful during sunrise or sunset\"\n",
        "    ],\n",
        "    \"santorini_oia\": [\n",
        "        \"Exploring the charming, narrow, winding pathways of Oia village, famous for its whitewashed cave houses (yposkafa), blue-domed churches, and vibrant bougainvillea\",\n",
        "        \"Watching and photographing the world-renowned sunset over the caldera from Oia, typically from the ruins of the Venetian castle (Kastro) or designated sunset viewing spots (arrive very early to secure a good spot as it gets extremely crowded)\",\n",
        "        \"Taking a boat tour to the volcanic islands of Nea Kameni (to hike on the crater) and Palea Kameni (to swim in the hot springs), and Thirassia island\",\n",
        "        \"Relaxing on unique volcanic sand beaches around Santorini, such as Red Beach (Kokkini Paralia), Perissa Beach, or Kamari Beach (Oia itself is on cliffs, not a beach town)\",\n",
        "        \"Hiking the scenic caldera trail between Fira (the capital) and Oia (approx. 3-4 hours) for stunning views\",\n",
        "        \"Indulging in local Santorinian cuisine and distinctive Assyrtiko wines at cliffside restaurants with caldera views\"\n",
        "    ],\n",
        "    \"canals_of_venice\": [\n",
        "        \"Taking a classic gondola ride through the narrow, picturesque canals, often accompanied by a serenading gondolier\",\n",
        "        \"Exploring the city on foot, getting lost in the maze-like streets (calli) and discovering charming squares (campi) and countless bridges\",\n",
        "        \"Cruising along the Grand Canal on a vaporetto (public water bus) to see famous landmarks like the Rialto Bridge, Doge's Palace, and Ca' d'Oro from the water\",\n",
        "        \"Photographing the unique cityscape with its historic buildings seemingly rising from the water, colorful reflections, and bustling canal life\",\n",
        "        \"Visiting iconic sights such as St. Mark's Square (Piazza San Marco), St. Mark's Basilica, and the Doge's Palace\",\n",
        "        \"Enjoying cicchetti (Venetian tapas) and wine at traditional bacari (local bars)\"\n",
        "    ],\n",
        "    \"florence_cathedral_duomo\": [ # Cattedrale di Santa Maria del Fiore\n",
        "        \"Admiring Brunelleschi's magnificent red-tiled dome, an architectural marvel of the Renaissance, and climbing to the top (463 steps, book well in advance) for breathtaking panoramic views of Florence\",\n",
        "        \"Exploring the interior of the Florence Cathedral (Cattedrale di Santa Maria del Fiore), noting its Gothic architecture, stained glass windows, and Vasari's frescoes of the Last Judgment inside the dome\",\n",
        "        \"Visiting Giotto's Campanile (bell tower) and climbing its 414 steps for another stunning perspective of the Duomo and the city\",\n",
        "        \"Admiring the Florence Baptistery (Battistero di San Giovanni) with its famous bronze doors, especially Ghiberti's 'Gates of Paradise'\",\n",
        "        \"Visiting the Museo dell'Opera del Duomo to see original artworks from the Duomo complex, including Ghiberti's original doors and Michelangelo's 'The Deposition' Pietà\",\n",
        "        \"Photographing the intricate white, green, and pink marble facade of the Duomo, Campanile, and Baptistery in Piazza del Duomo\"\n",
        "    ],\n",
        "    \"anne_frank_house\": [\n",
        "        \"Taking a poignant and reflective tour through the Secret Annex (Achterhuis) where Anne Frank and her family hid from Nazi persecution during World War II (book tickets online months in advance, as they sell out quickly)\",\n",
        "        \"Viewing Anne Frank's original diary and other personal belongings displayed in the museum\",\n",
        "        \"Learning about the lives of the people who hid in the annex, their helpers, and the historical context of the Holocaust and Jewish persecution in Amsterdam\",\n",
        "        \"Reflecting on Anne's story, her writings, and the enduring messages of tolerance, human rights, and hope\",\n",
        "        \"Visiting the museum exhibitions that provide further information about the persecution of Jews during the war and contemporary issues of discrimination\",\n",
        "        \"Seeing the unassuming exterior of the canal house on Prinsengracht 263 and imagining the hidden life within\"\n",
        "    ],\n",
        "    \"canals_of_amsterdam\": [\n",
        "        \"Taking a scenic canal cruise (day or evening) through the Grachtengordel (canal belt), a UNESCO World Heritage site, to admire the historic gabled canal houses, bridges, and houseboats\",\n",
        "        \"Renting a private boat or pedal boat (canal bike) to explore the canals at your own pace\",\n",
        "        \"Walking or cycling along the picturesque canals, such as Prinsengracht, Keizersgracht, and Herengracht, enjoying the charming atmosphere\",\n",
        "        \"Photographing the iconic canal scenes, including narrow houses, beautiful bridges (like Magere Brug 'Skinny Bridge'), and reflections in the water\",\n",
        "        \"Visiting canal house museums like Museum Willet-Holthuysen or Museum Van Loon to see how wealthy Amsterdammers lived in the Golden Age\",\n",
        "        \"Enjoying a drink or meal at a waterside cafe or restaurant along the canals\"\n",
        "    ],\n",
        "    \"charles_bridge_prague\": [\n",
        "        \"Walking across the historic Charles Bridge (Karlův most), a medieval stone arch bridge connecting the Old Town and Lesser Town (Malá Strana) over the Vltava River\",\n",
        "        \"Admiring the 30 statues and statuaries of saints that line the bridge, including the famous statue of St. John of Nepomuk (touching the plaque is said to bring good luck or ensure a return to Prague)\",\n",
        "        \"Enjoying panoramic views of Prague Castle, St. Vitus Cathedral, the Vltava River, and the surrounding city skyline from the bridge\",\n",
        "        \"Photographing the bridge, its Gothic towers (Old Town Bridge Tower and Lesser Town Bridge Towers), and the bustling atmosphere, especially beautiful at dawn, dusk, or at night\",\n",
        "        \"Observing street artists, musicians, and vendors who often line the bridge (can be very crowded during peak season)\",\n",
        "        \"Climbing one of the bridge towers for a higher vantage point and stunning photos\"\n",
        "    ],\n",
        "    \"red_square_st_basils_cathedral\": [\n",
        "        \"Admiring the iconic, vibrantly colored onion domes of St. Basil's Cathedral (Cathedral of Vasily the Blessed), a unique masterpiece of Russian architecture, located at the southern end of Red Square\",\n",
        "        \"Exploring Red Square (Krasnaya Ploshchad), the historic central square of Moscow, and visiting other significant landmarks such as Lenin's Mausoleum, the fortified walls of the Moscow Kremlin, the State Historical Museum, and the GUM department store\",\n",
        "        \"Taking a guided tour or visiting the interior of St. Basil's Cathedral (now a museum) to see its chapels and learn about its history\",\n",
        "        \"Photographing the stunning ensemble of Red Square, especially the contrast between St. Basil's, the Kremlin towers, and the red brick of the Historical Museum\",\n",
        "        \"Learning about the historical events that have taken place in Red Square, a UNESCO World Heritage site and a focal point of Russian history and culture\",\n",
        "        \"Visiting the GUM department store for its unique architecture, high-end shops, and traditional Russian ice cream\"\n",
        "    ],\n",
        "    \"edinburgh_castle\": [\n",
        "        \"Exploring the historic fortress perched atop Castle Rock, dominating the skyline of Edinburgh\",\n",
        "        \"Viewing the Honours of Scotland (the Scottish Crown Jewels) and the Stone of Destiny, ancient symbols of Scottish royalty\",\n",
        "        \"Visiting St. Margaret's Chapel, the oldest surviving building in Edinburgh, and the Great Hall with its impressive timber roof and collection of arms and armour\",\n",
        "        \"Witnessing the firing of the One O'Clock Gun (Monday to Saturday), a time-honored tradition\",\n",
        "        \"Walking along the castle ramparts for panoramic views of Edinburgh city, including the Royal Mile, Arthur's Seat, and the Firth of Forth\",\n",
        "        \"Learning about the castle's rich and often turbulent history, its role in Scottish wars, and its famous residents through exhibitions and guided tours\"\n",
        "    ],\n",
        "    \"matterhorn\": [\n",
        "        \"Photographing the iconic pyramidal peak of the Matterhorn, one of the world's most recognizable mountains, from Zermatt (Switzerland) or Breuil-Cervinia (Italy)\",\n",
        "        \"Taking a cable car or cogwheel train to viewpoints like Gornergrat (for stunning Matterhorn and glacier views), Klein Matterhorn (Matterhorn Glacier Paradise - Europe's highest cable car station), or Sunnegga/Rothorn for different perspectives\",\n",
        "        \"Hiking or mountain biking on the numerous trails around Zermatt that offer spectacular views of the Matterhorn and surrounding Alpine scenery (e.g., Riffelsee lake trail for reflections)\",\n",
        "        \"Skiing or snowboarding in the Zermatt-Cervinia ski area, which offers year-round skiing on the Theodul Glacier with the Matterhorn as a backdrop\",\n",
        "        \"Learning about the history of the first ascent and mountaineering in the region at the Matterhorn Museum (Zermatlantis) in Zermatt\",\n",
        "        \"Enjoying Alpine cuisine and the charming car-free village atmosphere of Zermatt\"\n",
        "    ],\n",
        "    \"palace_of_versailles\": [\n",
        "        \"Exploring the opulent State Apartments of the Palace of Versailles, including the magnificent Hall of Mirrors (Galerie des Glaces), the King's Grand Apartment, and the Queen's Grand Apartment\",\n",
        "        \"Wandering through the vast and meticulously designed Gardens of Versailles (Jardins de Versailles) by André Le Nôtre, with their formal parterres, fountains (musical fountain shows are held on certain days), canals, and groves\",\n",
        "        \"Visiting the Grand Trianon and Petit Trianon, smaller palaces within the estate, offering a more intimate glimpse into royal life, and Marie Antoinette's Hamlet (Le Hameau de la Reine), a rustic retreat\",\n",
        "        \"Taking a guided tour or using an audio guide to learn about the history of the French monarchy (especially Louis XIV, Louis XV, and Louis XVI), courtly life, and the significant historical events that took place at Versailles (like the signing of the Treaty of Versailles)\",\n",
        "        \"Renting a boat on the Grand Canal or exploring the gardens by bicycle or electric golf cart\",\n",
        "        \"Photographing the lavish Baroque architecture, gilded interiors, impressive sculptures, and expansive landscapes\"\n",
        "    ],\n",
        "\n",
        "    # 北美地標 (North America)\n",
        "    \"statue_of_liberty\": [\n",
        "        \"Taking a ferry from Battery Park (Manhattan) or Liberty State Park (New Jersey) to Liberty Island\",\n",
        "        \"Visiting the Statue of Liberty Museum to learn about its history, construction, symbolism, and Frederic Auguste Bartholdi's design\",\n",
        "        \"Accessing the pedestal for closer views of the statue and panoramic views of New York Harbor and the Manhattan skyline (requires advance booking)\",\n",
        "        \"Climbing to the crown for a unique, albeit small, viewing experience (requires very limited, advance booking months ahead)\",\n",
        "        \"Combining the visit with a trip to Ellis Island and the National Museum of Immigration, which is usually included in the same ferry ticket\",\n",
        "        \"Walking around the perimeter of Liberty Island for different photo opportunities of Lady Liberty and the surrounding views\"\n",
        "    ],\n",
        "    \"golden_gate_bridge\": [\n",
        "        \"Walking or biking across the bridge on the dedicated pedestrian and bicycle paths (check access times for each side)\",\n",
        "        \"Photographing the iconic Art Deco suspension bridge, painted in 'International Orange,' from various renowned viewpoints like Battery Spencer (Marin Headlands), Vista Point (north end), Fort Point National Historic Site (south end, underneath the bridge), or Baker Beach\",\n",
        "        \"Visiting the Golden Gate Bridge Welcome Center (south end) to learn about the bridge's history, engineering marvels, and see exhibits\",\n",
        "        \"Driving across the bridge for a classic experience (toll applies southbound into San Francisco)\",\n",
        "        \"Exploring the Golden Gate National Recreation Area, which encompasses areas on both sides of the bridge offering trails and views\",\n",
        "        \"Taking a bay cruise that sails under the Golden Gate Bridge and around Alcatraz Island for different perspectives\"\n",
        "    ],\n",
        "    \"grand_canyon\": [\n",
        "        \"Hiking along the Rim Trail or venturing down into the canyon on trails like Bright Angel Trail or South Kaibab Trail (South Rim) or North Kaibab Trail (North Rim) – be aware of difficulty, heat, and need for water\",\n",
        "        \"Taking a mule ride along the rim or into the canyon (book well in advance as these are very popular)\",\n",
        "        \"Watching and photographing the spectacular sunrise or sunset over the canyon from popular viewpoints like Mather Point, Yavapai Point, Hopi Point (South Rim), or Bright Angel Point (North Rim) as the canyon walls change colors dramatically\",\n",
        "        \"Visiting various viewpoints along the South Rim Drive (using the free park shuttle buses for much of the year) or the North Rim Scenic Drives\",\n",
        "        \"Taking a helicopter or fixed-wing aircraft tour for a breathtaking aerial perspective of the vastness of the Grand Canyon (optional, can be costly)\",\n",
        "        \"Learning about the geology, ecology, and human history (including Native American cultures) at visitor centers and ranger programs\"\n",
        "    ],\n",
        "    \"hollywood_sign\": [\n",
        "        \"Hiking to viewpoints for relatively close-up views of the sign, such as from trails in Griffith Park (e.g., Hollyridge Trail, Wonder View Trail, or near Griffith Observatory) or from Lake Hollywood Park (great for ground-level photos with the sign)\",\n",
        "        \"Photographing the iconic white capital letters on Mount Lee from various locations throughout Hollywood and Los Angeles, including the Hollywood & Highland Center observation decks\",\n",
        "        \"Visiting Griffith Observatory for excellent panoramic views of the Hollywood Sign, the Los Angeles basin, and the Pacific Ocean (on clear days), as well as its science exhibits\",\n",
        "        \"Learning about the history of the sign (originally 'HOLLYWOODLAND') and its significance as a symbol of the American film industry\",\n",
        "        \"Driving through the Hollywood Hills for different perspectives (be mindful of residential areas and parking restrictions)\",\n",
        "        \"Taking a guided Hollywood tour that often includes stops at optimal sign viewing locations\"\n",
        "    ],\n",
        "    \"white_house\": [\n",
        "        \"Viewing and photographing the iconic exterior of the White House from the North Side (Pennsylvania Avenue, in front of Lafayette Square) or the South Side (from the Ellipse)\",\n",
        "        \"Taking a public tour of select rooms in the East Wing (requires advance request through a U.S. Member of Congress for citizens, or through one's embassy for foreign nationals, months in advance; security is very strict)\",\n",
        "        \"Visiting the White House Visitor Center (located nearby) for exhibits on the history of the White House, its architecture, furnishings, first families, and presidential life\",\n",
        "        \"Exploring President's Park, which includes Lafayette Square to the north (with statues of revolutionary war heroes) and the Ellipse to the south\",\n",
        "        \"Learning about the history of the U.S. presidency and the symbolic importance of the White House as the executive mansion\",\n",
        "        \"Observing any official motorcades or security measures, which can be a unique part of the D.C. experience\"\n",
        "    ],\n",
        "    \"mount_rushmore\": [\n",
        "        \"Viewing and photographing the colossal carved faces of U.S. Presidents George Washington, Thomas Jefferson, Theodore Roosevelt, and Abraham Lincoln in the granite of Mount Rushmore\",\n",
        "        \"Walking the Presidential Trail, a boardwalk loop that provides closer views and different angles of the sculptures\",\n",
        "        \"Visiting the Lincoln Borglum Visitor Center and Museum to learn about the history of the carving, the sculptor Gutzon Borglum, the tools and techniques used, and the depicted presidents\",\n",
        "        \"Attending the evening lighting ceremony (held seasonally, typically May to September), which includes a ranger talk and the illumination of the monument\",\n",
        "        \"Exploring the Sculptor's Studio to see original plaster models and tools used in the carving process\",\n",
        "        \"Learning about the significance of each president chosen and the broader history of the United States represented by the memorial\"\n",
        "    ],\n",
        "    \"times_square\": [\n",
        "        \"Experiencing the dazzling and overwhelming display of massive digital billboards, flashing neon lights, and advertisements that illuminate the square 24/7\",\n",
        "        \"People-watching in one of the world's busiest and most famous pedestrian intersections, soaking in the vibrant and energetic atmosphere\",\n",
        "        \"Attending a Broadway show in the renowned Theater District, which is centered around Times Square (purchase tickets in advance or try the TKTS booth for same-day discounts)\",\n",
        "        \"Shopping at flagship stores of international brands, unique boutiques, and souvenir shops that line the square\",\n",
        "        \"Dining at diverse restaurants, from themed eateries and fast-food chains to upscale dining options\",\n",
        "        \"Photographing the iconic scenery, costumed characters (be aware they may expect tips), and the general buzz, especially stunning at night or during the New Year's Eve ball drop\"\n",
        "    ],\n",
        "    \"cn_tower\": [\n",
        "        \"Ascending via high-speed glass-fronted elevators to the main observation levels: the LookOut Level (with floor-to-ceiling panoramic window walls) and the famous Glass Floor (for a thrilling view 342m/1,122ft straight down)\",\n",
        "        \"Going even higher to the SkyPod, one of the highest observation platforms in the world (an additional 33 storeys above the main observation level, requires separate ticket)\",\n",
        "        \"Experiencing the EdgeWalk (seasonal, weather permitting), the world’s highest full-circle, hands-free walk on a 1.5m (5ft) wide ledge encircling the top of the Tower’s main pod, 356m/1,168ft above the ground (for thrill-seekers, book well in advance)\",\n",
        "        \"Dining at the award-winning 360 Restaurant, a revolving restaurant that completes a full rotation approximately every 72 minutes, offering stunning views and a cellar in the sky\",\n",
        "        \"Photographing the panoramic cityscape of Toronto, Lake Ontario, and on clear days, even Niagara Falls or New York State\",\n",
        "        \"Learning about the tower's construction, engineering, and its role as a communications tower through exhibits and informational displays\"\n",
        "    ],\n",
        "    \"chichen_itza\": [\n",
        "        \"Exploring the magnificent El Castillo (Pyramid of Kukulcán), the iconic step-pyramid that dominates the site, and learning about its Mayan astronomical alignments (e.g., the serpent shadow effect during the spring and autumn equinoxes)\",\n",
        "        \"Visiting other significant structures within the ancient Mayan city, such as the Great Ball Court (the largest in Mesoamerica), the Temple of the Warriors (with its Chac Mool figure and colonnades), the Group of a Thousand Columns, and the Observatory (El Caracol)\",\n",
        "        \"Observing the intricate stone carvings, Mayan hieroglyphs, and depictions of deities like Kukulcán (the feathered serpent) and Chaac (the rain god) on the buildings\",\n",
        "        \"Swimming in a nearby sacred cenote (natural sinkhole), such as Ik Kil or Yokdzonot, for a refreshing break after exploring the hot ruins (often combined with Chichen Itza tours)\",\n",
        "        \"Taking a guided tour (highly recommended) to understand the rich history, culture, rituals, and astronomical knowledge of the Mayan civilization that flourished at Chichen Itza (a UNESCO World Heritage site)\",\n",
        "        \"Photographing the impressive pyramids, ancient temples, and unique architectural features of this important archaeological site\"\n",
        "    ],\n",
        "    \"niagara_falls\": [\n",
        "        \"Taking the 'Maid of the Mist' (USA side) or 'Hornblower Niagara Cruises/Niagara City Cruises' (Canada side) boat tour for an up-close and powerful experience of the mist and roar of the Horseshoe Falls, American Falls, and Bridal Veil Falls\",\n",
        "        \"Experiencing the 'Cave of the Winds' (USA side), where you walk on wooden walkways near the base of the Bridal Veil Falls and get drenched by the spray\",\n",
        "        \"Walking along the Niagara Parkway (Canada) or within Niagara Falls State Park (USA) for various viewpoints of the falls, including Terrapin Point (USA) and Table Rock Centre (Canada)\",\n",
        "        \"Viewing the falls illuminated in vibrant colors at night, and enjoying seasonal fireworks displays over the falls\",\n",
        "        \"Visiting Journey Behind the Falls (Canada) to descend and walk through tunnels behind the Horseshoe Falls\",\n",
        "        \"Exploring other attractions in the Niagara Parks area, such as Queen Victoria Park, Clifton Hill (Canada side for entertainment), or taking a helicopter tour for an aerial view\"\n",
        "    ],\n",
        "    \"central_park\": [\n",
        "        \"Strolling or biking through the vast network of paths, exploring iconic areas like The Mall and Literary Walk, Bethesda Terrace and Fountain, Strawberry Fields (John Lennon memorial), and Conservatory Water (for model sailboat racing)\",\n",
        "        \"Having a picnic on the Great Lawn or Sheep Meadow with views of the surrounding Manhattan skyline\",\n",
        "        \"Renting a rowboat or taking a gondola ride on The Lake, passing under Bow Bridge\",\n",
        "        \"Visiting Central Park Zoo, the Central Park Carousel, or Wollman Rink (ice skating in winter, other activities in summer)\",\n",
        "        \"Exploring the more rugged northern section with the North Woods and Harlem Meer, or the formal Conservatory Garden\",\n",
        "        \"Attending free events like Shakespeare in the Park (summer), concerts by the New York Philharmonic, or SummerStage performances\"\n",
        "    ],\n",
        "    \"las_vegas_strip\": [\n",
        "        \"Walking along Las Vegas Boulevard South to see the extravagant themed mega-resorts and casinos, such as Bellagio (with its famous fountains), Venetian (with canals and gondola rides), Caesars Palace, Luxor (pyramid and sphinx), and Paris Las Vegas (Eiffel Tower replica)\",\n",
        "        \"Watching free street-side shows like the Fountains of Bellagio water ballet or the Mirage Volcano eruption\",\n",
        "        \"Trying your luck at casino games (responsibly, if you choose to gamble)\",\n",
        "        \"Attending a world-class show, concert, or residency featuring top entertainers\",\n",
        "        \"Shopping at high-end retail promenades like The Forum Shops at Caesars, Grand Canal Shoppes at The Venetian, or Crystals at CityCenter\",\n",
        "        \"Dining at celebrity chef restaurants or enjoying diverse culinary experiences, and experiencing the vibrant nightlife with clubs and bars\"\n",
        "    ],\n",
        "    \"yellowstone_national_park\": [\n",
        "        \"Watching the eruption of Old Faithful geyser and exploring the Upper Geyser Basin, home to the world's largest concentration of geysers\",\n",
        "        \"Admiring the vibrant colors of Grand Prismatic Spring in the Midway Geyser Basin and other geothermal features like mudpots and fumaroles at Mammoth Hot Springs' travertine terraces\",\n",
        "        \"Wildlife viewing: looking for bison, elk, grizzly bears, wolves, pronghorn, and bighorn sheep in areas like Lamar Valley (often called 'America's Serengeti') and Hayden Valley\",\n",
        "        \"Visiting the Grand Canyon of the Yellowstone to see the impressive Upper and Lower Falls of the Yellowstone River from viewpoints like Artist Point\",\n",
        "        \"Driving the scenic Grand Loop Road to access various park attractions and enjoying hikes on numerous trails of varying difficulty\",\n",
        "        \"Boating, fishing, or simply enjoying the views at Yellowstone Lake, North America's largest high-elevation lake\"\n",
        "    ],\n",
        "    \"banff_national_park_lake_louise\": [ # and Moraine Lake\n",
        "        \"Photographing the stunning turquoise waters of Lake Louise with the Victoria Glacier and the iconic Fairmont Chateau Lake Louise in the background; also visit the equally breathtaking Moraine Lake with its vivid blue water framed by the Valley of the Ten Peaks (access to Moraine Lake is restricted, plan ahead with shuttle or tour)\",\n",
        "        \"Canoeing or kayaking on Lake Louise or Moraine Lake for an unforgettable experience amidst the majestic mountain scenery\",\n",
        "        \"Hiking popular trails such as the Lake Agnes Teahouse Trail, Plain of Six Glaciers Trail (from Lake Louise), or the Rockpile Trail and Lakeshore Trail (at Moraine Lake)\",\n",
        "        \"Taking the Lake Louise Gondola (or Banff Gondola near Banff town) for panoramic views of the Canadian Rockies, glaciers, and valleys\",\n",
        "        \"Wildlife viewing for animals like elk, deer, bighorn sheep, and occasionally bears (maintain a safe distance)\",\n",
        "        \"Exploring the charming town of Banff, Johnston Canyon, or driving the scenic Icefields Parkway towards Jasper National Park\"\n",
        "    ],\n",
        "    \"space_needle_seattle\": [\n",
        "        \"Taking a 41-second elevator ride to the 520-foot high observation deck for 360-degree panoramic views of Seattle's skyline, Elliott Bay, Puget Sound, the Olympic Mountains, Cascade Mountains, and Mount Rainier on clear days\",\n",
        "        \"Stepping out onto 'The Loupe,' the world's first and only revolving glass floor, offering thrilling downward views of the city and the Needle's structure\",\n",
        "        \"Enjoying a meal or drinks at 'The Loupe Lounge' (revolving glass floor level) or other dining options within the Space Needle\",\n",
        "        \"Photographing the iconic futuristic structure, a symbol of Seattle and the 1962 World's Fair, from various angles and at different times of day (especially sunset or when illuminated at night)\",\n",
        "        \"Learning about the history of the Space Needle and Seattle through interactive exhibits on the observation deck\",\n",
        "        \"Visiting nearby attractions at Seattle Center, such as the Chihuly Garden and Glass, Museum of Pop Culture (MoPOP), or Pacific Science Center\"\n",
        "    ],\n",
        "\n",
        "    # 南美地標 (South America)\n",
        "    \"machu_picchu\": [\n",
        "        \"Exploring the remarkably preserved ancient Inca citadel, including the Temple of the Sun, Intihuatana stone, Royal Tomb, residential areas, and agricultural terraces\",\n",
        "        \"Hiking Huayna Picchu or Machu Picchu Mountain for breathtaking panoramic views of the ruins and surrounding Andes (requires separate, pre-booked tickets well in advance as permits are limited)\",\n",
        "        \"Taking a guided tour (highly recommended) to learn about Inca history, cosmology, architecture, and the possible purposes of this enigmatic 'Lost City of the Incas' (a UNESCO World Heritage site)\",\n",
        "        \"Photographing the stunning landscape of stone ruins nestled dramatically in the cloud-forested mountains, especially during sunrise or late afternoon for optimal lighting\",\n",
        "        \"Watching the sunrise over Machu Picchu (if staying in Aguas Calientes or taking an early bus/train to arrive before dawn)\",\n",
        "        \"Visiting the Sun Gate (Inti Punku) for a classic first view of Machu Picchu if hiking a portion of the Inca Trail, or the Inca Bridge for a glimpse of Inca engineering\"\n",
        "    ],\n",
        "    \"christ_the_redeemer\": [\n",
        "        \"Taking the historic cog train (Trem do Corcovado) or an official van up Corcovado Mountain through Tijuca National Park to reach the statue\",\n",
        "        \"Admiring the colossal Art Deco statue of Jesus Christ with outstretched arms, a global icon of Rio de Janeiro and Brazil, and one of the New Seven Wonders of the World\",\n",
        "        \"Enjoying breathtaking 360-degree panoramic views of Rio de Janeiro, including Sugarloaf Mountain, Copacabana and Ipanema beaches, Guanabara Bay, and the Rodrigo de Freitas Lagoon\",\n",
        "        \"Photographing the statue from its base and the spectacular surrounding cityscape and landscape\",\n",
        "        \"Visiting the small chapel located at the base of the statue, dedicated to Our Lady of Aparecida, the patron saint of Brazil\",\n",
        "        \"Learning about the history, construction, and significance of the monument through informational plaques or guided tours\"\n",
        "    ],\n",
        "    \"iguazu_falls\": [\n",
        "        \"Exploring the extensive network of walkways and viewpoints on both the Argentinian side (Parque Nacional Iguazú) and the Brazilian side (Parque Nacional do Iguaçu) for different perspectives of the hundreds of waterfalls\",\n",
        "        \"Experiencing the immense power and roar of the Devil's Throat (Garganta del Diablo / Garganta do Diabo), the largest and most dramatic cataract, from viewing platforms that extend over the falls\",\n",
        "        \"Taking a thrilling boat tour (e.g., Gran Aventura on the Argentinian side or Macuco Safari on the Brazilian side) that goes close to and even under some of the falls (expect to get soaked!)\",\n",
        "        \"Walking the Upper Circuit and Lower Circuit trails on the Argentinian side for varied views and close encounters with different sections of the falls\",\n",
        "        \"Photographing the spectacular waterfalls, lush subtropical rainforest, and frequent rainbows that form in the mist\",\n",
        "        \"Wildlife spotting in the surrounding national parks, looking for coatis, toucans, monkeys, and colorful butterflies\"\n",
        "    ],\n",
        "    \"galapagos_islands\": [\n",
        "        \"Taking a multi-day cruise on a small ship or yacht to visit various islands, as each island offers unique landscapes and wildlife viewing opportunities (the most common way to explore)\",\n",
        "        \"Snorkeling or scuba diving in the rich marine environment to see sea lions, marine iguanas, Galapagos penguins, sea turtles, sharks (like hammerheads and Galapagos sharks), rays, and colorful fish\",\n",
        "        \"Observing unique and fearless wildlife up close (maintaining a respectful distance as per park rules), such as giant tortoises in their natural habitat (e.g., at El Chato Tortoise Reserve on Santa Cruz Island), blue-footed boobies, frigatebirds with inflated red pouches, and land iguanas\",\n",
        "        \"Hiking on volcanic landscapes, lava fields, and pristine beaches, learning about the geology and evolutionary history of the islands that inspired Charles Darwin\",\n",
        "        \"Visiting the Charles Darwin Research Station on Santa Cruz Island to learn about conservation efforts and the tortoise breeding program\",\n",
        "        \"Kayaking, birdwatching, and photographing the extraordinary biodiversity and unique natural beauty of this UNESCO World Heritage site\"\n",
        "    ],\n",
        "    \"torres_del_paine_national_park\": [\n",
        "        \"Hiking famous multi-day treks like the 'W Trek' (typically 4-5 days) or the 'O Circuit' (full loop, 8-10 days) for stunning views of the granite Paine Towers, Cuernos del Paine (Horns), glaciers, lakes, and Patagonian landscapes\",\n",
        "        \"Undertaking day hikes to iconic viewpoints, such as the Base of the Towers (Mirador Las Torres), Mirador Cuernos, or viewpoints overlooking Grey Glacier and Lake Pehoé\",\n",
        "        \"Photographing the dramatic granite peaks, turquoise glacial lakes (like Pehoé, Nordenskjöld, Sarmiento), vast ice fields (Southern Patagonian Ice Field), and unique flora and fauna\",\n",
        "        \"Wildlife viewing for animals such as guanacos, condors, foxes, and occasionally pumas (though elusive)\",\n",
        "        \"Taking a boat trip on Lake Grey to get close to the face of Grey Glacier, or a catamaran across Lake Pehoé\",\n",
        "        \"Experiencing the wild and unpredictable Patagonian weather, and enjoying the pristine, rugged beauty of this renowned national park (a UNESCO Biosphere Reserve)\"\n",
        "    ],\n",
        "    \"angel_falls\": [\n",
        "        \"Taking a multi-day expedition (typically 3 days/2 nights) by motorized dugout canoe (curiara) up the Carrao and Churún rivers through Canaima National Park to reach the base of Angel Falls (Salto Ángel), the world's tallest uninterrupted waterfall\",\n",
        "        \"Hiking through the rainforest from the river camp to a viewpoint near the base of the falls (Mirador Laime) to witness the spectacular cascade plunging from the summit of Auyán-Tepui\",\n",
        "        \"Swimming in pools at the base of the falls or in the river (depending on conditions and guide advice)\",\n",
        "        \"Spending nights in hammocks at rustic jungle camps, experiencing the sounds and atmosphere of the remote wilderness\",\n",
        "        \"Taking a scenic overflight by small plane from Canaima or Ciudad Bolívar for a breathtaking aerial view of Angel Falls and the vast expanse of Auyán-Tepui (often done as part of a tour or separately)\",\n",
        "        \"Learning about the indigenous Pemón culture and the unique geology of the tepuis (table-top mountains) in Canaima National Park (a UNESCO World Heritage site)\"\n",
        "    ],\n",
        "    \"salar_de_uyuni\": [\n",
        "        \"Taking a multi-day 4x4 jeep tour (typically 1 to 4 days) across the vast Salar de Uyuni, the world's largest salt flat, and the surrounding Altiplano region\",\n",
        "        \"During the dry season (May-November): Experiencing the seemingly endless white expanse of hexagonal salt patterns, visiting Incahuasi Island (Fish Island) with its giant ancient cacti and panoramic views, and taking creative forced-perspective photographs\",\n",
        "        \"During the rainy season (December-April): Witnessing the breathtaking 'world's largest mirror' effect when a thin layer of water covers the salt flat, creating stunning reflections of the sky and clouds (access can be limited)\",\n",
        "        \"Visiting the 'train cemetery' (Cementerio de Trenes) just outside Uyuni town, with its rusted antique steam locomotives\",\n",
        "        \"Seeing the salt harvesting mounds and the original salt hotel (Palacio de Sal, now a museum), and learning about salt extraction\",\n",
        "        \"Exploring the surrounding Altiplano highlights on longer tours, such as colorful lagoons (Laguna Colorada with flamingos, Laguna Verde), geysers (Sol de Mañana), hot springs (Termas de Polques), and dramatic volcanic landscapes\"\n",
        "    ],\n",
        "\n",
        "    # 中東/非洲地標 (Middle East / Africa)\n",
        "    \"pyramids_of_giza\": [\n",
        "        \"Exploring the exteriors of the three main pyramids: the Great Pyramid of Giza (Pyramid of Khufu), the Pyramid of Khafre, and the Pyramid of Menkaure\",\n",
        "        \"Entering one of the pyramids (requires separate ticket, can be claustrophobic, limited access) to see the internal chambers\",\n",
        "        \"Visiting the Great Sphinx of Giza, the colossal limestone statue with the body of a lion and the head of a human, and the adjacent Valley Temple of Khafre\",\n",
        "        \"Taking a camel or horse ride across the Giza plateau for different perspectives and classic photo opportunities of the pyramids against the desert backdrop\",\n",
        "        \"Visiting the Solar Boat Museum (Khufu Ship Museum) next to the Great Pyramid to see a remarkably preserved ancient Egyptian funerary boat\",\n",
        "        \"Attending the Sound and Light Show in the evening, where the pyramids and Sphinx are illuminated with accompanying narration about ancient Egyptian history (optional)\"\n",
        "    ],\n",
        "    \"burj_khalifa\": [\n",
        "        \"Ascending to one of the world's highest observation decks: 'At the Top' on levels 124 and 125, or the more exclusive 'At the Top, SKY' on level 148, for breathtaking panoramic views of Dubai's futuristic skyline, the desert, and the Arabian Gulf\",\n",
        "        \"Photographing the stunning views, especially during sunset or at night when the city lights up\",\n",
        "        \"Dining at At.mosphere, the restaurant and lounge on level 122, one of the world's highest restaurants\",\n",
        "        \"Watching the spectacular Dubai Fountain show, a choreographed water and light display at the base of the Burj Khalifa on Burj Lake (best viewed from the Waterfront Promenade of The Dubai Mall or a nearby restaurant)\",\n",
        "        \"Learning about the engineering, architecture, and construction of the world's tallest building through interactive exhibits at the observation deck levels\",\n",
        "        \"Shopping at The Dubai Mall, one of the world's largest shopping malls, which is connected to the Burj Khalifa and also houses the Dubai Aquarium & Underwater Zoo\"\n",
        "    ],\n",
        "    \"petra_jordan\": [ # (Was \"petra\")\n",
        "        \"Walking through the Siq, a narrow, winding sandstone gorge that serves as the dramatic main entrance to the ancient Nabataean city of Petra\",\n",
        "        \"Emerging from the Siq to behold the iconic Al-Khazneh (The Treasury), an elaborately carved temple facade, one of the most famous archaeological sites in the world\",\n",
        "        \"Exploring the vast archaeological site, including the Street of Facades, the Theatre, the Royal Tombs, the Colonnaded Street, and the Great Temple\",\n",
        "        \"Hiking up the 800+ steps to Ad Deir (The Monastery), another magnificent rock-cut facade offering stunning views (a significant but rewarding climb)\",\n",
        "        \"Photographing the 'Rose City' with its unique rock-cut architecture and dramatic desert landscape, noting how the sandstone changes color throughout the day\",\n",
        "        \"Learning about the history of the Nabataean civilization, their ingenuity in water management, and their role as a trading hub, through a local guide or the Petra Museum\"\n",
        "    ],\n",
        "    \"table_mountain\": [\n",
        "        \"Taking the rotating aerial cableway (Table Mountain Aerial Cableway) to the summit for spectacular 360-degree views of Cape Town, Table Bay, Robben Island, the Cape Peninsula, and the Atlantic Ocean\",\n",
        "        \"Hiking up one of the many trails to the summit, such as Platteklip Gorge (the most direct but steep), Skeleton Gorge (more scenic, starting from Kirstenbosch Gardens), or India Venster (more challenging, for experienced hikers)\",\n",
        "        \"Walking along the well-maintained pathways on the flat-topped summit, exploring different viewpoints, and enjoying the unique fynbos vegetation (part of the Cape Floral Kingdom, a UNESCO World Heritage site)\",\n",
        "        \"Photographing the panoramic vistas, the city nestled below, and the dramatic cloud formations known as the 'tablecloth' that sometimes cover the mountain\",\n",
        "        \"Abseiling from the top of Table Mountain (for adventure seekers, with registered operators)\",\n",
        "        \"Enjoying refreshments or a meal at the café or restaurant on the summit while taking in the views\"\n",
        "    ],\n",
        "    \"sheikh_zayed_grand_mosque\": [\n",
        "        \"Taking a guided tour (free, offered regularly) to learn about the mosque's stunning architecture, Islamic art, cultural significance, and design elements\",\n",
        "        \"Admiring the pristine white Macedonian marble exterior, the 82 domes of various sizes, the four towering minarets, and the intricate floral designs inlaid with semi-precious stones\",\n",
        "        \"Exploring the vast main prayer hall, which houses the world's largest hand-knotted carpet and one of the world's largest Swarovski crystal chandeliers\",\n",
        "        \"Walking through the serene courtyards (sahan) with their reflective pools that beautifully mirror the mosque's columns and arches\",\n",
        "        \"Photographing the breathtaking beauty of the mosque, both during the day (when the white marble gleams) and at night (when it is illuminated by a unique lunar lighting system that changes with the phases of the moon)\",\n",
        "        \"Respecting the dress code (modest attire required for all visitors; abayas provided for women if needed) and behaving reverently within the sacred space\"\n",
        "    ],\n",
        "    \"masai_mara_national_reserve\": [\n",
        "        \"Going on multiple game drives (early morning and late afternoon are often best) in a 4x4 safari vehicle with an experienced guide to spot the 'Big Five' (lion, leopard, elephant, rhino, buffalo) and other wildlife like cheetahs, giraffes, zebras, wildebeest, hyenas, and numerous bird species\",\n",
        "        \"Witnessing the Great Migration (typically July to October), where millions of wildebeest and zebras cross the Mara River from Tanzania's Serengeti, facing crocodiles and predators (a dramatic natural spectacle)\",\n",
        "        \"Taking a hot air balloon safari at sunrise over the Masai Mara plains for a breathtaking panoramic view of the landscape and wildlife, followed by a champagne breakfast in the bush\",\n",
        "        \"Visiting a traditional Maasai village (manyatta) to learn about Maasai culture, customs, traditions, and their way of life (usually arranged through lodges or tour operators)\",\n",
        "        \"Enjoying bush breakfasts, lunches, or sundowner drinks in scenic spots within the reserve\",\n",
        "        \"Nature walks with armed rangers (where permitted) for a different perspective on the flora and fauna, or birdwatching (the Mara has a rich avian diversity)\"\n",
        "    ],\n",
        "    \"victoria_falls\": [\n",
        "        \"Viewing the spectacular curtain of falling water from various viewpoints on both the Zambian side (e.g., Knife-Edge Bridge, Boiling Pot trail) and the Zimbabwean side (e.g., Main Falls, Rainbow Falls, Danger Point) of the Zambezi River\",\n",
        "        \"Feeling the immense spray (the 'Smoke that Thunders' or Mosi-oa-Tunya) and hearing the roar of one of the world's largest waterfalls by combined width and height\",\n",
        "        \"Taking a guided tour of the rainforest trails on the Zimbabwean side, which offer numerous perspectives of the falls\",\n",
        "        \"Experiencing thrilling adventure activities such as white-water rafting or kayaking on the powerful Zambezi River below the falls (seasonal), bungee jumping from the Victoria Falls Bridge, or gorge swinging\",\n",
        "        \"Taking a helicopter or microlight flight ('Flight of Angels') over Victoria Falls for breathtaking aerial views\",\n",
        "        \"Enjoying a sunset cruise on the upper Zambezi River, spotting wildlife like hippos, crocodiles, and birds, or visiting Livingstone Island and swimming in Devil's Pool or Angel's Pool at the edge of the falls (seasonal, Zambian side only, requires guided tour)\"\n",
        "    ],\n",
        "    \"kilimanjaro\": [\n",
        "        \"Attempting to climb Mount Kilimanjaro, Africa's highest peak and the world's tallest freestanding mountain, via one of several routes (e.g., Machame, Lemosho, Marangu, Rongai) with a licensed guide and porters (a challenging multi-day trek requiring good physical condition and acclimatization)\",\n",
        "        \"Experiencing the diverse ecological zones on the ascent, from lush rainforest and moorland to alpine desert and the arctic summit zone with its glaciers and snowfields\",\n",
        "        \"Reaching Uhuru Peak (5,895m / 19,341ft) on Kibo, the highest of Kilimanjaro's three volcanic cones, typically at sunrise for spectacular views\",\n",
        "        \"Photographing the stunning mountain scenery, unique flora (like giant groundsels and lobelias), and the iconic snow-capped summit\",\n",
        "        \"Learning about the geology of the dormant volcano and the local Chagga culture from guides and porters\",\n",
        "        \"For those not climbing: Enjoying views of Kilimanjaro from nearby towns like Moshi or Arusha (Tanzania), or Amboseli National Park (Kenya) on clear days, or taking a scenic flight around the mountain\"\n",
        "    ],\n",
        "    \"dead_sea\": [\n",
        "        \"Effortlessly floating in the hyper-saline waters of the Dead Sea, an experience unique due to the water's high salt and mineral concentration (avoid getting water in your eyes)\",\n",
        "        \"Applying the mineral-rich black mud from the Dead Sea shores onto your skin, known for its therapeutic and cosmetic benefits, then rinsing off in the sea or showers\",\n",
        "        \"Relaxing at one of the resorts or public beaches along the shores in Jordan or Israel, often equipped with facilities like showers, pools, and spas\",\n",
        "        \"Photographing the unique landscape of the Dead Sea (the lowest point on Earth's land surface), with its calm, dense turquoise waters reflecting the arid surrounding mountains and desert, and distinctive salt formations\",\n",
        "        \"Learning about the history, geology, and unique ecosystem of the Dead Sea, and the challenges it faces (e.g., receding water levels)\",\n",
        "        \"Visiting nearby historical and natural sites, such as Masada and Ein Gedi (Israel side) or Mujib Biosphere Reserve and Ma'in Hot Springs (Jordan side)\"\n",
        "    ],\n",
        "    \"dome_of_the_rock\": [\n",
        "        \"Admiring the iconic, gleaming golden dome of the Dome of the Rock (Qubbat as-Sakhrah), an Islamic shrine located on the Temple Mount (Haram al-Sharif) in the Old City of Jerusalem (access for non-Muslims to the Temple Mount plaza is restricted to specific hours and days, and entry into the Dome of the Rock itself is generally not permitted for non-Muslims)\",\n",
        "        \"Observing the octagonal structure of the Dome of the Rock, adorned with intricate blue and turquoise ceramic tilework, Quranic calligraphy, and mosaics, from the Temple Mount plaza\",\n",
        "        \"Photographing this significant religious landmark, a site of immense importance in Islam, Judaism (as the location of the First and Second Temples), and Christianity, from various viewpoints within and outside the Old City (e.g., from the Mount of Olives)\",\n",
        "        \"Exploring the wider Temple Mount/Haram al-Sharif plaza, also home to Al-Aqsa Mosque (entry for non-Muslims generally not permitted into the mosque building) and other smaller Islamic structures, while respecting the site's sanctity and rules\",\n",
        "        \"Learning about the history and religious significance of the Foundation Stone (Even HaShetiya in Hebrew, As-Sakhrah in Arabic) which the Dome of the Rock enshrines, believed to be the site where Abraham prepared to sacrifice his son, and from where Prophet Muhammad is said to have ascended to heaven\",\n",
        "        \"Visiting other holy sites within the Old City of Jerusalem, such as the Western Wall, the Church of the Holy Sepulchre, and walking the Via Dolorosa\"\n",
        "    ],\n",
        "\n",
        "    # 大洋洲地標 (Oceania)\n",
        "    \"sydney_opera_house\": [\n",
        "        \"Taking a guided architectural tour to learn about its history, innovative design by Jørn Utzon, construction challenges, and its various performance venues (e.g., Concert Hall, Joan Sutherland Theatre)\",\n",
        "        \"Attending a world-class performance, such as opera, ballet, classical music concert, theatre, or contemporary music show, inside one of its iconic halls (book tickets in advance)\",\n",
        "        \"Photographing the iconic white sail-like shells from various angles and vantage points, such as from a ferry on Sydney Harbour, Mrs Macquarie's Chair, Circular Quay, or while walking across the Sydney Harbour Bridge\",\n",
        "        \"Dining at one of the many restaurants or enjoying drinks at bars with stunning harbour views located at the Opera House, like Opera Bar or Portside Sydney\",\n",
        "        \"Walking around the exterior promenade, admiring the building's unique form up close, and enjoying the bustling atmosphere of Circular Quay\",\n",
        "        \"Visiting the gift shop for souvenirs, or attending free outdoor events and festivals that sometimes take place on the forecourt\"\n",
        "    ],\n",
        "    \"uluru\": [\n",
        "        \"Walking the full Uluru base walk (approximately 10.6 km / 6.6 miles loop, takes about 3-4 hours) to experience the immense scale and diverse features of the monolith up close, including waterholes, rock art sites, and unique geological formations (best done early morning or late afternoon to avoid heat)\",\n",
        "        \"Watching and photographing the spectacular color changes of Uluru at sunrise and sunset from designated viewing areas (Talinguru Nyakunytjaku for sunrise, Uluru sunset viewing area for sunset)\",\n",
        "        \"Taking a guided tour led by an Anangu (local Aboriginal people) guide to learn about the cultural significance, Dreamtime stories (Tjukurpa), and traditional laws associated with Uluru (highly recommended for a deeper understanding)\",\n",
        "        \"Visiting the Uluru-Kata Tjuta Cultural Centre to gain insights into Anangu culture, art, and land management practices\",\n",
        "        \"Exploring the nearby Kata Tjuta (The Olgas) rock formations, particularly the Walpa Gorge walk or the Valley of the Winds walk, for different but equally stunning desert landscapes\",\n",
        "        \"Stargazing in the clear desert night sky (Uluru is in a remote area with minimal light pollution), or participating in an Sounds of Silence or Field of Light Uluru experience (optional, requires booking)\"\n",
        "    ],\n",
        "    \"great_barrier_reef\": [\n",
        "        \"Snorkeling or scuba diving from a boat tour or island resort to explore the vibrant coral reefs, encounter colorful tropical fish, sea turtles, manta rays, reef sharks, and other diverse marine life (many tour options cater to different skill levels)\",\n",
        "        \"Taking a glass-bottom boat tour or a semi-submersible tour to view the coral and marine life without getting wet, suitable for all ages\",\n",
        "        \"Going on a scenic helicopter or seaplane flight for a breathtaking aerial perspective of the reef's intricate patterns, turquoise waters, islands, and cays (e.g., seeing Heart Reef from the air)\",\n",
        "        \"Visiting a pontoon stationed on the outer reef, which often includes facilities like underwater observatories, snorkeling platforms, and introductory dive options\",\n",
        "        \"Learning about marine conservation, the ecology of the Great Barrier Reef (a UNESCO World Heritage site), and the threats it faces (e.g., climate change, coral bleaching) through onboard marine biologist talks or visitor centers\",\n",
        "        \"Sailing or taking a catamaran cruise through the Whitsunday Islands or other reef areas, often including stops for snorkeling, swimming, and relaxing on pristine beaches like Whitehaven Beach\"\n",
        "    ],\n",
        "    \"hobbiton_movie_set\": [\n",
        "        \"Taking a fully guided walking tour through the 12-acre movie set, visiting numerous Hobbit Holes with their distinctive round doors and charming details, as seen in 'The Lord of the Rings' and 'The Hobbit' trilogies\",\n",
        "        \"Photographing iconic locations such as Bag End (Bilbo and Frodo Baggins' home), the Party Tree, the Mill, and the double-arched stone bridge\",\n",
        "        \"Enjoying a complimentary, specially brewed beverage (ale, cider, or non-alcoholic ginger beer) at The Green Dragon Inn, a faithfully reconstructed pub from the movies\",\n",
        "        \"Listening to fascinating behind-the-scenes stories and filmmaking secrets from your guide about how the Hobbiton set was created and used in the films\",\n",
        "        \"Shopping for Middle-earth themed souvenirs, Weta Workshop collectibles, and other memorabilia at the Hobbiton Shire Store\",\n",
        "        \"Immersing oneself in the picturesque, meticulously maintained landscape of The Shire, with its rolling green hills, gardens, and charming atmosphere, located on a working sheep farm\"\n",
        "    ],\n",
        "    \"sydney_harbour_bridge\": [\n",
        "        \"Undertaking the BridgeClimb Sydney experience, climbing the steel arches of the bridge for breathtaking 360-degree panoramic views of Sydney Harbour, the Opera House, the city skyline, and beyond (various climb options available, book in advance)\",\n",
        "        \"Walking or cycling across the bridge on the dedicated pedestrian walkway (eastern side) or cycleway (western side) for free, enjoying fantastic views and photo opportunities\",\n",
        "        \"Visiting the Pylon Lookout on the southeastern pylon for historical exhibits about the bridge's construction and impressive views from its observation deck\",\n",
        "        \"Photographing the iconic 'Coathanger' from various vantage points, such as Mrs Macquarie's Chair, Luna Park, McMahon's Point, or from a ferry on the harbour\",\n",
        "        \"Taking a ferry ride under the bridge for a different perspective of its massive scale and engineering\",\n",
        "        \"Learning about the history, design, and construction of this engineering marvel, which opened in 1932\"\n",
        "    ],\n",
        "    \"fiordland_national_park_milford_sound\": [ # and Doubtful Sound\n",
        "        \"Taking a scenic boat cruise (day cruise or overnight cruise) on Milford Sound to experience its dramatic fiord scenery, with sheer cliffs (like Mitre Peak), cascading waterfalls (e.g., Stirling Falls, Bowen Falls), lush rainforest, and often, mist-shrouded peaks\",\n",
        "        \"Kayaking on Milford Sound or Doubtful Sound for a more intimate and peaceful experience of the fiords, getting closer to the shoreline and wildlife\",\n",
        "        \"Spotting wildlife such as New Zealand fur seals basking on rocks, dolphins, Fiordland crested penguins (seasonal), and various seabirds\",\n",
        "        \"Exploring Doubtful Sound, a larger and more remote fiord, often via a tour involving a cruise across Lake Manapouri and a bus trip over Wilmot Pass\",\n",
        "        \"Hiking parts of famous multi-day tracks like the Milford Track (requires advance booking months or even years ahead) or Kepler Track, or shorter day walks accessible from the Milford Road\",\n",
        "        \"Photographing the awe-inspiring, moody, and pristine landscapes of Fiordland National Park (a UNESCO World Heritage site), known for its high rainfall and dramatic beauty\"\n",
        "    ],\n",
        "    \"bondi_beach\": [\n",
        "        \"Swimming, surfing, or sunbathing on the famous crescent-shaped golden sands of Bondi Beach, one of Australia's most iconic beaches\",\n",
        "        \"Learning to surf at one of the surf schools located at Bondi Beach\",\n",
        "        \"Walking or jogging the scenic Bondi to Coogee Coastal Walk (approx. 6km), offering stunning ocean views, dramatic cliffs, and access to other beaches like Tamarama and Bronte\",\n",
        "        \"Visiting the Bondi Icebergs Club, a historic swimming club with its famous ocean pool that waves often crash into, and enjoying a meal or drink at its restaurant with panoramic beach views\",\n",
        "        \"Exploring the vibrant Campbell Parade, the street fronting the beach, lined with cafes, restaurants, surf shops, and fashion boutiques\",\n",
        "        \"People-watching and soaking in the lively beach culture, or visiting the Bondi Markets (on weekends) for local crafts, fashion, and food\"\n",
        "    ],\n",
        "    \"aoraki_mount_cook_national_park\": [\n",
        "        \"Hiking popular trails such as the Hooker Valley Track (relatively easy, 3-hour return) for spectacular views of Aoraki/Mount Cook, Mueller Glacier, Hooker Lake (with icebergs), and suspension bridges\",\n",
        "        \"Admiring New Zealand's highest peak, Aoraki/Mount Cook, and the surrounding majestic Southern Alps, glaciers, and turquoise glacial lakes like Lake Pukaki and Lake Tekapo (often framed by colorful lupins in summer - Nov/Dec)\",\n",
        "        \"Stargazing in the Aoraki Mackenzie International Dark Sky Reserve, one of the best places in the world for viewing the night sky due to its clear, dark conditions (guided stargazing tours available)\",\n",
        "        \"Taking a scenic helicopter or ski plane flight for breathtaking aerial views of the mountains and glaciers, possibly including a snow landing on Tasman Glacier\",\n",
        "        \"Visiting the Sir Edmund Hillary Alpine Centre at The Hermitage Hotel to learn about the region's mountaineering history, flora, fauna, and geology\",\n",
        "        \"Experienced mountaineering or glacier hiking with qualified guides (for advanced adventurers)\"\n",
        "    ],\n",
        "    \"twelve_apostles_great_ocean_road\": [\n",
        "        \"Viewing and photographing the iconic limestone stacks known as The Twelve Apostles (though fewer than twelve now remain due to erosion) rising dramatically from the Southern Ocean, from the designated clifftop viewing platforms\",\n",
        "        \"Visiting at sunrise or sunset for the most spectacular lighting conditions, as the stacks change color and long shadows are cast (be prepared for crowds during these times)\",\n",
        "        \"Walking along the boardwalks and pathways to different lookout points offering various perspectives of The Twelve Apostles and the rugged coastline\",\n",
        "        \"Exploring other nearby dramatic rock formations and coastal features along this section of the Great Ocean Road, such as Loch Ard Gorge (site of a famous shipwreck), Gibson Steps (descend to the beach for a different view of some stacks), The Arch, London Bridge (now London Arch), and The Grotto\",\n",
        "        \"Taking a scenic helicopter flight over The Twelve Apostles and the Shipwreck Coast for a breathtaking aerial view (optional)\",\n",
        "        \"Learning about the geology of the limestone formations, the power of coastal erosion, and the maritime history of the area at the Twelve Apostles Visitor Centre\"\n",
        "    ],\n",
        "    \"easter_island_moai\": [\n",
        "        \"Exploring Rano Raraku, the volcanic crater quarry where hundreds of moai were carved and many still stand in various stages of completion, some half-buried\",\n",
        "        \"Visiting Ahu Tongariki to witness the impressive sight of fifteen restored moai standing on the largest ceremonial platform on the island, especially spectacular at sunrise\",\n",
        "        \"Relaxing or swimming at Anakena Beach, a picturesque white coral sand beach with palm trees, featuring Ahu Nau Nau with its well-preserved moai (some with topknots) and Ahu Ature Huki\",\n",
        "        \"Hiking to the rim of the Rano Kau volcano to see its stunning crater lake and visiting the nearby ceremonial village of Orongo, known for its Birdman cult petroglyphs and dramatic cliffside location\",\n",
        "        \"Discovering Ahu Akivi, a unique inland platform with seven moai that face the ocean, aligned with the equinox\",\n",
        "        \"Learning about Rapa Nui culture, history, and the mysteries of the moai at the Museo Antropológico Sebastián Englert in Hanga Roa\",\n",
        "        \"Photographing the diverse moai sites across the island, such as Ahu Tahai (near Hanga Roa, good for sunset), Puna Pau (quarry for the red scoria pukao topknots), and Te Pito Kura (site of a large fallen moai and a magnetic stone)\",\n",
        "        \"Attending a traditional Rapa Nui cultural performance (dance and music) or experiencing a Curanto (traditional underground feast)\",\n",
        "        \"Stargazing in the exceptionally clear night skies due to the island's remote location and lack of light pollution\",\n",
        "        \"Renting a car, scooter, or bicycle to independently explore the island's numerous archaeological sites and natural beauty, or taking a guided tour for deeper insights\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile clip_model_manager.py\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import List, Dict, Tuple, Optional, Union, Any\n",
        "from PIL import Image\n",
        "\n",
        "class CLIPModelManager:\n",
        "    \"\"\"\n",
        "    專門管理 CLIP 模型相關的操作，包括模型載入、設備管理、圖像和文本的特徵編碼等核心功能\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"ViT-B/16\", device: str = None):\n",
        "        \"\"\"\n",
        "        初始化 CLIP 模型管理器\n",
        "\n",
        "        Args:\n",
        "            model_name: CLIP模型名稱，默認為\"ViT-B/16\"\n",
        "            device: 運行設備，None則自動選擇\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # 設置運行設備\n",
        "        if device is None:\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.model = None\n",
        "        self.preprocess = None\n",
        "\n",
        "        self._initialize_model()\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        \"\"\"\n",
        "        初始化CLIP模型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Initializing CLIP model ({self.model_name}) on {self.device}\")\n",
        "            self.model, self.preprocess = clip.load(self.model_name, device=self.device)\n",
        "            self.logger.info(\"Successfully loaded CLIP model\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading CLIP model: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def encode_image(self, image_input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        編碼圖像特徵\n",
        "\n",
        "        Args:\n",
        "            image_input: 預處理後的圖像張量\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 標準化後的圖像特徵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                image_features = self.model.encode_image(image_input)\n",
        "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "                return image_features\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error encoding image features: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def encode_text_batch(self, text_prompts: List[str], batch_size: int = 128) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        批量編碼文本特徵，避免CUDA內存問題\n",
        "\n",
        "        Args:\n",
        "            text_prompts: 文本提示列表\n",
        "            batch_size: 批處理大小\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 標準化後的文本特徵\n",
        "        \"\"\"\n",
        "        if not text_prompts:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                features_list = []\n",
        "\n",
        "                for i in range(0, len(text_prompts), batch_size):\n",
        "                    batch_prompts = text_prompts[i:i+batch_size]\n",
        "                    text_tokens = clip.tokenize(batch_prompts).to(self.device)\n",
        "                    batch_features = self.model.encode_text(text_tokens)\n",
        "                    batch_features = batch_features / batch_features.norm(dim=-1, keepdim=True)\n",
        "                    features_list.append(batch_features)\n",
        "\n",
        "                # 連接所有批次\n",
        "                if len(features_list) > 1:\n",
        "                    text_features = torch.cat(features_list, dim=0)\n",
        "                else:\n",
        "                    text_features = features_list[0]\n",
        "\n",
        "                return text_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error encoding text features: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def encode_single_text(self, text_prompts: List[str]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        編碼單個文本批次的特徵\n",
        "\n",
        "        Args:\n",
        "            text_prompts: 文本提示列表\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 標準化後的文本特徵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                text_tokens = clip.tokenize(text_prompts).to(self.device)\n",
        "                text_features = self.model.encode_text(text_tokens)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "                return text_features\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error encoding single text batch: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def calculate_similarity(self, image_features: torch.Tensor, text_features: torch.Tensor) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        計算圖像和文本特徵之間的相似度\n",
        "\n",
        "        Args:\n",
        "            image_features: 圖像特徵張量\n",
        "            text_features: 文本特徵張量\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: 相似度分數數組\n",
        "        \"\"\"\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "                similarity = similarity.cpu().numpy() if self.device == \"cuda\" else similarity.numpy()\n",
        "                return similarity\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating similarity: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def preprocess_image(self, image: Union[Image.Image, np.ndarray]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        預處理圖像以供CLIP模型使用\n",
        "\n",
        "        Args:\n",
        "            image: PIL圖像或numpy數組\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 預處理後的圖像張量\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "            return image_input\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error preprocessing image: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def process_image_region(self, image: Union[Image.Image, np.ndarray], box: List[float]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        處理圖像的特定區域\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            box: 邊界框 [x1, y1, x2, y2]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 區域圖像的特徵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 裁剪區域\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cropped_image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "            # 預處理並編碼\n",
        "            image_input = self.preprocess_image(cropped_image)\n",
        "            image_features = self.encode_image(image_input)\n",
        "\n",
        "            return image_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing image region: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def batch_process_regions(self, image: Union[Image.Image, np.ndarray],\n",
        "                             boxes: List[List[float]]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        批量處理多個圖像區域\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            boxes: 邊界框列表\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: 所有區域的圖像特徵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # ensure PIL format\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            if not boxes:\n",
        "                return torch.empty(0)\n",
        "\n",
        "            # 裁剪並預處理所有區域\n",
        "            cropped_inputs = []\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                cropped_image = image.crop((x1, y1, x2, y2))\n",
        "                processed_image = self.preprocess(cropped_image).unsqueeze(0)\n",
        "                cropped_inputs.append(processed_image)\n",
        "\n",
        "            # 批量處理\n",
        "            batch_tensor = torch.cat(cropped_inputs).to(self.device)\n",
        "            image_features = self.encode_image(batch_tensor)\n",
        "\n",
        "            return image_features\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error batch processing regions: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def is_model_loaded(self) -> bool:\n",
        "        \"\"\"\n",
        "        檢查模型是否已成功載入\n",
        "\n",
        "        Returns:\n",
        "            bool: 模型載入狀態\n",
        "        \"\"\"\n",
        "        return self.model is not None and self.preprocess is not None\n",
        "\n",
        "    def get_device(self) -> str:\n",
        "        \"\"\"\n",
        "        獲取當前設備\n",
        "\n",
        "        Returns:\n",
        "            str: 設備名稱\n",
        "        \"\"\"\n",
        "        return self.device\n",
        "\n",
        "    def get_model_name(self) -> str:\n",
        "        \"\"\"\n",
        "        獲取模型名稱\n",
        "\n",
        "        Returns:\n",
        "            str: 模型名稱\n",
        "        \"\"\"\n",
        "        return self.model_name"
      ],
      "metadata": {
        "id": "7DvjDbvJsuBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb7b5f5-577c-4b68-bf37-87dab20c0c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing clip_model_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile landmark_data_manager.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import List, Dict, Tuple, Optional, Union, Any\n",
        "\n",
        "# from landmark_data import ALL_LANDMARKS, get_all_landmark_prompts\n",
        "# from landmark_activities import LANDMARK_ACTIVITIES\n",
        "\n",
        "class LandmarkDataManager:\n",
        "    \"\"\"\n",
        "    專門處理地標數據的載入、管理和查詢功能，包括地標信息、提示詞和活動建議\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        initialize landmark related\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.landmark_data = {}\n",
        "        self.landmark_prompts = []\n",
        "        self.landmark_id_to_index = {}\n",
        "        self.is_enabled = False\n",
        "\n",
        "        self._load_landmark_data()\n",
        "\n",
        "    def _load_landmark_data(self):\n",
        "        \"\"\"\n",
        "        載入地標數據和相關資訊\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.landmark_data = ALL_LANDMARKS\n",
        "            self.landmark_prompts = get_all_landmark_prompts()\n",
        "            self.logger.info(f\"Loaded {len(self.landmark_prompts)} landmark prompts for classification\")\n",
        "\n",
        "            # 創建地標ID到索引的映射，可快速查找\n",
        "            self.landmark_id_to_index = {landmark_id: i for i, landmark_id in enumerate(ALL_LANDMARKS.keys())}\n",
        "\n",
        "            self.is_enabled = True\n",
        "            self.logger.info(f\"Successfully loaded landmark data with {len(self.landmark_data)} landmarks\")\n",
        "\n",
        "        except ImportError:\n",
        "            self.logger.warning(\"landmark_data.py not found. Landmark classification will be limited\")\n",
        "            self.landmark_data = {}\n",
        "            self.landmark_prompts = []\n",
        "            self.landmark_id_to_index = {}\n",
        "            self.is_enabled = False\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading landmark data: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            self.landmark_data = {}\n",
        "            self.landmark_prompts = []\n",
        "            self.landmark_id_to_index = {}\n",
        "            self.is_enabled = False\n",
        "\n",
        "    def get_landmark_prompts(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取所有地標提示詞\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 地標提示詞列表\n",
        "        \"\"\"\n",
        "        return self.landmark_prompts\n",
        "\n",
        "    def get_landmark_by_id(self, landmark_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        根據地標ID獲取地標信息\n",
        "\n",
        "        Args:\n",
        "            landmark_id: Landmark ID\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 地標詳細信息\n",
        "        \"\"\"\n",
        "        return self.landmark_data.get(landmark_id, {})\n",
        "\n",
        "    def get_landmark_by_index(self, index: int) -> Tuple[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        根據索引獲取地標信息\n",
        "\n",
        "        Args:\n",
        "            index: 地標在列表中的索引\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, Dict[str, Any]]: (地標ID, 地標info)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            landmark_ids = list(self.landmark_data.keys())\n",
        "            if 0 <= index < len(landmark_ids):\n",
        "                landmark_id = landmark_ids[index]\n",
        "                return landmark_id, self.landmark_data[landmark_id]\n",
        "            else:\n",
        "                self.logger.warning(f\"Index {index} out of range for landmark data\")\n",
        "                return None, {}\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting landmark by index {index}: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return None, {}\n",
        "\n",
        "    def get_landmark_index(self, landmark_id: str) -> Optional[int]:\n",
        "        \"\"\"\n",
        "        獲取地標ID對應的index\n",
        "\n",
        "        Args:\n",
        "            landmark_id: 地標ID\n",
        "\n",
        "        Returns:\n",
        "            Optional[int]: 索引，如果不存在則返回None\n",
        "        \"\"\"\n",
        "        return self.landmark_id_to_index.get(landmark_id)\n",
        "\n",
        "    def determine_landmark_type(self, landmark_id: str) -> str:\n",
        "        \"\"\"\n",
        "        自動判斷地標類型，基於地標數據和命名\n",
        "\n",
        "        Args:\n",
        "            landmark_id: 地標ID\n",
        "\n",
        "        Returns:\n",
        "            str: 地標類型，用於調整閾值\n",
        "        \"\"\"\n",
        "        if not landmark_id:\n",
        "            return \"building\"  # 預設類型\n",
        "\n",
        "        try:\n",
        "            # 獲取地標詳細數據\n",
        "            landmark_info = self.landmark_data.get(landmark_id, {})\n",
        "\n",
        "            # 獲取地標相關文本\n",
        "            landmark_id_lower = landmark_id.lower()\n",
        "            landmark_name = landmark_info.get(\"name\", \"\").lower()\n",
        "            landmark_location = landmark_info.get(\"location\", \"\").lower()\n",
        "            landmark_aliases = [alias.lower() for alias in landmark_info.get(\"aliases\", [])]\n",
        "\n",
        "            # 合併所有文本數據用於特徵判斷\n",
        "            combined_text = \" \".join([landmark_id_lower, landmark_name] + landmark_aliases)\n",
        "\n",
        "            # 地標類型的特色特徵\n",
        "            type_features = {\n",
        "                \"skyscraper\": [\"skyscraper\", \"tall\", \"tower\", \"高樓\", \"摩天\", \"大厦\", \"タワー\"],\n",
        "                \"tower\": [\"tower\", \"bell\", \"clock\", \"塔\", \"鐘樓\", \"タワー\", \"campanile\"],\n",
        "                \"monument\": [\"monument\", \"memorial\", \"statue\", \"紀念\", \"雕像\", \"像\", \"memorial\"],\n",
        "                \"natural\": [\"mountain\", \"lake\", \"canyon\", \"falls\", \"beach\", \"山\", \"湖\", \"峽谷\", \"瀑布\", \"海灘\"],\n",
        "                \"temple\": [\"temple\", \"shrine\", \"寺\", \"神社\", \"廟\"],\n",
        "                \"palace\": [\"palace\", \"castle\", \"宮\", \"城\", \"皇宮\", \"宫殿\"],\n",
        "                \"distinctive\": [\"unique\", \"leaning\", \"slanted\", \"傾斜\", \"斜\", \"獨特\", \"傾く\"]\n",
        "            }\n",
        "\n",
        "            # 檢查是否位於亞洲地區\n",
        "            asian_regions = [\"china\", \"japan\", \"korea\", \"taiwan\", \"singapore\", \"vietnam\", \"thailand\",\n",
        "                            \"hong kong\", \"中國\", \"日本\", \"韓國\", \"台灣\", \"新加坡\", \"越南\", \"泰國\", \"香港\"]\n",
        "            is_asian = any(region in landmark_location for region in asian_regions)\n",
        "\n",
        "            # 判斷地標類型\n",
        "            best_type = None\n",
        "            max_matches = 0\n",
        "\n",
        "            for type_name, features in type_features.items():\n",
        "                # 計算特徵詞匹配數量\n",
        "                matches = sum(1 for feature in features if feature in combined_text)\n",
        "                if matches > max_matches:\n",
        "                    max_matches = matches\n",
        "                    best_type = type_name\n",
        "\n",
        "            # 處理亞洲地區特例\n",
        "            if is_asian and best_type == \"tower\":\n",
        "                best_type = \"skyscraper\"  # 亞洲地區的塔型建築閾值較低\n",
        "\n",
        "            # 特例處理：檢測傾斜建築\n",
        "            if any(term in combined_text for term in [\"leaning\", \"slanted\", \"tilt\", \"inclined\", \"斜\", \"傾斜\"]):\n",
        "                return \"distinctive\"  # 傾斜建築需要特殊處理\n",
        "\n",
        "            return best_type if best_type and max_matches > 0 else \"building\"  # 預設為一般建築\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error determining landmark type for {landmark_id}: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return \"building\"\n",
        "\n",
        "    def extract_landmark_specific_info(self, landmark_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        提取特定地標的詳細信息，包括特色模板和活動建議\n",
        "\n",
        "        Args:\n",
        "            landmark_id: 地標ID\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 地標特定信息\n",
        "        \"\"\"\n",
        "        if not landmark_id or landmark_id == \"unknown\":\n",
        "            return {\"has_specific_activities\": False}\n",
        "\n",
        "        specific_info = {\"has_specific_activities\": False}\n",
        "\n",
        "        try:\n",
        "            # 從 landmark_data 中提取基本信息\n",
        "            landmark_data_source = self.landmark_data.get(landmark_id)\n",
        "\n",
        "            # 處理地標基本數據\n",
        "            if landmark_data_source:\n",
        "                # 提取正確的地標名稱\n",
        "                if \"name\" in landmark_data_source:\n",
        "                    specific_info[\"landmark_name\"] = landmark_data_source[\"name\"]\n",
        "\n",
        "                # 提取所有可用的 prompts 作為特色模板\n",
        "                if \"prompts\" in landmark_data_source:\n",
        "                    specific_info[\"feature_templates\"] = landmark_data_source[\"prompts\"][:5]\n",
        "                    specific_info[\"primary_template\"] = landmark_data_source[\"prompts\"][0]\n",
        "\n",
        "                # 提取別名info\n",
        "                if \"aliases\" in landmark_data_source:\n",
        "                    specific_info[\"aliases\"] = landmark_data_source[\"aliases\"]\n",
        "\n",
        "                # 提取位置信息\n",
        "                if \"location\" in landmark_data_source:\n",
        "                    specific_info[\"location\"] = landmark_data_source[\"location\"]\n",
        "\n",
        "                # 提取其他相關信息\n",
        "                for key in [\"year_built\", \"architectural_style\", \"significance\", \"description\"]:\n",
        "                    if key in landmark_data_source:\n",
        "                        specific_info[key] = landmark_data_source[key]\n",
        "\n",
        "            # 嘗試從 LANDMARK_ACTIVITIES 中提取活動建議\n",
        "            try:\n",
        "                if landmark_id in LANDMARK_ACTIVITIES:\n",
        "                    activities = LANDMARK_ACTIVITIES[landmark_id]\n",
        "                    specific_info[\"landmark_specific_activities\"] = activities\n",
        "                    specific_info[\"has_specific_activities\"] = True\n",
        "                    self.logger.info(f\"Found {len(activities)} specific activities for landmark {landmark_id}\")\n",
        "                else:\n",
        "                    self.logger.info(f\"No specific activities found for landmark {landmark_id} in LANDMARK_ACTIVITIES\")\n",
        "                    specific_info[\"has_specific_activities\"] = False\n",
        "            except ImportError:\n",
        "                self.logger.warning(\"Could not import LANDMARK_ACTIVITIES from landmark_activities\")\n",
        "                specific_info[\"has_specific_activities\"] = False\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error loading landmark activities for {landmark_id}: {e}\")\n",
        "                self.logger.error(traceback.format_exc())\n",
        "                specific_info[\"has_specific_activities\"] = False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting landmark specific info for {landmark_id}: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "        return specific_info\n",
        "\n",
        "    def get_landmark_count(self) -> int:\n",
        "        \"\"\"\n",
        "        獲取地標總數\n",
        "\n",
        "        Returns:\n",
        "            int: 地標數量\n",
        "        \"\"\"\n",
        "        return len(self.landmark_data)\n",
        "\n",
        "    def is_landmark_enabled(self) -> bool:\n",
        "        \"\"\"\n",
        "        檢查地標功能是否啟用\n",
        "\n",
        "        Returns:\n",
        "            bool: 地標功能狀態\n",
        "        \"\"\"\n",
        "        return self.is_enabled\n",
        "\n",
        "    def get_all_landmark_ids(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        獲取所有地標ID列表\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 地標ID列表\n",
        "        \"\"\"\n",
        "        return list(self.landmark_data.keys())\n",
        "\n",
        "    def validate_landmark_id(self, landmark_id: str) -> bool:\n",
        "        \"\"\"\n",
        "        驗證地標ID是否有效\n",
        "\n",
        "        Args:\n",
        "            landmark_id: 要驗證的地標ID\n",
        "\n",
        "        Returns:\n",
        "            bool: ID是否有效\n",
        "        \"\"\"\n",
        "        return landmark_id in self.landmark_data"
      ],
      "metadata": {
        "id": "OQcp_Ef1stw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818acd16-3f86-4bcd-b507-ec3521bb98f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing landmark_data_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile image_analyzer.py\n",
        "\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import List, Dict, Tuple, Optional, Union, Any\n",
        "from PIL import Image\n",
        "\n",
        "class ImageAnalyzer:\n",
        "    \"\"\"\n",
        "    專注於圖像分析和預處理，包括多尺度金字塔分析、視角分析、建築特徵識別和圖像增強等功能\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        初始化圖像分析器\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def get_image_hash(self, image: Union[Image.Image, np.ndarray]) -> int:\n",
        "        \"\"\"\n",
        "        為圖像生成簡單的 hash 值用於快取\n",
        "\n",
        "        Args:\n",
        "            image: PIL Image 或 numpy 數組\n",
        "\n",
        "        Returns:\n",
        "            int: 圖像的 hash 值\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(image, np.ndarray):\n",
        "                # 對於 numpy 數組，降採樣並計算簡單 hash\n",
        "                small_img = image[::10, ::10] if image.ndim == 3 else image\n",
        "                return hash(small_img.tobytes())\n",
        "            else:\n",
        "                # 對於 PIL 圖像，調整大小後轉換為 bytes\n",
        "                small_img = image.resize((32, 32))\n",
        "                return hash(small_img.tobytes())\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating image hash: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return 0\n",
        "\n",
        "    def enhance_features(self, image: Union[Image.Image, np.ndarray]) -> Image.Image:\n",
        "        \"\"\"\n",
        "        增強圖像特徵以改善地標檢測\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "\n",
        "        Returns:\n",
        "            PIL.Image: 增強後的圖像\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # ensure PIL format\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 轉換為numpy進行處理\n",
        "            img_array = np.array(image)\n",
        "\n",
        "            # 跳過灰度圖像的處理\n",
        "            if len(img_array.shape) < 3:\n",
        "                return image\n",
        "\n",
        "            # 應用自適應對比度增強\n",
        "            try:\n",
        "                from skimage import color, exposure\n",
        "\n",
        "                # 轉換到LAB色彩空間\n",
        "                if img_array.shape[2] == 4:  # 處理RGBA\n",
        "                    img_array = img_array[:,:,:3]\n",
        "\n",
        "                lab = color.rgb2lab(img_array[:,:,:3] / 255.0)\n",
        "                l_channel = lab[:,:,0]\n",
        "\n",
        "                # 增強L通道的對比度\n",
        "                p2, p98 = np.percentile(l_channel, (2, 98))\n",
        "                l_channel_enhanced = exposure.rescale_intensity(l_channel, in_range=(p2, p98))\n",
        "\n",
        "                # 替換L通道並轉換回RGB\n",
        "                lab[:,:,0] = l_channel_enhanced\n",
        "                enhanced_img = color.lab2rgb(lab) * 255.0\n",
        "                enhanced_img = enhanced_img.astype(np.uint8)\n",
        "\n",
        "                return Image.fromarray(enhanced_img)\n",
        "\n",
        "            except ImportError:\n",
        "                self.logger.warning(\"skimage not available for feature enhancement\")\n",
        "                return image\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in feature enhancement: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return image\n",
        "\n",
        "    def analyze_viewpoint(self, image: Union[Image.Image, np.ndarray],\n",
        "                         clip_model_manager) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        分析圖像視角以調整檢測參數\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            clip_model_manager: CLIP模型管理器實例\n",
        "\n",
        "        Returns:\n",
        "            Dict: 視角分析結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            viewpoint_prompts = {\n",
        "                \"aerial_view\": \"an aerial view from above looking down\",\n",
        "                \"street_level\": \"a street level view looking up at a tall structure\",\n",
        "                \"eye_level\": \"an eye-level horizontal view of a landmark\",\n",
        "                \"distant\": \"a distant view of a landmark on the horizon\",\n",
        "                \"close_up\": \"a close-up detailed view of architectural features\",\n",
        "                \"interior\": \"an interior view inside a structure\",\n",
        "                \"angled_view\": \"an angled view of a structure\",\n",
        "                \"low_angle\": \"a low angle view looking up at a building\"\n",
        "            }\n",
        "\n",
        "            # 計算相似度分數\n",
        "            viewpoint_scores = self.calculate_similarity_scores(image, viewpoint_prompts, clip_model_manager)\n",
        "\n",
        "            # 找到主要視角\n",
        "            dominant_viewpoint = max(viewpoint_scores.items(), key=lambda x: x[1])\n",
        "\n",
        "            return {\n",
        "                \"viewpoint_scores\": viewpoint_scores,\n",
        "                \"dominant_viewpoint\": dominant_viewpoint[0],\n",
        "                \"confidence\": dominant_viewpoint[1]\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in viewpoint analysis: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"viewpoint_scores\": {},\n",
        "                \"dominant_viewpoint\": \"eye_level\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "\n",
        "    def calculate_similarity_scores(self, image: Union[Image.Image, np.ndarray],\n",
        "                                  prompts: Dict[str, str],\n",
        "                                  clip_model_manager) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        計算圖像與一組特定提示之間的相似度分數\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            prompts: 提示詞字典 {名稱: 提示文本}\n",
        "            clip_model_manager: CLIP模型管理器實例\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 每個提示的相似度分數\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # ensure PIL format\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # preprocess image\n",
        "            image_input = clip_model_manager.preprocess_image(image)\n",
        "\n",
        "            # get image features\n",
        "            image_features = clip_model_manager.encode_image(image_input)\n",
        "\n",
        "            # 計算與每個提示的similarity\n",
        "            scores = {}\n",
        "            prompt_texts = list(prompts.values())\n",
        "            prompt_features = clip_model_manager.encode_single_text(prompt_texts)\n",
        "\n",
        "            # 計算相似度\n",
        "            similarity = clip_model_manager.calculate_similarity(image_features, prompt_features)\n",
        "\n",
        "            # result\n",
        "            for i, (name, _) in enumerate(prompts.items()):\n",
        "                scores[name] = float(similarity[0][i])\n",
        "\n",
        "            return scores\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating similarity scores: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {}\n",
        "\n",
        "    def analyze_architectural_features(self, image: Union[Image.Image, np.ndarray],\n",
        "                                     clip_model_manager) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        分析圖像中結構的建築特徵，不硬編碼特定地標\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            clip_model_manager: CLIP模型管理器實例\n",
        "\n",
        "        Returns:\n",
        "            Dict: 建築特徵分析結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 定義通用建築特徵提示，適用於所有類型的地標\n",
        "            architecture_prompts = {\n",
        "                \"tall_structure\": \"a tall vertical structure standing alone\",\n",
        "                \"tiered_building\": \"a building with multiple stacked tiers or segments\",\n",
        "                \"historical_structure\": \"a building with historical architectural elements\",\n",
        "                \"modern_design\": \"a modern structure with contemporary architectural design\",\n",
        "                \"segmented_exterior\": \"a structure with visible segmented or sectioned exterior\",\n",
        "                \"viewing_platform\": \"a tall structure with observation area at the top\",\n",
        "                \"time_display\": \"a structure with timepiece features\",\n",
        "                \"glass_facade\": \"a building with prominent glass exterior surfaces\",\n",
        "                \"memorial_structure\": \"a monument or memorial structure\",\n",
        "                \"ancient_construction\": \"ancient constructed elements or archaeological features\",\n",
        "                \"natural_landmark\": \"a natural geographic formation or landmark\",\n",
        "                \"slanted_design\": \"a structure with non-vertical or leaning profile\"\n",
        "            }\n",
        "\n",
        "            # 計算與通用建築模式的相似度分數\n",
        "            context_scores = self.calculate_similarity_scores(image, architecture_prompts, clip_model_manager)\n",
        "\n",
        "            # 確定最相關的建築特徵\n",
        "            top_features = sorted(context_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "            # 計算特徵置信度\n",
        "            context_confidence = sum(score for _, score in top_features) / 3\n",
        "\n",
        "            # 根據頂級特徵確定主要建築類別\n",
        "            architectural_categories = {\n",
        "                \"tower\": [\"tall_structure\", \"viewing_platform\", \"time_display\"],\n",
        "                \"skyscraper\": [\"tall_structure\", \"modern_design\", \"glass_facade\"],\n",
        "                \"historical\": [\"historical_structure\", \"ancient_construction\", \"memorial_structure\"],\n",
        "                \"natural\": [\"natural_landmark\"],\n",
        "                \"distinctive\": [\"tiered_building\", \"segmented_exterior\", \"slanted_design\"]\n",
        "            }\n",
        "\n",
        "            # 根據頂級特徵為每個類別評分\n",
        "            category_scores = {}\n",
        "            for category, features in architectural_categories.items():\n",
        "                category_score = 0\n",
        "                for feature, score in context_scores.items():\n",
        "                    if feature in features:\n",
        "                        category_score += score\n",
        "                category_scores[category] = category_score\n",
        "\n",
        "            primary_category = max(category_scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "            return {\n",
        "                \"architectural_features\": top_features,\n",
        "                \"context_confidence\": context_confidence,\n",
        "                \"primary_category\": primary_category,\n",
        "                \"category_scores\": category_scores\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in architectural feature analysis: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"architectural_features\": [],\n",
        "                \"context_confidence\": 0.0,\n",
        "                \"primary_category\": \"building\",\n",
        "                \"category_scores\": {}\n",
        "            }\n",
        "\n",
        "    def perform_pyramid_analysis(self, image: Union[Image.Image, np.ndarray],\n",
        "                               clip_model_manager, landmark_data_manager,\n",
        "                               levels: int = 4, base_threshold: float = 0.25,\n",
        "                               aspect_ratios: List[float] = [1.0, 0.75, 1.5]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        對圖像執行多尺度金字塔分析以改善地標檢測\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            clip_model_manager: CLIP模型管理器實例\n",
        "            landmark_data_manager: 地標數據管理器實例\n",
        "            levels: 金字塔層級數\n",
        "            base_threshold: 基礎置信度閾值\n",
        "            aspect_ratios: 不同縱橫比列表\n",
        "\n",
        "        Returns:\n",
        "            Dict: 金字塔分析結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            width, height = image.size\n",
        "            pyramid_results = []\n",
        "\n",
        "            # 獲取預計算的地標文本特徵\n",
        "            landmark_prompts = landmark_data_manager.get_landmark_prompts()\n",
        "            if not landmark_prompts:\n",
        "                return {\n",
        "                    \"is_landmark\": False,\n",
        "                    \"results\": [],\n",
        "                    \"best_result\": None\n",
        "                }\n",
        "\n",
        "            landmark_text_features = clip_model_manager.encode_text_batch(landmark_prompts)\n",
        "\n",
        "            # 對每個縮放和縱橫比組合進行處理\n",
        "            for level in range(levels):\n",
        "                # 計算縮放因子\n",
        "                scale_factor = 1.0 - (level * 0.2)\n",
        "\n",
        "                for aspect_ratio in aspect_ratios:\n",
        "                    # 計算新尺寸，保持面積近似不變\n",
        "                    if aspect_ratio != 1.0:\n",
        "                        # 保持面積近似不變的情況下調整縱橫比\n",
        "                        new_width = int(width * scale_factor * (1/aspect_ratio)**0.5)\n",
        "                        new_height = int(height * scale_factor * aspect_ratio**0.5)\n",
        "                    else:\n",
        "                        new_width = int(width * scale_factor)\n",
        "                        new_height = int(height * scale_factor)\n",
        "\n",
        "                    # 調整圖像大小\n",
        "                    scaled_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "                    # 預處理圖像\n",
        "                    image_input = clip_model_manager.preprocess_image(scaled_image)\n",
        "\n",
        "                    # 獲取圖像特徵\n",
        "                    image_features = clip_model_manager.encode_image(image_input)\n",
        "\n",
        "                    # 計算相似度\n",
        "                    similarity = clip_model_manager.calculate_similarity(image_features, landmark_text_features)\n",
        "\n",
        "                    # 找到最佳匹配\n",
        "                    best_idx = similarity[0].argmax().item()\n",
        "                    best_score = similarity[0][best_idx]\n",
        "\n",
        "                    if best_score >= base_threshold:\n",
        "                        landmark_id, landmark_info = landmark_data_manager.get_landmark_by_index(best_idx)\n",
        "                        if landmark_id:\n",
        "                            pyramid_results.append({\n",
        "                                \"landmark_id\": landmark_id,\n",
        "                                \"landmark_name\": landmark_info.get(\"name\", \"Unknown\"),\n",
        "                                \"confidence\": float(best_score),\n",
        "                                \"scale_factor\": scale_factor,\n",
        "                                \"aspect_ratio\": aspect_ratio,\n",
        "                                \"location\": landmark_info.get(\"location\", \"Unknown Location\")\n",
        "                            })\n",
        "\n",
        "            # 按置信度排序\n",
        "            pyramid_results.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
        "\n",
        "            return {\n",
        "                \"is_landmark\": len(pyramid_results) > 0,\n",
        "                \"results\": pyramid_results,\n",
        "                \"best_result\": pyramid_results[0] if pyramid_results else None\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in pyramid analysis: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"is_landmark\": False,\n",
        "                \"results\": [],\n",
        "                \"best_result\": None\n",
        "            }"
      ],
      "metadata": {
        "id": "i-BxGP3-tBZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942b8b8a-eb7e-465c-90b1-cb57af9689f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing image_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile confidence_manager.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "class ConfidenceManager:\n",
        "    \"\"\"\n",
        "    專門管理信心度相關邏輯，包括動態閾值調整、信心度乘數管理和地標類型特定的閾值處理\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        初始化置信度管理器\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # 初始化批處理參數\n",
        "        self.batch_size = 16  # 默認批處理大小\n",
        "\n",
        "        # 置信度閾值乘數配置\n",
        "        self.confidence_threshold_multipliers = {\n",
        "            \"close_up\": 0.9,     # 近景標準閾值\n",
        "            \"partial\": 0.6,      # 部分可見降低閾值要求\n",
        "            \"distant\": 0.5,      # 遠景更低閾值要求\n",
        "            \"full_image\": 0.7    # 整張圖像需要更高閾值\n",
        "        }\n",
        "\n",
        "        # 地標類型閾值配置\n",
        "        self.landmark_type_thresholds = {\n",
        "            \"tower\": 0.5,         # 塔型建築需要更高閾值\n",
        "            \"skyscraper\": 0.4,    # 摩天大樓使用較低閾值\n",
        "            \"building\": 0.55,     # 一般的建築物閾值略微降低\n",
        "            \"monument\": 0.5,      # 紀念碑閾值\n",
        "            \"natural\": 0.6        # 自然景觀可以使用較低閾值\n",
        "        }\n",
        "\n",
        "    def set_batch_size(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        設置批處理大小\n",
        "\n",
        "        Args:\n",
        "            batch_size: 新的批處理大小\n",
        "        \"\"\"\n",
        "        self.batch_size = max(1, batch_size)\n",
        "        self.logger.info(f\"Batch size set to {self.batch_size}\")\n",
        "\n",
        "    def adjust_confidence_threshold(self, detection_type: str, multiplier: float):\n",
        "        \"\"\"\n",
        "        調整特定檢測類型的信心度的threshold\n",
        "\n",
        "        Args:\n",
        "            detection_type: 檢測類型 ('close_up', 'partial', 'distant', 'full_image')\n",
        "            multiplier: 置信度閾值乘數\n",
        "        \"\"\"\n",
        "        if detection_type in self.confidence_threshold_multipliers:\n",
        "            self.confidence_threshold_multipliers[detection_type] = max(0.1, min(1.5, multiplier))\n",
        "            self.logger.info(f\"Adjusted confidence threshold multiplier for {detection_type} to {multiplier}\")\n",
        "        else:\n",
        "            self.logger.warning(f\"Unknown detection type: {detection_type}\")\n",
        "\n",
        "    def get_detection_type_multiplier(self, detection_type: str) -> float:\n",
        "        \"\"\"\n",
        "        獲取檢測類型的置信度乘數\n",
        "\n",
        "        Args:\n",
        "            detection_type: 檢測類型\n",
        "\n",
        "        Returns:\n",
        "            float: 置信度乘數\n",
        "        \"\"\"\n",
        "        return self.confidence_threshold_multipliers.get(detection_type, 1.0)\n",
        "\n",
        "    def get_landmark_type_threshold(self, landmark_type: str) -> float:\n",
        "        \"\"\"\n",
        "        獲取地標類型的閾值\n",
        "\n",
        "        Args:\n",
        "            landmark_type: 地標類型\n",
        "\n",
        "        Returns:\n",
        "            float: 地標類型閾值\n",
        "        \"\"\"\n",
        "        return self.landmark_type_thresholds.get(landmark_type, 0.5)\n",
        "\n",
        "    def calculate_adjusted_threshold(self, base_threshold: float, detection_type: str) -> float:\n",
        "        \"\"\"\n",
        "        根據檢測類型計算調整後的閾值\n",
        "\n",
        "        Args:\n",
        "            base_threshold: 基礎閾值\n",
        "            detection_type: 檢測type\n",
        "\n",
        "        Returns:\n",
        "            float: 調整後的閾值\n",
        "        \"\"\"\n",
        "        try:\n",
        "            base_multiplier = self.get_detection_type_multiplier(detection_type)\n",
        "            adjusted_threshold = base_threshold * base_multiplier\n",
        "            return adjusted_threshold\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating adjusted threshold: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return base_threshold\n",
        "\n",
        "    def calculate_final_threshold(self, base_threshold: float, detection_type: str,\n",
        "                                landmark_type: str) -> float:\n",
        "        \"\"\"\n",
        "        計算最終閾值，結合檢測類型和地標類型\n",
        "\n",
        "        Args:\n",
        "            base_threshold: 基礎閾值\n",
        "            detection_type: 檢測type\n",
        "            landmark_type: 地標type\n",
        "\n",
        "        Returns:\n",
        "            float: 最終閾值\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 根據檢測類型調整\n",
        "            adjusted_threshold = self.calculate_adjusted_threshold(base_threshold, detection_type)\n",
        "\n",
        "            # 根據地標類型進一步調整\n",
        "            if landmark_type == \"distinctive\":\n",
        "                # 特殊建築的閾值降低25%\n",
        "                type_multiplier = 0.75\n",
        "            else:\n",
        "                # 使用已有的類型閾值\n",
        "                type_multiplier = self.get_landmark_type_threshold(landmark_type) / 0.5\n",
        "\n",
        "            final_threshold = adjusted_threshold * type_multiplier\n",
        "            return final_threshold\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating final threshold: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return base_threshold\n",
        "\n",
        "    def evaluate_confidence(self, confidence: float, threshold: float) -> bool:\n",
        "        \"\"\"\n",
        "        評估置信度是否達到閾值\n",
        "\n",
        "        Args:\n",
        "            confidence: 信心度score\n",
        "            threshold: 閾值\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否達到閾值\n",
        "        \"\"\"\n",
        "        return confidence >= threshold\n",
        "\n",
        "    def apply_architectural_boost(self, confidence: float, architectural_analysis: Dict[str, Any],\n",
        "                                landmark_id: str) -> float:\n",
        "        \"\"\"\n",
        "        根據建築特徵分析調整信心度\n",
        "\n",
        "        Args:\n",
        "            confidence: 原始置信度\n",
        "            architectural_analysis: 建築特徵分析結果\n",
        "            landmark_id: 地標ID\n",
        "\n",
        "        Returns:\n",
        "            float: 調整後的信心度\n",
        "        \"\"\"\n",
        "        try:\n",
        "            confidence_boost = 0\n",
        "            landmark_id_lower = landmark_id.lower()\n",
        "\n",
        "            top_features = architectural_analysis.get(\"architectural_features\", [])\n",
        "            primary_category = architectural_analysis.get(\"primary_category\", \"\")\n",
        "\n",
        "            # 使用主要建築類別來調整置信度，使用通用條件而非特定地標名稱\n",
        "            if primary_category == \"tower\" and any(term in landmark_id_lower for term in [\"tower\", \"spire\", \"needle\"]):\n",
        "                confidence_boost += 0.05\n",
        "            elif primary_category == \"skyscraper\" and any(term in landmark_id_lower for term in [\"building\", \"skyscraper\", \"tall\"]):\n",
        "                confidence_boost += 0.05\n",
        "            elif primary_category == \"historical\" and any(term in landmark_id_lower for term in [\"monument\", \"castle\", \"palace\", \"temple\"]):\n",
        "                confidence_boost += 0.05\n",
        "            elif primary_category == \"distinctive\" and any(term in landmark_id_lower for term in [\"unusual\", \"unique\", \"special\", \"famous\"]):\n",
        "                confidence_boost += 0.05\n",
        "\n",
        "            # 根據特定特徵進一步微調，使用通用特徵描述而非特定地標\n",
        "            for feature, score in top_features:\n",
        "                if feature == \"time_display\" and \"clock\" in landmark_id_lower:\n",
        "                    confidence_boost += 0.03\n",
        "                elif feature == \"segmented_exterior\" and \"segmented\" in landmark_id_lower:\n",
        "                    confidence_boost += 0.03\n",
        "                elif feature == \"slanted_design\" and \"leaning\" in landmark_id_lower:\n",
        "                    confidence_boost += 0.03\n",
        "\n",
        "            # 應用信心度調整\n",
        "            if confidence_boost > 0:\n",
        "                adjusted_confidence = confidence + confidence_boost\n",
        "                self.logger.info(f\"Boosted confidence by {confidence_boost:.2f} based on architectural features ({primary_category})\")\n",
        "                return adjusted_confidence\n",
        "\n",
        "            return confidence\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error applying architectural boost: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return confidence\n",
        "\n",
        "    def determine_detection_type_from_region(self, region_width: int, region_height: int,\n",
        "                                           image_width: int, image_height: int) -> str:\n",
        "        \"\"\"\n",
        "        根據區域大小自動判斷檢測類型\n",
        "\n",
        "        Args:\n",
        "            region_width: 區域寬度\n",
        "            region_height: 區域高度\n",
        "            image_width: 圖像寬度\n",
        "            image_height: 圖像高度\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            region_area_ratio = (region_width * region_height) / (image_width * image_height)\n",
        "\n",
        "            if region_area_ratio > 0.5:\n",
        "                return \"close_up\"\n",
        "            elif region_area_ratio > 0.2:\n",
        "                return \"partial\"\n",
        "            else:\n",
        "                return \"distant\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error determining detection type from region: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return \"partial\"\n",
        "\n",
        "    def adjust_detection_type_by_viewpoint(self, detection_type: str, dominant_viewpoint: str) -> str:\n",
        "        \"\"\"\n",
        "        根據視角調整檢測類型\n",
        "\n",
        "        Args:\n",
        "            detection_type: 原始檢測類型\n",
        "            dominant_viewpoint: 主要視角\n",
        "\n",
        "        Returns:\n",
        "            str: 調整後的檢測類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if dominant_viewpoint == \"close_up\" and detection_type != \"close_up\":\n",
        "                return \"close_up\"\n",
        "            elif dominant_viewpoint == \"distant\" and detection_type != \"distant\":\n",
        "                return \"distant\"\n",
        "            elif dominant_viewpoint == \"angled_view\":\n",
        "                return \"partial\"  # 角度視圖可能是部分可見\n",
        "            else:\n",
        "                return detection_type\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error adjusting detection type by viewpoint: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return detection_type\n",
        "\n",
        "    def get_batch_size(self) -> int:\n",
        "        \"\"\"\n",
        "        獲取當前批處理大小\n",
        "\n",
        "        Returns:\n",
        "            int: 批處理大小\n",
        "        \"\"\"\n",
        "        return self.batch_size\n",
        "\n",
        "    def get_all_threshold_multipliers(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        獲取所有置信度閾值乘數\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 閾值乘數字典\n",
        "        \"\"\"\n",
        "        return self.confidence_threshold_multipliers.copy()\n",
        "\n",
        "    def get_all_landmark_type_thresholds(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        獲取所有地標類型閾值\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, float]: 地標類型閾值字典\n",
        "        \"\"\"\n",
        "        return self.landmark_type_thresholds.copy()"
      ],
      "metadata": {
        "id": "m0IEYVSustuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7a52aa-9ca3-46d4-afe4-2a03343c4a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting confidence_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile result_cache_manager.py\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, Any, Tuple, Optional, Union\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class ResultCacheManager:\n",
        "    \"\"\"\n",
        "    專門處理結果快取和性能優化，包括快取策略管理、快取大小控制和快取命中率優化\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cache_max_size: int = 100):\n",
        "        \"\"\"\n",
        "        初始化結果快取管理器\n",
        "\n",
        "        Args:\n",
        "            cache_max_size: 最大快取項目數\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # 初始化結果快取\n",
        "        self.results_cache = {}  # 使用圖像hash作為鍵\n",
        "        self.cache_max_size = cache_max_size  # 最大快取項目數\n",
        "\n",
        "    def generate_cache_key(self, image_hash: int, additional_params: Tuple) -> Tuple:\n",
        "        \"\"\"\n",
        "        生成快取鍵\n",
        "\n",
        "        Args:\n",
        "            image_hash\n",
        "            additional_params: 附加參數元組\n",
        "\n",
        "        Returns:\n",
        "            Tuple: 快取鍵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return (image_hash, additional_params)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating cache key: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return (0, additional_params)\n",
        "\n",
        "    def get_region_cache_key(self, image_hash: int, box: Tuple[float, ...],\n",
        "                           detection_type: str) -> Tuple:\n",
        "        \"\"\"\n",
        "        生成區域分析的快取鍵\n",
        "\n",
        "        Args:\n",
        "            image_hash\n",
        "            box: 邊界框\n",
        "            detection_type: 檢測類型\n",
        "\n",
        "        Returns:\n",
        "            Tuple: 區域快取鍵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.generate_cache_key(image_hash, (tuple(box), detection_type))\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating region cache key: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return (0, (tuple(box), detection_type))\n",
        "\n",
        "    def get_image_cache_key(self, image_hash: int, analysis_type: str,\n",
        "                          detailed_analysis: bool = False) -> Tuple:\n",
        "        \"\"\"\n",
        "        生成整張圖像分析的快取鍵\n",
        "\n",
        "        Args:\n",
        "            image_hash: 圖像哈希值\n",
        "            analysis_type: 分析類型\n",
        "            detailed_analysis: 是否詳細分析\n",
        "\n",
        "        Returns:\n",
        "            Tuple: 圖像快取鍵\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.generate_cache_key(image_hash, (analysis_type, detailed_analysis))\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating image cache key: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return (0, (analysis_type, detailed_analysis))\n",
        "\n",
        "    def get_cached_result(self, cache_key: Tuple) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        獲取快取結果\n",
        "\n",
        "        Args:\n",
        "            cache_key: 快取鍵\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: 快取結果，如果不存在則返回None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.results_cache.get(cache_key)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting cached result: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return None\n",
        "\n",
        "    def set_cached_result(self, cache_key: Tuple, result: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        設置快取結果\n",
        "\n",
        "        Args:\n",
        "            cache_key: 快取鍵\n",
        "            result: 要快取的結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.results_cache[cache_key] = result\n",
        "            self.manage_cache_size()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error setting cached result: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "    def manage_cache_size(self):\n",
        "        \"\"\"\n",
        "        管理結果快取大小\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(self.results_cache) > self.cache_max_size:\n",
        "                oldest_key = next(iter(self.results_cache))\n",
        "                del self.results_cache[oldest_key]\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error managing cache size: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "    def clear_cache(self):\n",
        "        \"\"\"\n",
        "        清空快取\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.results_cache.clear()\n",
        "            self.logger.info(\"Cache cleared successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error clearing cache: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "    def get_cache_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取快取統計信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 快取統計信息\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                \"cache_size\": len(self.results_cache),\n",
        "                \"max_cache_size\": self.cache_max_size,\n",
        "                \"cache_usage_ratio\": len(self.results_cache) / self.cache_max_size if self.cache_max_size > 0 else 0\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting cache stats: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"cache_size\": 0,\n",
        "                \"max_cache_size\": self.cache_max_size,\n",
        "                \"cache_usage_ratio\": 0\n",
        "            }\n",
        "\n",
        "    def set_max_cache_size(self, max_size: int):\n",
        "        \"\"\"\n",
        "        設置最大快取大小\n",
        "\n",
        "        Args:\n",
        "            max_size: 新的最大快取大小\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.cache_max_size = max(1, max_size)\n",
        "            self.manage_cache_size()\n",
        "            self.logger.info(f\"Max cache size set to {self.cache_max_size}\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error setting max cache size: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "    def remove_cached_result(self, cache_key: Tuple) -> bool:\n",
        "        \"\"\"\n",
        "        移除特定的快取結果\n",
        "\n",
        "        Args:\n",
        "            cache_key: 快取鍵\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否成功移除\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if cache_key in self.results_cache:\n",
        "                del self.results_cache[cache_key]\n",
        "                return True\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error removing cached result: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return False\n",
        "\n",
        "    def is_cache_enabled(self) -> bool:\n",
        "        \"\"\"\n",
        "        檢查快取是否啟用\n",
        "\n",
        "        Returns:\n",
        "            bool: 快取啟用狀態\n",
        "        \"\"\"\n",
        "        return self.cache_max_size > 0\n",
        "\n",
        "    def get_cache_keys(self) -> list:\n",
        "        \"\"\"\n",
        "        獲取所有快取鍵\n",
        "\n",
        "        Returns:\n",
        "            list: 快取鍵列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return list(self.results_cache.keys())\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting cache keys: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return []\n",
        "\n",
        "    def has_cached_result(self, cache_key: Tuple) -> bool:\n",
        "        \"\"\"\n",
        "        檢查是否存在快取結果\n",
        "\n",
        "        Args:\n",
        "            cache_key: 快取鍵\n",
        "\n",
        "        Returns:\n",
        "            bool: 是否存在快取結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return cache_key in self.results_cache\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error checking cached result: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return False"
      ],
      "metadata": {
        "id": "LJjy2bGxstrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad7753b-1c4f-43a8-f797-42a48a7ad046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing result_cache_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile clip_zero_shot_classifier.py\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import List, Dict, Tuple, Optional, Union, Any\n",
        "\n",
        "# from clip_model_manager import CLIPModelManager\n",
        "# from landmark_data_manager import LandmarkDataManager\n",
        "# from image_analyzer import ImageAnalyzer\n",
        "# from confidence_manager import ConfidenceManager\n",
        "# from result_cache_manager import ResultCacheManager\n",
        "\n",
        "class CLIPZeroShotClassifier:\n",
        "    \"\"\"\n",
        "    使用CLIP模型進行zero shot，專注於辨識世界知名地標。\n",
        "    作為YOLO的補充，處理YOLO無法辨識到的地標。\n",
        "\n",
        "    這是一個總窗口class，協調各個組件的工作以提供統一的對外接口。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"ViT-B/16\", device: str = None):\n",
        "        \"\"\"\n",
        "        初始化CLIP零樣本分類器\n",
        "\n",
        "        Args:\n",
        "            model_name: CLIP模型名稱，默認為\"ViT-B/16\"\n",
        "            device: 運行設備，None則自動選擇\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # 初始化各個組件\n",
        "        self.clip_model_manager = CLIPModelManager(model_name, device)\n",
        "        self.landmark_data_manager = LandmarkDataManager()\n",
        "        self.image_analyzer = ImageAnalyzer()\n",
        "        self.confidence_manager = ConfidenceManager()\n",
        "        self.cache_manager = ResultCacheManager()\n",
        "\n",
        "        # 預計算地標文本特徵\n",
        "        self.landmark_text_features = None\n",
        "        self._precompute_landmark_features()\n",
        "\n",
        "        self.logger.info(f\"Initializing CLIP Zero-Shot Landmark Classifier ({model_name}) on {self.clip_model_manager.get_device()}\")\n",
        "\n",
        "    def _precompute_landmark_features(self):\n",
        "        \"\"\"\n",
        "        預計算地標文本特徵，提高批處理效率\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.landmark_data_manager.is_landmark_enabled():\n",
        "                landmark_prompts = self.landmark_data_manager.get_landmark_prompts()\n",
        "                if landmark_prompts:\n",
        "                    self.landmark_text_features = self.clip_model_manager.encode_text_batch(landmark_prompts)\n",
        "                    self.logger.info(f\"Precomputed text features for {len(landmark_prompts)} landmark prompts\")\n",
        "                else:\n",
        "                    self.logger.warning(\"No landmark prompts available for precomputation\")\n",
        "            else:\n",
        "                self.logger.warning(\"Landmark data not enabled, skipping feature precomputation\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error precomputing landmark features: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "\n",
        "    def set_batch_size(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        設置批處理大小\n",
        "\n",
        "        Args:\n",
        "            batch_size: 新的批處理大小\n",
        "        \"\"\"\n",
        "        self.confidence_manager.set_batch_size(batch_size)\n",
        "\n",
        "    def adjust_confidence_threshold(self, detection_type: str, multiplier: float):\n",
        "        \"\"\"\n",
        "        調整特定檢測類型的置信度閾值乘數\n",
        "\n",
        "        Args\n",
        "            detection_type: 檢測類型 ('close_up', 'partial', 'distant', 'full_image')\n",
        "            multiplier: 置信度閾值乘數\n",
        "        \"\"\"\n",
        "        self.confidence_manager.adjust_confidence_threshold(detection_type, multiplier)\n",
        "\n",
        "    def classify_image_region(self,\n",
        "                            image: Union[Image.Image, np.ndarray],\n",
        "                            box: List[float],\n",
        "                            threshold: float = 0.25,\n",
        "                            detection_type: str = \"close_up\") -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        對圖像的特定區域進行地標分類，具有增強的多尺度和部分識別能力\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像 (PIL Image 或 numpy數組)\n",
        "            box: 邊界框 [x1, y1, x2, y2]\n",
        "            threshold: 基礎分類置信度閾值\n",
        "            detection_type: 檢測類型，影響置信度調整\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標分類結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.landmark_data_manager.is_landmark_enabled():\n",
        "                return {\"is_landmark\": False, \"confidence\": 0.0}\n",
        "\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 生成圖像區域的hash用於快取\n",
        "            image_hash = self.image_analyzer.get_image_hash(image)\n",
        "            region_key = self.cache_manager.get_region_cache_key(image_hash, tuple(box), detection_type)\n",
        "\n",
        "            # 檢查快取\n",
        "            cached_result = self.cache_manager.get_cached_result(region_key)\n",
        "            if cached_result is not None:\n",
        "                return cached_result\n",
        "\n",
        "            # 裁剪區域\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cropped_image = image.crop((x1, y1, x2, y2))\n",
        "            enhanced_image = self.image_analyzer.enhance_features(cropped_image)\n",
        "\n",
        "            # 分析視角信息\n",
        "            viewpoint_info = self.image_analyzer.analyze_viewpoint(enhanced_image, self.clip_model_manager)\n",
        "            dominant_viewpoint = viewpoint_info[\"dominant_viewpoint\"]\n",
        "\n",
        "            # 計算區域信息\n",
        "            region_width = x2 - x1\n",
        "            region_height = y2 - y1\n",
        "            image_width, image_height = image.size\n",
        "\n",
        "            # 根據區域大小判斷可能的檢測類型\n",
        "            if detection_type == \"auto\":\n",
        "                detection_type = self.confidence_manager.determine_detection_type_from_region(\n",
        "                    region_width, region_height, image_width, image_height\n",
        "                )\n",
        "\n",
        "            # 根據視角調整檢測類型\n",
        "            detection_type = self.confidence_manager.adjust_detection_type_by_viewpoint(detection_type, dominant_viewpoint)\n",
        "\n",
        "            # 調整置信度閾值\n",
        "            adjusted_threshold = self.confidence_manager.calculate_adjusted_threshold(threshold, detection_type)\n",
        "\n",
        "            # 準備多尺度和縱橫比分析\n",
        "            scales = [1.0]\n",
        "            if detection_type in [\"partial\", \"distant\"]:\n",
        "                scales = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
        "\n",
        "            if dominant_viewpoint in [\"angled_view\", \"low_angle\"]:\n",
        "                scales = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4]\n",
        "\n",
        "            aspect_ratios = [1.0, 0.8, 1.2]\n",
        "            if dominant_viewpoint in [\"angled_view\", \"unique_feature\"]:\n",
        "                aspect_ratios = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.5]\n",
        "\n",
        "            best_result = {\n",
        "                \"landmark_id\": None,\n",
        "                \"landmark_name\": None,\n",
        "                \"confidence\": 0.0,\n",
        "                \"is_landmark\": False\n",
        "            }\n",
        "\n",
        "            # 多尺度和縱橫比分析\n",
        "            for scale in scales:\n",
        "                for aspect_ratio in aspect_ratios:\n",
        "                    try:\n",
        "                        # 縮放裁剪區域\n",
        "                        current_width, current_height = cropped_image.size\n",
        "\n",
        "                        if aspect_ratio != 1.0:\n",
        "                            new_width = int(current_width * scale * (1/aspect_ratio)**0.5)\n",
        "                            new_height = int(current_height * scale * aspect_ratio**0.5)\n",
        "                        else:\n",
        "                            new_width = int(current_width * scale)\n",
        "                            new_height = int(current_height * scale)\n",
        "\n",
        "                        new_width = max(1, new_width)\n",
        "                        new_height = max(1, new_height)\n",
        "\n",
        "                        scaled_image = cropped_image.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "                        # 預處理並獲取特徵\n",
        "                        image_input = self.clip_model_manager.preprocess_image(scaled_image)\n",
        "                        image_features = self.clip_model_manager.encode_image(image_input)\n",
        "\n",
        "                        # 計算相似度\n",
        "                        similarity = self.clip_model_manager.calculate_similarity(image_features, self.landmark_text_features)\n",
        "\n",
        "                        # 找到最佳匹配\n",
        "                        best_idx = similarity[0].argmax().item()\n",
        "                        best_score = similarity[0][best_idx]\n",
        "\n",
        "                        # 如果當前尺度結果更好，則更新\n",
        "                        if best_score > best_result[\"confidence\"]:\n",
        "                            landmark_id, landmark_info = self.landmark_data_manager.get_landmark_by_index(best_idx)\n",
        "\n",
        "                            if landmark_id:\n",
        "                                # 先從 LandmarkDataManager 拿 location\n",
        "                                loc = landmark_info.get(\"location\", \"\")\n",
        "                                # 如果 loc 為空，就從全域 ALL_LANDMARKS 補上\n",
        "                                if not loc and landmark_id in ALL_LANDMARKS:\n",
        "                                    loc = ALL_LANDMARKS[landmark_id].get(\"location\", \"\")\n",
        "                                best_result = {\n",
        "                                    \"landmark_id\": landmark_id,\n",
        "                                    \"landmark_name\": landmark_info.get(\"name\", \"Unknown\"),\n",
        "                                    \"location\": loc or \"Unknown Location\",\n",
        "                                    \"confidence\": float(best_score),\n",
        "                                    \"is_landmark\": best_score >= adjusted_threshold,\n",
        "                                    \"scale_used\": scale,\n",
        "                                    \"aspect_ratio_used\": aspect_ratio,\n",
        "                                    \"viewpoint\": dominant_viewpoint\n",
        "                                }\n",
        "\n",
        "                                # 添加額外可用信息\n",
        "                                for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                                    if key in landmark_info:\n",
        "                                        best_result[key] = landmark_info[key]\n",
        "\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error in scale analysis: {e}\")\n",
        "                        continue\n",
        "\n",
        "            # 應用地標類型閾值調整\n",
        "            if best_result[\"landmark_id\"]:\n",
        "                landmark_type = self.landmark_data_manager.determine_landmark_type(best_result[\"landmark_id\"])\n",
        "                final_threshold = self.confidence_manager.calculate_final_threshold(adjusted_threshold, detection_type, landmark_type)\n",
        "\n",
        "                best_result[\"is_landmark\"] = self.confidence_manager.evaluate_confidence(best_result[\"confidence\"], final_threshold)\n",
        "                best_result[\"landmark_type\"] = landmark_type\n",
        "                best_result[\"threshold_applied\"] = final_threshold\n",
        "\n",
        "            # 快取結果\n",
        "            self.cache_manager.set_cached_result(region_key, best_result)\n",
        "\n",
        "            return best_result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in classify_image_region: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\"is_landmark\": False, \"confidence\": 0.0}\n",
        "\n",
        "\n",
        "    def classify_batch_regions(self,\n",
        "                              image: Union[Image.Image, np.ndarray],\n",
        "                              boxes: List[List[float]],\n",
        "                              threshold: float = 0.28) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        批量處理多個圖像區域，提高效率\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            boxes: 邊界框列表\n",
        "            threshold: 置信度閾值\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: 分類結果列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.landmark_data_manager.is_landmark_enabled() or self.landmark_text_features is None:\n",
        "                return [{\"is_landmark\": False, \"confidence\": 0.0} for _ in boxes]\n",
        "\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            if not boxes:\n",
        "                return []\n",
        "\n",
        "            # 批量處理所有區域\n",
        "            batch_features = self.clip_model_manager.batch_process_regions(image, boxes)\n",
        "\n",
        "            # 計算相似度\n",
        "            similarity = self.clip_model_manager.calculate_similarity(batch_features, self.landmark_text_features)\n",
        "\n",
        "            # 處理每個區域的結果\n",
        "            results = []\n",
        "            for i, sim in enumerate(similarity):\n",
        "                best_idx = sim.argmax().item()\n",
        "                best_score = sim[best_idx]\n",
        "\n",
        "                if best_score >= threshold:\n",
        "                    landmark_id, landmark_info = self.landmark_data_manager.get_landmark_by_index(best_idx)\n",
        "\n",
        "                    if landmark_id:\n",
        "                        # 如果landmark_info[\"location\"] 為空，則從 ALL_LANDMARKS 補\n",
        "                        loc = landmark_info.get(\"location\", \"\")\n",
        "                        if not loc and landmark_id in ALL_LANDMARKS:\n",
        "                            loc = ALL_LANDMARKS[landmark_id].get(\"location\", \"\")\n",
        "                        results.append({\n",
        "                            \"landmark_id\": landmark_id,\n",
        "                            \"landmark_name\": landmark_info.get(\"name\", \"Unknown\"),\n",
        "                            \"location\": loc or \"Unknown Location\",\n",
        "                            \"confidence\": float(best_score),\n",
        "                            \"is_landmark\": True,\n",
        "                            \"box\": boxes[i]\n",
        "                        })\n",
        "                    else:\n",
        "                        results.append({\n",
        "                            \"landmark_id\": None,\n",
        "                            \"landmark_name\": None,\n",
        "                            \"confidence\": float(best_score),\n",
        "                            \"is_landmark\": False,\n",
        "                            \"box\": boxes[i]\n",
        "                        })\n",
        "                else:\n",
        "                    results.append({\n",
        "                        \"landmark_id\": None,\n",
        "                        \"landmark_name\": None,\n",
        "                        \"confidence\": float(best_score),\n",
        "                        \"is_landmark\": False,\n",
        "                        \"box\": boxes[i]\n",
        "                    })\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in classify_batch_regions: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return [{\"is_landmark\": False, \"confidence\": 0.0} for _ in boxes]\n",
        "\n",
        "    def search_entire_image(self,\n",
        "                           image: Union[Image.Image, np.ndarray],\n",
        "                           threshold: float = 0.35,\n",
        "                           detailed_analysis: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        檢查整張圖像是否包含地標，具有增強的分析能力\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            threshold: 置信度閾值\n",
        "            detailed_analysis: 是否進行詳細分析，包括多區域檢測\n",
        "\n",
        "        Returns:\n",
        "            Dict: 地標分類結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.landmark_data_manager.is_landmark_enabled() or self.landmark_text_features is None:\n",
        "                return {\"is_landmark\": False, \"confidence\": 0.0}\n",
        "\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 檢查cache\n",
        "            image_hash = self.image_analyzer.get_image_hash(image)\n",
        "            image_key = self.cache_manager.get_image_cache_key(image_hash, \"entire_image\", detailed_analysis)\n",
        "\n",
        "            cached_result = self.cache_manager.get_cached_result(image_key)\n",
        "            if cached_result is not None:\n",
        "                return cached_result\n",
        "\n",
        "            # 調整閾值\n",
        "            adjusted_threshold = self.confidence_manager.calculate_adjusted_threshold(threshold, \"full_image\")\n",
        "\n",
        "            # 預處理並獲取特徵\n",
        "            image_input = self.clip_model_manager.preprocess_image(image)\n",
        "            image_features = self.clip_model_manager.encode_image(image_input)\n",
        "\n",
        "            # calculate相似度\n",
        "            similarity = self.clip_model_manager.calculate_similarity(image_features, self.landmark_text_features)\n",
        "\n",
        "            # 找到最佳匹配\n",
        "            best_idx = similarity[0].argmax().item()\n",
        "            best_score = similarity[0][best_idx]\n",
        "\n",
        "            # 獲取top3地標\n",
        "            top_indices = similarity[0].argsort()[-3:][::-1]\n",
        "            top_landmarks = []\n",
        "\n",
        "            for idx in top_indices:\n",
        "                score = similarity[0][idx]\n",
        "                landmark_id, landmark_info = self.landmark_data_manager.get_landmark_by_index(idx)\n",
        "\n",
        "                if landmark_id:\n",
        "                    # 補 location\n",
        "                    loc_top = landmark_info.get(\"location\", \"\")\n",
        "                    if not loc_top and landmark_id in ALL_LANDMARKS:\n",
        "                        loc_top = ALL_LANDMARKS[landmark_id].get(\"location\", \"\")\n",
        "                    landmark_result = {\n",
        "                        \"landmark_id\": landmark_id,\n",
        "                        \"landmark_name\": landmark_info.get(\"name\", \"Unknown\"),\n",
        "                        \"location\": loc_top or \"Unknown Location\",\n",
        "                        \"confidence\": float(score)\n",
        "                    }\n",
        "\n",
        "                    # 加額外可用信息\n",
        "                    for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                        if key in landmark_info:\n",
        "                            landmark_result[key] = landmark_info[key]\n",
        "\n",
        "                    top_landmarks.append(landmark_result)\n",
        "\n",
        "            # main result\n",
        "            result = {}\n",
        "            if best_score >= adjusted_threshold:\n",
        "                landmark_id, landmark_info = self.landmark_data_manager.get_landmark_by_index(best_idx)\n",
        "\n",
        "                if landmark_id:\n",
        "                    # 應用地標類型特定閾值\n",
        "                    landmark_type = self.landmark_data_manager.determine_landmark_type(landmark_id)\n",
        "                    final_threshold = self.confidence_manager.calculate_final_threshold(adjusted_threshold, \"full_image\", landmark_type)\n",
        "\n",
        "                    if self.confidence_manager.evaluate_confidence(best_score, final_threshold):\n",
        "                        # 補 location\n",
        "                        loc_main = landmark_info.get(\"location\", \"\")\n",
        "                        if not loc_main and landmark_id in ALL_LANDMARKS:\n",
        "                            loc_main = ALL_LANDMARKS[landmark_id].get(\"location\", \"\")\n",
        "                        result = {\n",
        "                            \"landmark_id\": landmark_id,\n",
        "                            \"landmark_name\": landmark_info.get(\"name\", \"Unknown\"),\n",
        "                            \"location\": loc_main or \"Unknown Location\",\n",
        "                            \"confidence\": float(best_score),\n",
        "                            \"is_landmark\": True,\n",
        "                            \"landmark_type\": landmark_type,\n",
        "                            \"top_landmarks\": top_landmarks\n",
        "                        }\n",
        "\n",
        "                        # 添加額外可用信息\n",
        "                        for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                            if key in landmark_info:\n",
        "                                result[key] = landmark_info[key]\n",
        "                    else:\n",
        "                        result = {\n",
        "                            \"landmark_id\": None,\n",
        "                            \"landmark_name\": None,\n",
        "                            \"confidence\": float(best_score),\n",
        "                            \"is_landmark\": False,\n",
        "                            \"top_landmarks\": top_landmarks\n",
        "                        }\n",
        "            else:\n",
        "                result = {\n",
        "                    \"landmark_id\": None,\n",
        "                    \"landmark_name\": None,\n",
        "                    \"confidence\": float(best_score),\n",
        "                    \"is_landmark\": False,\n",
        "                    \"top_landmarks\": top_landmarks\n",
        "                }\n",
        "\n",
        "            # 詳細分析\n",
        "            if detailed_analysis and result.get(\"is_landmark\", False):\n",
        "                width, height = image.size\n",
        "                regions = [\n",
        "                    [width * 0.25, height * 0.25, width * 0.75, height * 0.75],\n",
        "                    [0, 0, width * 0.5, height],\n",
        "                    [width * 0.5, 0, width, height],\n",
        "                    [0, 0, width, height * 0.5],\n",
        "                    [0, height * 0.5, width, height]\n",
        "                ]\n",
        "\n",
        "                region_results = []\n",
        "                for i, box in enumerate(regions):\n",
        "                    region_result = self.classify_image_region(\n",
        "                        image,\n",
        "                        box,\n",
        "                        threshold=threshold * 0.9,\n",
        "                        detection_type=\"partial\"\n",
        "                    )\n",
        "                    if region_result[\"is_landmark\"]:\n",
        "                        region_result[\"region_name\"] = [\"center\", \"left\", \"right\", \"top\", \"bottom\"][i]\n",
        "                        region_results.append(region_result)\n",
        "\n",
        "                if region_results:\n",
        "                    result[\"region_analyses\"] = region_results\n",
        "\n",
        "            # 快取結果\n",
        "            self.cache_manager.set_cached_result(image_key, result)\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in search_entire_image: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\"is_landmark\": False, \"confidence\": 0.0}\n",
        "\n",
        "\n",
        "    def intelligent_landmark_search(self,\n",
        "                                  image: Union[Image.Image, np.ndarray],\n",
        "                                  yolo_boxes: Optional[List[List[float]]] = None,\n",
        "                                  base_threshold: float = 0.25) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        對圖像進行地標搜索，綜合整張圖像分析和區域分析\n",
        "\n",
        "        Args:\n",
        "            image: 原始圖像\n",
        "            yolo_boxes: YOLO檢測到的邊界框 (可選)\n",
        "            base_threshold: 基礎置信度閾值\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含所有檢測結果的綜合分析\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.landmark_data_manager.is_landmark_enabled():\n",
        "                return {\n",
        "                    \"full_image_analysis\": {},\n",
        "                    \"is_landmark_scene\": False,\n",
        "                    \"detected_landmarks\": []\n",
        "                }\n",
        "\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 調整閾值\n",
        "            actual_threshold = base_threshold * 0.85 if yolo_boxes is None or len(yolo_boxes) == 0 else base_threshold\n",
        "\n",
        "            # 首先對整張圖像進行分析\n",
        "            full_image_result = self.search_entire_image(\n",
        "                image,\n",
        "                threshold=actual_threshold,\n",
        "                detailed_analysis=True\n",
        "            )\n",
        "\n",
        "            # 如果沒有YOLO框且全圖分析未發現地標，進行金字塔分析\n",
        "            if (yolo_boxes is None or len(yolo_boxes) == 0) and (not full_image_result or not full_image_result.get(\"is_landmark\", False)):\n",
        "                self.logger.info(\"No YOLO boxes provided, attempting multi-scale pyramid analysis\")\n",
        "                pyramid_results = self.image_analyzer.perform_pyramid_analysis(\n",
        "                    image,\n",
        "                    self.clip_model_manager,\n",
        "                    self.landmark_data_manager,\n",
        "                    levels=4,\n",
        "                    base_threshold=actual_threshold,\n",
        "                    aspect_ratios=[1.0, 0.75, 1.5, 0.5, 2.0]\n",
        "                )\n",
        "\n",
        "                if pyramid_results and pyramid_results.get(\"is_landmark\", False) and pyramid_results.get(\"best_result\", {}).get(\"confidence\", 0) > actual_threshold:\n",
        "                    if not full_image_result or not full_image_result.get(\"is_landmark\", False):\n",
        "                        full_image_result = {\n",
        "                            \"is_landmark\": True,\n",
        "                            \"landmark_id\": pyramid_results[\"best_result\"][\"landmark_id\"],\n",
        "                            \"landmark_name\": pyramid_results[\"best_result\"][\"landmark_name\"],\n",
        "                            \"confidence\": pyramid_results[\"best_result\"][\"confidence\"],\n",
        "                            \"location\": pyramid_results[\"best_result\"].get(\"location\", \"Unknown Location\")\n",
        "                        }\n",
        "                        self.logger.info(f\"Pyramid analysis detected landmark: {pyramid_results['best_result']['landmark_name']} with confidence {pyramid_results['best_result']['confidence']:.3f}\")\n",
        "\n",
        "            # 初始化結果dict\n",
        "            result = {\n",
        "                \"full_image_analysis\": full_image_result if full_image_result else {},\n",
        "                \"is_landmark_scene\": False,\n",
        "                \"detected_landmarks\": []\n",
        "            }\n",
        "\n",
        "            # 處理上下文感知比較\n",
        "            if full_image_result and \"top_landmarks\" in full_image_result and len(full_image_result[\"top_landmarks\"]) >= 2:\n",
        "                top_landmarks = full_image_result[\"top_landmarks\"]\n",
        "\n",
        "                if len(top_landmarks) >= 2 and abs(top_landmarks[0][\"confidence\"] - top_landmarks[1][\"confidence\"]) < 0.1:\n",
        "                    architectural_analysis = self.image_analyzer.analyze_architectural_features(image, self.clip_model_manager)\n",
        "\n",
        "                    for i, landmark in enumerate(top_landmarks[:2]):\n",
        "                        if i >= len(top_landmarks):\n",
        "                            continue\n",
        "\n",
        "                        adjusted_confidence = self.confidence_manager.apply_architectural_boost(\n",
        "                            landmark[\"confidence\"],\n",
        "                            architectural_analysis,\n",
        "                            landmark.get(\"landmark_id\", \"\")\n",
        "                        )\n",
        "\n",
        "                        if adjusted_confidence != landmark[\"confidence\"]:\n",
        "                            top_landmarks[i][\"confidence\"] = adjusted_confidence\n",
        "\n",
        "                    # 重新排序\n",
        "                    top_landmarks.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
        "                    full_image_result[\"top_landmarks\"] = top_landmarks\n",
        "                    if top_landmarks:\n",
        "                        full_image_result[\"landmark_id\"] = top_landmarks[0][\"landmark_id\"]\n",
        "                        full_image_result[\"landmark_name\"] = top_landmarks[0][\"landmark_name\"]\n",
        "                        full_image_result[\"confidence\"] = top_landmarks[0][\"confidence\"]\n",
        "                        full_image_result[\"location\"] = top_landmarks[0].get(\"location\", \"Unknown Location\")\n",
        "\n",
        "            # 處理全圖結果\n",
        "            if full_image_result and full_image_result.get(\"is_landmark\", False):\n",
        "                result[\"is_landmark_scene\"] = True\n",
        "                landmark_id = full_image_result.get(\"landmark_id\", \"unknown\")\n",
        "\n",
        "                landmark_specific_info = self.landmark_data_manager.extract_landmark_specific_info(landmark_id)\n",
        "\n",
        "                landmark_info = {\n",
        "                    \"landmark_id\": landmark_id,\n",
        "                    \"landmark_name\": full_image_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                    \"confidence\": full_image_result.get(\"confidence\", 0.0),\n",
        "                    \"location\": full_image_result.get(\"location\", \"Unknown Location\"),\n",
        "                    \"region_type\": \"full_image\",\n",
        "                    \"box\": [0, 0, getattr(image, 'width', 0), getattr(image, 'height', 0)]\n",
        "                }\n",
        "\n",
        "                landmark_info.update(landmark_specific_info)\n",
        "\n",
        "                if landmark_specific_info.get(\"landmark_name\"):\n",
        "                    landmark_info[\"landmark_name\"] = landmark_specific_info[\"landmark_name\"]\n",
        "\n",
        "                result[\"detected_landmarks\"].append(landmark_info)\n",
        "\n",
        "                if landmark_specific_info.get(\"has_specific_activities\", False):\n",
        "                    result[\"primary_landmark_activities\"] = landmark_specific_info.get(\"landmark_specific_activities\", [])\n",
        "                    self.logger.info(f\"Set primary landmark activities: {len(result['primary_landmark_activities'])} activities for {landmark_info['landmark_name']}\")\n",
        "\n",
        "            # 處理YOLO邊界框\n",
        "            if yolo_boxes and len(yolo_boxes) > 0:\n",
        "                for box in yolo_boxes:\n",
        "                    try:\n",
        "                        box_result = self.classify_image_region(\n",
        "                            image,\n",
        "                            box,\n",
        "                            threshold=base_threshold,\n",
        "                            detection_type=\"auto\"\n",
        "                        )\n",
        "\n",
        "                        if box_result and box_result.get(\"is_landmark\", False):\n",
        "                            is_duplicate = False\n",
        "                            for existing in result[\"detected_landmarks\"]:\n",
        "                                if existing.get(\"landmark_id\") == box_result.get(\"landmark_id\"):\n",
        "                                    if box_result.get(\"confidence\", 0) > existing.get(\"confidence\", 0):\n",
        "                                        existing.update({\n",
        "                                            \"confidence\": box_result.get(\"confidence\", 0),\n",
        "                                            \"region_type\": \"yolo_box\",\n",
        "                                            \"box\": box\n",
        "                                        })\n",
        "                                    is_duplicate = True\n",
        "                                    break\n",
        "\n",
        "                            if not is_duplicate:\n",
        "                                result[\"detected_landmarks\"].append({\n",
        "                                    \"landmark_id\": box_result.get(\"landmark_id\", \"unknown\"),\n",
        "                                    \"landmark_name\": box_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                    \"confidence\": box_result.get(\"confidence\", 0.0),\n",
        "                                    \"location\": box_result.get(\"location\", \"Unknown Location\"),\n",
        "                                    \"region_type\": \"yolo_box\",\n",
        "                                    \"box\": box\n",
        "                                })\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error in analyzing YOLO box: {e}\")\n",
        "                        continue\n",
        "\n",
        "            # 網格搜索（如果需要）\n",
        "            should_do_grid_search = (\n",
        "                len(result[\"detected_landmarks\"]) == 0 or\n",
        "                max([landmark.get(\"confidence\", 0) for landmark in result[\"detected_landmarks\"]], default=0) < 0.5\n",
        "            )\n",
        "\n",
        "            if should_do_grid_search:\n",
        "                try:\n",
        "                    width, height = getattr(image, 'size', (getattr(image, 'width', 0), getattr(image, 'height', 0)))\n",
        "                    if not isinstance(width, (int, float)) or width <= 0:\n",
        "                        width = getattr(image, 'width', 0)\n",
        "                    if not isinstance(height, (int, float)) or height <= 0:\n",
        "                        height = getattr(image, 'height', 0)\n",
        "\n",
        "                    if width > 0 and height > 0:\n",
        "                        grid_boxes = []\n",
        "                        for i in range(5):\n",
        "                            for j in range(5):\n",
        "                                grid_boxes.append([\n",
        "                                    width * (j/5), height * (i/5),\n",
        "                                    width * ((j+1)/5), height * ((i+1)/5)\n",
        "                                ])\n",
        "\n",
        "                        for box in grid_boxes:\n",
        "                            try:\n",
        "                                grid_result = self.classify_image_region(\n",
        "                                    image,\n",
        "                                    box,\n",
        "                                    threshold=base_threshold * 0.9,\n",
        "                                    detection_type=\"partial\"\n",
        "                                )\n",
        "\n",
        "                                if grid_result and grid_result.get(\"is_landmark\", False):\n",
        "                                    is_duplicate = False\n",
        "                                    for existing in result[\"detected_landmarks\"]:\n",
        "                                        if existing.get(\"landmark_id\") == grid_result.get(\"landmark_id\"):\n",
        "                                            is_duplicate = True\n",
        "                                            break\n",
        "\n",
        "                                    if not is_duplicate:\n",
        "                                        result[\"detected_landmarks\"].append({\n",
        "                                            \"landmark_id\": grid_result.get(\"landmark_id\", \"unknown\"),\n",
        "                                            \"landmark_name\": grid_result.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                            \"confidence\": grid_result.get(\"confidence\", 0.0),\n",
        "                                            \"location\": grid_result.get(\"location\", \"Unknown Location\"),\n",
        "                                            \"region_type\": \"grid\",\n",
        "                                            \"box\": box\n",
        "                                        })\n",
        "                            except Exception as e:\n",
        "                                self.logger.error(f\"Error in analyzing grid region: {e}\")\n",
        "                                continue\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in grid search: {e}\")\n",
        "                    self.logger.error(traceback.format_exc())\n",
        "\n",
        "            # 按置信度排序檢測結果\n",
        "            result[\"detected_landmarks\"].sort(key=lambda x: x.get(\"confidence\", 0), reverse=True)\n",
        "\n",
        "            # 更新整體場景類型判斷\n",
        "            if len(result[\"detected_landmarks\"]) > 0:\n",
        "                result[\"is_landmark_scene\"] = True\n",
        "                result[\"primary_landmark\"] = result[\"detected_landmarks\"][0]\n",
        "\n",
        "                if full_image_result and \"clip_analysis\" in full_image_result:\n",
        "                    result[\"clip_analysis_on_full_image\"] = full_image_result[\"clip_analysis\"]\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in intelligent_landmark_search: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"full_image_analysis\": {},\n",
        "                \"is_landmark_scene\": False,\n",
        "                \"detected_landmarks\": []\n",
        "            }\n",
        "\n",
        "    def enhanced_landmark_detection(self,\n",
        "                                  image: Union[Image.Image, np.ndarray],\n",
        "                                  threshold: float = 0.3) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        使用多種分析技術進行增強地標檢測\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            threshold: 基礎置信度閾值\n",
        "\n",
        "        Returns:\n",
        "            Dict: 綜合地標檢測結果\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not self.landmark_data_manager.is_landmark_enabled():\n",
        "                return {\"is_landmark_scene\": False, \"detected_landmarks\": []}\n",
        "\n",
        "            # 確保圖像是PIL格式\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported image format. Expected PIL Image or numpy array.\")\n",
        "\n",
        "            # 1: 分析視角以調整檢測參數\n",
        "            viewpoint_info = self.image_analyzer.analyze_viewpoint(image, self.clip_model_manager)\n",
        "            viewpoint = viewpoint_info[\"dominant_viewpoint\"]\n",
        "\n",
        "            # 根據視角調整閾值\n",
        "            if viewpoint == \"distant\":\n",
        "                adjusted_threshold = threshold * 0.7\n",
        "            elif viewpoint == \"close_up\":\n",
        "                adjusted_threshold = threshold * 1.1\n",
        "            else:\n",
        "                adjusted_threshold = threshold\n",
        "\n",
        "            # 2: 執行多尺度金字塔分析\n",
        "            pyramid_results = self.image_analyzer.perform_pyramid_analysis(\n",
        "                image,\n",
        "                self.clip_model_manager,\n",
        "                self.landmark_data_manager,\n",
        "                levels=3,\n",
        "                base_threshold=adjusted_threshold\n",
        "            )\n",
        "\n",
        "            # 3: 執行基於網格的區域分析\n",
        "            grid_results = []\n",
        "            width, height = image.size\n",
        "\n",
        "            # 根據視角創建自適應網格\n",
        "            if viewpoint == \"distant\":\n",
        "                grid_size = 3\n",
        "            elif viewpoint == \"close_up\":\n",
        "                grid_size = 5\n",
        "            else:\n",
        "                grid_size = 4\n",
        "\n",
        "            # 生成網格區域\n",
        "            for i in range(grid_size):\n",
        "                for j in range(grid_size):\n",
        "                    box = [\n",
        "                        width * (j/grid_size),\n",
        "                        height * (i/grid_size),\n",
        "                        width * ((j+1)/grid_size),\n",
        "                        height * ((i+1)/grid_size)\n",
        "                    ]\n",
        "\n",
        "                    region_result = self.classify_image_region(\n",
        "                        image,\n",
        "                        box,\n",
        "                        threshold=adjusted_threshold,\n",
        "                        detection_type=\"auto\"\n",
        "                    )\n",
        "\n",
        "                    if region_result[\"is_landmark\"]:\n",
        "                        region_result[\"grid_position\"] = (i, j)\n",
        "                        grid_results.append(region_result)\n",
        "\n",
        "            # 4: 交叉驗證並合併結果\n",
        "            all_detections = []\n",
        "\n",
        "            # 添加金字塔結果\n",
        "            if pyramid_results[\"is_landmark\"] and pyramid_results[\"best_result\"]:\n",
        "                all_detections.append({\n",
        "                    \"source\": \"pyramid\",\n",
        "                    \"landmark_id\": pyramid_results[\"best_result\"][\"landmark_id\"],\n",
        "                    \"landmark_name\": pyramid_results[\"best_result\"][\"landmark_name\"],\n",
        "                    \"confidence\": pyramid_results[\"best_result\"][\"confidence\"],\n",
        "                    \"scale_factor\": pyramid_results[\"best_result\"].get(\"scale_factor\", 1.0)\n",
        "                })\n",
        "\n",
        "            # 添加網格結果\n",
        "            for result in grid_results:\n",
        "                all_detections.append({\n",
        "                    \"source\": \"grid\",\n",
        "                    \"landmark_id\": result[\"landmark_id\"],\n",
        "                    \"landmark_name\": result[\"landmark_name\"],\n",
        "                    \"confidence\": result[\"confidence\"],\n",
        "                    \"grid_position\": result.get(\"grid_position\", (0, 0))\n",
        "                })\n",
        "\n",
        "            # 搜索整張圖像\n",
        "            full_image_result = self.search_entire_image(image, threshold=adjusted_threshold)\n",
        "            if full_image_result and full_image_result.get(\"is_landmark\", False):\n",
        "                all_detections.append({\n",
        "                    \"source\": \"full_image\",\n",
        "                    \"landmark_id\": full_image_result[\"landmark_id\"],\n",
        "                    \"landmark_name\": full_image_result[\"landmark_name\"],\n",
        "                    \"confidence\": full_image_result[\"confidence\"]\n",
        "                })\n",
        "\n",
        "            # 按地標ID分組並計算總體置信度\n",
        "            landmark_groups = {}\n",
        "            for detection in all_detections:\n",
        "                landmark_id = detection[\"landmark_id\"]\n",
        "                if landmark_id not in landmark_groups:\n",
        "                    landmark_groups[landmark_id] = {\n",
        "                        \"landmark_id\": landmark_id,\n",
        "                        \"landmark_name\": detection[\"landmark_name\"],\n",
        "                        \"detections\": [],\n",
        "                        \"sources\": set()\n",
        "                    }\n",
        "\n",
        "                landmark_groups[landmark_id][\"detections\"].append(detection)\n",
        "                landmark_groups[landmark_id][\"sources\"].add(detection[\"source\"])\n",
        "\n",
        "            # 計算每個地標的總體置信度\n",
        "            for landmark_id, group in landmark_groups.items():\n",
        "                detections = group[\"detections\"]\n",
        "\n",
        "                # 基礎置信度是任何來源的最大置信度\n",
        "                max_confidence = max(d[\"confidence\"] for d in detections)\n",
        "\n",
        "                # 多來源檢測獎勵\n",
        "                source_count = len(group[\"sources\"])\n",
        "                source_bonus = min(0.15, (source_count - 1) * 0.05)\n",
        "\n",
        "                # 一致性獎勵\n",
        "                detection_count = len(detections)\n",
        "                consistency_bonus = min(0.1, (detection_count - 1) * 0.02)\n",
        "\n",
        "                # 計算最終置信度\n",
        "                aggregate_confidence = min(1.0, max_confidence + source_bonus + consistency_bonus)\n",
        "\n",
        "                group[\"confidence\"] = aggregate_confidence\n",
        "                group[\"detection_count\"] = detection_count\n",
        "                group[\"source_count\"] = source_count\n",
        "\n",
        "            # 照信心度排序地標\n",
        "            sorted_landmarks = sorted(\n",
        "                landmark_groups.values(),\n",
        "                key=lambda x: x[\"confidence\"],\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"is_landmark_scene\": len(sorted_landmarks) > 0,\n",
        "                \"detected_landmarks\": sorted_landmarks,\n",
        "                \"viewpoint_info\": viewpoint_info,\n",
        "                \"primary_landmark\": sorted_landmarks[0] if sorted_landmarks else None\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in enhanced_landmark_detection: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\"is_landmark_scene\": False, \"detected_landmarks\": []}"
      ],
      "metadata": {
        "id": "ZYwht02Ls2lE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5eaafb1-9268-421e-8609-33bb619b0042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing clip_zero_shot_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile component_initializer.py\n",
        "import os\n",
        "import traceback\n",
        "import logging\n",
        "from typing import Dict, Optional, Any, Tuple\n",
        "\n",
        "# from spatial_analyzer import SpatialAnalyzer\n",
        "# from scene_description import SceneDescriptor\n",
        "# from enhance_scene_describer import EnhancedSceneDescriber\n",
        "# from clip_analyzer import CLIPAnalyzer\n",
        "# from clip_zero_shot_classifier import CLIPZeroShotClassifier\n",
        "# from llm_enhancer import LLMEnhancer\n",
        "# from landmark_activities import LANDMARK_ACTIVITIES\n",
        "# from scene_type import SCENE_TYPES\n",
        "# from object_categories import OBJECT_CATEGORIES\n",
        "\n",
        "\n",
        "class ComponentInitializer:\n",
        "    \"\"\"\n",
        "    負責初始化和管理 SceneAnalyzer 的所有子組件。\n",
        "    處理組件初始化失敗的情況並提供優雅的降級機制。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, use_llm: bool = True,\n",
        "                 use_clip: bool = True, enable_landmark: bool = True,\n",
        "                 llm_model_path: str = None):\n",
        "        \"\"\"\n",
        "        初始化組件管理器。\n",
        "\n",
        "        Args:\n",
        "            class_names: YOLO 類別 ID 到名稱的映射字典\n",
        "            use_llm: 是否啟用 LLM 增強功能\n",
        "            use_clip: 是否啟用 CLIP 分析功能\n",
        "            enable_landmark: 是否啟用地標檢測功能\n",
        "            llm_model_path: LLM 模型路徑（可選）\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # 存儲初始化參數\n",
        "        self.class_names = class_names\n",
        "        self.use_llm = use_llm\n",
        "        self.use_clip = use_clip\n",
        "        self.enable_landmark = enable_landmark\n",
        "        self.llm_model_path = llm_model_path\n",
        "\n",
        "        # 初始化組件容器\n",
        "        self.components = {}\n",
        "        self.data_structures = {}\n",
        "        self.initialization_status = {}\n",
        "\n",
        "        # 初始化所有組件\n",
        "        self._initialize_all_components()\n",
        "\n",
        "    def _initialize_all_components(self):\n",
        "        \"\"\"初始化所有必要的組件和數據結構。\"\"\"\n",
        "        try:\n",
        "            # 1. 首先載入數據\n",
        "            self._load_data_structures()\n",
        "\n",
        "            # 2. 初始化核心分析組件\n",
        "            self._initialize_core_analyzers()\n",
        "\n",
        "            # 3. 初始化 CLIP 相關內容\n",
        "            if self.use_clip:\n",
        "                self._initialize_clip_components()\n",
        "\n",
        "            # 4. 初始化 LLM 組件\n",
        "            if self.use_llm:\n",
        "                self._initialize_llm_components()\n",
        "\n",
        "            self.logger.info(\"All components initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error during component initialization: {e}\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def _load_data_structures(self):\n",
        "        \"\"\"載入必要的數據結構。\"\"\"\n",
        "        data_loaders = {\n",
        "            'LANDMARK_ACTIVITIES': self._load_landmark_activities,\n",
        "            'SCENE_TYPES': self._load_scene_types,\n",
        "            'OBJECT_CATEGORIES': self._load_object_categories\n",
        "        }\n",
        "\n",
        "        for data_name, loader_func in data_loaders.items():\n",
        "            try:\n",
        "                self.data_structures[data_name] = loader_func()\n",
        "                self.initialization_status[data_name] = True\n",
        "                self.logger.info(f\"Loaded {data_name} successfully\")\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Failed to load {data_name}: {e}\")\n",
        "                self.data_structures[data_name] = {}\n",
        "                self.initialization_status[data_name] = False\n",
        "\n",
        "    def _load_landmark_activities(self) -> Dict:\n",
        "        \"\"\"載入地標活動數據。\"\"\"\n",
        "        try:\n",
        "            return LANDMARK_ACTIVITIES\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Could not import LANDMARK_ACTIVITIES: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _load_scene_types(self) -> Dict:\n",
        "        \"\"\"載入場景類型數據。\"\"\"\n",
        "        try:\n",
        "            return SCENE_TYPES\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Could not import SCENE_TYPES: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _load_object_categories(self) -> Dict:\n",
        "        \"\"\"載入物體類別數據。\"\"\"\n",
        "        try:\n",
        "            return OBJECT_CATEGORIES\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Could not import OBJECT_CATEGORIES: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _initialize_core_analyzers(self):\n",
        "        \"\"\"初始化核心分析組件。\"\"\"\n",
        "        # 初始化 SpatialAnalyzer\n",
        "        try:\n",
        "            self.components['spatial_analyzer'] = SpatialAnalyzer(\n",
        "                class_names=self.class_names,\n",
        "                object_categories=self.data_structures.get('OBJECT_CATEGORIES', {})\n",
        "            )\n",
        "            self.initialization_status['spatial_analyzer'] = True\n",
        "            self.logger.info(\"Initialized SpatialAnalyzer successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error initializing SpatialAnalyzer: {e}\")\n",
        "            traceback.print_exc()\n",
        "            self.initialization_status['spatial_analyzer'] = False\n",
        "            self.components['spatial_analyzer'] = None\n",
        "\n",
        "        # 初始化 SceneDescriptor\n",
        "        try:\n",
        "            self.components['descriptor'] = SceneDescriptor(\n",
        "                scene_types=self.data_structures.get('SCENE_TYPES', {}),\n",
        "                object_categories=self.data_structures.get('OBJECT_CATEGORIES', {})\n",
        "            )\n",
        "            self.initialization_status['descriptor'] = True\n",
        "            self.logger.info(\"Initialized SceneDescriptor successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error initializing SceneDescriptor: {e}\")\n",
        "            traceback.print_exc()\n",
        "            self.initialization_status['descriptor'] = False\n",
        "            self.components['descriptor'] = None\n",
        "\n",
        "        # 初始化 EnhancedSceneDescriber\n",
        "        try:\n",
        "            if self.components.get('spatial_analyzer'):\n",
        "                self.components['scene_describer'] = EnhancedSceneDescriber(\n",
        "                    scene_types=self.data_structures.get('SCENE_TYPES', {}),\n",
        "                    spatial_analyzer_instance=self.components['spatial_analyzer']\n",
        "                )\n",
        "                self.initialization_status['scene_describer'] = True\n",
        "                self.logger.info(\"Initialized EnhancedSceneDescriber successfully\")\n",
        "            else:\n",
        "                self.logger.warning(\"Cannot initialize EnhancedSceneDescriber without SpatialAnalyzer\")\n",
        "                self.initialization_status['scene_describer'] = False\n",
        "                self.components['scene_describer'] = None\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error initializing EnhancedSceneDescriber: {e}\")\n",
        "            traceback.print_exc()\n",
        "            self.initialization_status['scene_describer'] = False\n",
        "            self.components['scene_describer'] = None\n",
        "\n",
        "    def _initialize_clip_components(self):\n",
        "        \"\"\"初始化 CLIP 相關組件。\"\"\"\n",
        "        # 初始化 CLIPAnalyzer\n",
        "        try:\n",
        "            self.components['clip_analyzer'] = CLIPAnalyzer()\n",
        "            self.initialization_status['clip_analyzer'] = True\n",
        "            self.logger.info(\"Initialized CLIPAnalyzer successfully\")\n",
        "\n",
        "            # 如果啟用地標檢測，初始化 CLIPZeroShotClassifier\n",
        "            if self.enable_landmark:\n",
        "                self._initialize_landmark_classifier()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Could not initialize CLIP analyzer: {e}\")\n",
        "            self.logger.info(\"Scene analysis will proceed without CLIP. Install CLIP with 'pip install clip' for enhanced scene understanding.\")\n",
        "            self.use_clip = False\n",
        "            self.initialization_status['clip_analyzer'] = False\n",
        "            self.components['clip_analyzer'] = None\n",
        "\n",
        "    def _initialize_landmark_classifier(self):\n",
        "        \"\"\"初始化地標分類器。\"\"\"\n",
        "        try:\n",
        "            # 嘗試使用已載入的 CLIP 模型實例\n",
        "            if (self.components.get('clip_analyzer') and\n",
        "                hasattr(self.components['clip_analyzer'], 'get_clip_instance')):\n",
        "                model, preprocess, device = self.components['clip_analyzer'].get_clip_instance()\n",
        "                self.components['landmark_classifier'] = CLIPZeroShotClassifier(device=device)\n",
        "                self.logger.info(\"Initialized landmark classifier with shared CLIP model\")\n",
        "            else:\n",
        "                self.components['landmark_classifier'] = CLIPZeroShotClassifier()\n",
        "                self.logger.info(\"Initialized landmark classifier with independent CLIP model\")\n",
        "\n",
        "            # 配置地標檢測器參數\n",
        "            self._configure_landmark_classifier()\n",
        "            self.initialization_status['landmark_classifier'] = True\n",
        "\n",
        "        except (ImportError, Exception) as e:\n",
        "            self.logger.warning(f\"Could not initialize landmark classifier: {e}\")\n",
        "            self.initialization_status['landmark_classifier'] = False\n",
        "            self.components['landmark_classifier'] = None\n",
        "            # 不完全禁用地標檢測，允許運行時重新嘗試\n",
        "\n",
        "    def _configure_landmark_classifier(self):\n",
        "        \"\"\"配置地標分類器的參數。\"\"\"\n",
        "        if self.components.get('landmark_classifier'):\n",
        "            try:\n",
        "                classifier = self.components['landmark_classifier']\n",
        "                classifier.set_batch_size(8)\n",
        "                classifier.adjust_confidence_threshold(\"full_image\", 0.8)\n",
        "                classifier.adjust_confidence_threshold(\"distant\", 0.65)\n",
        "                self.logger.info(\"Landmark detection enabled with optimized settings\")\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Error configuring landmark classifier: {e}\")\n",
        "\n",
        "    def _initialize_llm_components(self):\n",
        "        \"\"\"初始化 LLM 組件。\"\"\"\n",
        "        try:\n",
        "            self.components['llm_enhancer'] = LLMEnhancer(model_path=self.llm_model_path)\n",
        "            self.initialization_status['llm_enhancer'] = True\n",
        "            self.logger.info(\"LLM enhancer initialized successfully\")\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Could not initialize LLM enhancer: {e}\")\n",
        "            self.logger.info(\"Scene analysis will proceed without LLM. Make sure required packages are installed.\")\n",
        "            self.use_llm = False\n",
        "            self.initialization_status['llm_enhancer'] = False\n",
        "            self.components['llm_enhancer'] = None\n",
        "\n",
        "    def get_component(self, component_name: str) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        獲取指定的組件實例。\n",
        "\n",
        "        Args:\n",
        "            component_name: 組件名稱\n",
        "\n",
        "        Returns:\n",
        "            組件實例或 None（如果未初始化成功）\n",
        "        \"\"\"\n",
        "        return self.components.get(component_name)\n",
        "\n",
        "    def get_data_structure(self, data_name: str) -> Dict:\n",
        "        \"\"\"\n",
        "        獲取指定的數據結構。\n",
        "\n",
        "        Args:\n",
        "            data_name: 數據結構名稱\n",
        "\n",
        "        Returns:\n",
        "            數據結構字典\n",
        "        \"\"\"\n",
        "        return self.data_structures.get(data_name, {})\n",
        "\n",
        "    def is_component_available(self, component_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        檢查指定組件是否可用。\n",
        "\n",
        "        Args:\n",
        "            component_name: 組件名稱\n",
        "\n",
        "        Returns:\n",
        "            組件是否可用\n",
        "        \"\"\"\n",
        "        return self.initialization_status.get(component_name, False)\n",
        "\n",
        "    def get_initialization_summary(self) -> Dict[str, bool]:\n",
        "        \"\"\"\n",
        "        獲取所有組件的初始化狀態摘要。\n",
        "\n",
        "        Returns:\n",
        "            組件名稱到初始化狀態的映射\n",
        "        \"\"\"\n",
        "        return self.initialization_status.copy()\n",
        "\n",
        "    def reinitialize_component(self, component_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        重新初始化指定的組件。\n",
        "\n",
        "        Args:\n",
        "            component_name: 要重新初始化的組件名稱\n",
        "\n",
        "        Returns:\n",
        "            重新初始化是否成功\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if component_name == 'landmark_classifier' and self.use_clip and self.enable_landmark:\n",
        "                self._initialize_landmark_classifier()\n",
        "                return self.initialization_status.get('landmark_classifier', False)\n",
        "            else:\n",
        "                self.logger.warning(f\"Reinitializing {component_name} is not supported\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error reinitializing {component_name}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def update_landmark_enable_status(self, enable_landmark: bool):\n",
        "        \"\"\"\n",
        "        更新地標檢測的啟用狀態。\n",
        "\n",
        "        Args:\n",
        "            enable_landmark: 是否啟用地標檢測\n",
        "        \"\"\"\n",
        "        self.enable_landmark = enable_landmark\n",
        "\n",
        "        # 如果啟用地標檢測但分類器不可用，嘗試重新初始化\n",
        "        if enable_landmark and not self.is_component_available('landmark_classifier'):\n",
        "            if self.use_clip:\n",
        "                self.reinitialize_component('landmark_classifier')\n",
        "\n",
        "        # 更新相關組件的狀態\n",
        "        for component_name in ['scene_describer', 'clip_analyzer', 'landmark_classifier']:\n",
        "            component = self.get_component(component_name)\n",
        "            if component and hasattr(component, 'enable_landmark'):\n",
        "                component.enable_landmark = enable_landmark"
      ],
      "metadata": {
        "id": "x5tzzA9fuSKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87131908-6455-4c21-f181-a91346809c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing component_initializer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile scene_scoring_engine.py\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "\n",
        "# from scene_type import SCENE_TYPES\n",
        "\n",
        "class SceneScoringEngine:\n",
        "    \"\"\"\n",
        "    負責場景評分相關的所有計算邏輯，包括基於 YOLO 檢測的場景評分、\n",
        "    多種場景分數融合，以及最終場景類型的確定。\n",
        "    這邊會有YOLO, CLIP, Places365混合運用的分數計算\n",
        "    \"\"\"\n",
        "\n",
        "    # 日常場景，用於特殊評分\n",
        "    EVERYDAY_SCENE_TYPE_KEYS = [\n",
        "        \"general_indoor_space\", \"generic_street_view\",\n",
        "        \"desk_area_workspace\", \"outdoor_gathering_spot\",\n",
        "        \"kitchen_counter_or_utility_area\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, scene_types: Dict[str, Any], enable_landmark: bool = True):\n",
        "        \"\"\"\n",
        "        初始化場景評分引擎。\n",
        "\n",
        "        Args:\n",
        "            scene_types: 場景類型定義字典\n",
        "            enable_landmark: 是否啟用地標檢測功能\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.scene_types = scene_types\n",
        "        self.enable_landmark = enable_landmark\n",
        "\n",
        "    def compute_scene_scores(self, detected_objects: List[Dict],\n",
        "                           spatial_analysis_results: Optional[Dict] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        基於檢測到的物體計算各場景類型的置信度分數。\n",
        "        增強了對日常場景的評分能力，並考慮物體豐富度和空間聚合性。\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物體列表，包含物體詳細資訊\n",
        "            spatial_analysis_results: 空間分析器的輸出結果，特別是 'objects_by_region' 部分\n",
        "\n",
        "        Returns:\n",
        "            場景類型到置信度分數的映射字典\n",
        "        \"\"\"\n",
        "        scene_scores = {}\n",
        "        if not detected_objects:\n",
        "            for scene_type_key in self.scene_types:\n",
        "                scene_scores[scene_type_key] = 0.0\n",
        "            return scene_scores\n",
        "\n",
        "        # 準備檢測物體的數據\n",
        "        detected_class_ids_all = [obj[\"class_id\"] for obj in detected_objects]\n",
        "        detected_classes_set_all = set(detected_class_ids_all)\n",
        "        class_counts_all = {}\n",
        "        for obj in detected_objects:\n",
        "            class_id = obj[\"class_id\"]\n",
        "            class_counts_all[class_id] = class_counts_all.get(class_id, 0) + 1\n",
        "\n",
        "        # 評估 scene_types 中定義的每個場景類型\n",
        "        for scene_type, scene_def in self.scene_types.items():\n",
        "            required_obj_ids_defined = set(scene_def.get(\"required_objects\", []))\n",
        "            optional_obj_ids_defined = set(scene_def.get(\"optional_objects\", []))\n",
        "            min_required_matches_needed = scene_def.get(\"minimum_required\", 0)\n",
        "\n",
        "            # 確定哪些實際檢測到的物體與此場景類型相關\n",
        "            # 這些列表將存儲實際檢測到的物體字典，而不僅僅是 class_ids\n",
        "            actual_required_objects_found_list = []\n",
        "            for req_id in required_obj_ids_defined:\n",
        "                if req_id in detected_classes_set_all:\n",
        "                    # 找到此必需物體的第一個實例添加到列表中（用於後續的聚合性檢查）\n",
        "                    for dobj in detected_objects:\n",
        "                        if dobj['class_id'] == req_id:\n",
        "                            actual_required_objects_found_list.append(dobj)\n",
        "                            break\n",
        "\n",
        "            num_required_matches_found = len(actual_required_objects_found_list)\n",
        "\n",
        "            actual_optional_objects_found_list = []\n",
        "            for opt_id in optional_obj_ids_defined:\n",
        "                if opt_id in detected_classes_set_all:\n",
        "                    for dobj in detected_objects:\n",
        "                        if dobj['class_id'] == opt_id:\n",
        "                            actual_optional_objects_found_list.append(dobj)\n",
        "                            break\n",
        "\n",
        "            num_optional_matches_found = len(actual_optional_objects_found_list)\n",
        "\n",
        "            # 初始分數計算權重\n",
        "            # 基礎分數：55% 來自必需物體，25% 來自可選物體，10% 豐富度，10% 聚合性（最大值）\n",
        "            required_weight = 0.55\n",
        "            optional_weight = 0.25\n",
        "            richness_bonus_max = 0.10\n",
        "            cohesion_bonus_max = 0.10  # _get_object_spatial_cohesion_score 的最大獎勵是 0.1\n",
        "\n",
        "            current_scene_score = 0.0\n",
        "            objects_to_check_for_cohesion = []  # 用於空間聚合性評分\n",
        "\n",
        "            # 檢查 minimum_required 條件並計算基礎分數\n",
        "            if num_required_matches_found >= min_required_matches_needed:\n",
        "                if len(required_obj_ids_defined) > 0:\n",
        "                    required_ratio = num_required_matches_found / len(required_obj_ids_defined)\n",
        "                else:  # 沒有定義必需物體，但 min_required_matches_needed 可能為 0\n",
        "                    required_ratio = 1.0 if min_required_matches_needed == 0 else 0.0\n",
        "\n",
        "                current_scene_score = required_ratio * required_weight\n",
        "                objects_to_check_for_cohesion.extend(actual_required_objects_found_list)\n",
        "\n",
        "                # 從可選物體添加分數\n",
        "                if len(optional_obj_ids_defined) > 0:\n",
        "                    optional_ratio = num_optional_matches_found / len(optional_obj_ids_defined)\n",
        "                    current_scene_score += optional_ratio * optional_weight\n",
        "                objects_to_check_for_cohesion.extend(actual_optional_objects_found_list)\n",
        "\n",
        "            # 日常場景的靈活處理，如果嚴格的 minimum_required（基於 'required_objects'）未滿足\n",
        "            elif scene_type in self.EVERYDAY_SCENE_TYPE_KEYS:\n",
        "                # 如果日常場景有許多可選項目，它仍可能是一個弱候選\n",
        "                # 檢查是否存在相當比例的 'optional_objects'\n",
        "                if (len(optional_obj_ids_defined) > 0 and\n",
        "                    (num_optional_matches_found / len(optional_obj_ids_defined)) >= 0.25):  # 例如，至少 25% 的典型可選項目\n",
        "                    # 對這些類型的基礎分數更多地基於可選物體的滿足度\n",
        "                    current_scene_score = (num_optional_matches_found / len(optional_obj_ids_defined)) * (required_weight + optional_weight * 0.5)  # 給予一些基礎分數\n",
        "                    objects_to_check_for_cohesion.extend(actual_optional_objects_found_list)\n",
        "                else:\n",
        "                    scene_scores[scene_type] = 0.0\n",
        "                    continue  # 跳過此場景類型\n",
        "            else:  # 對於非日常場景，如果未滿足 minimum_required，分數為 0\n",
        "                scene_scores[scene_type] = 0.0\n",
        "                continue\n",
        "\n",
        "            # 物體豐富度/多樣性的獎勵\n",
        "            # 考慮找到的與場景定義相關的唯一物體類別\n",
        "            relevant_defined_class_ids = required_obj_ids_defined.union(optional_obj_ids_defined)\n",
        "            unique_relevant_detected_classes = relevant_defined_class_ids.intersection(detected_classes_set_all)\n",
        "\n",
        "            object_richness_score = 0.0\n",
        "            if len(relevant_defined_class_ids) > 0:\n",
        "                richness_ratio = len(unique_relevant_detected_classes) / len(relevant_defined_class_ids)\n",
        "                object_richness_score = min(richness_bonus_max, richness_ratio * 0.15)  # 豐富度最大 10% 獎勵\n",
        "            current_scene_score += object_richness_score\n",
        "\n",
        "            # 空間聚合性的獎勵（如果提供了 spatial_analysis_results）\n",
        "            spatial_cohesion_bonus = 0.0\n",
        "            if spatial_analysis_results and objects_to_check_for_cohesion:\n",
        "                spatial_cohesion_bonus = self._get_object_spatial_cohesion_score(\n",
        "                    objects_to_check_for_cohesion,  # 傳遞實際檢測到的物體字典列表\n",
        "                    spatial_analysis_results\n",
        "                )\n",
        "            current_scene_score += spatial_cohesion_bonus  # 此獎勵最大 0.1\n",
        "\n",
        "            # 關鍵物體多個實例的獎勵（原始邏輯的精煉版）\n",
        "            multiple_instance_bonus = 0.0\n",
        "            # 對於多實例獎勵，專注於場景定義中心的物體\n",
        "            key_objects_for_multi_instance_check = required_obj_ids_defined\n",
        "            if scene_type in self.EVERYDAY_SCENE_TYPE_KEYS and len(optional_obj_ids_defined) > 0:\n",
        "                # 對於日常場景，如果某些可選物體多次出現，也可以是關鍵的\n",
        "                # 例如，\"general_indoor_space\" 中的多把椅子\n",
        "                key_objects_for_multi_instance_check = key_objects_for_multi_instance_check.union(\n",
        "                    set(list(optional_obj_ids_defined)[:max(1, len(optional_obj_ids_defined)//2)])  # 考慮前半部分的可選物體\n",
        "                )\n",
        "\n",
        "            for class_id_check in key_objects_for_multi_instance_check:\n",
        "                if class_id_check in detected_classes_set_all and class_counts_all.get(class_id_check, 0) > 1:\n",
        "                    multiple_instance_bonus += 0.025  # 每種類型稍微小一點的獎勵\n",
        "            current_scene_score += min(0.075, multiple_instance_bonus)  # 最大 7.5% 獎勵\n",
        "\n",
        "            # 應用 SCENE_TYPES 中定義的場景特定優先級\n",
        "            if \"priority\" in scene_def:\n",
        "                current_scene_score *= scene_def[\"priority\"]\n",
        "\n",
        "            scene_scores[scene_type] = min(1.0, max(0.0, current_scene_score))\n",
        "\n",
        "        # 如果通過實例屬性 self.enable_landmark 禁用地標檢測，\n",
        "        # 確保地標特定場景類型的分數被歸零。\n",
        "        if not self.enable_landmark:\n",
        "            landmark_scene_types = [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]\n",
        "            for lm_scene_type in landmark_scene_types:\n",
        "                if lm_scene_type in scene_scores:\n",
        "                    scene_scores[lm_scene_type] = 0.0\n",
        "\n",
        "        return scene_scores\n",
        "\n",
        "    def _get_object_spatial_cohesion_score(self, objects_for_scene: List[Dict],\n",
        "                                         spatial_analysis_results: Optional[Dict]) -> float:\n",
        "        \"\"\"\n",
        "        基於場景關鍵物體的空間聚合程度計算分數。\n",
        "        較高的分數意味著物體在較少的區域中更加集中。\n",
        "        這是一個啟發式方法，可以進一步精煉。\n",
        "\n",
        "        Args:\n",
        "            objects_for_scene: 與當前評估場景類型相關的檢測物體列表（至少包含 'class_id' 的字典）\n",
        "            spatial_analysis_results: SpatialAnalyzer._analyze_regions 的輸出\n",
        "                                    預期格式：{'objects_by_region': {'region_name': [{'class_id': id, ...}, ...]}}\n",
        "\n",
        "        Returns:\n",
        "            float: 聚合性分數，通常是小額獎勵（例如，0.0 到 0.1）\n",
        "        \"\"\"\n",
        "        if (not objects_for_scene or not spatial_analysis_results or\n",
        "            \"objects_by_region\" not in spatial_analysis_results or\n",
        "            not spatial_analysis_results[\"objects_by_region\"]):\n",
        "            return 0.0\n",
        "\n",
        "        # 獲取定義當前場景類型的關鍵物體的 class_ids 集合\n",
        "        key_object_class_ids = {obj.get('class_id') for obj in objects_for_scene if obj.get('class_id') is not None}\n",
        "        if not key_object_class_ids:\n",
        "            return 0.0\n",
        "\n",
        "        # 找出這些關鍵物體出現在哪些區域\n",
        "        regions_containing_key_objects = set()\n",
        "        # 計算找到的關鍵物體實例數量\n",
        "        # 這有助於區分 1 個區域中的 1 把椅子與分佈在 5 個區域中的 5 把椅子\n",
        "        total_key_object_instances_found = 0\n",
        "\n",
        "        for region_name, objects_in_region_list in spatial_analysis_results[\"objects_by_region\"].items():\n",
        "            region_has_key_object = False\n",
        "            for obj_in_region in objects_in_region_list:\n",
        "                if obj_in_region.get('class_id') in key_object_class_ids:\n",
        "                    region_has_key_object = True\n",
        "                    total_key_object_instances_found += 1  # 計算每個實例\n",
        "            if region_has_key_object:\n",
        "                regions_containing_key_objects.add(region_name)\n",
        "\n",
        "        num_distinct_key_objects_in_scene = len(key_object_class_ids)  # 關鍵物體的類型數量\n",
        "        num_instances_of_key_objects_passed = len(objects_for_scene)  # 傳遞的實例數量\n",
        "\n",
        "        if not regions_containing_key_objects or num_instances_of_key_objects_passed == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # 簡單的啟發式方法：\n",
        "        if (len(regions_containing_key_objects) == 1 and\n",
        "            total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.75):\n",
        "            return 0.10  # 最強聚合性：大部分/所有關鍵物體實例在單個區域中\n",
        "        elif (len(regions_containing_key_objects) <= 2 and\n",
        "              total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.60):\n",
        "            return 0.05  # 中等聚合性：大部分/所有關鍵物體實例在最多兩個區域中\n",
        "        elif (len(regions_containing_key_objects) <= 3 and\n",
        "              total_key_object_instances_found >= num_instances_of_key_objects_passed * 0.50):\n",
        "            return 0.02  # 較弱聚合性\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "    def determine_scene_type(self, scene_scores: Dict[str, float]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        基於分數確定最可能的場景類型。如果偵測到地標分數夠高，則優先回傳 \"tourist_landmark\"。\n",
        "\n",
        "        Args:\n",
        "            scene_scores: 場景類型到置信度分數的映射字典\n",
        "\n",
        "        Returns:\n",
        "            (最佳場景類型, 置信度) 的元組\n",
        "        \"\"\"\n",
        "        if not scene_scores:\n",
        "            return \"unknown\", 0.0\n",
        "\n",
        "        # 檢查地標相關分數是否達到門檻，如果是，直接回傳 \"tourist_landmark\"\n",
        "        # 假設場景分數 dictionary 中，\"tourist_landmark\"、\"historical_monument\"、\"natural_landmark\" 三個 key\n",
        "        # 分別代表不同類型地標。將它們加總，若總分超過 0.3，就認定為地標場景。\n",
        "        landmark_score = (\n",
        "            scene_scores.get(\"tourist_landmark\", 0.0) +\n",
        "            scene_scores.get(\"historical_monument\", 0.0) +\n",
        "            scene_scores.get(\"natural_landmark\", 0.0)\n",
        "        )\n",
        "        if landmark_score >= 0.3:\n",
        "            # 回傳地標場景類型，以及該分數總和\n",
        "            return \"tourist_landmark\", float(landmark_score)\n",
        "\n",
        "        # 找分數最高的那個場景\n",
        "        best_scene = max(scene_scores, key=scene_scores.get)\n",
        "        best_score = scene_scores[best_scene]\n",
        "        return best_scene, float(best_score)\n",
        "\n",
        "    def fuse_scene_scores(self, yolo_scene_scores: Dict[str, float],\n",
        "                         clip_scene_scores: Dict[str, float],\n",
        "                         num_yolo_detections: int = 0,\n",
        "                         avg_yolo_confidence: float = 0.0,\n",
        "                         lighting_info: Optional[Dict] = None,\n",
        "                         places365_info: Optional[Dict] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        融合來自 YOLO 物體檢測、CLIP 分析和 Places365 場景分類的場景分數。\n",
        "        根據場景類型、YOLO 檢測的豐富度、照明資訊和 Places365 置信度調整權重。\n",
        "\n",
        "        Args:\n",
        "            yolo_scene_scores: 基於 YOLO 物體檢測的場景分數\n",
        "            clip_scene_scores: 基於 CLIP 分析的場景分數\n",
        "            num_yolo_detections: YOLO 檢測到的置信度足夠的非地標物體總數\n",
        "            avg_yolo_confidence: YOLO 檢測到的非地標物體的平均置信度\n",
        "            lighting_info: 可選的照明條件分析結果，預期包含 'is_indoor' (bool) 和 'confidence' (float)\n",
        "            places365_info: 可選的 Places365 場景分類結果，預期包含 'mapped_scene_type'、'confidence' 和 'is_indoor'\n",
        "\n",
        "        Returns:\n",
        "            Dict: 融合了所有三個分析來源的場景分數\n",
        "        \"\"\"\n",
        "        # 處理其中一個分數字典可能為空或所有分數實際上為零的情況\n",
        "        # 提取和處理 Places365 場景分數\n",
        "        places365_scene_scores_map = {}  # 修改變數名稱以避免與傳入的字典衝突\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.1:\n",
        "            mapped_scene_type = places365_info.get('mapped_scene_type', 'unknown')\n",
        "            places365_confidence = places365_info.get('confidence', 0.0)\n",
        "\n",
        "            if mapped_scene_type in self.scene_types.keys():\n",
        "                places365_scene_scores_map[mapped_scene_type] = places365_confidence  # 使用新的字典\n",
        "                self.logger.info(f\"Places365 contributing: {mapped_scene_type} with confidence {places365_confidence:.3f}\")\n",
        "\n",
        "        # 檢查各個數據來源是否具有有意義的分數\n",
        "        yolo_has_meaningful_scores = bool(yolo_scene_scores and any(s > 1e-5 for s in yolo_scene_scores.values()))  # 確保是布林值\n",
        "        clip_has_meaningful_scores = bool(clip_scene_scores and any(s > 1e-5 for s in clip_scene_scores.values()))  # 確保是布林值\n",
        "        places365_has_meaningful_scores = bool(places365_scene_scores_map and any(s > 1e-5 for s in places365_scene_scores_map.values()))\n",
        "\n",
        "        # 計算有意義的數據來源數量\n",
        "        meaningful_sources_count = sum([\n",
        "            yolo_has_meaningful_scores,\n",
        "            clip_has_meaningful_scores,\n",
        "            places365_has_meaningful_scores\n",
        "        ])\n",
        "\n",
        "        # 處理特殊情況：無有效數據源或僅有單一數據源\n",
        "        if meaningful_sources_count == 0:\n",
        "            return {st: 0.0 for st in self.scene_types.keys()}\n",
        "        elif meaningful_sources_count == 1:\n",
        "            if yolo_has_meaningful_scores:\n",
        "                return {st: yolo_scene_scores.get(st, 0.0) for st in self.scene_types.keys()}\n",
        "            elif clip_has_meaningful_scores:\n",
        "                return {st: clip_scene_scores.get(st, 0.0) for st in self.scene_types.keys()}\n",
        "            elif places365_has_meaningful_scores:\n",
        "                return {st: places365_scene_scores_map.get(st, 0.0) for st in self.scene_types.keys()}\n",
        "\n",
        "        # 初始化融合分數結果字典\n",
        "        fused_scores = {}\n",
        "        all_relevant_scene_types = set(self.scene_types.keys())\n",
        "        all_possible_scene_types = all_relevant_scene_types.union(\n",
        "            set(yolo_scene_scores.keys()),\n",
        "            set(clip_scene_scores.keys()),\n",
        "            set(places365_scene_scores_map.keys())\n",
        "        )\n",
        "\n",
        "        # 基礎權重 - 調整以適應三個來源\n",
        "        default_yolo_weight = 0.5\n",
        "        default_clip_weight = 0.3\n",
        "        default_places365_weight = 0.2\n",
        "\n",
        "        is_lighting_indoor = None\n",
        "        lighting_analysis_confidence = 0.0\n",
        "        if lighting_info and isinstance(lighting_info, dict):\n",
        "            is_lighting_indoor = lighting_info.get(\"is_indoor\")\n",
        "            lighting_analysis_confidence = lighting_info.get(\"confidence\", 0.0)\n",
        "\n",
        "        for scene_type in all_possible_scene_types:\n",
        "            yolo_score = yolo_scene_scores.get(scene_type, 0.0)\n",
        "            clip_score = clip_scene_scores.get(scene_type, 0.0)\n",
        "            places365_score = places365_scene_scores_map.get(scene_type, 0.0)\n",
        "\n",
        "            current_yolo_weight = default_yolo_weight\n",
        "            current_clip_weight = default_clip_weight\n",
        "            current_places365_weight = default_places365_weight\n",
        "\n",
        "            scene_definition = self.scene_types.get(scene_type, {})\n",
        "\n",
        "            # 基於場景類型性質和 YOLO 豐富度的權重調整\n",
        "            if scene_type in self.EVERYDAY_SCENE_TYPE_KEYS:\n",
        "                # Places365 在日常場景分類方面表現出色\n",
        "                if num_yolo_detections >= 5 and avg_yolo_confidence >= 0.45:  # 豐富的 YOLO 用於日常場景\n",
        "                    current_yolo_weight = 0.60\n",
        "                    current_clip_weight = 0.15\n",
        "                    current_places365_weight = 0.25\n",
        "                elif num_yolo_detections >= 3:  # 中等 YOLO 用於日常場景\n",
        "                    current_yolo_weight = 0.50\n",
        "                    current_clip_weight = 0.20\n",
        "                    current_places365_weight = 0.30\n",
        "                else:  # 降低 YOLO 用於日常場景，更多依賴 Places365\n",
        "                    current_yolo_weight = 0.35\n",
        "                    current_clip_weight = 0.25\n",
        "                    current_places365_weight = 0.40\n",
        "\n",
        "            # 對於 CLIP 的全域理解或特定訓練通常更有價值的場景\n",
        "            elif any(keyword in scene_type.lower() for keyword in [\"asian\", \"cultural\", \"aerial\", \"landmark\", \"monument\", \"tourist\", \"natural_landmark\", \"historical_monument\"]):\n",
        "                current_yolo_weight = 0.25\n",
        "                current_clip_weight = 0.65\n",
        "                current_places365_weight = 0.10  # 地標場景的較低權重\n",
        "\n",
        "            # 對於特定室內常見場景（非地標），物體檢測是關鍵，但 Places365 提供強大的場景上下文\n",
        "            elif any(keyword in scene_type.lower() for keyword in\n",
        "                    [\"room\", \"kitchen\", \"office\", \"bedroom\", \"desk_area\", \"indoor_space\",\n",
        "                     \"professional_kitchen\", \"cafe\", \"library\", \"gym\", \"retail_store\",\n",
        "                     \"supermarket\", \"classroom\", \"conference_room\", \"medical_facility\",\n",
        "                     \"educational_setting\", \"dining_area\"]):\n",
        "                current_yolo_weight = 0.55\n",
        "                current_clip_weight = 0.20\n",
        "                current_places365_weight = 0.25\n",
        "\n",
        "            # 對於特定室外常見場景（非地標），物體仍然重要\n",
        "            elif any(keyword in scene_type.lower() for keyword in\n",
        "                    [\"parking_lot\", \"park_area\", \"beach\", \"harbor\", \"playground\", \"sports_field\", \"bus_stop\", \"train_station\", \"airport\"]):\n",
        "                current_yolo_weight = 0.50\n",
        "                current_clip_weight = 0.25\n",
        "                current_places365_weight = 0.25\n",
        "\n",
        "            # 如果為此次運行全域禁用地標檢測\n",
        "            if not self.enable_landmark:\n",
        "                if any(keyword in scene_type.lower() for keyword in [\"landmark\", \"monument\", \"tourist\"]):\n",
        "                    yolo_score = 0.0  # 應該已經從 compute_scene_scores 中為 0\n",
        "                    clip_score *= 0.05  # 重度懲罰\n",
        "                    places365_score *= 0.8 if scene_type not in self.EVERYDAY_SCENE_TYPE_KEYS else 1.0  # 地標場景的輕微懲罰\n",
        "                elif (scene_type not in self.EVERYDAY_SCENE_TYPE_KEYS and\n",
        "                      not any(keyword in scene_type.lower() for keyword in [\"asian\", \"cultural\", \"aerial\"])):\n",
        "                    # 將權重從 CLIP 重新分配給 YOLO 和 Places365\n",
        "                    weight_boost = 0.05\n",
        "                    current_yolo_weight = min(0.9, current_yolo_weight + weight_boost)\n",
        "                    current_places365_weight = min(0.9, current_places365_weight + weight_boost)\n",
        "                    current_clip_weight = max(0.1, current_clip_weight - weight_boost * 2)\n",
        "\n",
        "            # 如果 Places365 對此特定場景類型有高置信度，則提升其權重\n",
        "            if places365_score > 0.0 and places365_info:  # 這裡的 places365_score 已經是從 map 中獲取\n",
        "                places365_original_confidence = places365_info.get('confidence', 0.0)  # 獲取原始的 Places365 信心度\n",
        "                if places365_original_confidence > 0.7:\n",
        "                    boost_factor = min(0.2, (places365_original_confidence - 0.7) * 0.4)\n",
        "                    current_places365_weight += boost_factor\n",
        "                    total_other_weight = current_yolo_weight + current_clip_weight\n",
        "                    if total_other_weight > 0:\n",
        "                        reduction_factor = boost_factor / total_other_weight\n",
        "                        current_yolo_weight *= (1 - reduction_factor)\n",
        "                        current_clip_weight *= (1 - reduction_factor)\n",
        "\n",
        "            # 權重標準化處理\n",
        "            total_weight = current_yolo_weight + current_clip_weight + current_places365_weight\n",
        "            if total_weight > 0:  # 避免除以零\n",
        "                current_yolo_weight /= total_weight\n",
        "                current_clip_weight /= total_weight\n",
        "                current_places365_weight /= total_weight\n",
        "            else:\n",
        "                current_yolo_weight = 1/3\n",
        "                current_clip_weight = 1/3\n",
        "                current_places365_weight = 1/3\n",
        "\n",
        "             # 計算融合score\n",
        "            fused_score = (yolo_score * current_yolo_weight) + (clip_score * current_clip_weight) + (places365_score * current_places365_weight)\n",
        "\n",
        "            # 處理室內外判斷的衝突分析\n",
        "            places365_is_indoor = None\n",
        "            places365_confidence_for_indoor = 0.0\n",
        "            effective_is_indoor = is_lighting_indoor\n",
        "            effective_confidence = lighting_analysis_confidence\n",
        "\n",
        "            if places365_info and isinstance(places365_info, dict):\n",
        "                places365_is_indoor = places365_info.get('is_indoor')\n",
        "                places365_confidence_for_indoor = places365_info.get('confidence', 0.0)\n",
        "\n",
        "                # Places365 在置信度高時覆蓋照明分析\n",
        "                if places365_confidence_for_indoor >= 0.8 and places365_is_indoor is not None:\n",
        "                    effective_is_indoor = places365_is_indoor\n",
        "                    effective_confidence = places365_confidence_for_indoor\n",
        "\n",
        "                    # 只在特定場景類型首次處理時輸出調試資訊\n",
        "                    if (scene_type == \"intersection\" or\n",
        "                        (scene_type in [\"urban_intersection\", \"street_view\"] and\n",
        "                         scene_type == sorted(all_possible_scene_types)[0])):\n",
        "                        self.logger.debug(f\"Using Places365 indoor/outdoor decision: {places365_is_indoor} (confidence: {places365_confidence_for_indoor:.3f}) over lighting analysis\")\n",
        "\n",
        "            if effective_is_indoor is not None and effective_confidence >= 0.65:\n",
        "                # 基於其定義確定場景類型本質上是室內還是室外\n",
        "                is_defined_as_indoor = (\"indoor\" in scene_definition.get(\"description\", \"\").lower() or\n",
        "                                       any(kw in scene_type.lower() for kw in [\"room\", \"kitchen\", \"office\", \"indoor\", \"library\", \"cafe\", \"gym\"]))\n",
        "                is_defined_as_outdoor = (\"outdoor\" in scene_definition.get(\"description\", \"\").lower() or\n",
        "                                        any(kw in scene_type.lower() for kw in [\"street\", \"park\", \"aerial\", \"beach\", \"harbor\", \"intersection\", \"crosswalk\"]))\n",
        "\n",
        "                lighting_adjustment_strength = 0.20  # 最大調整因子（例如，20%）\n",
        "                # 根據分析在閾值以上的置信度來縮放調整\n",
        "                adjustment_scale = (effective_confidence - 0.65) / (1.0 - 0.65)  # 從 0 到 1 縮放\n",
        "                adjustment = lighting_adjustment_strength * adjustment_scale\n",
        "                adjustment = min(lighting_adjustment_strength, max(0, adjustment))  # 限制調整\n",
        "\n",
        "                if effective_is_indoor and is_defined_as_outdoor:\n",
        "                    fused_score *= (1.0 - adjustment)\n",
        "                elif not effective_is_indoor and is_defined_as_indoor:\n",
        "                    fused_score *= (1.0 - adjustment)\n",
        "                elif effective_is_indoor and is_defined_as_indoor:\n",
        "                    fused_score = min(1.0, fused_score * (1.0 + adjustment * 0.5))\n",
        "                elif not effective_is_indoor and is_defined_as_outdoor:\n",
        "                    fused_score = min(1.0, fused_score * (1.0 + adjustment * 0.5))\n",
        "\n",
        "            fused_scores[scene_type] = min(1.0, max(0.0, fused_score))\n",
        "\n",
        "        return fused_scores\n",
        "\n",
        "    def update_enable_landmark_status(self, enable_landmark: bool):\n",
        "        \"\"\"\n",
        "        更新地標檢測的啟用狀態。\n",
        "\n",
        "        Args:\n",
        "            enable_landmark: 是否啟用地標檢測\n",
        "        \"\"\"\n",
        "        self.enable_landmark = enable_landmark"
      ],
      "metadata": {
        "id": "ls5Fd2dquSHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999339a0-3b3a-4292-e395-6acfb5dc3e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scene_scoring_engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile landmark_processing_manager.py\n",
        "import re\n",
        "import logging\n",
        "import traceback\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from PIL import Image\n",
        "\n",
        "# from clip_zero_shot_classifier import CLIPZeroShotClassifier\n",
        "# from landmark_activities import LANDMARK_ACTIVITIES\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "\n",
        "\n",
        "class LandmarkProcessingManager:\n",
        "    \"\"\"\n",
        "    負責處理所有地標相關的檢測和處理邏輯，包括未知物體的地標識別、\n",
        "    地標物體的創建和驗證，以及地標引用的清理。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, enable_landmark: bool = True, use_clip: bool = True):\n",
        "        \"\"\"\n",
        "        初始化地標處理管理器。\n",
        "\n",
        "        Args:\n",
        "            enable_landmark: 是否啟用地標檢測功能\n",
        "            use_clip: 是否啟用 CLIP 分析功能\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.enable_landmark = enable_landmark\n",
        "        self.use_clip = use_clip\n",
        "\n",
        "        # 載入地標相關數據\n",
        "        self.landmark_activities = {}\n",
        "        self.all_landmarks = {}\n",
        "        self._load_landmark_data()\n",
        "\n",
        "        # 地標分類器將按需初始化\n",
        "        self.landmark_classifier = None\n",
        "\n",
        "    def _load_landmark_data(self):\n",
        "        \"\"\"載入地標相關的數據結構。\"\"\"\n",
        "        try:\n",
        "            self.landmark_activities = LANDMARK_ACTIVITIES\n",
        "            self.logger.info(\"Loaded LANDMARK_ACTIVITIES successfully\")\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Failed to load LANDMARK_ACTIVITIES: {e}\")\n",
        "            self.landmark_activities = {}\n",
        "\n",
        "        try:\n",
        "            self.all_landmarks = ALL_LANDMARKS\n",
        "            self.logger.info(\"Loaded ALL_LANDMARKS successfully\")\n",
        "        except ImportError as e:\n",
        "            self.logger.warning(f\"Failed to load ALL_LANDMARKS: {e}\")\n",
        "            self.all_landmarks = {}\n",
        "\n",
        "    def set_landmark_classifier(self, landmark_classifier):\n",
        "        \"\"\"\n",
        "        設置地標分類器實例。\n",
        "\n",
        "        Args:\n",
        "            landmark_classifier: CLIPZeroShotClassifier 實例\n",
        "        \"\"\"\n",
        "        self.landmark_classifier = landmark_classifier\n",
        "\n",
        "    def process_unknown_objects(self, detection_result, detected_objects, clip_analyzer=None):\n",
        "        \"\"\"\n",
        "        對 YOLO 未能識別或信心度低的物體進行地標檢測。\n",
        "\n",
        "        Args:\n",
        "            detection_result: YOLO 檢測結果\n",
        "            detected_objects: 已識別的物體列表\n",
        "            clip_analyzer: CLIP 分析器實例（用於按需初始化地標分類器）\n",
        "\n",
        "        Returns:\n",
        "            tuple: (更新後的物體列表, 地標物體列表)\n",
        "        \"\"\"\n",
        "        if (not self.enable_landmark or not self.use_clip or\n",
        "            not hasattr(self, 'use_landmark_detection') or not self.use_landmark_detection):\n",
        "            # 未啟用地標識別時，確保返回的物體列表中不包含任何地標物體\n",
        "            cleaned_objects = [obj for obj in detected_objects if not obj.get(\"is_landmark\", False)]\n",
        "            return cleaned_objects, []\n",
        "\n",
        "        try:\n",
        "            # 獲取原始圖像\n",
        "            original_image = None\n",
        "            if detection_result is not None and hasattr(detection_result, 'orig_img'):\n",
        "                original_image = detection_result.orig_img\n",
        "\n",
        "            # 檢查原始圖像是否存在\n",
        "            if original_image is None:\n",
        "                self.logger.warning(\"Original image not available for landmark detection\")\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 確保原始圖像為 PIL 格式或可轉換為 PIL 格式\n",
        "            if not isinstance(original_image, Image.Image):\n",
        "                if isinstance(original_image, np.ndarray):\n",
        "                    try:\n",
        "                        if original_image.ndim == 3 and original_image.shape[2] == 4:  # RGBA\n",
        "                            original_image = original_image[:, :, :3]  # 轉換為 RGB\n",
        "                        if original_image.ndim == 2:  # 灰度圖\n",
        "                            original_image = Image.fromarray(original_image).convert(\"RGB\")\n",
        "                        else:  # 假設為 RGB 或 BGR\n",
        "                            original_image = Image.fromarray(original_image)\n",
        "\n",
        "                        if hasattr(original_image, 'mode') and original_image.mode == 'BGR':  # 從 OpenCV 明確將 BGR 轉換為 RGB\n",
        "                            original_image = original_image.convert('RGB')\n",
        "                    except Exception as e:\n",
        "                        self.logger.warning(f\"Error converting image for landmark detection: {e}\")\n",
        "                        return detected_objects, []\n",
        "                else:\n",
        "                    self.logger.warning(f\"Cannot process image of type {type(original_image)}\")\n",
        "                    return detected_objects, []\n",
        "\n",
        "            # 獲取圖像維度\n",
        "            if isinstance(original_image, np.ndarray):\n",
        "                h, w = original_image.shape[:2]\n",
        "            elif isinstance(original_image, Image.Image):\n",
        "                w, h = original_image.size\n",
        "            else:\n",
        "                self.logger.warning(f\"Unable to determine image dimensions for type {type(original_image)}\")\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 收集可能含有地標的區域\n",
        "            candidate_boxes = []\n",
        "            low_conf_boxes = []\n",
        "\n",
        "            # 即使沒有 YOLO 檢測到的物體，也嘗試進行更詳細的地標分析\n",
        "            if len(detected_objects) == 0:\n",
        "                # 創建一個包含整個圖像的框\n",
        "                full_image_box = [0, 0, w, h]\n",
        "                low_conf_boxes.append(full_image_box)\n",
        "                candidate_boxes.append((full_image_box, \"full_image\"))\n",
        "\n",
        "                # 加入網格分析以增加檢測成功率\n",
        "                grid_size = 2  # 2x2 網格\n",
        "                for i in range(grid_size):\n",
        "                    for j in range(grid_size):\n",
        "                        # 創建網格框\n",
        "                        grid_box = [\n",
        "                            j * w / grid_size,\n",
        "                            i * h / grid_size,\n",
        "                            (j + 1) * w / grid_size,\n",
        "                            (i + 1) * h / grid_size\n",
        "                        ]\n",
        "                        low_conf_boxes.append(grid_box)\n",
        "                        candidate_boxes.append((grid_box, \"grid\"))\n",
        "\n",
        "                # 創建更大的中心框（覆蓋中心 70% 區域）\n",
        "                center_box = [\n",
        "                    w * 0.15, h * 0.15,\n",
        "                    w * 0.85, h * 0.85\n",
        "                ]\n",
        "                low_conf_boxes.append(center_box)\n",
        "                candidate_boxes.append((center_box, \"center\"))\n",
        "\n",
        "                self.logger.info(\"No YOLO detections, attempting detailed landmark analysis with multiple regions\")\n",
        "            else:\n",
        "                try:\n",
        "                    # 獲取原始 YOLO 檢測結果中的低置信度物體\n",
        "                    if (hasattr(detection_result, 'boxes') and\n",
        "                        hasattr(detection_result.boxes, 'xyxy') and\n",
        "                        hasattr(detection_result.boxes, 'conf') and\n",
        "                        hasattr(detection_result.boxes, 'cls')):\n",
        "                        all_boxes = (detection_result.boxes.xyxy.cpu().numpy()\n",
        "                                   if hasattr(detection_result.boxes.xyxy, 'cpu')\n",
        "                                   else detection_result.boxes.xyxy)\n",
        "                        all_confs = (detection_result.boxes.conf.cpu().numpy()\n",
        "                                   if hasattr(detection_result.boxes.conf, 'cpu')\n",
        "                                   else detection_result.boxes.conf)\n",
        "                        all_cls = (detection_result.boxes.cls.cpu().numpy()\n",
        "                                 if hasattr(detection_result.boxes.cls, 'cpu')\n",
        "                                 else detection_result.boxes.cls)\n",
        "\n",
        "                        # 收集低置信度區域和可能含有地標的區域（如建築物）\n",
        "                        for i, (box, conf, cls) in enumerate(zip(all_boxes, all_confs, all_cls)):\n",
        "                            is_low_conf = conf < 0.4 and conf > 0.1\n",
        "\n",
        "                            # 根據物體類別 ID 識別建築物 - 使用通用分類\n",
        "                            common_building_classes = [11, 12, 13, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]  # 常見建築類別 ID\n",
        "                            is_building = int(cls) in common_building_classes\n",
        "\n",
        "                            # 計算相對面積 - 大物體\n",
        "                            is_large_object = (box[2] - box[0]) * (box[3] - box[1]) > (0.1 * w * h)\n",
        "\n",
        "                            if is_low_conf or is_building:\n",
        "                                # 確保 box 是一個有效的數組或列表\n",
        "                                if isinstance(box, (list, tuple, np.ndarray)) and len(box) >= 4:\n",
        "                                    low_conf_boxes.append(box)\n",
        "                                    if is_large_object:\n",
        "                                        candidate_boxes.append((box, \"building\" if is_building else \"low_conf\"))\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error processing YOLO detections: {e}\")\n",
        "                    traceback.print_exc()\n",
        "\n",
        "            # 按需初始化地標分類器\n",
        "            if not self.landmark_classifier:\n",
        "                if clip_analyzer and hasattr(clip_analyzer, 'get_clip_instance'):\n",
        "                    try:\n",
        "                        self.logger.info(\"Initializing landmark classifier for process_unknown_objects\")\n",
        "                        model, preprocess, device = clip_analyzer.get_clip_instance()\n",
        "                        self.landmark_classifier = CLIPZeroShotClassifier(device=device)\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error initializing landmark classifier: {e}\")\n",
        "                        return detected_objects, []\n",
        "                else:\n",
        "                    self.logger.warning(\"landmark_classifier not available and cannot be initialized\")\n",
        "                    return detected_objects, []\n",
        "\n",
        "            # 使用智能地標搜索\n",
        "            landmark_results = None\n",
        "            try:\n",
        "                # 確保有有效的框\n",
        "                if not low_conf_boxes:\n",
        "                    # 如果沒有低置信度框，添加全圖\n",
        "                    low_conf_boxes.append([0, 0, w, h])\n",
        "\n",
        "                landmark_results = self.landmark_classifier.intelligent_landmark_search(\n",
        "                    original_image,\n",
        "                    yolo_boxes=low_conf_boxes,\n",
        "                    base_threshold=0.25\n",
        "                )\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error in intelligent_landmark_search: {e}\")\n",
        "                traceback.print_exc()\n",
        "                return detected_objects, []\n",
        "\n",
        "            # 處理識別結果\n",
        "            landmark_objects = []\n",
        "\n",
        "            # 如果有效的地標結果\n",
        "            if landmark_results and landmark_results.get(\"is_landmark_scene\", False):\n",
        "                for landmark_info in landmark_results.get(\"detected_landmarks\", []):\n",
        "                    try:\n",
        "                        # 使用 landmark_classifier 的閾值判斷\n",
        "                        base_threshold = 0.25  # 基礎閾值\n",
        "\n",
        "                        # 獲取地標類型並設定閾值\n",
        "                        landmark_type = \"architectural\"  # 預設類型\n",
        "                        type_threshold = 0.5  # 預設閾值\n",
        "\n",
        "                        # 優先使用 landmark_classifier\n",
        "                        if (hasattr(self.landmark_classifier, '_determine_landmark_type') and\n",
        "                            landmark_info.get(\"landmark_id\")):\n",
        "                            landmark_type = self.landmark_classifier._determine_landmark_type(landmark_info.get(\"landmark_id\"))\n",
        "                            type_threshold = getattr(self.landmark_classifier, 'landmark_type_thresholds', {}).get(landmark_type, 0.5)\n",
        "                        # 否則使用本地方法\n",
        "                        elif hasattr(self, '_determine_landmark_type'):\n",
        "                            landmark_type = self._determine_landmark_type(landmark_info.get(\"landmark_id\", \"\"))\n",
        "                            # 依據地標類型調整閾值\n",
        "                            if landmark_type == \"skyscraper\":\n",
        "                                type_threshold = 0.4\n",
        "                            elif landmark_type == \"natural\":\n",
        "                                type_threshold = 0.6\n",
        "                        # 或者直接從地標 ID 推斷\n",
        "                        else:\n",
        "                            landmark_id = landmark_info.get(\"landmark_id\", \"\").lower()\n",
        "                            if any(term in landmark_id for term in [\"mountain\", \"canyon\", \"waterfall\", \"lake\", \"river\", \"natural\"]):\n",
        "                                landmark_type = \"natural\"\n",
        "                                type_threshold = 0.6\n",
        "                            elif any(term in landmark_id for term in [\"skyscraper\", \"building\", \"tower\", \"tall\"]):\n",
        "                                landmark_type = \"skyscraper\"\n",
        "                                type_threshold = 0.4\n",
        "                            elif any(term in landmark_id for term in [\"monument\", \"memorial\", \"statue\", \"historical\"]):\n",
        "                                landmark_type = \"monument\"\n",
        "                                type_threshold = 0.5\n",
        "\n",
        "                        effective_threshold = base_threshold * (type_threshold / 0.5)\n",
        "\n",
        "                        # 如果置信度足夠高\n",
        "                        if landmark_info.get(\"confidence\", 0) > effective_threshold:\n",
        "                            # 獲取邊界框\n",
        "                            if \"box\" in landmark_info:\n",
        "                                box = landmark_info[\"box\"]\n",
        "                            else:\n",
        "                                # 如果沒有邊界框，使用整個圖像的 90% 區域\n",
        "                                margin_x, margin_y = w * 0.05, h * 0.05\n",
        "                                box = [margin_x, margin_y, w - margin_x, h - margin_y]\n",
        "\n",
        "                            # 計算中心點和其他必要信息\n",
        "                            center_x = (box[0] + box[2]) / 2\n",
        "                            center_y = (box[1] + box[3]) / 2\n",
        "                            norm_center_x = center_x / w if w > 0 else 0.5\n",
        "                            norm_center_y = center_y / h if h > 0 else 0.5\n",
        "\n",
        "                            # 獲取區域位置（需要 spatial_analyzer 的支持）\n",
        "                            region = \"center\"  # 預設\n",
        "\n",
        "                            # 創建地標物體\n",
        "                            landmark_obj = {\n",
        "                                \"class_id\": (landmark_info.get(\"landmark_id\", \"\")[:15]\n",
        "                                           if isinstance(landmark_info.get(\"landmark_id\", \"\"), str)\n",
        "                                           else \"-100\"),  # 截斷過長的 ID\n",
        "                                \"class_name\": landmark_info.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                                \"confidence\": landmark_info.get(\"confidence\", 0.0),\n",
        "                                \"box\": box,\n",
        "                                \"center\": (center_x, center_y),\n",
        "                                \"normalized_center\": (norm_center_x, norm_center_y),\n",
        "                                \"size\": (box[2] - box[0], box[3] - box[1]),\n",
        "                                \"normalized_size\": (\n",
        "                                    (box[2] - box[0]) / w if w > 0 else 0,\n",
        "                                    (box[3] - box[1]) / h if h > 0 else 0\n",
        "                                ),\n",
        "                                \"area\": (box[2] - box[0]) * (box[3] - box[1]),\n",
        "                                \"normalized_area\": (\n",
        "                                    (box[2] - box[0]) * (box[3] - box[1]) / (w * h) if w * h > 0 else 0\n",
        "                                ),\n",
        "                                \"region\": region,\n",
        "                                \"is_landmark\": True,\n",
        "                                \"landmark_id\": landmark_info.get(\"landmark_id\", \"\"),\n",
        "                                \"location\": landmark_info.get(\"location\", \"Unknown Location\")\n",
        "                            }\n",
        "\n",
        "                            # 添加額外信息\n",
        "                            for key in [\"year_built\", \"architectural_style\", \"significance\"]:\n",
        "                                if key in landmark_info:\n",
        "                                    landmark_obj[key] = landmark_info[key]\n",
        "\n",
        "                            # 添加地標類型\n",
        "                            landmark_obj[\"landmark_type\"] = landmark_type\n",
        "\n",
        "                            # 添加到檢測物體列表\n",
        "                            detected_objects.append(landmark_obj)\n",
        "                            landmark_objects.append(landmark_obj)\n",
        "                            self.logger.info(f\"Detected landmark: {landmark_info.get('landmark_name', 'Unknown')} with confidence {landmark_info.get('confidence', 0.0):.2f}\")\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error processing landmark: {e}\")\n",
        "                        continue\n",
        "\n",
        "                return detected_objects, landmark_objects\n",
        "\n",
        "            return detected_objects, []\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in landmark detection: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return detected_objects, []\n",
        "\n",
        "    def remove_landmark_references(self, text):\n",
        "        \"\"\"\n",
        "        從文本中移除所有地標引用。\n",
        "\n",
        "        Args:\n",
        "            text: 輸入文本\n",
        "\n",
        "        Returns:\n",
        "            str: 清除地標引用後的文本\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        try:\n",
        "            # 動態收集所有地標名稱和位置\n",
        "            landmark_names = []\n",
        "            locations = []\n",
        "\n",
        "            for landmark_id, info in self.all_landmarks.items():\n",
        "                # 收集地標名稱及其別名\n",
        "                landmark_names.append(info[\"name\"])\n",
        "                landmark_names.extend(info.get(\"aliases\", []))\n",
        "\n",
        "                # 收集地理位置\n",
        "                if \"location\" in info:\n",
        "                    location = info[\"location\"]\n",
        "                    locations.append(location)\n",
        "\n",
        "                    # 處理分離的城市和國家名稱\n",
        "                    parts = location.split(\",\")\n",
        "                    if len(parts) >= 1:\n",
        "                        locations.append(parts[0].strip())\n",
        "                    if len(parts) >= 2:\n",
        "                        locations.append(parts[1].strip())\n",
        "\n",
        "            # 使用正則表達式動態替換所有地標名稱\n",
        "            for name in landmark_names:\n",
        "                if name and len(name) > 2:  # 避免過短的名稱\n",
        "                    text = re.sub(r'\\b' + re.escape(name) + r'\\b', \"tall structure\", text, flags=re.IGNORECASE)\n",
        "\n",
        "            # 動態替換所有位置引用\n",
        "            for location in locations:\n",
        "                if location and len(location) > 2:\n",
        "                    # 替換常見位置表述模式\n",
        "                    text = re.sub(r'in ' + re.escape(location), \"in the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'of ' + re.escape(location), \"of the urban area\", text, flags=re.IGNORECASE)\n",
        "                    text = re.sub(r'\\b' + re.escape(location) + r'\\b', \"the urban area\", text, flags=re.IGNORECASE)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in dynamic landmark reference removal, using generic patterns: {e}\")\n",
        "            # 通用地標描述模式\n",
        "            landmark_patterns = [\n",
        "                # 地標地點模式\n",
        "                (r'an iconic structure in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure'),\n",
        "                (r'a famous (monument|tower|landmark) in ([A-Z][a-zA-Z\\s,]+)', r'an urban structure'),\n",
        "                (r'(the [A-Z][a-zA-Z\\s]+ Tower)', r'the tower'),\n",
        "                (r'(the [A-Z][a-zA-Z\\s]+ Building)', r'the building'),\n",
        "                (r'(the CN Tower)', r'the tower'),\n",
        "                (r'([A-Z][a-zA-Z\\s]+) Tower', r'tall structure'),\n",
        "\n",
        "                # 地標位置關係模式\n",
        "                (r'(centered|built|located|positioned) around the ([A-Z][a-zA-Z\\s]+? (Tower|Monument|Landmark))', r'located in this area'),\n",
        "\n",
        "                # 地標活動模式\n",
        "                (r'(sightseeing|guided tours|cultural tourism) (at|around|near) (this landmark|the [A-Z][a-zA-Z\\s]+)', r'\\1 in this area'),\n",
        "\n",
        "                # 一般性地標形容模式\n",
        "                (r'this (famous|iconic|historic|well-known) (landmark|monument|tower|structure)', r'this urban structure'),\n",
        "                (r'landmark scene', r'urban scene'),\n",
        "                (r'tourist destination', r'urban area'),\n",
        "                (r'tourist attraction', r'urban area')\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in landmark_patterns:\n",
        "                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def get_alternative_scene_type(self, landmark_scene_type, detected_objects, scene_scores):\n",
        "        \"\"\"\n",
        "        為地標場景類型選擇適合的替代類型。\n",
        "\n",
        "        Args:\n",
        "            landmark_scene_type: 原始地標場景類型\n",
        "            detected_objects: 檢測到的物體列表\n",
        "            scene_scores: 所有場景類型的分數\n",
        "\n",
        "        Returns:\n",
        "            str: 適合的替代場景類型\n",
        "        \"\"\"\n",
        "        # 1. 嘗試從現有場景分數中找出第二高的非地標場景\n",
        "        landmark_types = {\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"}\n",
        "        alternative_scores = {k: v for k, v in scene_scores.items() if k not in landmark_types and v > 0.2}\n",
        "\n",
        "        if alternative_scores:\n",
        "            # 返回分數最高的非地標場景類型\n",
        "            return max(alternative_scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        # 2. 基於物體組合推斷場景類型\n",
        "        object_counts = {}\n",
        "        for obj in detected_objects:\n",
        "            class_name = obj.get(\"class_name\", \"\")\n",
        "            if class_name not in object_counts:\n",
        "                object_counts[class_name] = 0\n",
        "            object_counts[class_name] += 1\n",
        "\n",
        "        # 根據物體組合決定場景類型\n",
        "        if \"car\" in object_counts or \"truck\" in object_counts or \"bus\" in object_counts:\n",
        "            # 有車輛，可能是街道或交叉路口\n",
        "            if \"traffic light\" in object_counts or \"stop sign\" in object_counts:\n",
        "                return \"intersection\"\n",
        "            else:\n",
        "                return \"city_street\"\n",
        "\n",
        "        if \"building\" in object_counts and object_counts.get(\"person\", 0) > 0:\n",
        "            # 有建築物和人，可能是商業區\n",
        "            return \"commercial_district\"\n",
        "\n",
        "        if object_counts.get(\"person\", 0) > 3:\n",
        "            # 多個行人，可能是行人區\n",
        "            return \"pedestrian_area\"\n",
        "\n",
        "        if \"bench\" in object_counts or \"potted plant\" in object_counts:\n",
        "            # 有長椅或盆栽，可能是公園區域\n",
        "            return \"park_area\"\n",
        "\n",
        "        # 3. 根據原始地標場景類型選擇合適的替代場景\n",
        "        if landmark_scene_type == \"natural_landmark\":\n",
        "            return \"outdoor_natural_area\"\n",
        "        elif landmark_scene_type == \"historical_monument\":\n",
        "            return \"urban_architecture\"\n",
        "\n",
        "        # 默認回退到城市街道\n",
        "        return \"city_street\"\n",
        "\n",
        "    def extract_landmark_specific_activities(self, landmark_objects):\n",
        "        \"\"\"\n",
        "        從識別的地標中提取特定活動。\n",
        "\n",
        "        Args:\n",
        "            landmark_objects: 地標物體列表\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 地標特定活動列表\n",
        "        \"\"\"\n",
        "        landmark_specific_activities = []\n",
        "\n",
        "        # 優先收集來自識別地標的特定活動\n",
        "        for lm_obj in landmark_objects:\n",
        "            lm_id = lm_obj.get(\"landmark_id\")\n",
        "            if lm_id and lm_id in self.landmark_activities:\n",
        "                landmark_specific_activities.extend(self.landmark_activities[lm_id])\n",
        "\n",
        "        if landmark_specific_activities:\n",
        "            landmark_names = [lm.get('landmark_name', 'unknown') for lm in landmark_objects if lm.get('is_landmark', False)]\n",
        "            self.logger.info(f\"Added {len(landmark_specific_activities)} landmark-specific activities for {', '.join(landmark_names)}\")\n",
        "\n",
        "        return landmark_specific_activities\n",
        "\n",
        "    def update_enable_landmark_status(self, enable_landmark: bool):\n",
        "        \"\"\"\n",
        "        更新地標檢測的啟用狀態。\n",
        "\n",
        "        Args:\n",
        "            enable_landmark: 是否啟用地標檢測\n",
        "        \"\"\"\n",
        "        self.enable_landmark = enable_landmark\n",
        "\n",
        "    def update_use_landmark_detection_status(self, use_landmark_detection: bool):\n",
        "        \"\"\"\n",
        "        更新地標檢測使用狀態。\n",
        "\n",
        "        Args:\n",
        "            use_landmark_detection: 是否使用地標檢測\n",
        "        \"\"\"\n",
        "        self.use_landmark_detection = use_landmark_detection"
      ],
      "metadata": {
        "id": "4zWB0oeEuSEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7776a993-eba1-4488-ab6c-f745febfe2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing landmark_processing_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile scene_analysis_coordinator.py\n",
        "import logging\n",
        "import traceback\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from PIL import Image\n",
        "\n",
        "class SceneAnalysisCoordinator:\n",
        "    \"\"\"\n",
        "    負責整個場景分析流程的協調和控制邏輯，包含主要的分析流程、\n",
        "    處理無檢測結果的回退邏輯，以及多源分析結果的整合。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, component_initializer, scene_scoring_engine, landmark_processing_manager,\n",
        "                 scene_confidence_threshold: float = 0.6):\n",
        "        \"\"\"\n",
        "        初始化場景分析協調器。\n",
        "\n",
        "        Args:\n",
        "            component_initializer: 組件初始化器實例\n",
        "            scene_scoring_engine: 場景評分引擎實例\n",
        "            landmark_processing_manager: 地標處理管理器實例\n",
        "            scene_confidence_threshold: 場景置信度閾值\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.component_initializer = component_initializer\n",
        "        self.scene_scoring_engine = scene_scoring_engine\n",
        "        self.landmark_processing_manager = landmark_processing_manager\n",
        "        self.scene_confidence_threshold = scene_confidence_threshold\n",
        "\n",
        "        # 獲取必要的組件和數據\n",
        "        self.spatial_analyzer = component_initializer.get_component('spatial_analyzer')\n",
        "        self.descriptor = component_initializer.get_component('descriptor')\n",
        "        self.scene_describer = component_initializer.get_component('scene_describer')\n",
        "        self.clip_analyzer = component_initializer.get_component('clip_analyzer')\n",
        "        self.llm_enhancer = component_initializer.get_component('llm_enhancer')\n",
        "\n",
        "        self.scene_types = component_initializer.get_data_structure('SCENE_TYPES')\n",
        "\n",
        "        # 從組件初始化器獲取功能開關狀態\n",
        "        self.use_clip = component_initializer.use_clip\n",
        "        self.use_llm = component_initializer.use_llm\n",
        "        self.enable_landmark = component_initializer.enable_landmark\n",
        "\n",
        "    def analyze(self, detection_result: Any, lighting_info: Optional[Dict] = None,\n",
        "                class_confidence_threshold: float = 0.25, scene_confidence_threshold: float = 0.6,\n",
        "                enable_landmark: bool = True, places365_info: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        分析檢測結果以確定場景類型並提供理解。\n",
        "\n",
        "        Args:\n",
        "            detection_result: 來自 YOLOv8 或類似系統的檢測結果\n",
        "            lighting_info: 可選的照明條件分析結果\n",
        "            class_confidence_threshold: 考慮物體的最小置信度\n",
        "            scene_confidence_threshold: 確定場景的最小置信度\n",
        "            enable_landmark: 是否為此次運行啟用地標檢測和識別\n",
        "            places365_info: 可選的 Places365 場景分類結果\n",
        "\n",
        "        Returns:\n",
        "            包含場景分析結果的字典\n",
        "        \"\"\"\n",
        "        current_run_enable_landmark = enable_landmark\n",
        "        self.logger.info(f\"DIAGNOSTIC (SceneAnalyzer.analyze): Called with current_run_enable_landmark={current_run_enable_landmark}\")\n",
        "        self.logger.debug(f\"SceneAnalyzer received lighting_info type: {type(lighting_info)}\")\n",
        "        self.logger.debug(f\"SceneAnalyzer lighting_info source: {lighting_info.get('source', 'unknown') if isinstance(lighting_info, dict) else 'not_dict'}\")\n",
        "\n",
        "        # 記錄 Places365 資訊\n",
        "        if places365_info:\n",
        "            self.logger.info(f\"DIAGNOSTIC: Places365 info received - scene: {places365_info.get('scene_label', 'unknown')}, \"\n",
        "                           f\"mapped: {places365_info.get('mapped_scene_type', 'unknown')}, \"\n",
        "                           f\"confidence: {places365_info.get('confidence', 0.0):.3f}\")\n",
        "\n",
        "        # 同步 enable_landmark 狀態到子組件（為此次分析運行）\n",
        "        self._sync_landmark_status_to_components(current_run_enable_landmark)\n",
        "\n",
        "        # 提取和處理原始圖像\n",
        "        original_image_pil, image_dims_val = self._extract_image_info(detection_result)\n",
        "\n",
        "        # 處理無 YOLO 檢測結果的情況\n",
        "        no_yolo_detections = self._check_no_yolo_detections(detection_result)\n",
        "\n",
        "        if no_yolo_detections:\n",
        "            return self._handle_no_yolo_detections(\n",
        "                original_image_pil, image_dims_val, current_run_enable_landmark,\n",
        "                lighting_info, places365_info\n",
        "            )\n",
        "\n",
        "        # 主處理流程（有 YOLO 檢測結果）\n",
        "        return self._handle_main_analysis_flow(\n",
        "            detection_result, original_image_pil, image_dims_val,\n",
        "            class_confidence_threshold, scene_confidence_threshold,\n",
        "            current_run_enable_landmark, lighting_info, places365_info\n",
        "        )\n",
        "\n",
        "    def _sync_landmark_status_to_components(self, current_run_enable_landmark: bool):\n",
        "        \"\"\"同步地標狀態到所有相關組件。\"\"\"\n",
        "        # 更新場景評分引擎\n",
        "        self.scene_scoring_engine.update_enable_landmark_status(current_run_enable_landmark)\n",
        "\n",
        "        # 更新地標處理管理器\n",
        "        self.landmark_processing_manager.update_enable_landmark_status(current_run_enable_landmark)\n",
        "\n",
        "        # 更新其他組件的地標狀態\n",
        "        for component_name in ['scene_describer', 'clip_analyzer', 'landmark_classifier']:\n",
        "            component = self.component_initializer.get_component(component_name)\n",
        "            if component and hasattr(component, 'enable_landmark'):\n",
        "                component.enable_landmark = current_run_enable_landmark\n",
        "\n",
        "        # 更新實例狀態\n",
        "        self.enable_landmark = current_run_enable_landmark\n",
        "\n",
        "    def _extract_image_info(self, detection_result) -> Tuple[Optional[Image.Image], Optional[Tuple[int, int]]]:\n",
        "        \"\"\"從檢測結果中提取圖像信息。\"\"\"\n",
        "        original_image_pil = None\n",
        "        image_dims_val = None  # 將是 (width, height)\n",
        "\n",
        "        if (detection_result is not None and hasattr(detection_result, 'orig_img') and\n",
        "            detection_result.orig_img is not None):\n",
        "            if isinstance(detection_result.orig_img, np.ndarray):\n",
        "                try:\n",
        "                    img_array = detection_result.orig_img\n",
        "                    if img_array.ndim == 3 and img_array.shape[2] == 4:  # RGBA\n",
        "                        img_array = img_array[:, :, :3]  # 轉換為 RGB\n",
        "                    if img_array.ndim == 2:  # 灰度\n",
        "                        original_image_pil = Image.fromarray(img_array).convert(\"RGB\")\n",
        "                    else:  # 假設 RGB 或 BGR（如果源是 cv2 BGR，PIL 在 fromarray 時會處理 BGR->RGB，但明確處理更好）\n",
        "                        original_image_pil = Image.fromarray(img_array)\n",
        "\n",
        "                    if hasattr(original_image_pil, 'mode') and original_image_pil.mode == 'BGR':  # 明確將 OpenCV 的 BGR 轉換為 PIL 的 RGB\n",
        "                        original_image_pil = original_image_pil.convert('RGB')\n",
        "\n",
        "                    image_dims_val = (original_image_pil.width, original_image_pil.height)\n",
        "                except Exception as e:\n",
        "                    self.logger.warning(f\"Error converting NumPy orig_img to PIL: {e}\")\n",
        "            elif hasattr(detection_result.orig_img, 'size') and callable(getattr(detection_result.orig_img, 'convert', None)):\n",
        "                original_image_pil = detection_result.orig_img.copy().convert(\"RGB\")  # 確保 RGB\n",
        "                image_dims_val = original_image_pil.size\n",
        "            else:\n",
        "                self.logger.warning(f\"detection_result.orig_img (type: {type(detection_result.orig_img)}) is not a recognized NumPy array or PIL Image.\")\n",
        "        else:\n",
        "            self.logger.warning(\"detection_result.orig_img not available. Image-based analysis will be limited.\")\n",
        "\n",
        "        return original_image_pil, image_dims_val\n",
        "\n",
        "    def _check_no_yolo_detections(self, detection_result) -> bool:\n",
        "        \"\"\"檢查是否沒有 YOLO 檢測結果。\"\"\"\n",
        "        return (detection_result is None or\n",
        "                not hasattr(detection_result, 'boxes') or\n",
        "                not hasattr(detection_result.boxes, 'xyxy') or\n",
        "                len(detection_result.boxes.xyxy) == 0)\n",
        "\n",
        "    def _handle_no_yolo_detections(self, original_image_pil, image_dims_val,\n",
        "                                 current_run_enable_landmark, lighting_info, places365_info) -> Dict:\n",
        "        \"\"\"處理無 YOLO 檢測結果的情況。\"\"\"\n",
        "        tried_landmark_detection = False\n",
        "        landmark_detection_result = None\n",
        "\n",
        "        # 嘗試地標檢測\n",
        "        if original_image_pil and self.use_clip and current_run_enable_landmark:\n",
        "            landmark_detection_result = self._attempt_landmark_detection_no_yolo(\n",
        "                original_image_pil, image_dims_val, lighting_info\n",
        "            )\n",
        "            tried_landmark_detection = True\n",
        "\n",
        "            if landmark_detection_result:\n",
        "                return landmark_detection_result\n",
        "\n",
        "        # 如果地標檢測失敗或未嘗試，使用 CLIP 進行一般場景分析\n",
        "        if not landmark_detection_result and self.use_clip and original_image_pil:\n",
        "            clip_fallback_result = self._attempt_clip_fallback_analysis(\n",
        "                original_image_pil, image_dims_val, current_run_enable_landmark, lighting_info\n",
        "            )\n",
        "            if clip_fallback_result:\n",
        "                return clip_fallback_result\n",
        "\n",
        "        # 最終回退邏輯\n",
        "        return self._get_final_fallback_result(places365_info, lighting_info)\n",
        "\n",
        "    def _attempt_landmark_detection_no_yolo(self, original_image_pil, image_dims_val, lighting_info) -> Optional[Dict]:\n",
        "        \"\"\"在無 YOLO 檢測的情況下嘗試地標檢測。\"\"\"\n",
        "        try:\n",
        "            # 初始化地標分類器（如果需要）\n",
        "            landmark_classifier = self.component_initializer.get_component('landmark_classifier')\n",
        "            if not landmark_classifier and self.clip_analyzer:\n",
        "                if hasattr(self.clip_analyzer, 'get_clip_instance'):\n",
        "                    try:\n",
        "                        model, preprocess, device = self.clip_analyzer.get_clip_instance()\n",
        "                        landmark_classifier = CLIPZeroShotClassifier(device=device)\n",
        "                        self.landmark_processing_manager.set_landmark_classifier(landmark_classifier)\n",
        "                        self.logger.info(\"Initialized landmark classifier with shared CLIP model\")\n",
        "                    except Exception as e:\n",
        "                        self.logger.warning(f\"Could not initialize landmark classifier: {e}\")\n",
        "                        return None\n",
        "\n",
        "            if landmark_classifier:\n",
        "                self.logger.info(\"Attempting landmark detection with no YOLO boxes\")\n",
        "                landmark_results_no_yolo = landmark_classifier.intelligent_landmark_search(\n",
        "                    original_image_pil, yolo_boxes=None, base_threshold=0.2  # 略微降低閾值，提高靈敏度\n",
        "                )\n",
        "\n",
        "                # 確保在無地標場景時返回有效結果\n",
        "                if landmark_results_no_yolo is None:\n",
        "                    landmark_results_no_yolo = {\"is_landmark_scene\": False, \"detected_landmarks\": []}\n",
        "\n",
        "                if (landmark_results_no_yolo and landmark_results_no_yolo.get(\"is_landmark_scene\", False)):\n",
        "                    return self._process_landmark_detection_result(\n",
        "                        landmark_results_no_yolo, image_dims_val, lighting_info\n",
        "                    )\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in landmark-only detection path (analyze method): {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _process_landmark_detection_result(self, landmark_results, image_dims_val, lighting_info) -> Dict:\n",
        "        \"\"\"處理地標檢測結果並生成最終輸出。\"\"\"\n",
        "        primary_landmark = landmark_results.get(\"primary_landmark\")\n",
        "\n",
        "        # 放寬閾值條件，以便捕獲更多潛在地標\n",
        "        if not primary_landmark or primary_landmark.get(\"confidence\", 0) <= 0.25:\n",
        "            return None\n",
        "\n",
        "        detected_objects_from_landmarks_list = []\n",
        "        w_img, h_img = image_dims_val if image_dims_val else (1, 1)\n",
        "\n",
        "        for lm_info_item in landmark_results.get(\"detected_landmarks\", []):\n",
        "            if lm_info_item.get(\"confidence\", 0) > 0.25:  # 降低閾值與上面保持一致\n",
        "                # 安全獲取 box 值，避免索引錯誤\n",
        "                box = lm_info_item.get(\"box\", [0, 0, w_img, h_img])\n",
        "                if len(box) < 4:\n",
        "                    box = [0, 0, w_img, h_img]\n",
        "\n",
        "                # 計算中心點和標準化坐標\n",
        "                center_x, center_y = (box[0] + box[2]) / 2, (box[1] + box[3]) / 2\n",
        "                norm_cx = center_x / w_img if w_img > 0 else 0.5\n",
        "                norm_cy = center_y / h_img if h_img > 0 else 0.5\n",
        "\n",
        "                # 決定地標類型\n",
        "                landmark_type = \"architectural\"  # 預設類型\n",
        "                landmark_id = lm_info_item.get(\"landmark_id\", \"\")\n",
        "\n",
        "                landmark_classifier = self.component_initializer.get_component('landmark_classifier')\n",
        "                if (landmark_classifier and hasattr(landmark_classifier, '_determine_landmark_type') and landmark_id):\n",
        "                    try:\n",
        "                        landmark_type = landmark_classifier._determine_landmark_type(landmark_id)\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error determining landmark type: {e}\")\n",
        "                else:\n",
        "                    # 使用簡單的基於 ID 的啟發式方法推斷類型\n",
        "                    landmark_id_lower = landmark_id.lower() if isinstance(landmark_id, str) else \"\"\n",
        "                    if \"natural\" in landmark_id_lower or any(term in landmark_id_lower for term in [\"mountain\", \"waterfall\", \"canyon\", \"lake\"]):\n",
        "                        landmark_type = \"natural\"\n",
        "                    elif \"monument\" in landmark_id_lower or \"memorial\" in landmark_id_lower or \"historical\" in landmark_id_lower:\n",
        "                        landmark_type = \"monument\"\n",
        "\n",
        "                # 決定區域位置\n",
        "                region = \"center\"  # 預設值\n",
        "                if self.spatial_analyzer and hasattr(self.spatial_analyzer, '_determine_region'):\n",
        "                    try:\n",
        "                        region = self.spatial_analyzer._determine_region(norm_cx, norm_cy)\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error determining region: {e}\")\n",
        "\n",
        "                # 取得並補 location\n",
        "                loc_lm = lm_info_item.get(\"location\", \"\")\n",
        "                if not loc_lm and landmark_id in ALL_LANDMARKS:\n",
        "                    loc_lm = ALL_LANDMARKS[landmark_id].get(\"location\", \"\")\n",
        "\n",
        "                # 創建地標物體\n",
        "                landmark_obj = {\n",
        "                    \"class_id\": lm_info_item.get(\"landmark_id\", f\"LM_{lm_info_item.get('landmark_name','unk')}\")[:15],\n",
        "                    \"class_name\": lm_info_item.get(\"landmark_name\", \"Unknown Landmark\"),\n",
        "                    \"confidence\": lm_info_item.get(\"confidence\", 0.0),\n",
        "                    \"box\": box,\n",
        "                    \"center\": (center_x, center_y),\n",
        "                    \"normalized_center\": (norm_cx, norm_cy),\n",
        "                    \"size\": (box[2] - box[0], box[3] - box[1]),\n",
        "                    \"normalized_size\": (\n",
        "                        (box[2] - box[0])/(w_img if w_img>0 else 1),\n",
        "                        (box[3] - box[1])/(h_img if h_img>0 else 1)\n",
        "                    ),\n",
        "                    \"area\": (box[2] - box[0]) * (box[3] - box[1]),\n",
        "                    \"normalized_area\": (\n",
        "                        (box[2] - box[0]) * (box[3] - box[1])\n",
        "                    ) / ((w_img*h_img) if w_img*h_img >0 else 1),\n",
        "                    \"is_landmark\": True,\n",
        "                    \"landmark_id\": landmark_id,\n",
        "                    \"location\": loc_lm or \"Unknown Location\",\n",
        "                    \"region\": region,\n",
        "                    \"year_built\": lm_info_item.get(\"year_built\", \"\"),\n",
        "                    \"architectural_style\": lm_info_item.get(\"architectural_style\", \"\"),\n",
        "                    \"significance\": lm_info_item.get(\"significance\", \"\"),\n",
        "                    \"landmark_type\": landmark_type\n",
        "                }\n",
        "                detected_objects_from_landmarks_list.append(landmark_obj)\n",
        "\n",
        "        if not detected_objects_from_landmarks_list:\n",
        "            return None\n",
        "\n",
        "        # 設定場景類型\n",
        "        best_scene_val = \"tourist_landmark\"  # 預設\n",
        "        if primary_landmark:\n",
        "            try:\n",
        "                lm_type = primary_landmark.get(\"landmark_type\", \"architectural\")\n",
        "                if lm_type and \"natural\" in lm_type.lower():\n",
        "                    best_scene_val = \"natural_landmark\"\n",
        "                elif lm_type and (\"historical\" in lm_type.lower() or \"monument\" in lm_type.lower()):\n",
        "                    best_scene_val = \"historical_monument\"\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error determining scene type from landmark type: {e}\")\n",
        "\n",
        "        # 確保場景類型有效\n",
        "        if best_scene_val not in self.scene_types:\n",
        "            best_scene_val = \"tourist_landmark\"  # 預設場景類型\n",
        "\n",
        "        # 設定置信度\n",
        "        scene_confidence = primary_landmark.get(\"confidence\", 0.0) if primary_landmark else 0.0\n",
        "\n",
        "        # 生成其他必要的分析結果\n",
        "        region_analysis = self._generate_region_analysis(detected_objects_from_landmarks_list)\n",
        "\n",
        "        functional_zones = self._generate_functional_zones(\n",
        "            detected_objects_from_landmarks_list,\n",
        "            best_scene_val\n",
        "        )\n",
        "\n",
        "        scene_description = self._generate_scene_description(\n",
        "            best_scene_val, detected_objects_from_landmarks_list, scene_confidence,\n",
        "            lighting_info, functional_zones, image_dims_val\n",
        "        )\n",
        "\n",
        "        enhanced_description = self._enhance_description_with_llm(\n",
        "            scene_description, best_scene_val, detected_objects_from_landmarks_list,\n",
        "            scene_confidence, lighting_info, functional_zones, landmark_results, image_dims_val\n",
        "        )\n",
        "        possible_activities = self._extract_possible_activities(detected_objects_from_landmarks_list, landmark_results)\n",
        "\n",
        "        # 準備最終結果\n",
        "        return {\n",
        "            \"scene_type\": best_scene_val,\n",
        "            \"scene_name\": self.scene_types.get(best_scene_val, {}).get(\"name\", \"Landmark\"),\n",
        "            \"confidence\": round(float(scene_confidence), 4),\n",
        "            \"description\": scene_description,\n",
        "            \"enhanced_description\": enhanced_description,\n",
        "            \"objects_present\": detected_objects_from_landmarks_list,\n",
        "            \"object_count\": len(detected_objects_from_landmarks_list),\n",
        "            \"regions\": region_analysis,\n",
        "            \"possible_activities\": possible_activities,\n",
        "            \"functional_zones\": functional_zones,\n",
        "            \"detected_landmarks\": [lm for lm in detected_objects_from_landmarks_list if lm.get(\"is_landmark\", False)],\n",
        "            \"primary_landmark\": primary_landmark,\n",
        "            \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "        }\n",
        "\n",
        "\n",
        "    def _attempt_clip_fallback_analysis(self, original_image_pil, image_dims_val,\n",
        "                                      current_run_enable_landmark, lighting_info) -> Optional[Dict]:\n",
        "        \"\"\"嘗試使用 CLIP 進行一般場景分析。\"\"\"\n",
        "        try:\n",
        "            clip_analysis_val = None\n",
        "            if self.clip_analyzer and hasattr(self.clip_analyzer, 'analyze_image'):\n",
        "                try:\n",
        "                    clip_analysis_val = self.clip_analyzer.analyze_image(\n",
        "                        original_image_pil,\n",
        "                        enable_landmark=current_run_enable_landmark\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in CLIP analysis: {e}\")\n",
        "\n",
        "            scene_type_llm = \"llm_inferred_no_yolo\"\n",
        "            confidence_llm = 0.0\n",
        "\n",
        "            if clip_analysis_val and isinstance(clip_analysis_val, dict):\n",
        "                top_scene = clip_analysis_val.get(\"top_scene\")\n",
        "                if top_scene and isinstance(top_scene, tuple) and len(top_scene) >= 2:\n",
        "                    confidence_llm = top_scene[1]\n",
        "                    if isinstance(top_scene[0], str):\n",
        "                        scene_type_llm = top_scene[0]\n",
        "\n",
        "            desc_llm = \"Primary object detection did not yield results. This description is based on overall image context.\"\n",
        "\n",
        "            w_llm, h_llm = image_dims_val if image_dims_val else (1, 1)\n",
        "            enhanced_desc_llm = self._enhance_no_detection_description(\n",
        "                desc_llm, scene_type_llm, confidence_llm, lighting_info,\n",
        "                clip_analysis_val, current_run_enable_landmark, w_llm, h_llm\n",
        "            )\n",
        "\n",
        "            # 安全類型轉換\n",
        "            try:\n",
        "                confidence_float = float(confidence_llm)\n",
        "            except (ValueError, TypeError):\n",
        "                confidence_float = 0.0\n",
        "\n",
        "            # 確保增強描述不為空\n",
        "            if not enhanced_desc_llm or not isinstance(enhanced_desc_llm, str):\n",
        "                enhanced_desc_llm = desc_llm\n",
        "\n",
        "            # 返回結果\n",
        "            return {\n",
        "                \"scene_type\": scene_type_llm,\n",
        "                \"confidence\": round(confidence_float, 4),\n",
        "                \"description\": desc_llm,\n",
        "                \"enhanced_description\": enhanced_desc_llm,\n",
        "                \"objects_present\": [],\n",
        "                \"object_count\": 0,\n",
        "                \"regions\": {},\n",
        "                \"possible_activities\": [],\n",
        "                \"safety_concerns\": [],\n",
        "                \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in CLIP no-detection fallback (analyze method): {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def _get_final_fallback_result(self, places365_info, lighting_info) -> Dict:\n",
        "        \"\"\"獲取最終的回退結果。\"\"\"\n",
        "        # 檢查 Places365 是否提供有用的場景信息（即使沒有 YOLO 檢測）\n",
        "        fallback_scene_type = \"unknown\"\n",
        "        fallback_confidence = 0.0\n",
        "        fallback_description = \"No objects were detected in the image, and contextual analysis could not be performed or failed.\"\n",
        "\n",
        "        if places365_info and places365_info.get('confidence', 0) > 0.3:\n",
        "            fallback_scene_type = places365_info.get('mapped_scene_type', 'unknown')\n",
        "            fallback_confidence = places365_info.get('confidence', 0.0)\n",
        "            fallback_description = f\"Scene appears to be {places365_info.get('scene_label', 'an unidentified location')} based on overall visual context.\"\n",
        "\n",
        "        return {\n",
        "            \"scene_type\": fallback_scene_type,\n",
        "            \"confidence\": fallback_confidence,\n",
        "            \"description\": fallback_description,\n",
        "            \"enhanced_description\": \"The image analysis system could not detect any recognizable objects or landmarks in this image.\",\n",
        "            \"objects_present\": [],\n",
        "            \"object_count\": 0,\n",
        "            \"regions\": {},\n",
        "            \"possible_activities\": [],\n",
        "            \"safety_concerns\": [],\n",
        "            \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "        }\n",
        "\n",
        "    def _handle_main_analysis_flow(self, detection_result, original_image_pil, image_dims_val,\n",
        "                                 class_confidence_threshold, scene_confidence_threshold,\n",
        "                                 current_run_enable_landmark, lighting_info, places365_info) -> Dict:\n",
        "        \"\"\"處理主要的分析流程（有 YOLO 檢測結果）。\"\"\"\n",
        "        # 更新類別名稱映射\n",
        "        if hasattr(detection_result, 'names'):\n",
        "            if hasattr(self.spatial_analyzer, 'class_names'):\n",
        "                self.spatial_analyzer.class_names = detection_result.names\n",
        "\n",
        "        # 提取檢測到的物體\n",
        "        detected_objects_main = self.spatial_analyzer._extract_detected_objects(\n",
        "            detection_result,\n",
        "            confidence_threshold=class_confidence_threshold\n",
        "        )\n",
        "\n",
        "        if not detected_objects_main:\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\", \"confidence\": 0.0,\n",
        "                \"description\": \"No objects detected with sufficient confidence by the primary vision system.\",\n",
        "                \"objects_present\": [], \"object_count\": 0, \"regions\": {}, \"possible_activities\": [],\n",
        "                \"safety_concerns\": [], \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "        # 空間分析\n",
        "        region_analysis_val = self.spatial_analyzer._analyze_regions(detected_objects_main)\n",
        "\n",
        "        # 地標處理和整合\n",
        "        landmark_objects_identified = []\n",
        "        landmark_specific_activities = []\n",
        "        final_landmark_info = {}\n",
        "\n",
        "        if self.use_clip and current_run_enable_landmark:\n",
        "            detected_objects_main, landmark_objects_identified = self.landmark_processing_manager.process_unknown_objects(\n",
        "                detection_result, detected_objects_main, self.clip_analyzer\n",
        "            )\n",
        "\n",
        "            if landmark_objects_identified:\n",
        "                landmark_specific_activities = self.landmark_processing_manager.extract_landmark_specific_activities(\n",
        "                    landmark_objects_identified\n",
        "                )\n",
        "                final_landmark_info = {\n",
        "                    \"detected_landmarks\": landmark_objects_identified,\n",
        "                    \"primary_landmark\": max(landmark_objects_identified, key=lambda x: x.get(\"confidence\", 0.0), default=None),\n",
        "                    \"detailed_landmarks\": landmark_objects_identified\n",
        "                }\n",
        "\n",
        "        # 如果當前運行禁用地標檢測，清理地標物體\n",
        "        if not current_run_enable_landmark:\n",
        "            detected_objects_main = [obj for obj in detected_objects_main if not obj.get(\"is_landmark\", False)]\n",
        "            final_landmark_info = {}\n",
        "\n",
        "        # 計算場景分數並進行融合\n",
        "        yolo_scene_scores = self.scene_scoring_engine.compute_scene_scores(\n",
        "            detected_objects_main, spatial_analysis_results=region_analysis_val\n",
        "        )\n",
        "\n",
        "        clip_scene_scores = {}\n",
        "        clip_analysis_results = None\n",
        "        if self.use_clip and original_image_pil is not None:\n",
        "            clip_analysis_results, clip_scene_scores = self._perform_clip_analysis(\n",
        "                original_image_pil, current_run_enable_landmark, lighting_info\n",
        "            )\n",
        "\n",
        "        # 融合場景分數\n",
        "        yolo_only_objects = [obj for obj in detected_objects_main if not obj.get(\"is_landmark\")]\n",
        "        num_yolo_detections = len(yolo_only_objects)\n",
        "        avg_yolo_confidence = (sum(obj.get('confidence', 0.0) for obj in yolo_only_objects) / num_yolo_detections\n",
        "                              if num_yolo_detections > 0 else 0.0)\n",
        "\n",
        "        scene_scores_fused = self.scene_scoring_engine.fuse_scene_scores(\n",
        "            yolo_scene_scores, clip_scene_scores,\n",
        "            num_yolo_detections=num_yolo_detections,\n",
        "            avg_yolo_confidence=avg_yolo_confidence,\n",
        "            lighting_info=lighting_info,\n",
        "            places365_info=places365_info\n",
        "        )\n",
        "\n",
        "        # 確定最終場景類型\n",
        "        final_best_scene, final_scene_confidence = self.scene_scoring_engine.determine_scene_type(scene_scores_fused)\n",
        "\n",
        "        # 處理禁用地標檢測時的替代場景類型\n",
        "        if (not current_run_enable_landmark and\n",
        "            final_best_scene in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]):\n",
        "            alt_scene_type = self.landmark_processing_manager.get_alternative_scene_type(\n",
        "                final_best_scene, detected_objects_main, scene_scores_fused\n",
        "            )\n",
        "            final_best_scene = alt_scene_type\n",
        "            final_scene_confidence = scene_scores_fused.get(alt_scene_type, 0.6)\n",
        "\n",
        "        # 生成最終的描述性內容\n",
        "        final_result = self._generate_final_result(\n",
        "            final_best_scene, final_scene_confidence, detected_objects_main,\n",
        "            landmark_specific_activities, landmark_objects_identified, final_landmark_info,\n",
        "            region_analysis_val, lighting_info, scene_scores_fused, current_run_enable_landmark,\n",
        "            clip_analysis_results, image_dims_val, scene_confidence_threshold\n",
        "        )\n",
        "\n",
        "        return final_result\n",
        "\n",
        "    def _perform_clip_analysis(self, original_image_pil, current_run_enable_landmark, lighting_info) -> Tuple[Optional[Dict], Dict]:\n",
        "        \"\"\"執行 CLIP 分析。\"\"\"\n",
        "        clip_analysis_results = None\n",
        "        clip_scene_scores = {}\n",
        "\n",
        "        try:\n",
        "            clip_analysis_results = self.clip_analyzer.analyze_image(\n",
        "                original_image_pil,\n",
        "                enable_landmark=current_run_enable_landmark,\n",
        "                exclude_categories=[\"landmark\", \"tourist\", \"monument\", \"tower\", \"attraction\", \"scenic\", \"historical\", \"famous\"] if not current_run_enable_landmark else None\n",
        "            )\n",
        "\n",
        "            if isinstance(clip_analysis_results, dict):\n",
        "                clip_scene_scores = clip_analysis_results.get(\"scene_scores\", {})\n",
        "\n",
        "                # 如果禁用地標檢測，再次過濾\n",
        "                if not current_run_enable_landmark:\n",
        "                    clip_scene_scores = {k: v for k, v in clip_scene_scores.items()\n",
        "                                       if not any(kw in k.lower() for kw in [\"landmark\", \"monument\", \"tourist\"])}\n",
        "                    if \"cultural_analysis\" in clip_analysis_results:\n",
        "                        del clip_analysis_results[\"cultural_analysis\"]\n",
        "                    if (\"top_scene\" in clip_analysis_results and\n",
        "                        any(term in clip_analysis_results.get(\"top_scene\", [\"unknown\", 0.0])[0].lower()\n",
        "                            for term in [\"landmark\", \"monument\", \"tourist\"])):\n",
        "                        non_lm_cs = sorted([item for item in clip_scene_scores.items() if item[1] > 0],\n",
        "                                         key=lambda x: x[1], reverse=True)\n",
        "                        clip_analysis_results[\"top_scene\"] = non_lm_cs[0] if non_lm_cs else (\"unknown\", 0.0)\n",
        "\n",
        "                # 處理照明信息回退\n",
        "                if (not lighting_info and \"lighting_condition\" in clip_analysis_results):\n",
        "                    lt, lc = clip_analysis_results.get(\"lighting_condition\", (\"unknown\", 0.0))\n",
        "                    lighting_info = {\"time_of_day\": lt, \"confidence\": lc, \"source\": \"CLIP_fallback\"}\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in main CLIP analysis for YOLO path (analyze method): {e}\")\n",
        "\n",
        "        return clip_analysis_results, clip_scene_scores\n",
        "\n",
        "    def _generate_final_result(self, final_best_scene, final_scene_confidence, detected_objects_main,\n",
        "                             landmark_specific_activities, landmark_objects_identified, final_landmark_info,\n",
        "                             region_analysis_val, lighting_info, scene_scores_fused, current_run_enable_landmark,\n",
        "                             clip_analysis_results, image_dims_val, scene_confidence_threshold) -> Dict:\n",
        "        \"\"\"生成最終的分析結果。\"\"\"\n",
        "        # 生成最終的描述性內容（活動、安全、區域）\n",
        "        final_activities = []\n",
        "\n",
        "        # 通用活動推斷\n",
        "        generic_activities = []\n",
        "        if self.descriptor and hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "            generic_activities = self.descriptor._infer_possible_activities(\n",
        "                final_best_scene, detected_objects_main,\n",
        "                enable_landmark=current_run_enable_landmark, scene_scores=scene_scores_fused\n",
        "            )\n",
        "\n",
        "        # 優先處理策略：使用特定地標活動，不足時才從通用活動補充\n",
        "        if landmark_specific_activities:\n",
        "            # 如果有特定活動，優先保留，去除與特定活動重複的通用活動\n",
        "            unique_generic_activities = [act for act in generic_activities if act not in landmark_specific_activities]\n",
        "\n",
        "            # 如果特定活動少於3個，從通用活動中補充\n",
        "            if len(landmark_specific_activities) < 3:\n",
        "                # 補充通用活動但總數不超過7個\n",
        "                supplement_count = min(3 - len(landmark_specific_activities), len(unique_generic_activities))\n",
        "                if supplement_count > 0:\n",
        "                    final_activities.extend(unique_generic_activities[:supplement_count])\n",
        "        else:\n",
        "            # 若無特定活動，則使用所有通用活動\n",
        "            final_activities.extend(generic_activities)\n",
        "\n",
        "        # 去重並排序，但確保特定地標活動保持在前面\n",
        "        final_activities_set = set(final_activities)\n",
        "        final_activities = []\n",
        "\n",
        "        # 先加入特定地標活動（按原順序）\n",
        "        for activity in landmark_specific_activities:\n",
        "            if activity in final_activities_set:\n",
        "                final_activities.append(activity)\n",
        "                final_activities_set.remove(activity)\n",
        "\n",
        "        # 再加入通用活動（按字母排序）\n",
        "        final_activities.extend(sorted(list(final_activities_set)))\n",
        "\n",
        "        # 安全問題識別\n",
        "        final_safety_concerns = []\n",
        "        if self.descriptor and hasattr(self.descriptor, '_identify_safety_concerns'):\n",
        "            final_safety_concerns = self.descriptor._identify_safety_concerns(detected_objects_main, final_best_scene)\n",
        "\n",
        "        # 功能區域識別\n",
        "        final_functional_zones = {}\n",
        "        if self.spatial_analyzer and hasattr(self.spatial_analyzer, '_identify_functional_zones'):\n",
        "            general_zones = self.spatial_analyzer._identify_functional_zones(detected_objects_main, final_best_scene)\n",
        "            final_functional_zones.update(general_zones)\n",
        "\n",
        "        # 地標相關的功能區域\n",
        "        if landmark_objects_identified and self.spatial_analyzer and hasattr(self.spatial_analyzer, '_identify_landmark_zones'):\n",
        "            landmark_zones = self.spatial_analyzer._identify_landmark_zones(landmark_objects_identified)\n",
        "            final_functional_zones.update(landmark_zones)\n",
        "\n",
        "        # 如果當前運行禁用地標檢測，過濾相關內容\n",
        "        if not current_run_enable_landmark:\n",
        "            final_functional_zones = {\n",
        "                        str(k): v\n",
        "                        for k, v in final_functional_zones.items()\n",
        "                        if (not str(k).isdigit())\n",
        "                        and (not any(kw in str(k).lower() for kw in [\"landmark\", \"monument\", \"viewing\", \"tourist\"]))\n",
        "                    }\n",
        "\n",
        "\n",
        "            current_activities_temp = [act for act in final_activities\n",
        "                                     if not any(kw in act.lower() for kw in [\"sightsee\", \"photograph\", \"tour\", \"histor\", \"landmark\", \"monument\", \"cultur\"])]\n",
        "            final_activities = current_activities_temp\n",
        "            if not final_activities and self.descriptor and hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "                final_activities = self.descriptor._infer_possible_activities(\"generic_street_view\", detected_objects_main, enable_landmark=False)\n",
        "\n",
        "        # 創建淨化的光線資訊，避免不合理的時間描述\n",
        "        lighting_info_clean = None\n",
        "        if lighting_info:\n",
        "            lighting_info_clean = {\n",
        "                \"is_indoor\": lighting_info.get(\"is_indoor\"),\n",
        "                \"confidence\": lighting_info.get(\"confidence\", 0.0),\n",
        "                \"time_of_day\": lighting_info.get(\"time_of_day\", \"unknown\")\n",
        "            }\n",
        "\n",
        "        # 生成場景描述\n",
        "        base_scene_description = self._generate_scene_description(\n",
        "            final_best_scene, detected_objects_main, final_scene_confidence,\n",
        "            lighting_info_clean, final_functional_zones, image_dims_val\n",
        "        )\n",
        "\n",
        "        # 清理地標引用（如果禁用地標檢測）\n",
        "        if not current_run_enable_landmark:\n",
        "            base_scene_description = self.landmark_processing_manager.remove_landmark_references(base_scene_description)\n",
        "\n",
        "        # LLM 增強\n",
        "        enhanced_final_description = self._enhance_final_description(\n",
        "            base_scene_description, final_best_scene, final_scene_confidence, detected_objects_main,\n",
        "            final_functional_zones, final_activities, final_safety_concerns, lighting_info,\n",
        "            clip_analysis_results, current_run_enable_landmark, image_dims_val, final_landmark_info\n",
        "        )\n",
        "\n",
        "        # 清理增強描述的地標引用\n",
        "        if not current_run_enable_landmark:\n",
        "            enhanced_final_description = self.landmark_processing_manager.remove_landmark_references(enhanced_final_description)\n",
        "\n",
        "        # 構建最終輸出字典\n",
        "        output_result = {\n",
        "            \"scene_type\": final_best_scene if final_scene_confidence >= scene_confidence_threshold else \"unknown\",\n",
        "            \"scene_name\": (self.scene_types.get(final_best_scene, {}).get(\"name\", \"Unknown Scene\")\n",
        "                          if final_scene_confidence >= scene_confidence_threshold else \"Unknown Scene\"),\n",
        "            \"confidence\": round(float(final_scene_confidence), 4),\n",
        "            \"description\": base_scene_description,\n",
        "            \"enhanced_description\": enhanced_final_description,\n",
        "            \"objects_present\": [{\"class_id\": obj.get(\"class_id\", -1),\n",
        "                               \"class_name\": obj.get(\"class_name\", \"unknown\"),\n",
        "                               \"confidence\": round(float(obj.get(\"confidence\", 0.0)), 4)}\n",
        "                              for obj in detected_objects_main],\n",
        "            \"object_count\": len(detected_objects_main),\n",
        "            \"regions\": region_analysis_val,\n",
        "            \"possible_activities\": final_activities,\n",
        "            \"safety_concerns\": final_safety_concerns,\n",
        "            \"functional_zones\": final_functional_zones,\n",
        "            \"lighting_conditions\": lighting_info if lighting_info else {\"time_of_day\": \"unknown\", \"confidence\": 0.0, \"source\": \"default\"}\n",
        "        }\n",
        "\n",
        "        # 添加替代場景\n",
        "        if self.descriptor and hasattr(self.descriptor, '_get_alternative_scenes'):\n",
        "            output_result[\"alternative_scenes\"] = self.descriptor._get_alternative_scenes(\n",
        "                scene_scores_fused, scene_confidence_threshold, top_k=2\n",
        "            )\n",
        "\n",
        "        # 添加地標相關信息\n",
        "        if current_run_enable_landmark and final_landmark_info and final_landmark_info.get(\"detected_landmarks\"):\n",
        "            output_result.update(final_landmark_info)\n",
        "            if final_best_scene in [\"tourist_landmark\", \"natural_landmark\", \"historical_monument\"]:\n",
        "                output_result[\"scene_source\"] = \"landmark_detection\"\n",
        "        elif not current_run_enable_landmark:\n",
        "            for key_rm in [\"detected_landmarks\", \"primary_landmark\", \"detailed_landmarks\", \"scene_source\"]:\n",
        "                if key_rm in output_result:\n",
        "                    del output_result[key_rm]\n",
        "\n",
        "        # 添加 CLIP 分析結果\n",
        "        if clip_analysis_results and isinstance(clip_analysis_results, dict) and \"error\" not in clip_analysis_results:\n",
        "            top_scene_clip = clip_analysis_results.get(\"top_scene\", (\"unknown\", 0.0))\n",
        "            output_result[\"clip_analysis\"] = {\n",
        "                \"top_scene\": (top_scene_clip[0], round(float(top_scene_clip[1]), 4)),\n",
        "                \"cultural_analysis\": clip_analysis_results.get(\"cultural_analysis\", {}) if current_run_enable_landmark else {}\n",
        "            }\n",
        "\n",
        "        return output_result\n",
        "\n",
        "    # 輔助方法\n",
        "    def _generate_region_analysis(self, detected_objects):\n",
        "        \"\"\"生成區域分析結果。\"\"\"\n",
        "        if self.spatial_analyzer and hasattr(self.spatial_analyzer, '_analyze_regions'):\n",
        "            try:\n",
        "                return self.spatial_analyzer._analyze_regions(detected_objects)\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error analyzing regions: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def _generate_functional_zones(self, detected_objects, scene_type):\n",
        "        \"\"\"\n",
        "        生成功能區域。\n",
        "        由於原本直接呼叫 _identify_landmark_zones，導致非地標場景必定回 {}。\n",
        "        這裡改為呼叫 _identify_functional_zones，並帶入 scene_type。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 如果 spatial_analyzer 可以識別 functional zones，就調用它\n",
        "            if self.spatial_analyzer and hasattr(self.spatial_analyzer, '_identify_functional_zones'):\n",
        "                return self.spatial_analyzer._identify_functional_zones(detected_objects, scene_type)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error identifying functional zones: {e}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "        return {}\n",
        "\n",
        "\n",
        "    def _generate_scene_description(self, scene_type, detected_objects, confidence,\n",
        "                                  lighting_info, functional_zones, image_dims):\n",
        "        \"\"\"生成場景描述。\"\"\"\n",
        "        if self.scene_describer and hasattr(self.scene_describer, 'generate_description'):\n",
        "            try:\n",
        "                for obj in detected_objects:\n",
        "                    if obj.get(\"is_landmark\"):\n",
        "                        loc_obj = obj.get(\"location\", \"\")\n",
        "                        lm_id_obj = obj.get(\"landmark_id\")\n",
        "                        if (not loc_obj) and lm_id_obj and lm_id_obj in ALL_LANDMARKS:\n",
        "                            obj[\"location\"] = ALL_LANDMARKS[lm_id_obj].get(\"location\", \"\")\n",
        "\n",
        "                return self.scene_describer.generate_description(\n",
        "                    scene_type=scene_type,\n",
        "                    detected_objects=detected_objects,\n",
        "                    confidence=confidence,\n",
        "                    lighting_info=lighting_info,\n",
        "                    functional_zones=list(functional_zones.keys()) if functional_zones else [],\n",
        "                    enable_landmark=self.enable_landmark,\n",
        "                    scene_scores={scene_type: confidence},\n",
        "                    spatial_analysis={},\n",
        "                    image_dimensions=image_dims\n",
        "                )\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error generating scene description: {e}\")\n",
        "        return f\"A {scene_type} scene.\"\n",
        "\n",
        "    def _enhance_description_with_llm(self, scene_description, scene_type, detected_objects,\n",
        "                                    confidence, lighting_info, functional_zones, landmark_results, image_dims):\n",
        "        \"\"\"使用 LLM 增強描述。\"\"\"\n",
        "        if not self.use_llm or not self.llm_enhancer:\n",
        "            return scene_description\n",
        "\n",
        "        try:\n",
        "            prominent_objects_detail = \"\"\n",
        "            if self.scene_describer and hasattr(self.scene_describer, 'format_object_list_for_description'):\n",
        "                try:\n",
        "                    prominent_objects_detail = self.scene_describer.format_object_list_for_description(\n",
        "                        detected_objects[:min(1, len(detected_objects))]\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error formatting object list: {e}\")\n",
        "\n",
        "            w_img, h_img = image_dims if image_dims else (1, 1)\n",
        "            scene_data_llm = {\n",
        "                \"original_description\": scene_description,\n",
        "                \"scene_type\": scene_type,\n",
        "                \"scene_name\": self.scene_types.get(scene_type, {}).get(\"name\", \"Landmark\"),\n",
        "                \"detected_objects\": detected_objects,\n",
        "                \"object_list\": \"landmark\",\n",
        "                \"confidence\": confidence,\n",
        "                \"lighting_info\": lighting_info,\n",
        "                \"functional_zones\": functional_zones,\n",
        "                \"clip_analysis\": landmark_results.get(\"clip_analysis_on_full_image\", {}),\n",
        "                \"enable_landmark\": True,\n",
        "                \"image_width\": w_img,\n",
        "                \"image_height\": h_img,\n",
        "                \"prominent_objects_detail\": prominent_objects_detail\n",
        "            }\n",
        "\n",
        "            return self.llm_enhancer.enhance_description(scene_data_llm)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error enhancing description with LLM: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return scene_description\n",
        "\n",
        "    def _enhance_no_detection_description(self, desc, scene_type, confidence, lighting_info,\n",
        "                                        clip_analysis, enable_landmark, width, height):\n",
        "        \"\"\"增強無檢測結果的描述。\"\"\"\n",
        "        if not self.use_llm or not self.llm_enhancer:\n",
        "            return desc\n",
        "\n",
        "        try:\n",
        "            clip_analysis_safe = {}\n",
        "            if isinstance(clip_analysis, dict):\n",
        "                clip_analysis_safe = clip_analysis\n",
        "\n",
        "            scene_data_llm = {\n",
        "                \"original_description\": desc,\n",
        "                \"scene_type\": scene_type,\n",
        "                \"scene_name\": \"Contextually Inferred (No Detections)\",\n",
        "                \"detected_objects\": [],\n",
        "                \"object_list\": \"general ambiance\",\n",
        "                \"confidence\": confidence,\n",
        "                \"lighting_info\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0},\n",
        "                \"clip_analysis\": clip_analysis_safe,\n",
        "                \"enable_landmark\": enable_landmark,\n",
        "                \"image_width\": width,\n",
        "                \"image_height\": height,\n",
        "                \"prominent_objects_detail\": \"the overall visual context\"\n",
        "            }\n",
        "\n",
        "            if hasattr(self.llm_enhancer, 'enhance_description'):\n",
        "                try:\n",
        "                    enhanced = self.llm_enhancer.enhance_description(scene_data_llm)\n",
        "                    if enhanced and len(enhanced.strip()) >= 20:\n",
        "                        return enhanced\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in enhance_description: {e}\")\n",
        "\n",
        "            if hasattr(self.llm_enhancer, 'handle_no_detection'):\n",
        "                try:\n",
        "                    return self.llm_enhancer.handle_no_detection(clip_analysis_safe)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in handle_no_detection: {e}\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error preparing data for LLM enhancement: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        return desc\n",
        "\n",
        "    def _extract_possible_activities(self, detected_objects, landmark_results):\n",
        "        \"\"\"提取可能的活動。\"\"\"\n",
        "        possible_activities = [\"Sightseeing\"]\n",
        "\n",
        "        # 檢查是否有主要地標活動從 CLIP 分析結果中獲取\n",
        "        primary_landmark_activities = landmark_results.get(\"primary_landmark_activities\", [])\n",
        "\n",
        "        if primary_landmark_activities:\n",
        "            self.logger.info(f\"Using {len(primary_landmark_activities)} landmark-specific activities\")\n",
        "            possible_activities = primary_landmark_activities\n",
        "        else:\n",
        "            # 從檢測到的地標中提取特定活動\n",
        "            landmark_specific_activities = self.landmark_processing_manager.extract_landmark_specific_activities(detected_objects)\n",
        "\n",
        "            if landmark_specific_activities:\n",
        "                possible_activities = list(set(landmark_specific_activities))  # 去重\n",
        "                self.logger.info(f\"Extracted {len(possible_activities)} activities from landmark data\")\n",
        "            else:\n",
        "                # 回退到通用活動推斷\n",
        "                if self.descriptor and hasattr(self.descriptor, '_infer_possible_activities'):\n",
        "                    try:\n",
        "                        possible_activities = self.descriptor._infer_possible_activities(\n",
        "                            \"tourist_landmark\",\n",
        "                            detected_objects,\n",
        "                            enable_landmark=True,\n",
        "                            scene_scores={\"tourist_landmark\": 0.8}\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        self.logger.error(f\"Error inferring possible activities: {e}\")\n",
        "\n",
        "        return possible_activities\n",
        "\n",
        "    def _enhance_final_description(self, base_description, scene_type, scene_confidence, detected_objects,\n",
        "                                 functional_zones, activities, safety_concerns, lighting_info,\n",
        "                                 clip_analysis_results, enable_landmark, image_dims, landmark_info):\n",
        "        \"\"\"增強最終描述。\"\"\"\n",
        "        if not self.use_llm or not self.llm_enhancer:\n",
        "            return base_description\n",
        "\n",
        "        try:\n",
        "            obj_list_for_llm = \", \".join(sorted(list(set(\n",
        "                obj[\"class_name\"] for obj in detected_objects\n",
        "                if obj.get(\"confidence\", 0) > 0.4 and not obj.get(\"is_landmark\")\n",
        "            ))))\n",
        "\n",
        "            if not obj_list_for_llm and enable_landmark and landmark_info.get(\"primary_landmark\"):\n",
        "                obj_list_for_llm = landmark_info[\"primary_landmark\"].get(\"class_name\", \"a prominent feature\")\n",
        "            elif not obj_list_for_llm:\n",
        "                obj_list_for_llm = \"various visual elements\"\n",
        "\n",
        "            # 生成物體統計信息\n",
        "            object_statistics = {}\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                if class_name not in object_statistics:\n",
        "                    object_statistics[class_name] = {\n",
        "                        \"count\": 0,\n",
        "                        \"avg_confidence\": 0.0,\n",
        "                        \"max_confidence\": 0.0,\n",
        "                        \"instances\": []\n",
        "                    }\n",
        "\n",
        "                stats = object_statistics[class_name]\n",
        "                stats[\"count\"] += 1\n",
        "                stats[\"instances\"].append(obj)\n",
        "                stats[\"max_confidence\"] = max(stats[\"max_confidence\"], obj.get(\"confidence\", 0.0))\n",
        "\n",
        "            # 計算平均信心度\n",
        "            for class_name, stats in object_statistics.items():\n",
        "                if stats[\"count\"] > 0:\n",
        "                    total_conf = sum(inst.get(\"confidence\", 0.0) for inst in stats[\"instances\"])\n",
        "                    stats[\"avg_confidence\"] = total_conf / stats[\"count\"]\n",
        "\n",
        "            llm_scene_data = {\n",
        "                \"original_description\": base_description,\n",
        "                \"scene_type\": scene_type,\n",
        "                \"scene_name\": self.scene_types.get(scene_type, {}).get(\"name\", \"Unknown Scene\"),\n",
        "                \"detected_objects\": detected_objects,\n",
        "                \"object_list\": obj_list_for_llm,\n",
        "                \"object_statistics\": object_statistics,\n",
        "                \"confidence\": scene_confidence,\n",
        "                \"lighting_info\": lighting_info,\n",
        "                \"functional_zones\": functional_zones,\n",
        "                \"activities\": activities,\n",
        "                \"safety_concerns\": safety_concerns,\n",
        "                \"clip_analysis\": clip_analysis_results if isinstance(clip_analysis_results, dict) else None,\n",
        "                \"enable_landmark\": enable_landmark,\n",
        "                \"image_width\": image_dims[0] if image_dims else None,\n",
        "                \"image_height\": image_dims[1] if image_dims else None,\n",
        "                \"prominent_objects_detail\": \"\"\n",
        "            }\n",
        "\n",
        "            # 添加顯著物體詳細信息\n",
        "            if self.scene_describer and hasattr(self.scene_describer, 'get_prominent_objects') and hasattr(self.scene_describer, 'format_object_list_for_description'):\n",
        "                try:\n",
        "                    prominent_objects = self.scene_describer.get_prominent_objects(\n",
        "                        detected_objects, min_prominence_score=0.1, max_categories_to_return=3, max_total_objects=7\n",
        "                    )\n",
        "                    llm_scene_data[\"prominent_objects_detail\"] = self.scene_describer.format_object_list_for_description(prominent_objects)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error getting prominent objects: {e}\")\n",
        "\n",
        "            if enable_landmark and landmark_info.get(\"primary_landmark\"):\n",
        "                llm_scene_data[\"primary_landmark_info\"] = landmark_info[\"primary_landmark\"]\n",
        "\n",
        "            return self.llm_enhancer.enhance_description(llm_scene_data)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in LLM Enhancement in main flow (analyze method): {e}\")\n",
        "            return base_description"
      ],
      "metadata": {
        "id": "X6TCkBOYuSBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c841c10d-b57a-4603-d439-00116be6d2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_analysis_coordinator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile scene_analyzer.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "from PIL import Image\n",
        "\n",
        "# from component_initializer import ComponentInitializer\n",
        "# from scene_scoring_engine import SceneScoringEngine\n",
        "# from landmark_processing_manager import LandmarkProcessingManager\n",
        "# from scene_analysis_coordinator import SceneAnalysisCoordinator\n",
        "\n",
        "class SceneAnalyzer:\n",
        "    \"\"\"\n",
        "    Core class for scene analysis and understanding based on object detection results.\n",
        "    Analyzes detected objects, their relationships, and infers the scene type.\n",
        "    此class為場景理解的總窗口\n",
        "\n",
        "    This is the main Facade class that coordinates all scene analysis components\n",
        "    while maintaining the original public interface for backward compatibility.\n",
        "    \"\"\"\n",
        "\n",
        "    EVERYDAY_SCENE_TYPE_KEYS = [\n",
        "        \"general_indoor_space\", \"generic_street_view\",\n",
        "        \"desk_area_workspace\", \"outdoor_gathering_spot\",\n",
        "        \"kitchen_counter_or_utility_area\"\n",
        "    ]\n",
        "\n",
        "    def __init__(self, class_names: Dict[int, str] = None, use_llm: bool = True,\n",
        "                 use_clip: bool = True, enable_landmark: bool = True,\n",
        "                 llm_model_path: str = None):\n",
        "        \"\"\"\n",
        "        Initialize the scene analyzer with optional class name mappings.\n",
        "\n",
        "        Args:\n",
        "            class_names: Dictionary mapping class IDs to class names (optional)\n",
        "            use_llm: Whether to enable LLM enhancement functionality\n",
        "            use_clip: Whether to enable CLIP analysis functionality\n",
        "            enable_landmark: Whether to enable landmark detection functionality\n",
        "            llm_model_path: Path to LLM model (optional)\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        try:\n",
        "            # Initialize all components through the component initializer\n",
        "            self.component_initializer = ComponentInitializer(\n",
        "                class_names=class_names,\n",
        "                use_llm=use_llm,\n",
        "                use_clip=use_clip,\n",
        "                enable_landmark=enable_landmark,\n",
        "                llm_model_path=llm_model_path\n",
        "            )\n",
        "\n",
        "            # Get data structures for easy access\n",
        "            self.SCENE_TYPES = self.component_initializer.get_data_structure('SCENE_TYPES')\n",
        "            self.OBJECT_CATEGORIES = self.component_initializer.get_data_structure('OBJECT_CATEGORIES')\n",
        "            self.LANDMARK_ACTIVITIES = self.component_initializer.get_data_structure('LANDMARK_ACTIVITIES')\n",
        "\n",
        "            # Initialize specialized engines\n",
        "            self.scene_scoring_engine = SceneScoringEngine(\n",
        "                scene_types=self.SCENE_TYPES,\n",
        "                enable_landmark=enable_landmark\n",
        "            )\n",
        "\n",
        "            self.landmark_processing_manager = LandmarkProcessingManager(\n",
        "                enable_landmark=enable_landmark,\n",
        "                use_clip=use_clip\n",
        "            )\n",
        "\n",
        "            # Initialize the main coordinator\n",
        "            self.scene_analysis_coordinator = SceneAnalysisCoordinator(\n",
        "                component_initializer=self.component_initializer,\n",
        "                scene_scoring_engine=self.scene_scoring_engine,\n",
        "                landmark_processing_manager=self.landmark_processing_manager\n",
        "            )\n",
        "\n",
        "            # Store configuration for backward compatibility\n",
        "            self.class_names = class_names\n",
        "            self.use_clip = use_clip\n",
        "            self.use_llm = use_llm\n",
        "            self.enable_landmark = enable_landmark\n",
        "            self.use_landmark_detection = enable_landmark\n",
        "\n",
        "            # Get component references for backward compatibility\n",
        "            self.spatial_analyzer = self.component_initializer.get_component('spatial_analyzer')\n",
        "            self.descriptor = self.component_initializer.get_component('descriptor')\n",
        "            self.scene_describer = self.component_initializer.get_component('scene_describer')\n",
        "            self.clip_analyzer = self.component_initializer.get_component('clip_analyzer')\n",
        "            self.llm_enhancer = self.component_initializer.get_component('llm_enhancer')\n",
        "            self.landmark_classifier = self.component_initializer.get_component('landmark_classifier')\n",
        "\n",
        "            # Set landmark classifier in the processing manager\n",
        "            if self.landmark_classifier:\n",
        "                self.landmark_processing_manager.set_landmark_classifier(self.landmark_classifier)\n",
        "\n",
        "            self.logger.info(\"SceneAnalyzer initialized successfully with all components\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Critical error during SceneAnalyzer initialization: {e}\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def analyze(self, detection_result: Any, lighting_info: Optional[Dict] = None,\n",
        "                class_confidence_threshold: float = 0.25, scene_confidence_threshold: float = 0.6,\n",
        "                enable_landmark: bool = True, places365_info: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze detection results to determine scene type and provide understanding.\n",
        "\n",
        "        Args:\n",
        "            detection_result: Detection result from YOLOv8 or similar\n",
        "            lighting_info: Optional lighting condition analysis results\n",
        "            class_confidence_threshold: Minimum confidence to consider an object\n",
        "            scene_confidence_threshold: Minimum confidence to determine a scene\n",
        "            enable_landmark: Whether to enable landmark detection and recognition for this run\n",
        "            places365_info: Optional Places365 scene classification results\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with scene analysis results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.scene_analysis_coordinator.analyze(\n",
        "                detection_result=detection_result,\n",
        "                lighting_info=lighting_info,\n",
        "                class_confidence_threshold=class_confidence_threshold,\n",
        "                scene_confidence_threshold=scene_confidence_threshold,\n",
        "                enable_landmark=enable_landmark,\n",
        "                places365_info=places365_info\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in scene analysis: {e}\")\n",
        "            traceback.print_exc()\n",
        "            # Return a safe fallback result\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\",\n",
        "                \"confidence\": 0.0,\n",
        "                \"description\": \"Scene analysis failed due to an internal error.\",\n",
        "                \"enhanced_description\": \"An error occurred during scene analysis. Please check the system logs for details.\",\n",
        "                \"objects_present\": [],\n",
        "                \"object_count\": 0,\n",
        "                \"regions\": {},\n",
        "                \"possible_activities\": [],\n",
        "                \"safety_concerns\": [],\n",
        "                \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "    def generate_scene_description(self, scene_type: str, detected_objects: List[Dict],\n",
        "                                 confidence: float, lighting_info: Optional[Dict] = None,\n",
        "                                 functional_zones: Optional[Dict] = None,\n",
        "                                 enable_landmark: bool = True,\n",
        "                                 scene_scores: Optional[Dict] = None,\n",
        "                                 spatial_analysis: Optional[Dict] = None,\n",
        "                                 image_dimensions: Optional[Tuple[int, int]] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate scene description and pass all necessary context to the underlying describer.\n",
        "\n",
        "        Args:\n",
        "            scene_type: Identified scene type\n",
        "            detected_objects: List of detected objects\n",
        "            confidence: Scene classification confidence\n",
        "            lighting_info: Lighting condition information (optional)\n",
        "            functional_zones: Functional zone information (optional)\n",
        "            enable_landmark: Whether to enable landmark description (optional)\n",
        "            scene_scores: Scene scores (optional)\n",
        "            spatial_analysis: Spatial analysis results (optional)\n",
        "            image_dimensions: Image dimensions (width, height) (optional)\n",
        "\n",
        "        Returns:\n",
        "            str: Generated scene description\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert functional_zones from Dict to List[str] and filter technical terms\n",
        "            functional_zones_list = []\n",
        "            if functional_zones and isinstance(functional_zones, dict):\n",
        "                # Filter out technical terms, keep only meaningful descriptions\n",
        "                filtered_zones = {k: v for k, v in functional_zones.items()\n",
        "                                if not k.endswith('_zone') or k in ['dining_zone', 'seating_zone', 'work_zone']}\n",
        "                functional_zones_list = [v.get('description', k) for k, v in filtered_zones.items()\n",
        "                                       if isinstance(v, dict) and v.get('description')]\n",
        "            elif functional_zones and isinstance(functional_zones, list):\n",
        "                # Filter technical terms from list\n",
        "                functional_zones_list = [zone for zone in functional_zones\n",
        "                                       if not zone.endswith('_zone') or 'area' in zone]\n",
        "\n",
        "            # Generate detailed object statistics\n",
        "            object_statistics = {}\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                if class_name not in object_statistics:\n",
        "                    object_statistics[class_name] = {\n",
        "                        \"count\": 0,\n",
        "                        \"avg_confidence\": 0.0,\n",
        "                        \"max_confidence\": 0.0,\n",
        "                        \"instances\": []\n",
        "                    }\n",
        "\n",
        "                stats = object_statistics[class_name]\n",
        "                stats[\"count\"] += 1\n",
        "                stats[\"instances\"].append(obj)\n",
        "                stats[\"max_confidence\"] = max(stats[\"max_confidence\"], obj.get(\"confidence\", 0.0))\n",
        "\n",
        "            # Calculate average confidence\n",
        "            for class_name, stats in object_statistics.items():\n",
        "                if stats[\"count\"] > 0:\n",
        "                    total_conf = sum(inst.get(\"confidence\", 0.0) for inst in stats[\"instances\"])\n",
        "                    stats[\"avg_confidence\"] = total_conf / stats[\"count\"]\n",
        "\n",
        "            if self.scene_describer:\n",
        "                return self.scene_describer.generate_description(\n",
        "                    scene_type=scene_type,\n",
        "                    detected_objects=detected_objects,\n",
        "                    confidence=confidence,\n",
        "                    lighting_info=lighting_info,\n",
        "                    functional_zones=functional_zones_list,\n",
        "                    enable_landmark=enable_landmark,\n",
        "                    scene_scores=scene_scores,\n",
        "                    spatial_analysis=spatial_analysis,\n",
        "                    image_dimensions=image_dimensions,\n",
        "                    object_statistics=object_statistics\n",
        "                )\n",
        "            else:\n",
        "                return f\"A {scene_type} scene with {len(detected_objects)} detected objects.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating scene description: {e}\")\n",
        "            return f\"A {scene_type} scene.\"\n",
        "\n",
        "    def process_unknown_objects(self, detection_result, detected_objects):\n",
        "        \"\"\"\n",
        "        Process objects that YOLO failed to identify or have low confidence for landmark detection.\n",
        "\n",
        "        Args:\n",
        "            detection_result: YOLO detection results\n",
        "            detected_objects: List of identified objects\n",
        "\n",
        "        Returns:\n",
        "            tuple: (updated object list, landmark object list)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.landmark_processing_manager.process_unknown_objects(\n",
        "                detection_result, detected_objects, self.clip_analyzer\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing unknown objects: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return detected_objects, []\n",
        "\n",
        "    def _compute_scene_scores(self, detected_objects: List[Dict],\n",
        "                            spatial_analysis_results: Optional[Dict] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute confidence scores for each scene type based on detected objects.\n",
        "\n",
        "        Args:\n",
        "            detected_objects: List of detected objects with their details\n",
        "            spatial_analysis_results: Optional output from SpatialAnalyzer\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping scene types to confidence scores\n",
        "        \"\"\"\n",
        "        return self.scene_scoring_engine.compute_scene_scores(\n",
        "            detected_objects, spatial_analysis_results\n",
        "        )\n",
        "\n",
        "    def _determine_scene_type(self, scene_scores: Dict[str, float]) -> Tuple[str, float]:\n",
        "        \"\"\"\n",
        "        Determine the most likely scene type based on scores.\n",
        "\n",
        "        Args:\n",
        "            scene_scores: Dictionary mapping scene types to confidence scores\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (best_scene_type, confidence)\n",
        "        \"\"\"\n",
        "        return self.scene_scoring_engine.determine_scene_type(scene_scores)\n",
        "\n",
        "    def _fuse_scene_scores(self, yolo_scene_scores: Dict[str, float],\n",
        "                          clip_scene_scores: Dict[str, float],\n",
        "                          num_yolo_detections: int = 0,\n",
        "                          avg_yolo_confidence: float = 0.0,\n",
        "                          lighting_info: Optional[Dict] = None,\n",
        "                          places365_info: Optional[Dict] = None) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Fuse scene scores from YOLO-based object detection, CLIP-based analysis, and Places365.\n",
        "\n",
        "        Args:\n",
        "            yolo_scene_scores: Scene scores based on YOLO object detection\n",
        "            clip_scene_scores: Scene scores based on CLIP analysis\n",
        "            num_yolo_detections: Total number of non-landmark objects detected by YOLO\n",
        "            avg_yolo_confidence: Average confidence of non-landmark objects detected by YOLO\n",
        "            lighting_info: Optional lighting condition analysis results\n",
        "            places365_info: Optional Places365 scene classification results\n",
        "\n",
        "        Returns:\n",
        "            Dict: Fused scene scores incorporating all analysis sources\n",
        "        \"\"\"\n",
        "        return self.scene_scoring_engine.fuse_scene_scores(\n",
        "            yolo_scene_scores, clip_scene_scores, num_yolo_detections,\n",
        "            avg_yolo_confidence, lighting_info, places365_info\n",
        "        )\n",
        "\n",
        "    def _get_alternative_scene_type(self, landmark_scene_type, detected_objects, scene_scores):\n",
        "        \"\"\"\n",
        "        Select appropriate alternative type for landmark scene types.\n",
        "\n",
        "        Args:\n",
        "            landmark_scene_type: Original landmark scene type\n",
        "            detected_objects: List of detected objects\n",
        "            scene_scores: All scene type scores\n",
        "\n",
        "        Returns:\n",
        "            str: Appropriate alternative scene type\n",
        "        \"\"\"\n",
        "        return self.landmark_processing_manager.get_alternative_scene_type(\n",
        "            landmark_scene_type, detected_objects, scene_scores\n",
        "        )\n",
        "\n",
        "    def _remove_landmark_references(self, text):\n",
        "        \"\"\"\n",
        "        Remove all landmark references from text.\n",
        "\n",
        "        Args:\n",
        "            text: Input text\n",
        "\n",
        "        Returns:\n",
        "            str: Text with landmark references removed\n",
        "        \"\"\"\n",
        "        return self.landmark_processing_manager.remove_landmark_references(text)\n",
        "\n",
        "    def _define_image_regions(self):\n",
        "        \"\"\"Define regions of the image for spatial analysis (3x3 grid).\"\"\"\n",
        "        self.regions = {\n",
        "            \"top_left\": (0, 0, 1/3, 1/3),\n",
        "            \"top_center\": (1/3, 0, 2/3, 1/3),\n",
        "            \"top_right\": (2/3, 0, 1, 1/3),\n",
        "            \"middle_left\": (0, 1/3, 1/3, 2/3),\n",
        "            \"middle_center\": (1/3, 1/3, 2/3, 2/3),\n",
        "            \"middle_right\": (2/3, 1/3, 1, 2/3),\n",
        "            \"bottom_left\": (0, 2/3, 1/3, 1),\n",
        "            \"bottom_center\": (1/3, 2/3, 2/3, 1),\n",
        "            \"bottom_right\": (2/3, 2/3, 1, 1)\n",
        "        }\n",
        "\n",
        "    def get_component_status(self) -> Dict[str, bool]:\n",
        "        \"\"\"\n",
        "        Get the initialization status of all components.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping component names to their initialization status\n",
        "        \"\"\"\n",
        "        return self.component_initializer.get_initialization_summary()\n",
        "\n",
        "    def is_component_available(self, component_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        Check if a specific component is available and properly initialized.\n",
        "\n",
        "        Args:\n",
        "            component_name: Name of the component to check\n",
        "\n",
        "        Returns:\n",
        "            bool: Whether the component is available\n",
        "        \"\"\"\n",
        "        return self.component_initializer.is_component_available(component_name)\n",
        "\n",
        "    def update_landmark_enable_status(self, enable_landmark: bool):\n",
        "        \"\"\"\n",
        "        Update the landmark detection enable status across all components.\n",
        "\n",
        "        Args:\n",
        "            enable_landmark: Whether to enable landmark detection\n",
        "        \"\"\"\n",
        "        self.enable_landmark = enable_landmark\n",
        "        self.use_landmark_detection = enable_landmark\n",
        "\n",
        "        # Update all related components\n",
        "        self.component_initializer.update_landmark_enable_status(enable_landmark)\n",
        "        self.scene_scoring_engine.update_enable_landmark_status(enable_landmark)\n",
        "        self.landmark_processing_manager.update_enable_landmark_status(enable_landmark)\n",
        "\n",
        "        # Update the coordinator's enable_landmark status\n",
        "        if hasattr(self.scene_analysis_coordinator, 'enable_landmark'):\n",
        "            self.scene_analysis_coordinator.enable_landmark = enable_landmark"
      ],
      "metadata": {
        "id": "9l0gIOK3ujjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9c688f-4ddc-4095-82f5-66742a41caba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scene_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVw5JMy6qhY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee5a811-0305-4f29-cb87-e04bb73628d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing image_processor.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile image_processor.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import uuid\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "# from detection_model import DetectionModel\n",
        "# from color_mapper import ColorMapper\n",
        "# from visualization_helper import VisualizationHelper\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from lighting_analyzer import LightingAnalyzer\n",
        "# from scene_analyzer import SceneAnalyzer\n",
        "# from places365_model import Places365Model\n",
        "\n",
        "class ImageProcessor:\n",
        "    \"\"\"\n",
        "    Class for handling image processing and object detection operations\n",
        "    Separates processing logic from UI components\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_llm=True, llm_model_path=None, enable_places365=True, places365_model_name='resnet50_places365'):\n",
        "        \"\"\"Initialize the image processor with required components\"\"\"\n",
        "        print(f\"Initializing ImageProcessor with use_llm={use_llm}, enable_places365={enable_places365}\")\n",
        "\n",
        "        try:\n",
        "            # Initialize basic components first\n",
        "            self.use_llm = use_llm\n",
        "            self.llm_model_path = llm_model_path\n",
        "            self.enable_places365 = enable_places365\n",
        "            self.model_instances = {}\n",
        "\n",
        "            self.coco_class_names = {\n",
        "                0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane',\n",
        "                5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light',\n",
        "                10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench',\n",
        "                14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
        "                20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack',\n",
        "                25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee',\n",
        "                30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat',\n",
        "                35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket',\n",
        "                39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife',\n",
        "                44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich',\n",
        "                49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',\n",
        "                54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',\n",
        "                59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop',\n",
        "                64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone',\n",
        "                68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator',\n",
        "                73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear',\n",
        "                78: 'hair drier', 79: 'toothbrush'\n",
        "            }\n",
        "\n",
        "            # Initialize ColorMapper\n",
        "            self.color_mapper = ColorMapper()\n",
        "            print(\"ColorMapper initialized successfully\")\n",
        "\n",
        "            # Initialize LightingAnalyzer\n",
        "            self.lighting_analyzer = LightingAnalyzer()\n",
        "            print(\"LightingAnalyzer initialized successfully\")\n",
        "\n",
        "            # Initialize Places365 model if enabled\n",
        "            self.places365_model = None\n",
        "            if self.enable_places365:\n",
        "                try:\n",
        "                    self.places365_model = Places365Model(\n",
        "                        model_name=places365_model_name,\n",
        "                        device=None\n",
        "                    )\n",
        "                    print(f\"Places365 model initialized successfully with {places365_model_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Failed to initialize Places365 model: {e}\")\n",
        "                    print(\"Continuing without Places365 analysis\")\n",
        "                    self.enable_places365 = False\n",
        "                    self.places365_model = None\n",
        "\n",
        "            # Initialize SceneAnalyzer with error handling\n",
        "            self.scene_analyzer = None\n",
        "            self.class_names = self.coco_class_names\n",
        "\n",
        "            try:\n",
        "                # Initialize SceneAnalyzer without class_names (will be set later)\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=self.coco_class_names,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=True,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "                print(\"SceneAnalyzer initialized successfully\")\n",
        "\n",
        "                # Verify critical components\n",
        "                if self.scene_analyzer is not None:\n",
        "                    print(f\"SceneAnalyzer status - spatial_analyzer: {hasattr(self.scene_analyzer, 'spatial_analyzer')}, \"\n",
        "                        f\"descriptor: {hasattr(self.scene_analyzer, 'descriptor')}, \"\n",
        "                        f\"scene_describer: {hasattr(self.scene_analyzer, 'scene_describer')}\")\n",
        "                else:\n",
        "                    print(\"WARNING: scene_analyzer is None after initialization\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error initializing SceneAnalyzer: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                self.scene_analyzer = None\n",
        "\n",
        "            print(\"ImageProcessor initialization completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Critical error during ImageProcessor initialization: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise RuntimeError(f\"Failed to initialize ImageProcessor: {str(e)}\")\n",
        "\n",
        "    def get_model_instance(self, model_name: str, confidence: float = 0.25, iou: float = 0.25) -> DetectionModel:\n",
        "        \"\"\"\n",
        "        Get or create a model instance based on model name\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the model to use\n",
        "            confidence: Confidence threshold for detection\n",
        "            iou: IoU threshold for non-maximum suppression\n",
        "\n",
        "        Returns:\n",
        "            DetectionModel instance\n",
        "        \"\"\"\n",
        "        if model_name not in self.model_instances:\n",
        "            print(f\"Creating new model instance for {model_name}\")\n",
        "            self.model_instances[model_name] = DetectionModel(\n",
        "                model_name=model_name,\n",
        "                confidence=confidence,\n",
        "                iou=iou\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Using existing model instance for {model_name}\")\n",
        "            self.model_instances[model_name].confidence = confidence\n",
        "\n",
        "        return self.model_instances[model_name]\n",
        "\n",
        "    def analyze_scene(self, detection_result: Any, lighting_info: Optional[Dict] = None, enable_landmark=True, places365_info=None) -> Dict:\n",
        "        \"\"\"\n",
        "        Perform scene analysis on detection results\n",
        "\n",
        "        Args:\n",
        "            detection_result: Object detection result from YOLOv8\n",
        "            lighting_info: Lighting condition analysis results (optional)\n",
        "            enable_landmark: Whether to enable landmark detection\n",
        "            places365_info: Places365 analysis results (optional)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing scene analysis results\n",
        "        \"\"\"\n",
        "        print(f\"DEBUG: analyze_scene received enable_landmark={enable_landmark}\")\n",
        "        try:\n",
        "            # Check if detection_result has valid names\n",
        "            class_names = getattr(detection_result, 'names', None) if detection_result else None\n",
        "\n",
        "            # Initialize or reinitialize scene analyzer if needed\n",
        "            if self.scene_analyzer is None:\n",
        "                print(\"Scene analyzer not initialized, creating new instance\")\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=class_names,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=enable_landmark,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "\n",
        "                if self.scene_analyzer is None:\n",
        "                    raise ValueError(\"Failed to create SceneAnalyzer instance\")\n",
        "            else:\n",
        "                # Update existing scene analyzer settings\n",
        "                self.scene_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # Update class names if available and different\n",
        "                if class_names and self.scene_analyzer.class_names != class_names:\n",
        "                    self.scene_analyzer.class_names = class_names\n",
        "                    if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                        self.scene_analyzer.spatial_analyzer.class_names = class_names\n",
        "\n",
        "                # Update landmark detection settings in child components\n",
        "                if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                    self.scene_analyzer.spatial_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "            # Perform scene analysis with lighting info and Places365 context\n",
        "            scene_analysis = self.scene_analyzer.analyze(\n",
        "                detection_result=detection_result,\n",
        "                lighting_info=lighting_info,\n",
        "                class_confidence_threshold=0.35,\n",
        "                scene_confidence_threshold=0.6,\n",
        "                enable_landmark=enable_landmark,\n",
        "                places365_info=places365_info\n",
        "            )\n",
        "\n",
        "            return scene_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in scene analysis: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Return a valid default result\n",
        "            return {\n",
        "                \"scene_type\": \"unknown\",\n",
        "                \"confidence\": 0.0,\n",
        "                \"description\": f\"Error during scene analysis: {str(e)}\",\n",
        "                \"enhanced_description\": \"Scene analysis could not be completed due to an error.\",\n",
        "                \"objects_present\": [],\n",
        "                \"object_count\": 0,\n",
        "                \"regions\": {},\n",
        "                \"possible_activities\": [],\n",
        "                \"safety_concerns\": [],\n",
        "                \"lighting_conditions\": lighting_info or {\"time_of_day\": \"unknown\", \"confidence\": 0.0}\n",
        "            }\n",
        "\n",
        "    def analyze_lighting_conditions(self, image, places365_info: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        分析光照條件並考慮 Places365 場景資訊。\n",
        "\n",
        "        Args:\n",
        "            image: 輸入圖像\n",
        "            places365_info: Places365 場景分析結果，用於覆蓋邏輯\n",
        "\n",
        "        Returns:\n",
        "            Dict: 光照分析結果\n",
        "        \"\"\"\n",
        "        return self.lighting_analyzer.analyze(image, places365_info=places365_info)\n",
        "\n",
        "    def analyze_places365_scene(self, image):\n",
        "        \"\"\"\n",
        "        Analyze scene using Places365 model.\n",
        "\n",
        "        Args:\n",
        "            image: Input image (PIL Image)\n",
        "\n",
        "        Returns:\n",
        "            Dict: Places365 analysis results or None if disabled/failed\n",
        "        \"\"\"\n",
        "        if not self.enable_places365 or self.places365_model is None:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if not isinstance(image, Image.Image):\n",
        "                if isinstance(image, np.ndarray):\n",
        "                    image = Image.fromarray(image)\n",
        "                else:\n",
        "                    print(f\"Warning: Cannot process image of type {type(image)} for Places365\")\n",
        "                    return None\n",
        "\n",
        "            places365_result = self.places365_model.predict(image)\n",
        "\n",
        "            if places365_result and places365_result.get('confidence', 0) > 0.1:\n",
        "                print(f\"Places365 detected: {places365_result['scene_label']} \"\n",
        "                    f\"(mapped: {places365_result['mapped_scene_type']}) \"\n",
        "                    f\"confidence: {places365_result['confidence']:.3f}\")\n",
        "                return places365_result\n",
        "            else:\n",
        "                print(\"Places365 analysis failed or low confidence\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Places365 analysis: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_image(self, image: Any, model_name: str, confidence_threshold: float, filter_classes: Optional[List[int]] = None,  enable_landmark: bool = True) -> Tuple[Any, str, Dict]:\n",
        "        \"\"\"\n",
        "        Process an image for object detection and scene analysis.\n",
        "        Args:\n",
        "            image: Input image (numpy array or PIL Image).\n",
        "            model_name: Name of the model to use.\n",
        "            confidence_threshold: Confidence threshold for detection.\n",
        "            filter_classes: Optional list of classes to filter results.\n",
        "            enable_landmark: Whether to enable landmark detection for this run.\n",
        "        Returns:\n",
        "            Tuple of (result_image_pil, result_text, stats_data_with_scene_analysis).\n",
        "        \"\"\"\n",
        "        model_instance = self.get_model_instance(model_name, confidence_threshold)\n",
        "        if model_instance is None:\n",
        "            return None, f\"Failed to load model: {model_name}. Please check model configuration.\", {}\n",
        "\n",
        "        result = None\n",
        "        stats_data = {}\n",
        "        temp_path = None\n",
        "        pil_image_for_processing = None # Use this to store the consistently processed PIL image\n",
        "\n",
        "        try:\n",
        "            if isinstance(image, np.ndarray):\n",
        "                if image.ndim == 3 and image.shape[2] == 3: # RGB or BGR\n",
        "                    # Assuming BGR from OpenCV, convert to RGB for PIL standard\n",
        "                    image_rgb_np = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                    pil_image_for_processing = Image.fromarray(image_rgb_np)\n",
        "                elif image.ndim == 3 and image.shape[2] == 4: # RGBA or BGRA\n",
        "                    image_rgba_np = cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA) # Ensure RGBA\n",
        "                    pil_image_for_processing = Image.fromarray(image_rgba_np).convert(\"RGB\") # Convert to RGB\n",
        "                elif image.ndim == 2: # Grayscale\n",
        "                    pil_image_for_processing = Image.fromarray(image).convert(\"RGB\")\n",
        "                else:\n",
        "                    pil_image_for_processing = Image.fromarray(image) # Hope for the best\n",
        "            elif isinstance(image, Image.Image):\n",
        "                pil_image_for_processing = image.copy() # Use a copy\n",
        "            elif image is None:\n",
        "                return None, \"No image provided. Please upload an image.\", {}\n",
        "            else:\n",
        "                return None, f\"Unsupported image type: {type(image)}. Please provide a NumPy array or PIL Image.\", {}\n",
        "\n",
        "            if pil_image_for_processing.mode != \"RGB\": # Ensure final image is RGB\n",
        "                pil_image_for_processing = pil_image_for_processing.convert(\"RGB\")\n",
        "\n",
        "            # Add Places365 scene analysis parallel to lighting analysis\n",
        "            places365_info = self.analyze_places365_scene(pil_image_for_processing)\n",
        "\n",
        "            lighting_info = self.analyze_lighting_conditions(pil_image_for_processing, places365_info=places365_info)\n",
        "\n",
        "            temp_dir = tempfile.gettempdir()\n",
        "            temp_filename = f\"temp_{uuid.uuid4().hex}.jpg\"\n",
        "            temp_path = os.path.join(temp_dir, temp_filename)\n",
        "            pil_image_for_processing.save(temp_path, format=\"JPEG\")\n",
        "\n",
        "            result = model_instance.detect(temp_path)\n",
        "\n",
        "            if result is None or not hasattr(result, 'boxes'):\n",
        "                scene_analysis_no_yolo = self.analyze_scene(result, lighting_info, enable_landmark=enable_landmark, places365_info=places365_info)\n",
        "                desc_no_yolo = scene_analysis_no_yolo.get(\"enhanced_description\", scene_analysis_no_yolo.get(\"description\", \"Detection failed, scene context analysis attempted.\"))\n",
        "                stats_data[\"scene_analysis\"] = scene_analysis_no_yolo\n",
        "                if places365_info:\n",
        "                    stats_data[\"places365_analysis\"] = places365_info\n",
        "                return pil_image_for_processing, desc_no_yolo, stats_data\n",
        "\n",
        "            # 統計資訊\n",
        "            stats_data = EvaluationMetrics.calculate_basic_stats(result)\n",
        "            spatial_metrics = EvaluationMetrics.calculate_distance_metrics(result)\n",
        "            stats_data[\"spatial_metrics\"] = spatial_metrics\n",
        "            stats_data[\"lighting_conditions\"] = lighting_info\n",
        "            if places365_info:\n",
        "                stats_data[\"places365_analysis\"] = places365_info\n",
        "\n",
        "            if filter_classes and len(filter_classes) > 0:\n",
        "                classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "                confs = result.boxes.conf.cpu().numpy()\n",
        "                mask = np.isin(classes, filter_classes)\n",
        "                filtered_stats_data = {\n",
        "                    \"total_objects\": int(np.sum(mask)), \"class_statistics\": {},\n",
        "                    \"average_confidence\": float(np.mean(confs[mask])) if np.any(mask) else 0.0,\n",
        "                    \"spatial_metrics\": stats_data.get(\"spatial_metrics\",{}),\n",
        "                    \"lighting_conditions\": lighting_info\n",
        "                }\n",
        "                if places365_info:\n",
        "                    filtered_stats_data[\"places365_analysis\"] = places365_info\n",
        "                names = result.names\n",
        "                class_conf_sums = {}\n",
        "                for cls_id_int, conf_val in zip(classes[mask], confs[mask]):\n",
        "                    cls_name = names[cls_id_int]\n",
        "                    if cls_name not in filtered_stats_data[\"class_statistics\"]:\n",
        "                        filtered_stats_data[\"class_statistics\"][cls_name] = {\"count\": 0}\n",
        "                        class_conf_sums[cls_name] = 0.0\n",
        "                    filtered_stats_data[\"class_statistics\"][cls_name][\"count\"] += 1 # 累計統計資訊\n",
        "                    class_conf_sums[cls_name] += conf_val\n",
        "                for cls_name_stat, data_stat in filtered_stats_data[\"class_statistics\"].items():\n",
        "                    data_stat[\"average_confidence\"] = round(class_conf_sums[cls_name_stat] / data_stat[\"count\"] if data_stat[\"count\"] > 0 else 0.0, 4)\n",
        "                stats_data = filtered_stats_data\n",
        "\n",
        "            viz_data = EvaluationMetrics.generate_visualization_data(result, self.color_mapper.get_all_colors())\n",
        "\n",
        "            result_image_pil = VisualizationHelper.visualize_detection(\n",
        "                temp_path, result, color_mapper=self.color_mapper,\n",
        "                figsize=(12, 12), return_pil=True, filter_classes=filter_classes\n",
        "            )\n",
        "\n",
        "            result_text_summary = EvaluationMetrics.format_detection_summary(viz_data)\n",
        "\n",
        "            #  Pass the enable_landmark parameter from function signature\n",
        "            # Initialize or update scene analyzer if needed\n",
        "            if self.scene_analyzer is None:\n",
        "                print(\"Creating SceneAnalyzer in process_image\")\n",
        "                self.scene_analyzer = SceneAnalyzer(\n",
        "                    class_names=result.names if result else None,\n",
        "                    use_llm=self.use_llm,\n",
        "                    use_clip=True,\n",
        "                    enable_landmark=enable_landmark,\n",
        "                    llm_model_path=self.llm_model_path\n",
        "                )\n",
        "\n",
        "                if self.scene_analyzer is None:\n",
        "                    print(\"ERROR: Failed to create SceneAnalyzer in process_image\")\n",
        "            else:\n",
        "                # Update existing scene analyzer with current settings\n",
        "                if result and hasattr(result, 'names'):\n",
        "                    # 使用檢測結果的類別名稱或回退到預定義映射\n",
        "                    current_class_names = result.names if result.names else self.coco_class_names\n",
        "\n",
        "                    self.scene_analyzer.class_names = current_class_names\n",
        "                    if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                        self.scene_analyzer.spatial_analyzer.update_class_names(current_class_names)\n",
        "\n",
        "                    logger.info(f\"Updated class names in scene analyzer: {list(current_class_names.keys())}\")\n",
        "\n",
        "                self.scene_analyzer.enable_landmark = enable_landmark\n",
        "                if hasattr(self.scene_analyzer, 'spatial_analyzer') and self.scene_analyzer.spatial_analyzer:\n",
        "                    self.scene_analyzer.spatial_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "            # Perform scene analysis using the existing analyze_scene method\n",
        "            scene_analysis_result = self.analyze_scene(\n",
        "                detection_result=result,\n",
        "                lighting_info=lighting_info,\n",
        "                enable_landmark=enable_landmark,\n",
        "                places365_info=places365_info\n",
        "            )\n",
        "\n",
        "            stats_data[\"scene_analysis\"] = scene_analysis_result\n",
        "\n",
        "            final_result_text = result_text_summary\n",
        "\n",
        "            # Use enable_landmark parameter for landmark block\n",
        "            if enable_landmark and \"detected_landmarks\" in scene_analysis_result:\n",
        "                landmarks_detected = scene_analysis_result.get(\"detected_landmarks\", [])\n",
        "                if not landmarks_detected and scene_analysis_result.get(\"primary_landmark\"):\n",
        "                    primary_lm = scene_analysis_result.get(\"primary_landmark\")\n",
        "                    if isinstance(primary_lm, dict): landmarks_detected = [primary_lm]\n",
        "\n",
        "                if landmarks_detected:\n",
        "                    final_result_text += \"\\n\\n--- Detected Landmarks ---\\n\"\n",
        "                    # Ensure drawing on the correct PIL image\n",
        "                    img_to_draw_on = result_image_pil.copy() # Draw on a copy\n",
        "                    img_for_drawing_cv2 = cv2.cvtColor(np.array(img_to_draw_on), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                    for landmark_item in landmarks_detected:\n",
        "                        if not isinstance(landmark_item, dict): continue\n",
        "\n",
        "                        # Use .get() for all potentially missing keys 比較保險\n",
        "                        landmark_name_disp = landmark_item.get(\"class_name\", landmark_item.get(\"name\", \"N/A\"))\n",
        "                        landmark_loc_disp = landmark_item.get(\"location\", \"N/A\")\n",
        "                        landmark_conf_disp = landmark_item.get(\"confidence\", 0.0)\n",
        "\n",
        "                        final_result_text += f\"• {landmark_name_disp} ({landmark_loc_disp}, confidence: {landmark_conf_disp:.2f})\\n\"\n",
        "\n",
        "                        if \"box\" in landmark_item:\n",
        "                            box = landmark_item[\"box\"]\n",
        "                            pt1 = (int(box[0]), int(box[1])); pt2 = (int(box[2]), int(box[3]))\n",
        "                            color_lm = (255, 0, 255); thickness_lm = 3 # Magenta BGR\n",
        "                            cv2.rectangle(img_for_drawing_cv2, pt1, pt2, color_lm, thickness_lm)\n",
        "\n",
        "                            label_lm = f\"{landmark_name_disp} ({landmark_conf_disp:.2f})\"\n",
        "                            font_scale_lm = 0.6; font_thickness_lm = 1\n",
        "                            (w_text, h_text), baseline = cv2.getTextSize(label_lm, cv2.FONT_HERSHEY_SIMPLEX, font_scale_lm, font_thickness_lm)\n",
        "\n",
        "                            # Label position logic (simplified from your extensive one for brevity)\n",
        "                            label_y_pos = pt1[1] - baseline - 3\n",
        "                            if label_y_pos < h_text : # If label goes above image, put it below box\n",
        "                                label_y_pos = pt2[1] + h_text + baseline + 3\n",
        "\n",
        "                            label_bg_pt1 = (pt1[0], label_y_pos - h_text - baseline)\n",
        "                            label_bg_pt2 = (pt1[0] + w_text, label_y_pos + baseline)\n",
        "\n",
        "                            cv2.rectangle(img_for_drawing_cv2, label_bg_pt1, label_bg_pt2, color_lm, -1)\n",
        "                            cv2.putText(img_for_drawing_cv2, label_lm, (pt1[0], label_y_pos),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, font_scale_lm, (255,255,255), font_thickness_lm, cv2.LINE_AA)\n",
        "\n",
        "                    result_image_pil = Image.fromarray(cv2.cvtColor(img_for_drawing_cv2, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            return result_image_pil, final_result_text, stats_data\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"Error in ImageProcessor.process_image: {str(e)}\"\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return pil_image_for_processing if pil_image_for_processing else None, error_message, {}\n",
        "        finally:\n",
        "            if temp_path and os.path.exists(temp_path):\n",
        "                try: os.remove(temp_path)\n",
        "                except Exception as e: print(f\"Warning: Cannot delete temp file {temp_path}: {str(e)}\")\n",
        "\n",
        "    def format_result_text(self, stats: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Format detection statistics into readable text with improved spacing\n",
        "\n",
        "        Args:\n",
        "            stats: Dictionary containing detection statistics\n",
        "\n",
        "        Returns:\n",
        "            Formatted text summary\n",
        "        \"\"\"\n",
        "        if not stats or \"total_objects\" not in stats:\n",
        "            return \"No objects detected.\"\n",
        "\n",
        "        # 減少不必要的空行\n",
        "        lines = [\n",
        "            f\"Detected {stats['total_objects']} objects.\",\n",
        "            f\"Average confidence: {stats.get('average_confidence', 0):.2f}\",\n",
        "            \"Objects by class:\"\n",
        "        ]\n",
        "\n",
        "        if \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            # 按計數排序類別\n",
        "            sorted_classes = sorted(\n",
        "                stats[\"class_statistics\"].items(),\n",
        "                key=lambda x: x[1][\"count\"],\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            for cls_name, cls_stats in sorted_classes:\n",
        "                count = cls_stats[\"count\"]\n",
        "                conf = cls_stats.get(\"average_confidence\", 0)\n",
        "\n",
        "                item_text = \"item\" if count == 1 else \"items\"\n",
        "                lines.append(f\"• {cls_name}: {count} {item_text} (avg conf: {conf:.2f})\")\n",
        "        else:\n",
        "            lines.append(\"No class information available.\")\n",
        "\n",
        "        # 添加空間資訊\n",
        "        if \"spatial_metrics\" in stats and \"spatial_distribution\" in stats[\"spatial_metrics\"]:\n",
        "            lines.append(\"Object Distribution:\")\n",
        "\n",
        "            dist = stats[\"spatial_metrics\"][\"spatial_distribution\"]\n",
        "            x_mean = dist.get(\"x_mean\", 0)\n",
        "            y_mean = dist.get(\"y_mean\", 0)\n",
        "\n",
        "            # 描述物體的大致位置\n",
        "            if x_mean < 0.33:\n",
        "                h_pos = \"on the left side\"\n",
        "            elif x_mean < 0.67:\n",
        "                h_pos = \"in the center\"\n",
        "            else:\n",
        "                h_pos = \"on the right side\"\n",
        "\n",
        "            if y_mean < 0.33:\n",
        "                v_pos = \"in the upper part\"\n",
        "            elif y_mean < 0.67:\n",
        "                v_pos = \"in the middle\"\n",
        "            else:\n",
        "                v_pos = \"in the lower part\"\n",
        "\n",
        "            lines.append(f\"• Most objects appear {h_pos} {v_pos} of the image\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def format_json_for_display(self, stats: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Format statistics JSON for better display\n",
        "\n",
        "        Args:\n",
        "            stats: Raw statistics dictionary\n",
        "\n",
        "        Returns:\n",
        "            Formatted statistics structure for display\n",
        "        \"\"\"\n",
        "        # Create a cleaner copy of the stats for display\n",
        "        display_stats = {}\n",
        "\n",
        "        # Add summary section\n",
        "        display_stats[\"summary\"] = {\n",
        "            \"total_objects\": stats.get(\"total_objects\", 0),\n",
        "            \"average_confidence\": round(stats.get(\"average_confidence\", 0), 3)\n",
        "        }\n",
        "\n",
        "        # Add class statistics in a more organized way\n",
        "        if \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            # Sort classes by count (descending)\n",
        "            sorted_classes = sorted(\n",
        "                stats[\"class_statistics\"].items(),\n",
        "                key=lambda x: x[1].get(\"count\", 0),\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            class_stats = {}\n",
        "            for cls_name, cls_data in sorted_classes:\n",
        "                class_stats[cls_name] = {\n",
        "                    \"count\": cls_data.get(\"count\", 0),\n",
        "                    \"average_confidence\": round(cls_data.get(\"average_confidence\", 0), 3)\n",
        "                }\n",
        "\n",
        "            display_stats[\"detected_objects\"] = class_stats\n",
        "\n",
        "        # Simplify spatial metrics\n",
        "        if \"spatial_metrics\" in stats:\n",
        "            spatial = stats[\"spatial_metrics\"]\n",
        "\n",
        "            # Simplify spatial distribution\n",
        "            if \"spatial_distribution\" in spatial:\n",
        "                dist = spatial[\"spatial_distribution\"]\n",
        "                display_stats[\"spatial\"] = {\n",
        "                    \"distribution\": {\n",
        "                        \"x_mean\": round(dist.get(\"x_mean\", 0), 3),\n",
        "                        \"y_mean\": round(dist.get(\"y_mean\", 0), 3),\n",
        "                        \"x_std\": round(dist.get(\"x_std\", 0), 3),\n",
        "                        \"y_std\": round(dist.get(\"y_std\", 0), 3)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            # Add simplified size information\n",
        "            if \"size_distribution\" in spatial:\n",
        "                size = spatial[\"size_distribution\"]\n",
        "                display_stats[\"spatial\"][\"size\"] = {\n",
        "                    \"mean_area\": round(size.get(\"mean_area\", 0), 3),\n",
        "                    \"min_area\": round(size.get(\"min_area\", 0), 3),\n",
        "                    \"max_area\": round(size.get(\"max_area\", 0), 3)\n",
        "                }\n",
        "\n",
        "        return display_stats\n",
        "\n",
        "    def prepare_visualization_data(self, stats: Dict, available_classes: Dict[int, str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Prepare data for visualization based on detection statistics\n",
        "\n",
        "        Args:\n",
        "            stats: Detection statistics\n",
        "            available_classes: Dictionary of available class IDs and names\n",
        "\n",
        "        Returns:\n",
        "            Visualization data dictionary\n",
        "        \"\"\"\n",
        "        if not stats or \"class_statistics\" not in stats or not stats[\"class_statistics\"]:\n",
        "            return {\"error\": \"No detection data available\"}\n",
        "\n",
        "        # Prepare visualization data\n",
        "        viz_data = {\n",
        "            \"total_objects\": stats.get(\"total_objects\", 0),\n",
        "            \"average_confidence\": stats.get(\"average_confidence\", 0),\n",
        "            \"class_data\": []\n",
        "        }\n",
        "\n",
        "        # Class data\n",
        "        for cls_name, cls_stats in stats.get(\"class_statistics\", {}).items():\n",
        "            # Search class ID\n",
        "            class_id = -1\n",
        "            for id, name in available_classes.items():\n",
        "                if name == cls_name:\n",
        "                    class_id = id\n",
        "                    break\n",
        "\n",
        "            cls_data = {\n",
        "                \"name\": cls_name,\n",
        "                \"class_id\": class_id,\n",
        "                \"count\": cls_stats.get(\"count\", 0),\n",
        "                \"average_confidence\": cls_stats.get(\"average_confidence\", 0),\n",
        "                \"color\": self.color_mapper.get_color(class_id if class_id >= 0 else cls_name)\n",
        "            }\n",
        "\n",
        "            viz_data[\"class_data\"].append(cls_data)\n",
        "\n",
        "        # Descending order\n",
        "        viz_data[\"class_data\"].sort(key=lambda x: x[\"count\"], reverse=True)\n",
        "\n",
        "        return viz_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGtfLV0N2g10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cd98cc-f863-4db8-ac5a-87ab7cee5515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing video_processor.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile video_processor.py\n",
        "import cv2\n",
        "import os\n",
        "import tempfile\n",
        "import uuid\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "# from image_processor import ImageProcessor\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from scene_analyzer import SceneAnalyzer\n",
        "# from detection_model import DetectionModel\n",
        "\n",
        "class VideoProcessor:\n",
        "    \"\"\"\n",
        "    Handles the processing of video files, including object detection\n",
        "    and scene analysis on selected frames.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_processor: ImageProcessor):\n",
        "        \"\"\"\n",
        "        Initializes the VideoProcessor.\n",
        "\n",
        "        Args:\n",
        "            image_processor (ImageProcessor): An initialized ImageProcessor instance.\n",
        "        \"\"\"\n",
        "        self.image_processor = image_processor\n",
        "\n",
        "    def process_video_file(self,\n",
        "                           video_path: str,\n",
        "                           model_name: str,\n",
        "                           confidence_threshold: float,\n",
        "                           process_interval: int = 5,\n",
        "                           scene_desc_interval_sec: int = 3) -> Tuple[Optional[str], str, Dict]:\n",
        "        \"\"\"\n",
        "        Processes an uploaded video file, performs detection and periodic scene analysis,\n",
        "        and returns the path to the annotated output video file along with a summary.\n",
        "\n",
        "        Args:\n",
        "            video_path (str): Path to the input video file.\n",
        "            model_name (str): Name of the YOLO model to use.\n",
        "            confidence_threshold (float): Confidence threshold for object detection.\n",
        "            process_interval (int): Process every Nth frame. Defaults to 5.\n",
        "            scene_desc_interval_sec (int): Update scene description every N seconds. Defaults to 3.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Optional[str], str, Dict]: (Path to output video or None, Summary text, Statistics dictionary)\n",
        "        \"\"\"\n",
        "        if not video_path or not os.path.exists(video_path):\n",
        "            print(f\"Error: Video file not found at {video_path}\")\n",
        "            return None, \"Error: Video file not found.\", {}\n",
        "\n",
        "        print(f\"Starting video processing for: {video_path}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            return None, \"Error opening video file.\", {}\n",
        "\n",
        "        # Get video properties\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        if fps <= 0: # Handle case where fps is not available or invalid\n",
        "             fps = 30 # Assume a default fps\n",
        "             print(f\"Warning: Could not get valid FPS for video. Assuming {fps} FPS.\")\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(f\"Video properties: {width}x{height} @ {fps:.2f} FPS, Total Frames: {total_frames_video}\")\n",
        "\n",
        "        # Calculate description update interval in frames\n",
        "        description_update_interval_frames = int(fps * scene_desc_interval_sec)\n",
        "        if description_update_interval_frames < 1:\n",
        "            description_update_interval_frames = int(fps) # Update at least once per second if interval is too short\n",
        "\n",
        "        object_trackers = {}  # 儲存ID與物體的映射\n",
        "        last_detected_objects = {}  # 儲存上一次檢測到的物體資訊\n",
        "        next_object_id = 0  # 下一個可用的物體ID\n",
        "        tracking_threshold = 0.6  # 相同物體的IoU\n",
        "        object_colors = {}  # 每個被追蹤的物體分配固定顏色\n",
        "\n",
        "        # Setup Output Video\n",
        "        output_filename = f\"processed_{uuid.uuid4().hex}_{os.path.basename(video_path)}\"\n",
        "        temp_dir = tempfile.gettempdir() # Use system's temp directory\n",
        "        output_path = os.path.join(temp_dir, output_filename)\n",
        "        # Ensure the output path has a compatible extension (like .mp4)\n",
        "        if not output_path.lower().endswith(('.mp4', '.avi', '.mov')):\n",
        "            output_path += \".mp4\"\n",
        "\n",
        "        # Use 'mp4v' for MP4, common and well-supported\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "        if not out.isOpened():\n",
        "            print(f\"Error: Could not open VideoWriter for path: {output_path}\")\n",
        "            cap.release()\n",
        "            return None, f\"Error creating output video file at {output_path}.\", {}\n",
        "        print(f\"Output video will be saved to: {output_path}\")\n",
        "\n",
        "        frame_count = 0\n",
        "        processed_frame_count = 0\n",
        "        all_stats = [] # Store stats for each processed frame\n",
        "        summary_lines = []\n",
        "        last_description = \"Analyzing scene...\" # Initial description\n",
        "        frame_since_last_desc = description_update_interval_frames # Trigger analysis on first processed frame\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break # End of video\n",
        "\n",
        "                frame_count += 1\n",
        "                frame_since_last_desc += 1\n",
        "                current_frame_annotated = False # Flag if this frame was processed and annotated\n",
        "\n",
        "                # Process frame based on interval\n",
        "                if frame_count % process_interval == 0:\n",
        "                    processed_frame_count += 1\n",
        "                    print(f\"Processing frame {frame_count}...\")\n",
        "                    current_frame_annotated = True\n",
        "\n",
        "                    # Use ImageProcessor for single-frame tasks\n",
        "                    # 1. Convert frame format BGR -> RGB -> PIL\n",
        "                    try:\n",
        "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                        pil_image = Image.fromarray(frame_rgb)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error converting frame {frame_count}: {e}\")\n",
        "                        continue # Skip this frame\n",
        "\n",
        "                    # 2. Get appropriate model instance\n",
        "                    # Confidence is passed from UI, model_name too\n",
        "                    model_instance = self.image_processor.get_model_instance(model_name, confidence_threshold)\n",
        "                    if not model_instance or not model_instance.is_model_loaded:\n",
        "                         print(f\"Error: Model {model_name} not loaded. Skipping frame {frame_count}.\")\n",
        "                         # Draw basic frame without annotation\n",
        "                         cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
        "                         cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "                         out.write(frame)\n",
        "                         continue\n",
        "\n",
        "\n",
        "                    # 3. Perform detection\n",
        "                    detection_result = model_instance.detect(pil_image) # Use PIL image\n",
        "\n",
        "                    current_description_for_frame = last_description # Default to last known description\n",
        "                    scene_analysis_result = None\n",
        "                    stats = {}\n",
        "\n",
        "                    if detection_result and hasattr(detection_result, 'boxes') and len(detection_result.boxes) > 0:\n",
        "                        # Ensure SceneAnalyzer is ready within ImageProcessor\n",
        "                        if not hasattr(self.image_processor, 'scene_analyzer') or self.image_processor.scene_analyzer is None:\n",
        "                             print(\"Initializing SceneAnalyzer...\")\n",
        "                             # Pass class names from the current detection result\n",
        "                             self.image_processor.scene_analyzer = SceneAnalyzer(class_names=detection_result.names)\n",
        "                        elif self.image_processor.scene_analyzer.class_names is None:\n",
        "                             # Update class names if they were missing\n",
        "                             self.image_processor.scene_analyzer.class_names = detection_result.names\n",
        "                             if hasattr(self.image_processor.scene_analyzer, 'spatial_analyzer'):\n",
        "                                 self.image_processor.scene_analyzer.spatial_analyzer.class_names = detection_result.names\n",
        "\n",
        "\n",
        "                        # 4. Perform Scene Analysis (periodically)\n",
        "                        if frame_since_last_desc >= description_update_interval_frames:\n",
        "                            print(f\"Analyzing scene at frame {frame_count} (threshold: {description_update_interval_frames} frames)...\")\n",
        "                            # Pass lighting_info=None for now, as it's disabled for performance\n",
        "                            scene_analysis_result = self.image_processor.analyze_scene(detection_result, lighting_info=None)\n",
        "                            current_description_for_frame = scene_analysis_result.get(\"description\", last_description)\n",
        "                            last_description = current_description_for_frame # Cache the new description\n",
        "                            frame_since_last_desc = 0 # Reset counter\n",
        "\n",
        "                        # 5. Calculate Statistics for this frame\n",
        "                        stats = EvaluationMetrics.calculate_basic_stats(detection_result)\n",
        "                        stats['frame_number'] = frame_count # Add frame number to stats\n",
        "                        all_stats.append(stats)\n",
        "\n",
        "                        # 6. Draw annotations\n",
        "                        names = detection_result.names\n",
        "                        boxes = detection_result.boxes.xyxy.cpu().numpy()\n",
        "                        classes = detection_result.boxes.cls.cpu().numpy().astype(int)\n",
        "                        confs = detection_result.boxes.conf.cpu().numpy()\n",
        "\n",
        "                        def calculate_iou(box1, box2):\n",
        "                            \"\"\"Calculate Intersection IOU value\"\"\"\n",
        "                            x1_1, y1_1, x2_1, y2_1 = box1\n",
        "                            x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "                            xi1 = max(x1_1, x1_2)\n",
        "                            yi1 = max(y1_1, y1_2)\n",
        "                            xi2 = min(x2_1, x2_2)\n",
        "                            yi2 = min(y2_1, y2_2)\n",
        "\n",
        "                            inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "                            box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "                            box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "\n",
        "                            union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "                            return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "                        # 處理當前幀中的所有檢測\n",
        "                        current_detected_objects = {}\n",
        "\n",
        "                        for box, cls_id, conf in zip(boxes, classes, confs):\n",
        "                            x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                            # 查找最匹配的已追蹤物體\n",
        "                            best_match_id = None\n",
        "                            best_match_iou = 0\n",
        "\n",
        "                            for obj_id, (old_box, old_cls_id, _) in last_detected_objects.items():\n",
        "                                if old_cls_id == cls_id:  # 同一類別才比較\n",
        "                                    iou = calculate_iou(box, old_box)\n",
        "                                    if iou > tracking_threshold and iou > best_match_iou:\n",
        "                                        best_match_id = obj_id\n",
        "                                        best_match_iou = iou\n",
        "\n",
        "                            # 如果找到匹配，使用現有ID；否則分配新ID\n",
        "                            if best_match_id is not None:\n",
        "                                obj_id = best_match_id\n",
        "                            else:\n",
        "                                obj_id = next_object_id\n",
        "                                next_object_id += 1\n",
        "\n",
        "                                # 使用更明顯的顏色\n",
        "                                bright_colors = [\n",
        "                                    (0, 0, 255),    # red\n",
        "                                    (0, 255, 0),    # green\n",
        "                                    (255, 0, 0),    # blue\n",
        "                                    (0, 255, 255),  # yellow\n",
        "                                    (255, 0, 255),  # purple\n",
        "                                    (255, 128, 0),  # orange\n",
        "                                    (128, 0, 255)   # purple\n",
        "                                ]\n",
        "                                object_colors[obj_id] = bright_colors[obj_id % len(bright_colors)]\n",
        "\n",
        "                            # update tracking info\n",
        "                            current_detected_objects[obj_id] = (box, cls_id, conf)\n",
        "\n",
        "                            color = object_colors.get(obj_id, (0, 255, 0))  # default is green\n",
        "                            label = f\"{names.get(cls_id, 'Unknown')}-{obj_id}: {conf:.2f}\"\n",
        "\n",
        "                            # 平滑化邊界框：如果是已知物體，與上一幀位置平均\n",
        "                            if obj_id in last_detected_objects:\n",
        "                                old_box, _, _ = last_detected_objects[obj_id]\n",
        "                                old_x1, old_y1, old_x2, old_y2 = map(int, old_box)\n",
        "                                # 平滑係數\n",
        "                                alpha = 0.7  # current weight\n",
        "                                beta = 0.3   # history weight\n",
        "\n",
        "                                x1 = int(alpha * x1 + beta * old_x1)\n",
        "                                y1 = int(alpha * y1 + beta * old_y1)\n",
        "                                x2 = int(alpha * x2 + beta * old_x2)\n",
        "                                y2 = int(alpha * y2 + beta * old_y2)\n",
        "\n",
        "                            # draw box and label\n",
        "                            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                            # add text\n",
        "                            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "                            cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w, y1 - 10), color, -1)\n",
        "                            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "                        # update tracking info\n",
        "                        last_detected_objects = current_detected_objects.copy()\n",
        "\n",
        "\n",
        "                    # Draw the current scene description on the frame\n",
        "                    cv2.putText(frame, f\"Scene: {current_description_for_frame[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA) # Black outline\n",
        "                    cv2.putText(frame, f\"Scene: {current_description_for_frame[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA) # White text\n",
        "\n",
        "                # Write the frame (annotated or original) to the output video\n",
        "                # Draw last known description if this frame wasn't processed\n",
        "                if not current_frame_annotated:\n",
        "                    cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
        "                    cv2.putText(frame, f\"Scene: {last_description[:80]}...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "                out.write(frame) # Write frame to output file\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during video processing loop for {video_path}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            summary_lines.append(f\"An error occurred during processing: {e}\")\n",
        "        finally:\n",
        "            # Release resources\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            print(f\"Video processing finished. Resources released. Output path: {output_path}\")\n",
        "            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "                print(f\"Error: Output video file was not created or is empty at {output_path}\")\n",
        "                summary_lines.append(\"Error: Failed to create output video.\")\n",
        "                output_path = None\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        summary_lines.insert(0, f\"Finished processing in {processing_time:.2f} seconds.\")\n",
        "        summary_lines.insert(1, f\"Processed {processed_frame_count} frames out of {frame_count} (interval: {process_interval} frames).\")\n",
        "        summary_lines.insert(2, f\"Scene description updated approximately every {scene_desc_interval_sec} seconds.\")\n",
        "\n",
        "        # Generate Aggregate Statistics\n",
        "        aggregated_stats = {\n",
        "            \"total_frames_read\": frame_count,\n",
        "            \"total_frames_processed\": processed_frame_count,\n",
        "            \"avg_objects_per_processed_frame\": 0, # Calculate below\n",
        "            \"cumulative_detections\": {}, # Total times each class was detected\n",
        "            \"max_concurrent_detections\": {} # Max count of each class in a single processed frame\n",
        "            }\n",
        "        object_cumulative_counts = {}\n",
        "        object_max_concurrent_counts = {} # Store the max count found for each object type\n",
        "        total_detected_in_processed = 0\n",
        "\n",
        "        # Iterate through stats collected from each processed frame\n",
        "        for frame_stats in all_stats:\n",
        "            total_objects_in_frame = frame_stats.get(\"total_objects\", 0)\n",
        "            total_detected_in_processed += total_objects_in_frame\n",
        "\n",
        "            # Iterate through object classes detected in this frame\n",
        "            for obj_name, obj_data in frame_stats.get(\"class_statistics\", {}).items():\n",
        "                count_in_frame = obj_data.get(\"count\", 0)\n",
        "\n",
        "                # Cumulative count\n",
        "                if obj_name not in object_cumulative_counts:\n",
        "                    object_cumulative_counts[obj_name] = 0\n",
        "                object_cumulative_counts[obj_name] += count_in_frame\n",
        "\n",
        "                # Max concurrent count\n",
        "                if obj_name not in object_max_concurrent_counts:\n",
        "                    object_max_concurrent_counts[obj_name] = 0\n",
        "                # Update the max count if the current frame's count is higher\n",
        "                object_max_concurrent_counts[obj_name] = max(object_max_concurrent_counts[obj_name], count_in_frame)\n",
        "\n",
        "        # Add sorted results to the final dictionary\n",
        "        aggregated_stats[\"cumulative_detections\"] = dict(sorted(object_cumulative_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "        aggregated_stats[\"max_concurrent_detections\"] = dict(sorted(object_max_concurrent_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "        # Calculate average objects per processed frame\n",
        "        if processed_frame_count > 0:\n",
        "             aggregated_stats[\"avg_objects_per_processed_frame\"] = round(total_detected_in_processed / processed_frame_count, 2)\n",
        "\n",
        "        summary_text = \"\\n\".join(summary_lines)\n",
        "        print(\"Generated Summary:\\n\", summary_text)\n",
        "        print(\"Aggregated Stats (Revised):\\n\", aggregated_stats) # Print the revised stats\n",
        "\n",
        "        # Return the potentially updated output_path\n",
        "        return output_path, summary_text, aggregated_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile model_manager.py\n",
        "import os\n",
        "import torch\n",
        "import logging\n",
        "from typing import Dict, Optional, Any\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "class ModelLoadingError(Exception):\n",
        "    \"\"\"Custom exception for model loading failures\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ModelGenerationError(Exception):\n",
        "    \"\"\"Custom exception for model generation failures\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ModelManager:\n",
        "    \"\"\"\n",
        "    負責LLM模型的載入、設備管理和文本生成。\n",
        "    管理模型、記憶體優化和設備配置。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_path: Optional[str] = None,\n",
        "                 tokenizer_path: Optional[str] = None,\n",
        "                 device: Optional[str] = None,\n",
        "                 max_length: int = 2048,\n",
        "                 temperature: float = 0.3,\n",
        "                 top_p: float = 0.85):\n",
        "        \"\"\"\n",
        "        初始化模型管理器\n",
        "\n",
        "        Args:\n",
        "            model_path: LLM模型的路徑或HuggingFace模型名稱，默認使用Llama 3.2\n",
        "            tokenizer_path: tokenizer的路徑，通常與model_path相同\n",
        "            device: 運行設備 ('cpu'或'cuda')，None時自動檢測\n",
        "            max_length: 輸入文本的最大長度\n",
        "            temperature: 生成文本的溫度參數\n",
        "            top_p: 生成文本時的核心採樣機率閾值\n",
        "        \"\"\"\n",
        "        # 設置專屬logger\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        # 模型配置\n",
        "        self.model_path = model_path or \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "        self.tokenizer_path = tokenizer_path or self.model_path\n",
        "\n",
        "        # 設備管理\n",
        "        self.device = self._detect_device(device)\n",
        "        self.logger.info(f\"Device selected: {self.device}\")\n",
        "\n",
        "        # 生成參數\n",
        "        self.max_length = max_length\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "\n",
        "        # 模型狀態\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self._model_loaded = False\n",
        "        self.call_count = 0\n",
        "\n",
        "        # HuggingFace認證\n",
        "        self.hf_token = self._setup_huggingface_auth()\n",
        "\n",
        "    def _detect_device(self, device: Optional[str]) -> str:\n",
        "        \"\"\"\n",
        "        檢測並設置運行設備\n",
        "\n",
        "        Args:\n",
        "            device: 用戶指定的設備，None時自動檢測\n",
        "\n",
        "        Returns:\n",
        "            str: ('cuda' or 'cpu')\n",
        "        \"\"\"\n",
        "        if device:\n",
        "            if device == 'cuda' and not torch.cuda.is_available():\n",
        "                self.logger.warning(\"CUDA requested but not available, falling back to CPU\")\n",
        "                return 'cpu'\n",
        "            return device\n",
        "\n",
        "        detected_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        if detected_device == 'cuda':\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "            self.logger.info(f\"CUDA detected with {gpu_memory:.2f} GB GPU memory\")\n",
        "\n",
        "        return detected_device\n",
        "\n",
        "    def _setup_huggingface_auth(self) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        設置HuggingFace認證\n",
        "\n",
        "        Returns:\n",
        "            Optional[str]: HuggingFace token，如果可用\n",
        "        \"\"\"\n",
        "        hf_token = os.environ.get(\"HF_TOKEN\")\n",
        "\n",
        "        if hf_token:\n",
        "            try:\n",
        "                login(token=hf_token)\n",
        "                self.logger.info(\"Successfully authenticated with HuggingFace\")\n",
        "                return hf_token\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"HuggingFace authentication failed: {e}\")\n",
        "                return None\n",
        "        else:\n",
        "            self.logger.warning(\"HF_TOKEN not found. Access to gated models may be limited\")\n",
        "            return None\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"\n",
        "        載入LLM模型和tokenizer，使用8位量化以節省記憶體\n",
        "\n",
        "        Raises:\n",
        "            ModelLoadingError: 當模型載入失敗時\n",
        "        \"\"\"\n",
        "        if self._model_loaded:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            self.logger.info(f\"Loading model from {self.model_path} with 8-bit quantization\")\n",
        "\n",
        "            # 清理GPU記憶體\n",
        "            self._clear_gpu_cache()\n",
        "\n",
        "            # 設置8位量化配置\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_8bit=True,\n",
        "                llm_int8_enable_fp32_cpu_offload=True\n",
        "            )\n",
        "\n",
        "            # 載入tokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.tokenizer_path,\n",
        "                padding_side=\"left\",\n",
        "                use_fast=False,\n",
        "                token=self.hf_token\n",
        "            )\n",
        "\n",
        "            # 設置特殊標記\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # 載入模型\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_path,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                low_cpu_mem_usage=True,\n",
        "                token=self.hf_token\n",
        "            )\n",
        "\n",
        "            self._model_loaded = True\n",
        "            self.logger.info(\"Model loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to load model: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            raise ModelLoadingError(error_msg) from e\n",
        "\n",
        "    def _clear_gpu_cache(self):\n",
        "        \"\"\"清理GPU記憶體緩存\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            self.logger.debug(\"GPU cache cleared\")\n",
        "\n",
        "    def generate_response(self, prompt: str, **generation_kwargs) -> str:\n",
        "        \"\"\"\n",
        "        生成LLM回應\n",
        "\n",
        "        Args:\n",
        "            prompt: 輸入提示詞\n",
        "            **generation_kwargs: 額外的生成參數，可覆蓋預設值\n",
        "\n",
        "        Returns:\n",
        "            str: 生成的回應文本\n",
        "\n",
        "        Raises:\n",
        "            ModelGenerationError: 當生成失敗時\n",
        "        \"\"\"\n",
        "        # 確保模型已載入\n",
        "        if not self._model_loaded:\n",
        "            self._load_model()\n",
        "\n",
        "        try:\n",
        "            self.call_count += 1\n",
        "            self.logger.info(f\"Generating response (call #{self.call_count})\")\n",
        "\n",
        "            # clean GPU\n",
        "            self._clear_gpu_cache()\n",
        "\n",
        "            # 設置固定種子以提高一致性\n",
        "            torch.manual_seed(42)\n",
        "\n",
        "            # prepare input\n",
        "            inputs = self.tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=self.max_length\n",
        "            ).to(self.device)\n",
        "\n",
        "            # 準備生成參數\n",
        "            generation_params = self._prepare_generation_params(**generation_kwargs)\n",
        "            generation_params.update({\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id,\n",
        "                \"attention_mask\": inputs.attention_mask,\n",
        "                \"use_cache\": True,\n",
        "            })\n",
        "\n",
        "            # resposne\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(inputs.input_ids, **generation_params)\n",
        "\n",
        "            # 解碼回應\n",
        "            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            response = self._extract_generated_response(full_response, prompt)\n",
        "\n",
        "            if not response or len(response.strip()) < 10:\n",
        "                raise ModelGenerationError(\"Generated response is too short or empty\")\n",
        "\n",
        "            self.logger.info(f\"Response generated successfully ({len(response)} characters)\")\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Text generation failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            raise ModelGenerationError(error_msg) from e\n",
        "\n",
        "    def _prepare_generation_params(self, **kwargs) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        準備生成參數，支援模型特定的優化\n",
        "\n",
        "        Args:\n",
        "            **kwargs: 用戶提供的生成參數\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 完整的生成參數配置\n",
        "        \"\"\"\n",
        "        # basic parameters\n",
        "        params = {\n",
        "            \"max_new_tokens\": 120,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"top_p\": self.top_p,\n",
        "            \"do_sample\": True,\n",
        "        }\n",
        "\n",
        "        # 針對Llama模型的特殊優化\n",
        "        if \"llama\" in self.model_path.lower():\n",
        "            params.update({\n",
        "                \"max_new_tokens\": 600,\n",
        "                \"temperature\": 0.35, # not too big\n",
        "                \"top_p\": 0.75,\n",
        "                \"repetition_penalty\": 1.5,\n",
        "                \"num_beams\": 5,\n",
        "                \"length_penalty\": 1,\n",
        "                \"no_repeat_ngram_size\": 3\n",
        "            })\n",
        "        else:\n",
        "            params.update({\n",
        "                \"max_new_tokens\": 300,\n",
        "                \"temperature\": 0.6,\n",
        "                \"top_p\": 0.9,\n",
        "                \"num_beams\": 1,\n",
        "                \"repetition_penalty\": 1.05\n",
        "            })\n",
        "\n",
        "        # 用戶參數覆蓋預設值\n",
        "        params.update(kwargs)\n",
        "\n",
        "        return params\n",
        "\n",
        "    def _extract_generated_response(self, full_response: str, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        從完整回應中提取生成的部分\n",
        "\n",
        "        Args:\n",
        "            full_response: 模型的完整輸出\n",
        "            prompt: 原始提示詞\n",
        "\n",
        "        Returns:\n",
        "            str: 提取的生成回應\n",
        "        \"\"\"\n",
        "        # 尋找assistant標記\n",
        "        assistant_tag = \"<|assistant|>\"\n",
        "        if assistant_tag in full_response:\n",
        "            response = full_response.split(assistant_tag)[-1].strip()\n",
        "\n",
        "            # 檢查是否有未閉合的user標記\n",
        "            user_tag = \"<|user|>\"\n",
        "            if user_tag in response:\n",
        "                response = response.split(user_tag)[0].strip()\n",
        "\n",
        "            return response\n",
        "\n",
        "        # 移除輸入提示詞\n",
        "        if full_response.startswith(prompt):\n",
        "            return full_response[len(prompt):].strip()\n",
        "\n",
        "        return full_response.strip()\n",
        "\n",
        "    def reset_context(self):\n",
        "        \"\"\"重置模型上下文，清理GPU緩存\"\"\"\n",
        "        if self._model_loaded:\n",
        "            self._clear_gpu_cache()\n",
        "            self.logger.info(\"Model context reset\")\n",
        "        else:\n",
        "            self.logger.info(\"Model not loaded, no context to reset\")\n",
        "\n",
        "    def get_current_device(self) -> str:\n",
        "        \"\"\"\n",
        "        獲取當前運行設備\n",
        "\n",
        "        Returns:\n",
        "            str: 當前設備名稱\n",
        "        \"\"\"\n",
        "        return self.device\n",
        "\n",
        "    def is_model_loaded(self) -> bool:\n",
        "        \"\"\"\n",
        "        檢查模型是否已載入\n",
        "\n",
        "        Returns:\n",
        "            bool: 模型載入狀態\n",
        "        \"\"\"\n",
        "        return self._model_loaded\n",
        "\n",
        "    def get_call_count(self) -> int:\n",
        "        \"\"\"\n",
        "        獲取模型調用次數\n",
        "\n",
        "        Returns:\n",
        "            int: 調用次數\n",
        "        \"\"\"\n",
        "        return self.call_count\n",
        "\n",
        "    def get_model_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取模型信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 包含模型路徑、設備、載入狀態等信息\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"model_path\": self.model_path,\n",
        "            \"device\": self.device,\n",
        "            \"is_loaded\": self._model_loaded,\n",
        "            \"call_count\": self.call_count,\n",
        "            \"has_hf_token\": self.hf_token is not None\n",
        "        }"
      ],
      "metadata": {
        "id": "kUcr71QHsX4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49077de-a32d-4e74-9d54-c4258a511ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile prompt_template_manager.py\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "class PromptTemplateError(Exception):\n",
        "    \"\"\"提示模板相關錯誤的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class PromptTemplateManager:\n",
        "    \"\"\"\n",
        "    負責管理和格式化各種LLM提示模板。\n",
        "    包含場景描述增強、錯誤檢測、無檢測處理等不同場景的模板。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化提示模板管理器\"\"\"\n",
        "        # set the logger\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        # initialize all templates\n",
        "        self._initialize_templates()\n",
        "        self.logger.info(\"PromptTemplateManager initialized successfully\")\n",
        "\n",
        "    def _initialize_templates(self):\n",
        "        \"\"\"初始化所有提示模板\"\"\"\n",
        "        try:\n",
        "            self._setup_enhancement_template()\n",
        "            self._setup_verification_template()\n",
        "            self._setup_no_detection_template()\n",
        "            self.logger.info(\"All prompt templates initialized\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to initialize templates: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise PromptTemplateError(f\"Template initialization failed: {str(e)}\") from e\n",
        "\n",
        "\n",
        "    def format_enhancement_prompt_with_landmark(self, scene_data: Dict[str, Any], object_list: str, original_description: str) -> str:\n",
        "        try:\n",
        "            # 確保場景類型被正確清理\n",
        "            scene_type = scene_data.get(\"scene_type\", \"unknown scene\")\n",
        "            cleaned_scene_type = self._clean_scene_type(scene_type)\n",
        "\n",
        "            # 通用文本格式清理：處理底線和格式化問題\n",
        "            cleaned_description = self._clean_text_formatting(original_description)\n",
        "\n",
        "            # 額外清理場景類型底線格式\n",
        "            cleaned_description = self._clean_scene_type_underscores(cleaned_description)\n",
        "\n",
        "            # 強化輸入清理\n",
        "            cleaned_description = self._enhance_input_cleaning(cleaned_description)\n",
        "\n",
        "            # 在原始描述中替換未清理的場景類型\n",
        "            if scene_type != cleaned_scene_type:\n",
        "                cleaned_description = cleaned_description.replace(scene_type, cleaned_scene_type)\n",
        "\n",
        "            # 檢查是否有地標資訊\n",
        "            landmark_info = scene_data.get(\"landmark_location_info\")\n",
        "            is_fallback = scene_data.get(\"is_fallback\", False)\n",
        "\n",
        "            # 準備額外的地標指導內容\n",
        "            additional_guidance = \"\"\n",
        "            if landmark_info:\n",
        "                landmark_name = landmark_info.get(\"name\", \"\")\n",
        "                landmark_location = landmark_info.get(\"location\", \"\")\n",
        "                additional_guidance = f\"\"\"\n",
        "            LANDMARK LOCATION REQUIREMENT: This scene features {landmark_name} located in {landmark_location}.\n",
        "            16. MANDATORY: Include the specific location \"{landmark_location}\" when first mentioning {landmark_name}. Use natural phrasing such as \"Located in {landmark_location}, the {landmark_name}...\" or \"The {landmark_name} in {landmark_location}...\" or \"Standing majestically in {landmark_location}, {landmark_name}...\".\n",
        "            17. Avoid mechanical openings like \"The tourist landmark is centered around\" or \"The scene is centered around\". Instead, begin with the landmark itself as the subject.\n",
        "            18. NEVER use terms with underscores like \"tourist_landmark\" or \"historical_site\" in your response. Use natural language: \"tourist landmark\", \"historical site\", \"cultural attraction\" etc.\n",
        "            19. The geographical reference must appear naturally in the opening sentence, integrated as essential context rather than supplementary information.\"\"\"\n",
        "            elif is_fallback:\n",
        "                additional_guidance = \"\"\"\n",
        "            FALLBACK MODE: The previous enhancement was insufficient. Provide a more detailed description focusing on key visual elements, human activities, atmospheric details, and architectural features.\"\"\"\n",
        "\n",
        "            # 建構完整的模板內容\n",
        "            if additional_guidance:\n",
        "                # 在CRITICAL RULES後添加地標相關指導\n",
        "                enhanced_template = self.enhance_description_template.replace(\n",
        "                    \"15. When describing quantities or arrangements, use only information explicitly confirmed by the object detection system.\",\n",
        "                    f\"15. When describing quantities or arrangements, use only information explicitly confirmed by the object detection system.{additional_guidance}\"\n",
        "                )\n",
        "            else:\n",
        "                enhanced_template = self.enhance_description_template\n",
        "\n",
        "            formatted_prompt = enhanced_template.format(\n",
        "                original_description=cleaned_description,\n",
        "                object_list=object_list\n",
        "            )\n",
        "\n",
        "            return formatted_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to format enhancement prompt: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise PromptTemplateError(f\"Prompt formatting failed: {e}\") from e\n",
        "\n",
        "    def _clean_text_formatting(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        通用文本格式清理方法，處理底線、格式化等問題\n",
        "\n",
        "        Args:\n",
        "            text: 需要清理的原始文本\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的文本\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 替換常見的技術性詞彙\n",
        "            replacements = {\n",
        "                'tourist_landmark': 'tourist landmark',\n",
        "                'historical_site': 'historical site',\n",
        "                'religious_building': 'religious building',\n",
        "                'cultural_landmark': 'cultural landmark',\n",
        "                'architectural_site': 'architectural site',\n",
        "                'natural_landmark': 'natural landmark'\n",
        "            }\n",
        "\n",
        "            cleaned = text\n",
        "            for old_term, new_term in replacements.items():\n",
        "                cleaned = cleaned.replace(old_term, new_term)\n",
        "\n",
        "            # 處理其他底線情況\n",
        "            cleaned = re.sub(r'(\\w+)_(\\w+)', lambda m: f\"{m.group(1)} {m.group(2)}\", cleaned)\n",
        "\n",
        "            # 處理多個連續底線\n",
        "            cleaned = re.sub(r'_+', ' ', cleaned)\n",
        "\n",
        "            # 清理多餘空格\n",
        "            cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
        "\n",
        "            return cleaned.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in text formatting cleanup: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def _clean_scene_type_underscores(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        專門清理場景類型中的底線格式\n",
        "\n",
        "        Args:\n",
        "            text: 需要清理的文本\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的文本\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 專門處理場景類型的底線格式\n",
        "            scene_type_patterns = [\n",
        "                'urban_intersection', 'city_street', 'downtown_area', 'business_district',\n",
        "                'residential_area', 'commercial_zone', 'industrial_area', 'shopping_center',\n",
        "                'traffic_intersection', 'pedestrian_crossing', 'public_square'\n",
        "            ]\n",
        "\n",
        "            for pattern in scene_type_patterns:\n",
        "                if pattern in text:\n",
        "                    replacement = pattern.replace('_', ' ')\n",
        "                    text = text.replace(pattern, replacement)\n",
        "\n",
        "            # 處理任何剩餘的場景類型底線模式\n",
        "            text = re.sub(r'\\b([a-z]+)_([a-z]+)(?=\\s+(?:features|shows|displays|contains|is|area|zone|scene))',\n",
        "                        r'\\1 \\2', text, flags=re.IGNORECASE)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in scene type underscore cleanup: {str(e)}\")\n",
        "            return text\n",
        "\n",
        "    def _enhance_input_cleaning(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        增強輸入描述的清理功能\n",
        "\n",
        "        Args:\n",
        "            description: 待清理的描述\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的描述\n",
        "        \"\"\"\n",
        "        if not description:\n",
        "            return description\n",
        "\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 預防性清理底線格式\n",
        "            description = re.sub(r'\\b(\\w+)_(\\w+)\\b', r'\\1 \\2', description)\n",
        "\n",
        "            # 清理可能導致語法問題的模式\n",
        "            problematic_patterns = [\n",
        "                (r'\\s+,\\s+', ', '),  # 修正空格-逗號問題\n",
        "                (r'\\bIn\\s*,', 'In the area,'),  # 預防性修正\n",
        "                (r'\\s+\\.', '.'),  # 修正句號前空格\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in problematic_patterns:\n",
        "                description = re.sub(pattern, replacement, description)\n",
        "\n",
        "            return description.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in enhanced input cleaning: {str(e)}\")\n",
        "            return description\n",
        "\n",
        "    def _setup_enhancement_template(self):\n",
        "        \"\"\"設置場景描述增強模板\"\"\"\n",
        "        self.enhance_description_template = \"\"\"\n",
        "            <|system|>\n",
        "            You are an expert visual analyst. Your task is to improve the readability and fluency of scene descriptions using STRICT factual accuracy.\n",
        "            Your **top priority is to avoid hallucination** or fabrication. You are working in a computer vision pipeline using object detection (YOLO) and image embeddings. You MUST treat the input object list as a whitelist. Do not speculate beyond this list.\n",
        "            </|system|>\n",
        "            <|user|>\n",
        "            Rewrite the following scene description to be fluent and clear. DO NOT add any objects, events, or spatial relationships that are not explicitly present in the original or object list.\n",
        "            ORIGINAL:\n",
        "            {original_description}\n",
        "            CRITICAL RULES:\n",
        "            1. CRITICAL ADHERENCE TO INPUT: Strictly adhere to the information explicitly provided in the ORIGINAL description and the {object_list}.\n",
        "               a. NEVER assume or infer room types, object functions, scene purposes, or abstract conceptual zones (e.g., 'personal items zone', 'activity area') unless such concepts, along with their specific constituent objects and locations, are explicitly detailed in the ORIGINAL description or clearly supported by multiple items in the {object_list}.\n",
        "               b. Your role is to rephrase and enhance the provided factual data, not to introduce new conceptual layers or interpretations not directly supported by the input.\n",
        "            2. OBJECT WHITELIST & DETAIL ACCURACY:\n",
        "               a. The provided {object_list} is an exhaustive list of objects confirmed by the vision system. Mention ONLY objects from this list or objects explicitly detailed in the ORIGINAL description.\n",
        "               b. DO NOT invent additional objects or infer the presence of 'various scattered objects' if only a single specific item (e.g., one 'handbag') is mentioned in relation to a category or area. Describe only what is explicitly listed.\n",
        "            3. NEVER speculate on object quantity. If the description says \"10 people\" , DO NOT say \"dozens\" or \"many\". Maintain the original quantity unless specified.\n",
        "            4. SPATIAL ACCURACY - STRICTLY FROM ORIGINAL:\n",
        "               a. Base ALL descriptions of object locations (e.g., 'foreground', 'background', 'middle center') and spatial relationships STRICTLY on the information explicitly provided in the ORIGINAL description.\n",
        "               b. If the ORIGINAL description states an object is 'in the background,' use that exact term. If it specifies 'in the foreground,' use that. If it describes an object as being 'carried by a person', reflect this precise relationship.\n",
        "               c. If the ORIGINAL description is less specific about an object's location (e.g., 'a car is present'), then use general, non-committal terms like 'visible in the scene' or 'present in the image.'\n",
        "               d. DO NOT re-interpret object positions from any perceived understanding of the raw image; your sole source for spatial information is the ORIGINAL description. Do not relocate objects (e.g., moving a carried handbag from the person to 'the background').\n",
        "            5. You MAY describe confirmed materials, colors, and composition style if visually obvious and non-speculative, AND if such details are hinted at or present in the ORIGINAL description or {object_list}.\n",
        "            6. Write 2–4 complete, well-structured sentences with punctuation.\n",
        "            7. Final output MUST be a single fluent paragraph of 60–200 words (not longer). Within this concise format, every sentence should aim to introduce new information or build upon previous statements without significant overlap.\n",
        "            8. Begin your response directly with the scene description. Do NOT include any introductory phrases, explanations, or formatting indicators.\n",
        "            9. Ensure grammatical completeness in all sentences. Each sentence must have a complete subject and predicate structure.\n",
        "               a. NEVER use underscore formatting (e.g., tourist_landmark, urban_intersection). Always use natural spacing (tourist landmark, urban intersection).\n",
        "               b. NEVER begin sentences with incomplete phrases like \"In ,\" or \"Overall,\" without proper subjects. Always ensure complete sentence structure.\n",
        "               c. AVOID redundant or circular phrasing such as \"with lights turned illuminating\" or \"atmosphere of is one of.\"\n",
        "               d. If you encounter incomplete spatial descriptions like \"visible in ,\" or \"positioned in the middle of.\", complete them naturally by adding appropriate context such as \"visible in the scene\" or \"positioned in the middle of the frame\", ensuring these completions are consistent with the ORIGINAL description. Always ensure spatial descriptions have complete prepositional phrases.\n",
        "               e. GRAMMAR AND FLUENCY CHECK: Ensure all sentences are grammatically flawless and flow naturally. Avoid awkward phrasing or dangling prepositions (e.g., 'glow over ,'). Mentally re-read your generated description to catch and correct such minor errors before finalizing.\n",
        "            10. Vary sentence structures naturally while maintaining grammatical accuracy.\n",
        "            11. CRITICAL: Avoid repeating the mention of specific objects, groups of objects, or their spatial arrangements. Once an object or layout aspect is described, only refer to it again if providing genuinely NEW and DISTINCT information or a significantly different perspective that adds substantial value. Strive for conciseness and information density.\n",
        "            12. Create natural spatial flow by connecting object descriptions organically rather than listing positions mechanically.\n",
        "            13. Use transitional phrases to connect ideas smoothly, varying expression patterns throughout the description.\n",
        "            14. For the concluding sentence, focus on the overall atmosphere, style, perceived activity, or overarching impression of the scene. DO NOT simply restate the primary objects or their layout as a summary or 'backdrop' if they have already been clearly described earlier in the paragraph. The conclusion should offer a higher-level takeaway.\n",
        "            15. When describing quantities or arrangements, use only information explicitly confirmed by the object detection system or ORIGINAL description.\n",
        "            </|user|>\n",
        "            <|assistant|>\n",
        "            \"\"\"\n",
        "\n",
        "    def _setup_verification_template(self):\n",
        "        \"\"\"設置檢測結果驗證模板\"\"\"\n",
        "        self.verify_detection_template = \"\"\"\n",
        "            Task: You are an advanced vision system that verifies computer vision detections for accuracy.\n",
        "            Analyze the following detection results and identify any potential errors or inconsistencies:\n",
        "            SCENE TYPE: {scene_type}\n",
        "            SCENE NAME: {scene_name}\n",
        "            CONFIDENCE: {confidence:.2f}\n",
        "            DETECTED OBJECTS: {detected_objects}\n",
        "            CLIP ANALYSIS RESULTS:\n",
        "            {clip_analysis}\n",
        "            Possible Errors to Check:\n",
        "            1. Objects misidentified (e.g., architectural elements labeled as vehicles)\n",
        "            2. Cultural elements misunderstood (e.g., Asian temple structures labeled as boats)\n",
        "            3. Objects that seem out of place for this type of scene\n",
        "            4. Inconsistencies between different detection systems\n",
        "            If you find potential errors, list them clearly with explanations. If the detections seem reasonable, state that they appear accurate.\n",
        "            Verification Results:\n",
        "            \"\"\"\n",
        "\n",
        "    def _setup_no_detection_template(self):\n",
        "        \"\"\"設置無檢測結果處理模板\"\"\"\n",
        "        self.no_detection_template = \"\"\"\n",
        "            Task: You are an advanced scene understanding system analyzing an image where standard object detection failed to identify specific objects.\n",
        "            Based on advanced image embeddings (CLIP analysis), we have the following information:\n",
        "            MOST LIKELY SCENE: {top_scene} (confidence: {top_confidence:.2f})\n",
        "            VIEWPOINT: {viewpoint}\n",
        "            LIGHTING: {lighting_condition}\n",
        "            CULTURAL ANALYSIS: {cultural_analysis}\n",
        "            Create a detailed description of what might be in this scene, considering:\n",
        "            1. The most likely type of location or setting\n",
        "            2. Possible architectural or natural elements present\n",
        "            3. The lighting and atmosphere\n",
        "            4. Potential cultural or regional characteristics\n",
        "            Your description should be natural, flowing, and offer insights into what the image likely contains despite the lack of specific object detection.\n",
        "            Scene Description:\n",
        "            \"\"\"\n",
        "\n",
        "    def format_enhancement_prompt(self, scene_data: Dict[str, Any], object_list: str, original_description: str) -> str:\n",
        "        try:\n",
        "            # 確保場景類型被正確清理\n",
        "            scene_type = scene_data.get(\"scene_type\", \"unknown scene\")\n",
        "            cleaned_scene_type = self._clean_scene_type(scene_type)\n",
        "\n",
        "            # 在原始描述中替換未清理的場景類型\n",
        "            if scene_type != cleaned_scene_type:\n",
        "                original_description = original_description.replace(scene_type, cleaned_scene_type)\n",
        "\n",
        "            formatted_prompt = self.enhance_description_template.format(\n",
        "                original_description=original_description,\n",
        "                object_list=object_list\n",
        "            )\n",
        "\n",
        "            return formatted_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to format enhancement prompt: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise PromptTemplateError(f\"Prompt formatting failed: {e}\") from e\n",
        "\n",
        "\n",
        "    def format_verification_prompt(self,\n",
        "                                 detected_objects: List[Dict],\n",
        "                                 clip_analysis: Dict[str, Any],\n",
        "                                 scene_type: str,\n",
        "                                 scene_name: str,\n",
        "                                 confidence: float) -> str:\n",
        "        \"\"\"\n",
        "        格式化檢測結果驗證提示\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "            clip_analysis: CLIP分析結果\n",
        "            scene_type: 場景類型\n",
        "            scene_name: 場景名稱\n",
        "            confidence: 場景分類信心度\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的驗證提示字符串\n",
        "\n",
        "        Raises:\n",
        "            PromptTemplateError: 當模板格式化失敗時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Formatting verification prompt\")\n",
        "\n",
        "            # 格式化物件列表和CLIP分析結果\n",
        "            objects_str = self._format_objects_for_prompt(detected_objects)\n",
        "            clip_str = self._format_clip_results(clip_analysis)\n",
        "\n",
        "            # 格式化提示\n",
        "            formatted_prompt = self.verify_detection_template.format(\n",
        "                scene_type=scene_type,\n",
        "                scene_name=scene_name,\n",
        "                confidence=confidence,\n",
        "                detected_objects=objects_str,\n",
        "                clip_analysis=clip_str\n",
        "            )\n",
        "\n",
        "            self.logger.debug(f\"Verification prompt formatted successfully (length: {len(formatted_prompt)})\")\n",
        "            return formatted_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to format verification prompt: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise PromptTemplateError(error_msg) from e\n",
        "\n",
        "    def format_no_detection_prompt(self, clip_analysis: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        格式化無檢測結果處理提示\n",
        "\n",
        "        Args:\n",
        "            clip_analysis: CLIP分析結果字典\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的無檢測處理提示字符串\n",
        "\n",
        "        Raises:\n",
        "            PromptTemplateError: 當模板格式化失敗時\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Formatting no-detection prompt\")\n",
        "\n",
        "            # 提取CLIP分析結果\n",
        "            top_scene, top_confidence = clip_analysis.get(\"top_scene\", (\"unknown\", 0))\n",
        "            viewpoint = clip_analysis.get(\"viewpoint\", (\"standard\", 0))[0]\n",
        "            lighting = clip_analysis.get(\"lighting_condition\", (\"unknown\", 0))[0]\n",
        "\n",
        "            # 格式化文化分析\n",
        "            cultural_str = self._format_cultural_analysis(clip_analysis.get(\"cultural_analysis\", {}))\n",
        "\n",
        "            # 格式化提示\n",
        "            formatted_prompt = self.no_detection_template.format(\n",
        "                top_scene=top_scene,\n",
        "                top_confidence=top_confidence,\n",
        "                viewpoint=viewpoint,\n",
        "                lighting_condition=lighting,\n",
        "                cultural_analysis=cultural_str\n",
        "            )\n",
        "\n",
        "            self.logger.debug(f\"No-detection prompt formatted successfully (length: {len(formatted_prompt)})\")\n",
        "            return formatted_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to format no-detection prompt: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise PromptTemplateError(error_msg) from e\n",
        "\n",
        "    def _clean_scene_type(self, scene_type: str) -> str:\n",
        "        \"\"\"\n",
        "        清理場景類型，使其更適合用於提示詞\n",
        "\n",
        "        Args:\n",
        "            scene_type: 原始場景類型\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的場景類型\n",
        "        \"\"\"\n",
        "        if not scene_type:\n",
        "            return \"scene\"\n",
        "\n",
        "        # 將底線替換為空格並首字母大寫\n",
        "        if '_' in scene_type:\n",
        "            return ' '.join(word.capitalize() for word in scene_type.split('_'))\n",
        "\n",
        "        return scene_type\n",
        "\n",
        "    def _format_objects_for_prompt(self, objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        格式化物件列表以用於提示\n",
        "\n",
        "        Args:\n",
        "            objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的物件字符串\n",
        "        \"\"\"\n",
        "        if not objects:\n",
        "            return \"No objects detected\"\n",
        "\n",
        "        try:\n",
        "            formatted = []\n",
        "            for obj in objects:\n",
        "                class_name = obj.get(\"class_name\", \"unknown\")\n",
        "                confidence = obj.get(\"confidence\", 0)\n",
        "                formatted.append(f\"{class_name} (confidence: {confidence:.2f})\")\n",
        "\n",
        "            return \"\\n- \" + \"\\n- \".join(formatted)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting objects: {str(e)}\")\n",
        "            return \"Object formatting error\"\n",
        "\n",
        "    def _format_clip_results(self, clip_analysis: Dict) -> str:\n",
        "        \"\"\"\n",
        "        格式化CLIP分析結果以用於提示\n",
        "\n",
        "        Args:\n",
        "            clip_analysis: CLIP分析結果字典\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的CLIP分析字符串\n",
        "        \"\"\"\n",
        "        if not clip_analysis or \"error\" in clip_analysis:\n",
        "            return \"No CLIP analysis available\"\n",
        "\n",
        "        try:\n",
        "            parts = [\"CLIP Analysis Results:\"]\n",
        "\n",
        "            # 添加頂級場景\n",
        "            top_scene, confidence = clip_analysis.get(\"top_scene\", (\"unknown\", 0))\n",
        "            parts.append(f\"- Most likely scene: {top_scene} (confidence: {confidence:.2f})\")\n",
        "\n",
        "            # 添加視角\n",
        "            viewpoint, vp_conf = clip_analysis.get(\"viewpoint\", (\"standard\", 0))\n",
        "            parts.append(f\"- Camera viewpoint: {viewpoint} (confidence: {vp_conf:.2f})\")\n",
        "\n",
        "            # 添加物件組合\n",
        "            if \"object_combinations\" in clip_analysis:\n",
        "                combos = []\n",
        "                for combo, score in clip_analysis[\"object_combinations\"][:3]:\n",
        "                    combos.append(f\"{combo} ({score:.2f})\")\n",
        "                parts.append(f\"- Object combinations: {', '.join(combos)}\")\n",
        "\n",
        "            # 添加文化分析\n",
        "            if \"cultural_analysis\" in clip_analysis:\n",
        "                parts.append(\"- Cultural analysis:\")\n",
        "                for culture_type, data in clip_analysis[\"cultural_analysis\"].items():\n",
        "                    best_desc = data.get(\"best_description\", \"\")\n",
        "                    desc_conf = data.get(\"confidence\", 0)\n",
        "                    parts.append(f\"  * {culture_type}: {best_desc} ({desc_conf:.2f})\")\n",
        "\n",
        "            return \"\\n\".join(parts)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting CLIP results: {str(e)}\")\n",
        "            return \"CLIP analysis formatting error\"\n",
        "\n",
        "    def _format_cultural_analysis(self, cultural_analysis: Dict) -> str:\n",
        "        \"\"\"\n",
        "        格式化文化分析結果\n",
        "\n",
        "        Args:\n",
        "            cultural_analysis: 文化分析結果字典\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化後的文化分析字符串\n",
        "        \"\"\"\n",
        "        if not cultural_analysis:\n",
        "            return \"No specific cultural elements detected\"\n",
        "\n",
        "        try:\n",
        "            parts = []\n",
        "            for culture_type, data in cultural_analysis.items():\n",
        "                best_desc = data.get(\"best_description\", \"\")\n",
        "                desc_conf = data.get(\"confidence\", 0)\n",
        "                parts.append(f\"{culture_type}: {best_desc} (confidence: {desc_conf:.2f})\")\n",
        "\n",
        "            return \"\\n\".join(parts)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error formatting cultural analysis: {str(e)}\")\n",
        "            return \"Cultural analysis formatting error\"\n",
        "\n",
        "    def get_template_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取模板管理器的信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 包含模板數量和狀態的信息\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"templates_count\": 3,\n",
        "            \"available_templates\": [\n",
        "                \"enhance_description_template\",\n",
        "                \"verify_detection_template\",\n",
        "                \"no_detection_template\"\n",
        "            ],\n",
        "            \"initialization_status\": \"success\"\n",
        "        }"
      ],
      "metadata": {
        "id": "2Gq9rdtlsX2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df32cf0e-e6fd-4b3a-bd60-705b6c943b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prompt_template_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile response_processor.py\n",
        "import re\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional, Set\n",
        "\n",
        "\n",
        "class ResponseProcessingError(Exception):\n",
        "    \"\"\"回應處理相關錯誤的自定義異常\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ResponseProcessor:\n",
        "    \"\"\"\n",
        "    負責處理和清理LLM模型輸出的回應。\n",
        "    包含格式清理、重複內容檢測、語法完整性確保等功能。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化回應處理器\"\"\"\n",
        "        # set the logger\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        # 初始化清理規則和替換字典\n",
        "        self._initialize_cleaning_rules()\n",
        "        self.logger.info(\"ResponseProcessor initialized successfully\")\n",
        "\n",
        "\n",
        "    def _initialize_cleaning_rules(self):\n",
        "        \"\"\"初始化各種清理規則和替換字典，把常見有問題情況優化\"\"\"\n",
        "        try:\n",
        "            # 設置重複詞彙的替換字典\n",
        "            self.replacement_alternatives = {\n",
        "                'visible': ['present', 'evident', 'apparent', 'observable'],\n",
        "                'positioned': ['arranged', 'placed', 'set', 'organized'],\n",
        "                'located': ['found', 'placed', 'situated', 'established'],\n",
        "                'situated': ['placed', 'positioned', 'arranged', 'set'],\n",
        "                'appears': ['seems', 'looks', 'presents', 'exhibits'],\n",
        "                'features': ['includes', 'contains', 'displays', 'showcases'],\n",
        "                'shows': ['reveals', 'presents', 'exhibits', 'demonstrates'],\n",
        "                'displays': ['presents', 'exhibits', 'shows', 'reveals']\n",
        "            }\n",
        "\n",
        "            # 設置需要移除的前綴短語\n",
        "            self.prefixes_to_remove = [\n",
        "                \"Here's the enhanced description:\",\n",
        "                \"Enhanced description:\",\n",
        "                \"Here is the enhanced scene description:\",\n",
        "                \"I've enhanced the description while preserving all factual details:\",\n",
        "                \"Enhanced Description:\",\n",
        "                \"Scene Description:\",\n",
        "                \"Description:\",\n",
        "                \"Here is the enhanced description:\",\n",
        "                \"Here's the enhanced description:\",\n",
        "                \"Here is a rewritten scene description that adheres to the provided critical rules:\",\n",
        "                \"Here is the rewritten scene description:\",\n",
        "                \"Here's a rewritten scene description:\",\n",
        "                \"The rewritten scene description is as follows:\"\n",
        "            ]\n",
        "\n",
        "            # 設置需要移除的後綴短語\n",
        "            self.suffixes_to_remove = [\n",
        "                \"I've maintained all the key factual elements\",\n",
        "                \"I've preserved all the factual details\",\n",
        "                \"All factual elements have been maintained\"\n",
        "            ]\n",
        "\n",
        "            # 設置重複檢測模式\n",
        "            self.repetitive_patterns = [\n",
        "                (r'\\b(visible)\\b.*?\\b(visible)\\b', 'Multiple uses of \"visible\" detected'),\n",
        "                (r'\\b(positioned)\\b.*?\\b(positioned)\\b', 'Multiple uses of \"positioned\" detected'),\n",
        "                (r'\\b(located)\\b.*?\\b(located)\\b', 'Multiple uses of \"located\" detected'),\n",
        "                (r'\\b(situated)\\b.*?\\b(situated)\\b', 'Multiple uses of \"situated\" detected'),\n",
        "                (r'\\b(appears)\\b.*?\\b(appears)\\b', 'Multiple uses of \"appears\" detected'),\n",
        "                (r'\\b(features)\\b.*?\\b(features)\\b', 'Multiple uses of \"features\" detected'),\n",
        "                (r'\\bThis\\s+(\\w+)\\s+.*?\\bThis\\s+\\1\\b', 'Repetitive sentence structure detected')\n",
        "            ]\n",
        "\n",
        "            # 斜線組合的形容詞替換字典(有時會有斜線格式問題)\n",
        "            self.slash_replacements = {\n",
        "                'sunrise/sunset': 'warm lighting',\n",
        "                'sunset/sunrise': 'warm lighting',\n",
        "                'day/night': 'ambient lighting',\n",
        "                'night/day': 'ambient lighting',\n",
        "                'morning/evening': 'soft lighting',\n",
        "                'evening/morning': 'soft lighting',\n",
        "                'dawn/dusk': 'gentle lighting',\n",
        "                'dusk/dawn': 'gentle lighting',\n",
        "                'sunny/cloudy': 'natural lighting',\n",
        "                'cloudy/sunny': 'natural lighting',\n",
        "                'bright/dark': 'varied lighting',\n",
        "                'dark/bright': 'varied lighting',\n",
        "                'light/shadow': 'contrasting illumination',\n",
        "                'shadow/light': 'contrasting illumination',\n",
        "                'indoor/outdoor': 'mixed environment',\n",
        "                'outdoor/indoor': 'mixed environment',\n",
        "                'inside/outside': 'transitional space',\n",
        "                'outside/inside': 'transitional space',\n",
        "                'urban/rural': 'diverse landscape',\n",
        "                'rural/urban': 'diverse landscape',\n",
        "                'modern/traditional': 'architectural blend',\n",
        "                'traditional/modern': 'architectural blend',\n",
        "                'old/new': 'varied architecture',\n",
        "                'new/old': 'varied architecture',\n",
        "                'busy/quiet': 'dynamic atmosphere',\n",
        "                'quiet/busy': 'dynamic atmosphere',\n",
        "                'crowded/empty': 'varying occupancy',\n",
        "                'empty/crowded': 'varying occupancy',\n",
        "                'hot/cold': 'comfortable temperature',\n",
        "                'cold/hot': 'comfortable temperature',\n",
        "                'wet/dry': 'mixed conditions',\n",
        "                'dry/wet': 'mixed conditions',\n",
        "                'summer/winter': 'seasonal atmosphere',\n",
        "                'winter/summer': 'seasonal atmosphere',\n",
        "                'spring/autumn': 'transitional season',\n",
        "                'autumn/spring': 'transitional season',\n",
        "                'left/right': 'balanced composition',\n",
        "                'right/left': 'balanced composition',\n",
        "                'near/far': 'layered perspective',\n",
        "                'far/near': 'layered perspective',\n",
        "                'high/low': 'varied elevation',\n",
        "                'low/high': 'varied elevation',\n",
        "                'big/small': 'diverse scale',\n",
        "                'small/big': 'diverse scale',\n",
        "                'wide/narrow': 'varied width',\n",
        "                'narrow/wide': 'varied width',\n",
        "                'open/closed': 'flexible space',\n",
        "                'closed/open': 'flexible space',\n",
        "                'public/private': 'community space',\n",
        "                'private/public': 'community space',\n",
        "                'formal/informal': 'relaxed setting',\n",
        "                'informal/formal': 'relaxed setting',\n",
        "                'commercial/residential': 'mixed-use area',\n",
        "                'residential/commercial': 'mixed-use area'\n",
        "            }\n",
        "\n",
        "            # 新增：擴展的底線替換字典\n",
        "            self.underscore_replacements = {\n",
        "                'urban_intersection': 'urban intersection',\n",
        "                'tourist_landmark': 'tourist landmark',\n",
        "                'historical_site': 'historical site',\n",
        "                'religious_building': 'religious building',\n",
        "                'natural_landmark': 'natural landmark',\n",
        "                'commercial_area': 'commercial area',\n",
        "                'residential_area': 'residential area',\n",
        "                'public_space': 'public space',\n",
        "                'outdoor_scene': 'outdoor scene',\n",
        "                'indoor_scene': 'indoor scene',\n",
        "                'street_scene': 'street scene',\n",
        "                'city_center': 'city center',\n",
        "                'shopping_district': 'shopping district',\n",
        "                'business_district': 'business district',\n",
        "                'traffic_light': 'traffic light',\n",
        "                'street_lamp': 'street lamp',\n",
        "                'parking_meter': 'parking meter',\n",
        "                'fire_hydrant': 'fire hydrant',\n",
        "                'bus_stop': 'bus stop',\n",
        "                'train_station': 'train station',\n",
        "                'police_car': 'police car',\n",
        "                'fire_truck': 'fire truck',\n",
        "                'school_bus': 'school bus',\n",
        "                'time_of_day': 'time of day',\n",
        "                'weather_condition': 'weather condition',\n",
        "                'lighting_condition': 'lighting condition',\n",
        "                'atmospheric_condition': 'atmospheric condition',\n",
        "                'human_activity': 'human activity',\n",
        "                'pedestrian_traffic': 'pedestrian traffic',\n",
        "                'vehicle_traffic': 'vehicle traffic',\n",
        "                'social_gathering': 'social gathering',\n",
        "                'object_detection': 'object detection',\n",
        "                'scene_analysis': 'scene analysis',\n",
        "                'image_classification': 'image classification',\n",
        "                'computer_vision': 'computer vision'\n",
        "            }\n",
        "\n",
        "            self.logger.info(\"Cleaning rules initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize cleaning rules: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise ResponseProcessingError(error_msg) from e\n",
        "\n",
        "    def clean_response(self, response: str, model_type: str = \"general\") -> str:\n",
        "        \"\"\"\n",
        "        清理LLM回應\n",
        "\n",
        "        Args:\n",
        "            response: 原始LLM回應\n",
        "            model_type: 模型類型（用於特定清理規則）\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的回應\n",
        "\n",
        "        Raises:\n",
        "            ResponseProcessingError: 當回應處理失敗時\n",
        "        \"\"\"\n",
        "        if not response:\n",
        "            raise ResponseProcessingError(\"Empty response provided for cleaning\")\n",
        "\n",
        "        try:\n",
        "            self.logger.debug(f\"Starting response cleaning (original length: {len(response)})\")\n",
        "\n",
        "            # 保存原始回應作為備份\n",
        "            original_response = response\n",
        "\n",
        "            # 根據模型類型選擇清理策略\n",
        "            if \"llama\" in model_type.lower():\n",
        "                cleaned_response = self._clean_llama_response(response)\n",
        "            else:\n",
        "                cleaned_response = self._clean_general_response(response)\n",
        "\n",
        "            # 如果清理後內容過短，嘗試從原始回應中恢復\n",
        "            if len(cleaned_response.strip()) < 40:\n",
        "                self.logger.warning(\"Cleaned response too short, attempting recovery\")\n",
        "                cleaned_response = self._recover_from_overcleaning(original_response)\n",
        "\n",
        "            # 最終驗證\n",
        "            self._validate_cleaned_response(cleaned_response)\n",
        "\n",
        "            self.logger.debug(f\"Response cleaning completed (final length: {len(cleaned_response)})\")\n",
        "            return cleaned_response\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Response cleaning failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise ResponseProcessingError(error_msg) from e\n",
        "\n",
        "    def _clean_llama_response(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        專門處理Llama模型的回應清理\n",
        "\n",
        "        Args:\n",
        "            response: 原始Llama回應\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的回應\n",
        "        \"\"\"\n",
        "        # 首先應用通用清理\n",
        "        response = self._clean_general_response(response)\n",
        "\n",
        "        # Llama特有的前綴清理\n",
        "        llama_prefixes = [\n",
        "            \"Here's the enhanced description:\",\n",
        "            \"Enhanced description:\",\n",
        "            \"Here is the enhanced scene description:\",\n",
        "            \"I've enhanced the description while preserving all factual details:\"\n",
        "        ]\n",
        "\n",
        "        for prefix in llama_prefixes:\n",
        "            if response.lower().startswith(prefix.lower()):\n",
        "                response = response[len(prefix):].strip()\n",
        "\n",
        "        # Llama特有的後綴清理\n",
        "        llama_suffixes = [\n",
        "            \"I've maintained all the key factual elements\",\n",
        "            \"I've preserved all the factual details\",\n",
        "            \"All factual elements have been maintained\"\n",
        "        ]\n",
        "\n",
        "        for suffix in llama_suffixes:\n",
        "            if response.lower().endswith(suffix.lower()):\n",
        "                response = response[:response.rfind(suffix)].strip()\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _clean_general_response(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        通用回應清理方法\n",
        "\n",
        "        Args:\n",
        "            response: 原始回應\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的回應\n",
        "        \"\"\"\n",
        "        response = self._critical_format_preprocess(response)\n",
        "\n",
        "        # 1. 移除系統remark\n",
        "        response = self._remove_system_markers(response)\n",
        "\n",
        "        # 2. 移除介紹性prefix\n",
        "        response = self._remove_introduction_prefixes(response)\n",
        "\n",
        "        # 3. 移除格式標記和上下文標籤\n",
        "        response = self._remove_format_markers(response)\n",
        "\n",
        "        # 4. 清理場景類型引用\n",
        "        response = self._clean_scene_type_references(response)\n",
        "\n",
        "        # 5. 標準化標點符號\n",
        "        response = self._normalize_punctuation(response)\n",
        "\n",
        "        # 6. 移除重複句子\n",
        "        response = self._remove_duplicate_sentences(response)\n",
        "\n",
        "        # 7. 處理重複詞彙\n",
        "        response = self._handle_repetitive_vocabulary(response)\n",
        "\n",
        "        # 8. ensure completement\n",
        "        response = self._ensure_grammatical_completeness(response)\n",
        "\n",
        "        # 9. 控制字數長度\n",
        "        response = self._control_word_length(response)\n",
        "\n",
        "        # 10. 最終格式化\n",
        "        response = self._final_formatting(response)\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def _critical_format_preprocess(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        關鍵格式預處理，處理最常見的格式問題\n",
        "\n",
        "        Args:\n",
        "            response: 原始回應\n",
        "\n",
        "        Returns:\n",
        "            str: 預處理後的回應\n",
        "        \"\"\"\n",
        "        if not response:\n",
        "            return response\n",
        "\n",
        "        try:\n",
        "            import re\n",
        "\n",
        "            # 第一優先級：處理斜線問題\n",
        "            # 首先處理已知的斜線組合，使用形容詞替換\n",
        "            for slash_combo, replacement in self.slash_replacements.items():\n",
        "                if slash_combo.lower() in response.lower():\n",
        "                    # 保持原始大小寫格式\n",
        "                    if slash_combo.upper() in response:\n",
        "                        replacement_formatted = replacement.upper()\n",
        "                    elif slash_combo.title() in response:\n",
        "                        replacement_formatted = replacement.title()\n",
        "                    else:\n",
        "                        replacement_formatted = replacement\n",
        "\n",
        "                    # 執行替換（不區分大小寫）\n",
        "                    response = re.sub(re.escape(slash_combo), replacement_formatted, response, flags=re.IGNORECASE)\n",
        "                    self.logger.debug(f\"Replaced slash pattern '{slash_combo}' with '{replacement_formatted}'\")\n",
        "\n",
        "            # 處理其他未預定義的斜線模式\n",
        "            # 標準斜線模式：word/word\n",
        "            slash_pattern = r'\\b([a-zA-Z]+)/([a-zA-Z]+)\\b'\n",
        "            matches = list(re.finditer(slash_pattern, response))\n",
        "            for match in reversed(matches):  # 從後往前處理避免位置偏移\n",
        "                word1, word2 = match.groups()\n",
        "                # 選擇較短或更常見的詞作為替換\n",
        "                if len(word1) <= len(word2):\n",
        "                    replacement = word1\n",
        "                else:\n",
        "                    replacement = word2\n",
        "                response = response[:match.start()] + replacement + response[match.end():]\n",
        "                self.logger.debug(f\"Replaced general slash pattern '{match.group(0)}' with '{replacement}'\")\n",
        "\n",
        "            # 第二優先級：處理底線格式\n",
        "            # 首先處理已知的底線組合\n",
        "            for underscore_combo, replacement in self.underscore_replacements.items():\n",
        "                if underscore_combo in response:\n",
        "                    response = response.replace(underscore_combo, replacement)\n",
        "                    self.logger.debug(f\"Replaced underscore pattern '{underscore_combo}' with '{replacement}'\")\n",
        "\n",
        "            # 處理三個詞的底線組合：word_word_word → word word word\n",
        "            response = re.sub(r'\\b([a-z]+)_([a-z]+)_([a-z]+)\\b', r'\\1 \\2 \\3', response)\n",
        "\n",
        "            # 處理任何剩餘的底線模式：word_word → word word\n",
        "            response = re.sub(r'\\b([a-zA-Z]+)_([a-zA-Z]+)\\b', r'\\1 \\2', response)\n",
        "\n",
        "            # 第三優先級：修正不完整句子\n",
        "            incomplete_sentence_fixes = [\n",
        "                (r'\\bIn\\s*,\\s*', 'Throughout the area, '),\n",
        "                (r'\\bOverall,\\s+exudes\\b', 'Overall, the scene exudes'),\n",
        "                (r'\\bThe overall atmosphere of\\s+is\\b', 'The overall atmosphere'),\n",
        "                (r'\\bwith its lights turned illuminating\\b', 'with its lights illuminating'),\n",
        "                (r'\\bwhere it stands as\\b', 'where it stands as'),\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in incomplete_sentence_fixes:\n",
        "                response = re.sub(pattern, replacement, response, flags=re.IGNORECASE)\n",
        "\n",
        "            # 第四優先級：語法修正處理(像是person and people)\n",
        "            grammar_fixes = [\n",
        "                (r'\\b(\\d+)\\s+persons\\b', r'\\1 people'),\n",
        "                (r'\\bone\\s+persons\\b', 'one person'),\n",
        "                (r'\\btwo\\s+persons\\b', 'two people'),\n",
        "                (r'\\bthree\\s+persons\\b', 'three people'),\n",
        "                (r'\\bfour\\s+persons\\b', 'four people'),\n",
        "                (r'\\bfive\\s+persons\\b', 'five people'),\n",
        "                (r'\\bsix\\s+persons\\b', 'six people'),\n",
        "                (r'\\bseven\\s+persons\\b', 'seven people'),\n",
        "                (r'\\beight\\s+persons\\b', 'eight people'),\n",
        "                (r'\\bnine\\s+persons\\b', 'nine people'),\n",
        "                (r'\\bten\\s+persons\\b', 'ten people'),\n",
        "                (r'\\bmultiple\\s+persons\\b', 'multiple people'),\n",
        "                (r'\\bseveral\\s+persons\\b', 'several people'),\n",
        "                (r'\\bmany\\s+persons\\b', 'many people'),\n",
        "                (r'\\ba\\s+few\\s+persons\\b', 'a few people'),\n",
        "                (r'\\bsome\\s+persons\\b', 'some people')\n",
        "            ]\n",
        "\n",
        "            for pattern, replacement in grammar_fixes:\n",
        "                response = re.sub(pattern, replacement, response, flags=re.IGNORECASE)\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error in critical format preprocessing: {str(e)}\")\n",
        "            return response\n",
        "\n",
        "    def _remove_system_markers(self, response: str) -> str:\n",
        "        \"\"\"移除系統樣式標記\"\"\"\n",
        "        # 移除對話remark\n",
        "        response = re.sub(r'<\\|.*?\\|>', '', response)\n",
        "\n",
        "        # 移除輸出remark\n",
        "        output_start = response.find(\"[OUTPUT_START]\")\n",
        "        output_end = response.find(\"[OUTPUT_END]\")\n",
        "        if output_start != -1 and output_end != -1 and output_end > output_start:\n",
        "            response = response[output_start + len(\"[OUTPUT_START]\"):output_end].strip()\n",
        "\n",
        "        # 移除其他remark\n",
        "        section_markers = [\n",
        "            r'\\[.*?\\]',\n",
        "            r'OUTPUT_START\\s*:|OUTPUT_END\\s*:',\n",
        "            r'ENHANCED DESCRIPTION\\s*:',\n",
        "            r'Scene Type\\s*:.*?(?=\\n|$)',\n",
        "            r'Original Description\\s*:.*?(?=\\n|$)',\n",
        "            r'GOOD\\s*:|BAD\\s*:',\n",
        "            r'PROBLEM\\s*:.*?(?=\\n|$)',\n",
        "            r'</?\\|(?:assistant|system|user)\\|>',\n",
        "            r'\\(Note:.*?\\)',\n",
        "            r'\\(.*?I\\'ve.*?\\)',\n",
        "            r'\\(.*?as per your request.*?\\)'\n",
        "        ]\n",
        "\n",
        "        for marker in section_markers:\n",
        "            response = re.sub(marker, '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _remove_introduction_prefixes(self, response: str) -> str:\n",
        "        \"\"\"移除介紹性前綴\"\"\"\n",
        "        # 處理 \"Here is...\" 類型的prefix\n",
        "        intro_prefixes = [\n",
        "            r'^Here\\s+is\\s+(?:a\\s+|the\\s+)?(?:rewritten\\s+|enhanced\\s+)?scene\\s+description.*?:\\s*',\n",
        "            r'^The\\s+(?:rewritten\\s+|enhanced\\s+)?(?:scene\\s+)?description\\s+is.*?:\\s*',\n",
        "            r'^Here\\'s\\s+(?:a\\s+|the\\s+)?(?:rewritten\\s+|enhanced\\s+)?description.*?:\\s*'\n",
        "        ]\n",
        "\n",
        "        for prefix_pattern in intro_prefixes:\n",
        "            response = re.sub(prefix_pattern, '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        # 處理固定prefix\n",
        "        for prefix in self.prefixes_to_remove:\n",
        "            if response.lower().startswith(prefix.lower()):\n",
        "                response = response[len(prefix):].strip()\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _remove_format_markers(self, response: str) -> str:\n",
        "        \"\"\"移除格式標記和上下文標籤（保留括號內的地理與細節資訊）\"\"\"\n",
        "        # 移除上下文相關remark\n",
        "        response = re.sub(r'<\\s*Context:.*?>', '', response)\n",
        "        response = re.sub(r'Context:.*?(?=\\n|$)', '', response)\n",
        "        response = re.sub(r'Note:.*?(?=\\n|$)', '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        # 移除Markdown格式\n",
        "        response = re.sub(r'\\*\\*|\\*|__|\\|', '', response)\n",
        "\n",
        "        # 移除任何剩餘的特殊標記 (避開括號內容，以免剔除地理位置等有用資訊)\n",
        "        response = re.sub(r'</?\\|.*?\\|>', '', response)\n",
        "        # ※ 以下移除「刪除整個括號及其內文」的方式已註解，以保留地理位置資訊\n",
        "        # response = re.sub(r'\\(.*?\\)', '', response)\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def _clean_scene_type_references(self, response: str) -> str:\n",
        "        \"\"\"清理不當的場景類型引用\"\"\"\n",
        "        scene_type_pattern = r'This ([a-zA-Z_]+) (features|shows|displays|contains)'\n",
        "        match = re.search(scene_type_pattern, response)\n",
        "        if match and '_' in match.group(1):\n",
        "            fixed_text = f\"This scene {match.group(2)}\"\n",
        "            response = re.sub(scene_type_pattern, fixed_text, response)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _normalize_punctuation(self, response: str) -> str:\n",
        "        \"\"\"標準化標點符號\"\"\"\n",
        "        # 減少破折號使用\n",
        "        response = re.sub(r'—', ', ', response)\n",
        "        response = re.sub(r' - ', ', ', response)\n",
        "\n",
        "        # 處理連續標點符號\n",
        "        response = re.sub(r'([.,;:!?])\\1+', r'\\1', response)\n",
        "\n",
        "        # 修復不完整句子的標點\n",
        "        response = re.sub(r',\\s*$', '.', response)\n",
        "\n",
        "        # 修復句號後缺少空格的問題\n",
        "        response = re.sub(r'([.!?])([A-Z])', r'\\1 \\2', response)\n",
        "\n",
        "        # 清理多餘空格和換行\n",
        "        response = response.replace('\\r', ' ')\n",
        "        response = re.sub(r'\\n+', ' ', response)\n",
        "        response = re.sub(r'\\s{2,}', ' ', response)\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def _remove_duplicate_sentences(self, response: str, similarity_threshold: float = 0.85) -> str:\n",
        "        \"\"\"\n",
        "        移除重複或高度相似的句子，使用 Jaccard 相似度進行比較。\n",
        "        Args:\n",
        "            response: 原始回應文本。\n",
        "            similarity_threshold: 認定句子重複的相似度閾值 (0.0 到 1.0)。\n",
        "                                  較高的閾值表示句子需要非常相似才會被移除。\n",
        "        Returns:\n",
        "            str: 移除重複句子後的文本。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not response or not response.strip():\n",
        "                return \"\"\n",
        "\n",
        "            # (?<=[.!?]) 會保留分隔符在句尾, \\s+ 會消耗句尾的空格\n",
        "            # 這樣用 ' ' join 回去時, 標點和下個句子間剛好一個空格\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', response.strip())\n",
        "\n",
        "            unique_sentences_data = [] # Store tuples of (original_sentence, simplified_word_set)\n",
        "\n",
        "            min_sentence_len_for_check = 8 # 簡化後詞彙數少於此值，除非完全相同否則不輕易判斷為重複\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence = sentence.strip()\n",
        "                if not sentence:\n",
        "                    continue\n",
        "\n",
        "                # 創建簡化版本用於比較 (小寫，移除標點，分割為詞彙集合)\n",
        "                # 保留數字，因為數字可能是關鍵資訊\n",
        "                simplified_text = re.sub(r'[^\\w\\s\\d]', '', sentence.lower())\n",
        "                current_sentence_words = set(simplified_text.split())\n",
        "\n",
        "                if not current_sentence_words: # 如果處理後是空集合，跳過\n",
        "                    continue\n",
        "\n",
        "                is_duplicate = False\n",
        "                # 與已保留的唯一句子比較\n",
        "                for i, (kept_sentence_text, kept_sentence_words) in enumerate(unique_sentences_data):\n",
        "                    # Jaccard Index\n",
        "                    intersection_len = len(current_sentence_words.intersection(kept_sentence_words))\n",
        "                    union_len = len(current_sentence_words.union(kept_sentence_words))\n",
        "\n",
        "                    if union_len == 0: # 兩個都是空集合，代表相同句子\n",
        "                        jaccard_similarity = 1.0\n",
        "                    else:\n",
        "                        jaccard_similarity = intersection_len / union_len\n",
        "\n",
        "                    # 用Jaccard 相似度超過閾值，不是兩個都非常短的句子 (避免 \"Yes.\" 和 \"No.\" 被錯誤合併)\n",
        "                    # 新句子完全被舊句子包含 (且舊句子更長)\n",
        "                    # 舊句子完全被新句子包含 (且新句子更長) -> 這種情況就需要替換\n",
        "                    if jaccard_similarity >= similarity_threshold:\n",
        "                        # 如果當前句子比已保留的句子短，且高度相似，則認為是重複\n",
        "                        if len(current_sentence_words) < len(kept_sentence_words):\n",
        "                            is_duplicate = True\n",
        "                            self.logger.debug(f\"Sentence \\\"{sentence[:30]}...\\\" marked duplicate (shorter, similar to \\\"{kept_sentence_text[:30]}...\\\") Jaccard: {jaccard_similarity:.2f}\")\n",
        "                            break\n",
        "                        # 如果當前句子比已保留的句子長，且高度相似，則替換掉已保留的\n",
        "                        elif len(current_sentence_words) > len(kept_sentence_words):\n",
        "                            self.logger.debug(f\"Sentence \\\"{kept_sentence_text[:30]}...\\\" replaced by longer similar sentence \\\"{sentence[:30]}...\\\" Jaccard: {jaccard_similarity:.2f}\")\n",
        "                            unique_sentences_data.pop(i) # 移除舊的、較短的句子\n",
        "\n",
        "                        # 如果長度差不多，但相似度高，保留第一個出現的\n",
        "                        elif current_sentence_words != kept_sentence_words : # 避免完全相同的句子被錯誤地跳過替換邏輯\n",
        "                             is_duplicate = True # 保留先出現的\n",
        "                             self.logger.debug(f\"Sentence \\\"{sentence[:30]}...\\\" marked duplicate (similar length, similar to \\\"{kept_sentence_text[:30]}...\\\") Jaccard: {jaccard_similarity:.2f}\")\n",
        "                             break\n",
        "\n",
        "                if not is_duplicate:\n",
        "                    unique_sentences_data.append((sentence, current_sentence_words))\n",
        "\n",
        "            # 重組唯一句子\n",
        "            final_sentences = [s_data[0] for s_data in unique_sentences_data]\n",
        "\n",
        "            # 確保每個句子以標點結尾 (因為 split 可能會產生沒有標點的最後一個片段)\n",
        "            reconstructed_response = \"\"\n",
        "            for i, s in enumerate(final_sentences):\n",
        "                s = s.strip()\n",
        "                if not s: continue\n",
        "                if not s[-1] in \".!?\":\n",
        "                    s += \".\"\n",
        "                reconstructed_response += s\n",
        "                if i < len(final_sentences) - 1:\n",
        "                     reconstructed_response += \" \" # 在句子間添加空格\n",
        "\n",
        "            return reconstructed_response.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in _remove_duplicate_sentences: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return response # 發生錯誤時返回原始回應\n",
        "\n",
        "    def _handle_repetitive_vocabulary(self, response: str) -> str:\n",
        "        \"\"\"處理重複詞彙，使用 re.sub 和可呼叫的替換函數以提高效率和準確性。\"\"\"\n",
        "        try:\n",
        "            # 檢測重複模式 (僅警告)\n",
        "            if hasattr(self, 'repetitive_patterns'):\n",
        "                for pattern, issue in self.repetitive_patterns:\n",
        "                    if re.search(pattern, response, re.IGNORECASE | re.DOTALL):\n",
        "                        self.logger.warning(f\"Text quality issue detected: {issue} in response: \\\"{response[:100]}...\\\"\")\n",
        "\n",
        "            if not hasattr(self, 'replacement_alternatives') or not self.replacement_alternatives:\n",
        "                return response\n",
        "\n",
        "            processed_response = response\n",
        "\n",
        "            for word_to_replace, alternatives in self.replacement_alternatives.items():\n",
        "                if not alternatives:  # 如果沒有可用的替代詞，則跳過\n",
        "                    continue\n",
        "\n",
        "                # 為每個詞創建一個獨立的計數器和替代索引\n",
        "                # 使用閉包或一個小類來封裝狀態\n",
        "                class WordReplacer:\n",
        "                    def __init__(self, alternatives_list):\n",
        "                        self.count = 0\n",
        "                        self.alternative_idx = 0\n",
        "                        self.alternatives_list = alternatives_list\n",
        "\n",
        "                    def __call__(self, match_obj):\n",
        "                        self.count += 1\n",
        "                        original_word = match_obj.group(0)\n",
        "                        if self.count > 1:  # 從第二次出現開始替換\n",
        "                            replacement = self.alternatives_list[self.alternative_idx % len(self.alternatives_list)]\n",
        "                            self.alternative_idx += 1\n",
        "                            # 保持原始大小寫格式\n",
        "                            if original_word.isupper():\n",
        "                                return replacement.upper()\n",
        "                            elif original_word.istitle():\n",
        "                                return replacement.capitalize()\n",
        "                            return replacement\n",
        "                        return original_word # 因為第一次出現, 就不用替換\n",
        "\n",
        "                replacer_instance = WordReplacer(alternatives)\n",
        "                # 使用 \\b 確保匹配的是整個單詞\n",
        "                pattern = re.compile(r'\\b' + re.escape(word_to_replace) + r'\\b', re.IGNORECASE)\n",
        "                processed_response = pattern.sub(replacer_instance, processed_response)\n",
        "\n",
        "            return processed_response\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in _handle_repetitive_vocabulary: {str(e)}\")\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return response # 發生錯誤時返回原始回應\n",
        "\n",
        "    def _ensure_grammatical_completeness(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        確保語法完整性，處理不完整句子和格式問題\n",
        "\n",
        "        Args:\n",
        "            response: 待檢查的回應文本\n",
        "\n",
        "        Returns:\n",
        "            str: 語法完整的回應文本\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not response or not response.strip():\n",
        "                return response\n",
        "\n",
        "            # 第一階段：檢查並修正不完整的句子模式\n",
        "            incomplete_patterns = [\n",
        "                # 介詞後直接結束的問題（針對 \"over .\" 等情況）\n",
        "                (r'\\b(over|under|through|across|along|beneath|beyond|throughout)\\s*\\.', 'incomplete_preposition'),\n",
        "                (r'\\b(with|without|against|towards|beside|between|among)\\s*\\.', 'incomplete_preposition'),\n",
        "                (r'\\b(into|onto|upon|within|behind|below|above)\\s*\\.', 'incomplete_preposition'),\n",
        "\n",
        "                # 處理 \"In ,\" 這類缺失詞彙的問題\n",
        "                (r'\\bIn\\s*,', 'incomplete_location'),\n",
        "                (r'\\bAt\\s*,', 'incomplete_location'),\n",
        "                (r'\\bOn\\s*,', 'incomplete_location'),\n",
        "                (r'\\bWith\\s*,', 'incomplete_context'),\n",
        "\n",
        "                # 不完整的描述模式\n",
        "                (r'\\b(fine|the)\\s+(the\\s+)?(?:urban|area|scene)\\b(?!\\s+\\w)', 'incomplete_description'),\n",
        "\n",
        "                # 連詞或介詞後直接標點的問題\n",
        "                (r'\\b(and|or|but|with|from|in|at|on|by|for|to)\\s*[.!?]', 'incomplete_conjunction'),\n",
        "\n",
        "                # 重複詞彙\n",
        "                (r'\\b(\\w+)\\s+\\1\\b', 'word_repetition'),\n",
        "\n",
        "                # 不完整的場景類型引用（如 \"urban_intersection\" 格式問題）\n",
        "                (r'\\b(\\w+)_(\\w+)\\b', 'underscore_format'),\n",
        "\n",
        "                # 地標場景特有問題\n",
        "                (r'\\btourist_landmark\\b', 'underscore_format'),\n",
        "                (r'\\burban_intersection\\b', 'underscore_format'),\n",
        "                (r'\\bIn\\s*,\\s*(?=\\w)', 'incomplete_prepositional'),\n",
        "                (r'\\bOverall,\\s+(?=exudes|shows|displays)(?!\\s+(?:the|this|it))', 'missing_subject'),\n",
        "                (r'\\batmosphere of\\s+is one of\\b', 'redundant_structure'),\n",
        "                (r'\\bwith.*?turned\\s+illuminating\\b', 'redundant_participle')\n",
        "            ]\n",
        "\n",
        "            for pattern, issue_type in incomplete_patterns:\n",
        "                try:\n",
        "                    matches = list(re.finditer(pattern, response, re.IGNORECASE))\n",
        "\n",
        "                    for match in matches:\n",
        "                        if issue_type == 'incomplete_preposition':\n",
        "                            # 處理介詞後直接結束的情況\n",
        "                            response = self._fix_incomplete_preposition(response, match)\n",
        "\n",
        "                        elif issue_type == 'underscore_format':\n",
        "                            # 將下劃線格式轉換為空格分隔\n",
        "                            original = match.group(0)\n",
        "                            replacement = original.replace('_', ' ')\n",
        "                            response = response.replace(original, replacement)\n",
        "\n",
        "                        elif issue_type == 'word_repetition':\n",
        "                            # 移除重複的詞彙\n",
        "                            repeated_word = match.group(1)\n",
        "                            response = response.replace(f\"{repeated_word} {repeated_word}\", repeated_word)\n",
        "\n",
        "                        elif issue_type == 'incomplete_location' or issue_type == 'incomplete_context':\n",
        "                            # 移除不完整的位置或上下文引用\n",
        "                            response = response.replace(match.group(0), '')\n",
        "\n",
        "                        elif issue_type == 'incomplete_prepositional':\n",
        "                            # 處理不完整的介詞短語\n",
        "                            response = re.sub(r'\\bIn\\s*,\\s*', 'Throughout the scene, ', response)\n",
        "\n",
        "                        elif issue_type == 'missing_subject':\n",
        "                            # 為Overall句子添加主語\n",
        "                            response = re.sub(r'\\bOverall,\\s+(?=exudes)', 'Overall, the scene ', response)\n",
        "\n",
        "                        elif issue_type == 'redundant_structure':\n",
        "                            # 簡化冗餘結構\n",
        "                            response = re.sub(r'\\batmosphere of\\s+is one of\\b', 'atmosphere is one of', response)\n",
        "\n",
        "                        elif issue_type == 'redundant_participle':\n",
        "                            # 清理冗餘分詞\n",
        "                            response = re.sub(r'turned\\s+illuminating', 'illuminating', response)\n",
        "\n",
        "                        else:\n",
        "                            # 對於其他不完整模式，直接移除\n",
        "                            response = response.replace(match.group(0), '')\n",
        "\n",
        "                    # 清理多餘空格\n",
        "                    response = re.sub(r'\\s{2,}', ' ', response).strip()\n",
        "\n",
        "                except re.error as e:\n",
        "                    self.logger.warning(f\"Regular expression pattern error for {issue_type}: {pattern} - {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # 第二階段：處理物件類別格式問題\n",
        "            response = self._clean_object_class_references(response)\n",
        "\n",
        "            # 第三階段：確保句子正確結束\n",
        "            response = self._ensure_proper_sentence_ending(response)\n",
        "\n",
        "            # 第四階段：最終語法檢查\n",
        "            response = self._final_grammar_check(response)\n",
        "\n",
        "            return response.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in _ensure_grammatical_completeness: {str(e)}\")\n",
        "            return response\n",
        "\n",
        "    def _fix_incomplete_preposition(self, response: str, match) -> str:\n",
        "        \"\"\"\n",
        "        修正不完整的介詞短語\n",
        "\n",
        "        Args:\n",
        "            response: 回應文本\n",
        "            match: 正則匹配對象\n",
        "\n",
        "        Returns:\n",
        "            str: 修正後的回應\n",
        "        \"\"\"\n",
        "        preposition = match.group(1)\n",
        "        match_start = match.start()\n",
        "\n",
        "        # 找到句子的開始位置\n",
        "        sentence_start = response.rfind('.', 0, match_start)\n",
        "        sentence_start = sentence_start + 1 if sentence_start != -1 else 0\n",
        "\n",
        "        # 提取句子片段\n",
        "        sentence_fragment = response[sentence_start:match_start].strip()\n",
        "\n",
        "        # 如果句子片段有意義，嘗試移除不完整的介詞部分\n",
        "        if len(sentence_fragment) > 10:\n",
        "            # 移除介詞及其後的內容，添加適當的句號\n",
        "            response = response[:match_start].rstrip() + '.'\n",
        "        else:\n",
        "            # 如果句子片段太短，移除整個不完整的句子\n",
        "            response = response[:sentence_start] + response[match.end():]\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _clean_object_class_references(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        清理物件類別引用中的格式問題\n",
        "\n",
        "        Args:\n",
        "            response: 回應文本\n",
        "\n",
        "        Returns:\n",
        "            str: 清理後的回應\n",
        "        \"\"\"\n",
        "        # 移除類別ID引用（如 \"unknown-class 2\", \"Class 0\" 等）\n",
        "        class_id_patterns = [\n",
        "            r'\\bunknown[- ]?class\\s*\\d+\\s*objects?',\n",
        "            r'\\bclass[- ]?\\d+\\s*objects?',\n",
        "            r'\\b[Cc]lass\\s*\\d+\\s*objects?',\n",
        "            r'\\bunknown[- ][Cc]lass\\s*\\d+\\s*objects?'\n",
        "        ]\n",
        "\n",
        "        for pattern in class_id_patterns:\n",
        "            try:\n",
        "                # 替換為更自然的描述\n",
        "                response = re.sub(pattern, 'objects', response, flags=re.IGNORECASE)\n",
        "            except re.error as e:\n",
        "                self.logger.warning(f\"Error cleaning class reference pattern {pattern}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        # 處理數量描述中的問題\n",
        "        response = re.sub(r'\\b(\\w+)\\s+unknown[- ]?\\w*\\s*objects?', r'\\1 objects', response, flags=re.IGNORECASE)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _ensure_proper_sentence_ending(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        確保句子有適當的結尾\n",
        "\n",
        "        Args:\n",
        "            response: 回應文本\n",
        "\n",
        "        Returns:\n",
        "            str: 具有適當結尾的回應\n",
        "        \"\"\"\n",
        "        if not response or not response.strip():\n",
        "            return response\n",
        "\n",
        "        response = response.strip()\n",
        "\n",
        "        # 檢查是否以標點符號結尾\n",
        "        if response and response[-1] not in ['.', '!', '?']:\n",
        "\n",
        "            # 常見介詞和連詞列表\n",
        "            problematic_endings = [\n",
        "                \"into\", \"onto\", \"about\", \"above\", \"across\", \"after\", \"along\", \"around\",\n",
        "                \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"between\",\n",
        "                \"beyond\", \"by\", \"down\", \"during\", \"except\", \"for\", \"from\", \"in\",\n",
        "                \"inside\", \"near\", \"of\", \"off\", \"on\", \"over\", \"through\", \"to\",\n",
        "                \"toward\", \"under\", \"up\", \"upon\", \"with\", \"within\", \"and\", \"or\", \"but\"\n",
        "            ]\n",
        "\n",
        "            words = response.split()\n",
        "            if words:\n",
        "                last_word = words[-1].lower().rstrip('.,!?')\n",
        "\n",
        "                if last_word in problematic_endings:\n",
        "                    # 找到最後完整的句子\n",
        "                    last_period_pos = max(\n",
        "                        response.rfind('.'),\n",
        "                        response.rfind('!'),\n",
        "                        response.rfind('?')\n",
        "                    )\n",
        "\n",
        "                    if last_period_pos > len(response) // 2:  # 如果有較近的完整句子\n",
        "                        response = response[:last_period_pos + 1]\n",
        "                    else:\n",
        "                        # 移除問題詞彙並添加句號\n",
        "                        if len(words) > 1:\n",
        "                            response = \" \".join(words[:-1]) + \".\"\n",
        "                        else:\n",
        "                            response = \"The scene displays various elements.\"\n",
        "                else:\n",
        "                    # 正常情況下添加句號\n",
        "                    response += \".\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _final_grammar_check(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        最終語法檢查和清理\n",
        "\n",
        "        Args:\n",
        "            response: 回應文本\n",
        "\n",
        "        Returns:\n",
        "            str: 最終清理後的回應\n",
        "        \"\"\"\n",
        "        if not response:\n",
        "            return response\n",
        "\n",
        "        # 修正連續標點符號\n",
        "        response = re.sub(r'([.!?]){2,}', r'\\1', response)\n",
        "\n",
        "        # 修正句號前的空格\n",
        "        response = re.sub(r'\\s+([.!?])', r'\\1', response)\n",
        "\n",
        "        # 修正句號後缺少空格的問題\n",
        "        response = re.sub(r'([.!?])([A-Z])', r'\\1 \\2', response)\n",
        "\n",
        "        # 確保首字母大寫\n",
        "        if response and response[0].islower():\n",
        "            response = response[0].upper() + response[1:]\n",
        "\n",
        "        # 移除多餘的空格\n",
        "        response = re.sub(r'\\s{2,}', ' ', response)\n",
        "\n",
        "        # 處理空句子或過短的回應\n",
        "        if len(response.strip()) < 20:\n",
        "            return \"The scene contains various visual elements.\"\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "    def _control_word_length(self, response: str) -> str:\n",
        "        \"\"\"控制文字長度在合理範圍內\"\"\"\n",
        "        words = response.split()\n",
        "        if len(words) > 200:\n",
        "            # 找到接近字數限制的句子結束處\n",
        "            truncated = ' '.join(words[:200])\n",
        "            last_period = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('?'))\n",
        "\n",
        "            if last_period > 0:\n",
        "                response = truncated[:last_period+1]\n",
        "            else:\n",
        "                response = truncated + \".\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _final_formatting(self, response: str) -> str:\n",
        "        \"\"\"最終格式化處理\"\"\"\n",
        "        # 確保首字母大寫\n",
        "        if response and response[0].islower():\n",
        "            response = response[0].upper() + response[1:]\n",
        "\n",
        "        # 統一格式為單一段落\n",
        "        response = re.sub(r'\\s*\\n\\s*', ' ', response)\n",
        "        response = ' '.join(response.split())\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "    def _recover_from_overcleaning(self, original_response: str) -> str:\n",
        "        \"\"\"從過度清理中恢復內容\"\"\"\n",
        "        try:\n",
        "            # 嘗試從原始回應中找到最佳段落\n",
        "            paragraphs = [p for p in original_response.split('\\n\\n') if p.strip()]\n",
        "            if paragraphs:\n",
        "                # 選擇最長的段落作為主要描述\n",
        "                best_para = max(paragraphs, key=len)\n",
        "                # 使用基本清理規則\n",
        "                best_para = re.sub(r'\\[.*?\\]', '', best_para)\n",
        "                best_para = re.sub(r'\\s{2,}', ' ', best_para).strip()\n",
        "\n",
        "                if len(best_para) >= 40:\n",
        "                    return best_para\n",
        "\n",
        "            return \"Unable to generate a valid enhanced description.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Recovery from overcleaning failed: {str(e)}\")\n",
        "            return \"Description generation error.\"\n",
        "\n",
        "    def _validate_cleaned_response(self, response: str):\n",
        "        \"\"\"驗證清理後的回應\"\"\"\n",
        "        if not response:\n",
        "            raise ResponseProcessingError(\"Response is empty after cleaning\")\n",
        "\n",
        "        if len(response.strip()) < 20:\n",
        "            raise ResponseProcessingError(\"Response is too short after cleaning\")\n",
        "\n",
        "        # 檢查是否包含基本的句子結構\n",
        "        if not re.search(r'[.!?]', response):\n",
        "            raise ResponseProcessingError(\"Response lacks proper sentence structure\")\n",
        "\n",
        "    def remove_explanatory_notes(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        移除解釋性注釋和說明\n",
        "\n",
        "        Args:\n",
        "            response: 包含可能注釋的回應\n",
        "\n",
        "        Returns:\n",
        "            str: 移除注釋後的回應\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 識別常見的注釋和解釋模式\n",
        "            note_patterns = [\n",
        "                r'(?:^|\\n)Note:.*?(?:\\n|$)',\n",
        "                r'(?:^|\\n)I have (?:followed|adhered to|ensured).*?(?:\\n|$)',\n",
        "                r'(?:^|\\n)This description (?:follows|adheres to|maintains).*?(?:\\n|$)',\n",
        "                r'(?:^|\\n)The enhanced description (?:maintains|preserves).*?(?:\\n|$)'\n",
        "            ]\n",
        "\n",
        "            # 尋找段落\n",
        "            paragraphs = [p.strip() for p in response.split('\\n\\n') if p.strip()]\n",
        "\n",
        "            # 如果只有一個段落，檢查並清理它\n",
        "            if len(paragraphs) == 1:\n",
        "                for pattern in note_patterns:\n",
        "                    paragraphs[0] = re.sub(pattern, '', paragraphs[0], flags=re.IGNORECASE)\n",
        "                return paragraphs[0].strip()\n",
        "\n",
        "            # 如果有多個段落，移除注釋段落\n",
        "            content_paragraphs = []\n",
        "            for paragraph in paragraphs:\n",
        "                is_note = False\n",
        "                for pattern in note_patterns:\n",
        "                    if re.search(pattern, paragraph, flags=re.IGNORECASE):\n",
        "                        is_note = True\n",
        "                        break\n",
        "\n",
        "                # 檢查段落是否以常見的注釋詞開頭\n",
        "                if paragraph.lower().startswith(('note:', 'please note:', 'remember:')):\n",
        "                    is_note = True\n",
        "\n",
        "                if not is_note:\n",
        "                    content_paragraphs.append(paragraph)\n",
        "\n",
        "            return '\\n\\n'.join(content_paragraphs).strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to remove explanatory notes: {str(e)}\")\n",
        "            return response\n",
        "\n",
        "    def get_processor_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取處理器信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 包含處理器狀態和配置的信息\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"replacement_alternatives_count\": len(self.replacement_alternatives),\n",
        "            \"prefixes_to_remove_count\": len(self.prefixes_to_remove),\n",
        "            \"suffixes_to_remove_count\": len(self.suffixes_to_remove),\n",
        "            \"repetitive_patterns_count\": len(self.repetitive_patterns),\n",
        "            \"initialization_status\": \"success\"\n",
        "        }"
      ],
      "metadata": {
        "id": "eQ1RRbwGsX0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae704d52-7f32-44d7-e705-74ebb5efec7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing response_processor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile text_quality_validator.py\n",
        "import re\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional, Set, Tuple\n",
        "\n",
        "\n",
        "class TextQualityValidator:\n",
        "    \"\"\"\n",
        "    負責驗證和確保生成文本的品質和事實準確性。\n",
        "    包含事實檢查、視角一致性、場景類型一致性等驗證功能。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"初始化文本品質驗證器\"\"\"\n",
        "        # 設置專屬logger\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        # 初始化驗證規則\n",
        "        self._initialize_validation_rules()\n",
        "        self.logger.info(\"TextQualityValidator initialized successfully\")\n",
        "\n",
        "    def _initialize_validation_rules(self):\n",
        "        \"\"\"初始化各種驗證規則和詞彙庫\"\"\"\n",
        "        try:\n",
        "            # 地點和文化詞彙列表\n",
        "            self.location_terms = [\"plaza\", \"square\", \"market\", \"mall\", \"avenue\", \"boulevard\"]\n",
        "            self.cultural_terms = [\"european\", \"asian\", \"american\", \"african\", \"western\", \"eastern\"]\n",
        "\n",
        "            # 視角詞彙對應表\n",
        "            self.perspective_terms = {\n",
        "                \"aerial\": [\"aerial\", \"bird's-eye\", \"overhead\", \"top-down\", \"above\", \"looking down\"],\n",
        "                \"ground\": [\"street-level\", \"ground level\", \"eye-level\", \"standing\"],\n",
        "                \"indoor\": [\"inside\", \"interior\", \"indoor\", \"within\"],\n",
        "                \"close-up\": [\"close-up\", \"detailed view\", \"close shot\"]\n",
        "            }\n",
        "\n",
        "            # 視角前綴對應表\n",
        "            self.perspective_prefixes = {\n",
        "                \"aerial\": \"From an aerial perspective, \",\n",
        "                \"ground\": \"From street level, \",\n",
        "                \"indoor\": \"In this indoor setting, \",\n",
        "                \"close-up\": \"In this close-up view, \"\n",
        "            }\n",
        "\n",
        "            # 數值檢測模式\n",
        "            self.number_patterns = [\n",
        "                (r'(\\d+)\\s+(people|person|pedestrians|individuals)', r'\\1', r'\\2'),\n",
        "                (r'(\\d+)\\s+(cars|vehicles|automobiles)', r'\\1', r'\\2'),\n",
        "                (r'(\\d+)\\s+(buildings|structures)', r'\\1', r'\\2'),\n",
        "                (r'(\\d+)\\s+(plants|potted plants|flowers)', r'\\1', r'\\2'),\n",
        "                (r'(\\d+)\\s+(beds|furniture|tables|chairs)', r'\\1', r'\\2')\n",
        "            ]\n",
        "\n",
        "            # 禁用場景詞列表\n",
        "            self.prohibited_scene_words = [\"plaza\", \"square\", \"european\", \"asian\", \"american\"]\n",
        "\n",
        "            self.logger.info(\"Validation rules initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize validation rules: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise Exception(error_msg) from e\n",
        "\n",
        "    def verify_factual_accuracy(self,\n",
        "                               original_desc: str,\n",
        "                               generated_desc: str,\n",
        "                               object_list: str) -> str:\n",
        "        \"\"\"\n",
        "        驗證生成描述的事實準確性\n",
        "\n",
        "        Args:\n",
        "            original_desc: 原始場景描述\n",
        "            generated_desc: 生成的描述\n",
        "            object_list: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 驗證並可能修正後的描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Starting factual accuracy verification\")\n",
        "\n",
        "            # 將原始描述和物體列表合併為授權詞彙源\n",
        "            authorized_content = original_desc.lower() + \" \" + object_list.lower()\n",
        "\n",
        "            # 檢查和替換未授權的地點和文化詞彙\n",
        "            verified_desc = self._check_unauthorized_terms(generated_desc, authorized_content)\n",
        "\n",
        "            # 檢查重複用詞問題\n",
        "            verified_desc = self._detect_repetitive_patterns(verified_desc)\n",
        "\n",
        "            self.logger.debug(\"Factual accuracy verification completed\")\n",
        "            return verified_desc\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Factual accuracy verification failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return generated_desc  # 發生錯誤時返回原始生成描述\n",
        "\n",
        "    def _check_unauthorized_terms(self, generated_desc: str, authorized_content: str) -> str:\n",
        "        \"\"\"檢查並替換未授權的詞彙\"\"\"\n",
        "        # 檢查生成文本中的每個詞\n",
        "        for term in self.location_terms + self.cultural_terms:\n",
        "            # 僅當該詞出現在生成文本但不在授權內容中時進行替換\n",
        "            if term in generated_desc.lower() and term not in authorized_content:\n",
        "                # 根據詞語類型選擇適當的替換詞\n",
        "                if term in self.location_terms:\n",
        "                    replacement = \"area\"\n",
        "                else:\n",
        "                    replacement = \"scene\"\n",
        "\n",
        "                # 使用正則表達式進行完整詞匹配替換\n",
        "                pattern = re.compile(r'\\b' + term + r'\\b', re.IGNORECASE)\n",
        "                generated_desc = pattern.sub(replacement, generated_desc)\n",
        "\n",
        "        return generated_desc\n",
        "\n",
        "    def _detect_repetitive_patterns(self, generated_desc: str) -> str:\n",
        "        \"\"\"檢測並處理重複用詞問題\"\"\"\n",
        "        repetitive_patterns = [\n",
        "            (r'\\b(visible)\\b.*?\\b(visible)\\b', 'Multiple uses of \"visible\" detected'),\n",
        "            (r'\\b(positioned)\\b.*?\\b(positioned)\\b', 'Multiple uses of \"positioned\" detected'),\n",
        "            (r'\\b(located)\\b.*?\\b(located)\\b', 'Multiple uses of \"located\" detected'),\n",
        "            (r'\\b(situated)\\b.*?\\b(situated)\\b', 'Multiple uses of \"situated\" detected'),\n",
        "            (r'\\b(appears)\\b.*?\\b(appears)\\b', 'Multiple uses of \"appears\" detected'),\n",
        "            (r'\\b(features)\\b.*?\\b(features)\\b', 'Multiple uses of \"features\" detected'),\n",
        "            (r'\\bThis\\s+(\\w+)\\s+.*?\\bThis\\s+\\1\\b', 'Repetitive sentence structure detected')\n",
        "        ]\n",
        "\n",
        "        # 替換詞典\n",
        "        replacement_dict = {\n",
        "            'visible': ['present', 'evident', 'apparent', 'observable'],\n",
        "            'positioned': ['arranged', 'placed', 'set', 'organized'],\n",
        "            'located': ['found', 'placed', 'situated', 'established'],\n",
        "            'situated': ['placed', 'positioned', 'arranged', 'set'],\n",
        "            'appears': ['seems', 'looks', 'presents', 'exhibits'],\n",
        "            'features': ['includes', 'contains', 'displays', 'showcases']\n",
        "        }\n",
        "\n",
        "        for pattern, issue in repetitive_patterns:\n",
        "            matches = list(re.finditer(pattern, generated_desc, re.IGNORECASE | re.DOTALL))\n",
        "            if matches:\n",
        "                self.logger.warning(f\"Text quality issue detected: {issue}\")\n",
        "\n",
        "                # 針對特定重複詞彙進行替換\n",
        "                for word in replacement_dict.keys():\n",
        "                    if word in issue.lower():\n",
        "                        word_pattern = re.compile(r'\\b' + word + r'\\b', re.IGNORECASE)\n",
        "                        word_matches = list(word_pattern.finditer(generated_desc))\n",
        "\n",
        "                        # 保留第一次出現，替換後續出現\n",
        "                        for i, match in enumerate(word_matches[1:], 1):\n",
        "                            if i <= len(replacement_dict[word]):\n",
        "                                replacement = replacement_dict[word][(i-1) % len(replacement_dict[word])]\n",
        "\n",
        "                                # 保持原始大小寫格式\n",
        "                                if match.group().isupper():\n",
        "                                    replacement = replacement.upper()\n",
        "                                elif match.group().istitle():\n",
        "                                    replacement = replacement.capitalize()\n",
        "\n",
        "                                # 執行替換\n",
        "                                generated_desc = generated_desc[:match.start()] + replacement + generated_desc[match.end():]\n",
        "                                # 重新計算後續匹配位置\n",
        "                                word_matches = list(word_pattern.finditer(generated_desc))\n",
        "                        break\n",
        "\n",
        "        return generated_desc\n",
        "\n",
        "    def fact_check_description(self,\n",
        "                             original_desc: str,\n",
        "                             enhanced_desc: str,\n",
        "                             scene_type: str,\n",
        "                             detected_objects: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        對增強後的描述進行全面的事實檢查\n",
        "\n",
        "        Args:\n",
        "            original_desc: 原始場景描述\n",
        "            enhanced_desc: 增強後的描述\n",
        "            scene_type: 場景類型\n",
        "            detected_objects: 檢測到的物體名稱列表\n",
        "\n",
        "        Returns:\n",
        "            str: 經過事實檢查的描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Starting comprehensive fact checking\")\n",
        "\n",
        "            # 如果增強描述為空或太短，返回原始描述\n",
        "            if not enhanced_desc or len(enhanced_desc) < 30:\n",
        "                return original_desc\n",
        "\n",
        "            # 1. 檢查數值一致性\n",
        "            enhanced_desc = self._check_numerical_consistency(original_desc, enhanced_desc)\n",
        "\n",
        "            # 2. 檢查視角一致性\n",
        "            enhanced_desc = self._check_perspective_consistency(original_desc, enhanced_desc)\n",
        "\n",
        "            # 3. 檢查場景類型一致性\n",
        "            enhanced_desc = self._check_scene_type_consistency(enhanced_desc, scene_type)\n",
        "\n",
        "            # 4. 確保文字長度適當\n",
        "            enhanced_desc = self._ensure_appropriate_length(enhanced_desc)\n",
        "\n",
        "            self.logger.debug(\"Comprehensive fact checking completed\")\n",
        "            return enhanced_desc\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Fact checking failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return enhanced_desc  # 發生錯誤時返回增強描述\n",
        "\n",
        "    def _check_numerical_consistency(self, original_desc: str, enhanced_desc: str) -> str:\n",
        "        \"\"\"檢查數值一致性\"\"\"\n",
        "        # 檢查原始描述中的每個數字\n",
        "        for pattern, num_group, word_group in self.number_patterns:\n",
        "            original_matches = re.finditer(pattern, original_desc, re.IGNORECASE)\n",
        "            for match in original_matches:\n",
        "                number = match.group(1)\n",
        "                noun = match.group(2)\n",
        "\n",
        "                # 檢查增強描述中是否保留了這個數字\n",
        "                enhanced_pattern = r'(\\d+)\\s+(' + re.escape(noun) + r'|' + re.escape(noun.rstrip('s')) + r'|' + re.escape(noun + 's') + r')'\n",
        "                enhanced_matches = list(re.finditer(enhanced_pattern, enhanced_desc, re.IGNORECASE))\n",
        "\n",
        "                if not enhanced_matches:\n",
        "                    # 數字+名詞未在增強描述中找到\n",
        "                    plural_form = noun if noun.endswith('s') or number == '1' else noun + 's'\n",
        "                    if enhanced_desc.startswith(\"This\") or enhanced_desc.startswith(\"The\"):\n",
        "                        enhanced_desc = enhanced_desc.replace(\"This \", f\"This scene with {number} {plural_form} \", 1)\n",
        "                        enhanced_desc = enhanced_desc.replace(\"The \", f\"The scene with {number} {plural_form} \", 1)\n",
        "                    else:\n",
        "                        enhanced_desc = f\"The scene includes {number} {plural_form}. \" + enhanced_desc\n",
        "                elif enhanced_matches and enhanced_matches[0].group(1) != number:\n",
        "                    # 存在但數字不一致，需要更正數字\n",
        "                    for ematch in enhanced_matches:\n",
        "                        wrong_number = ematch.group(1)\n",
        "                        enhanced_desc = enhanced_desc.replace(f\"{wrong_number} {ematch.group(2)}\", f\"{number} {ematch.group(2)}\")\n",
        "\n",
        "        return enhanced_desc\n",
        "\n",
        "    def _check_perspective_consistency(self, original_desc: str, enhanced_desc: str) -> str:\n",
        "        \"\"\"檢查視角一致性\"\"\"\n",
        "        # 確定原始視角\n",
        "        original_perspective = None\n",
        "        for persp, terms in self.perspective_terms.items():\n",
        "            if any(term in original_desc.lower() for term in terms):\n",
        "                original_perspective = persp\n",
        "                break\n",
        "\n",
        "        # 檢查是否保留了視角\n",
        "        if original_perspective:\n",
        "            enhanced_has_perspective = any(term in enhanced_desc.lower() for term in self.perspective_terms[original_perspective])\n",
        "\n",
        "            if not enhanced_has_perspective:\n",
        "                # 添加缺失的視角\n",
        "                prefix = self.perspective_prefixes.get(original_perspective, \"\")\n",
        "                if prefix:\n",
        "                    if enhanced_desc[0].isupper():\n",
        "                        enhanced_desc = prefix + enhanced_desc[0].lower() + enhanced_desc[1:]\n",
        "                    else:\n",
        "                        enhanced_desc = prefix + enhanced_desc\n",
        "\n",
        "        return enhanced_desc\n",
        "\n",
        "    def _check_scene_type_consistency(self, enhanced_desc: str, scene_type: str) -> str:\n",
        "        \"\"\"檢查場景類型一致性\"\"\"\n",
        "        if scene_type and scene_type.lower() != \"unknown\" and scene_type.lower() not in enhanced_desc.lower():\n",
        "            # 添加場景類型\n",
        "            if enhanced_desc.startswith(\"This \") or enhanced_desc.startswith(\"The \"):\n",
        "                # 避免產生重複\n",
        "                if \"scene\" in enhanced_desc[:15].lower():\n",
        "                    fixed_type = scene_type.lower()\n",
        "                    enhanced_desc = enhanced_desc.replace(\"scene\", fixed_type, 1)\n",
        "                else:\n",
        "                    enhanced_desc = enhanced_desc.replace(\"This \", f\"This {scene_type} \", 1)\n",
        "                    enhanced_desc = enhanced_desc.replace(\"The \", f\"The {scene_type} \", 1)\n",
        "            else:\n",
        "                enhanced_desc = f\"This {scene_type} \" + enhanced_desc\n",
        "\n",
        "        return enhanced_desc\n",
        "\n",
        "    def _ensure_appropriate_length(self, enhanced_desc: str) -> str:\n",
        "        \"\"\"確保文字長度適當\"\"\"\n",
        "        words = enhanced_desc.split()\n",
        "        if len(words) > 200:\n",
        "            # 找尋接近字數限制的句子結束處\n",
        "            truncated = ' '.join(words[:200])\n",
        "            last_period = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('?'))\n",
        "\n",
        "            if last_period > 0:\n",
        "                enhanced_desc = truncated[:last_period+1]\n",
        "            else:\n",
        "                enhanced_desc = truncated + '.'\n",
        "\n",
        "        return enhanced_desc\n",
        "\n",
        "    def ensure_scene_type_consistency(self,\n",
        "                                    description: str,\n",
        "                                    scene_type: str,\n",
        "                                    original_desc: str) -> str:\n",
        "        \"\"\"\n",
        "        確保描述中的場景類型與指定的場景類型一致\n",
        "\n",
        "        Args:\n",
        "            description: 待檢查的描述\n",
        "            scene_type: 指定的場景類型\n",
        "            original_desc: 原始描述（用於參考）\n",
        "\n",
        "        Returns:\n",
        "            str: 場景類型一致的描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.debug(\"Ensuring scene type consistency\")\n",
        "            scene_type = scene_type.replace('_', ' ')\n",
        "            # 檢查是否包含禁止的場景詞\n",
        "            for word in self.prohibited_scene_words:\n",
        "                if word in description.lower() and word not in original_desc.lower() and word not in scene_type.lower():\n",
        "                    # 替換錯誤場景詞為正確場景類型\n",
        "                    pattern = re.compile(r'\\b' + word + r'\\b', re.IGNORECASE)\n",
        "                    description = pattern.sub(scene_type, description)\n",
        "\n",
        "            # 確保場景類型在描述中被提及\n",
        "            if scene_type.lower() not in description.lower():\n",
        "                # 尋找通用場景詞並替換\n",
        "                for general_term in [\"scene\", \"area\", \"place\", \"location\"]:\n",
        "                    if general_term in description.lower():\n",
        "                        pattern = re.compile(r'\\b' + general_term + r'\\b', re.IGNORECASE)\n",
        "                        description = pattern.sub(scene_type, description, count=1)\n",
        "                        break\n",
        "                else:\n",
        "                    # 如果沒有找到通用詞，在開頭添加場景類型\n",
        "                    if description.startswith(\"The \"):\n",
        "                        description = description.replace(\"The \", f\"The {scene_type} \", 1)\n",
        "                    elif description.startswith(\"This \"):\n",
        "                        description = description.replace(\"This \", f\"This {scene_type} \", 1)\n",
        "                    else:\n",
        "                        description = f\"This {scene_type} \" + description\n",
        "\n",
        "            self.logger.debug(\"Scene type consistency ensured\")\n",
        "            return description\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Scene type consistency check failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return description\n",
        "\n",
        "    def extract_perspective_from_description(self, description: str) -> str:\n",
        "        \"\"\"\n",
        "        從原始描述中提取視角信息\n",
        "\n",
        "        Args:\n",
        "            description: 原始場景描述\n",
        "\n",
        "        Returns:\n",
        "            str: 提取到的視角描述，如果沒有則返回空字符串\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for persp_type, terms in self.perspective_terms.items():\n",
        "                for term in terms:\n",
        "                    if term.lower() in description.lower():\n",
        "                        self.logger.debug(f\"Perspective detected: {term}\")\n",
        "                        return term\n",
        "\n",
        "            return \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Perspective extraction failed: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_objects_from_description(self, description: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        從原始描述中提取物件提及\n",
        "\n",
        "        Args:\n",
        "            description: 原始場景描述\n",
        "\n",
        "        Returns:\n",
        "            List[str]: 提取到的物件列表\n",
        "        \"\"\"\n",
        "        try:\n",
        "            extracted_objects = []\n",
        "\n",
        "            for pattern in self.number_patterns:\n",
        "                matches = re.finditer(pattern[0], description, re.IGNORECASE)\n",
        "                for match in matches:\n",
        "                    number = match.group(1)\n",
        "                    object_type = match.group(2)\n",
        "                    extracted_objects.append(f\"{number} {object_type}\")\n",
        "\n",
        "            self.logger.debug(f\"Extracted {len(extracted_objects)} objects from description\")\n",
        "            return extracted_objects\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Object extraction failed: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def validate_response_completeness(self, response: str) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        驗證回應的完整性\n",
        "\n",
        "        Args:\n",
        "            response: 待驗證的回應\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (是否完整, 問題描述)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 檢查回應長度\n",
        "            if len(response) < 100:\n",
        "                return False, \"Response too short\"\n",
        "\n",
        "            # 檢查句子結尾\n",
        "            if len(response) < 200 and \".\" not in response[-30:]:\n",
        "                return False, \"No proper sentence ending\"\n",
        "\n",
        "            # 檢查不完整短語\n",
        "            incomplete_phrases = [\"in the\", \"with the\", \"and the\"]\n",
        "            if any(response.endswith(phrase) for phrase in incomplete_phrases):\n",
        "                return False, \"Ends with incomplete phrase\"\n",
        "\n",
        "            return True, \"Response is complete\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Response completeness validation failed: {str(e)}\")\n",
        "            return False, \"Validation error\"\n",
        "\n",
        "    def get_validator_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取驗證器信息\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 包含驗證器狀態和配置的信息\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"location_terms_count\": len(self.location_terms),\n",
        "            \"cultural_terms_count\": len(self.cultural_terms),\n",
        "            \"perspective_types_count\": len(self.perspective_terms),\n",
        "            \"number_patterns_count\": len(self.number_patterns),\n",
        "            \"prohibited_words_count\": len(self.prohibited_scene_words),\n",
        "            \"initialization_status\": \"success\"\n",
        "        }"
      ],
      "metadata": {
        "id": "T8vvuTw3sXeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcce8309-abb9-4b32-a3d6-19d308ed29d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing text_quality_validator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile llm_enhancer.py\n",
        "import logging\n",
        "import traceback\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "# from model_manager import ModelManager\n",
        "# from prompt_template_manager import PromptTemplateManager\n",
        "# from response_processor import ResponseProcessor\n",
        "# from text_quality_validator import TextQualityValidator\n",
        "# from landmark_data import ALL_LANDMARKS\n",
        "\n",
        "class LLMEnhancer:\n",
        "    \"\"\"\n",
        "    LLM增強器的主要窗口，協調模型管理、提示模板、回應處理和品質驗證等組件。\n",
        "    提供統一的接口來處理場景描述增強、檢測結果驗證和無檢測情況處理。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_path: Optional[str] = None,\n",
        "                 tokenizer_path: Optional[str] = None,\n",
        "                 device: Optional[str] = None,\n",
        "                 max_length: int = 2048,\n",
        "                 temperature: float = 0.3,\n",
        "                 top_p: float = 0.85):\n",
        "        \"\"\"\n",
        "        初始化LLM增強器門面\n",
        "\n",
        "        Args:\n",
        "            model_path: LLM模型的路徑或HuggingFace模型名稱，預設使用Llama 3.2\n",
        "            tokenizer_path: tokenizer的路徑，通常與model_path相同\n",
        "            device: 運行設備 ('cpu'或'cuda')，None時自動檢測\n",
        "            max_length: 輸入文本的最大長度\n",
        "            temperature: 生成文本的溫度參數\n",
        "            top_p: 生成文本時的核心採樣機率閾值\n",
        "        \"\"\"\n",
        "        # 設置專屬logger\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        try:\n",
        "            # 初始化四個核心組件\n",
        "            self.model_manager = ModelManager(\n",
        "                model_path=model_path,\n",
        "                tokenizer_path=tokenizer_path,\n",
        "                device=device,\n",
        "                max_length=max_length,\n",
        "                temperature=temperature,\n",
        "                top_p=top_p\n",
        "            )\n",
        "\n",
        "            self.prompt_manager = PromptTemplateManager()\n",
        "            self.response_processor = ResponseProcessor()\n",
        "            self.quality_validator = TextQualityValidator()\n",
        "\n",
        "            # 保存模型路徑以供後續使用\n",
        "            self.model_path = model_path or \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "            self.logger.info(\"LLMEnhancer facade initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to initialize LLMEnhancer facade: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            raise Exception(error_msg) from e\n",
        "\n",
        "    def enhance_description(self, scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        場景描述增強器主要入口方法，整合所有組件來處理場景描述增強\n",
        "\n",
        "        Args:\n",
        "            scene_data: 包含場景資訊的字典，包括原始描述、檢測物件 (含 is_landmark)、\n",
        "                        場景類型、時間/光線資訊等\n",
        "\n",
        "        Returns:\n",
        "            str: 增強後的場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Starting scene description enhancement\")\n",
        "\n",
        "            # 1. 重置模型上下文\n",
        "            self.model_manager.reset_context()\n",
        "\n",
        "            # 2. 取出原始描述\n",
        "            original_desc = scene_data.get(\"original_description\", \"\")\n",
        "            if not original_desc:\n",
        "                self.logger.warning(\"No original description provided\")\n",
        "                return \"No original description provided.\"\n",
        "\n",
        "            # 3. 準備物件統計資訊\n",
        "            object_list = self._prepare_object_statistics(scene_data)\n",
        "            if not object_list:\n",
        "                object_keywords = self.quality_validator.extract_objects_from_description(original_desc)\n",
        "                object_list = \", \".join(object_keywords) if object_keywords else \"objects visible in the scene\"\n",
        "\n",
        "            # 4. 檢測地標並準備地標資訊\n",
        "            landmark_info = self._extract_landmark_info(scene_data)\n",
        "\n",
        "            # 5. 將地標資訊加入scene_data\n",
        "            enhanced_scene_data = scene_data.copy()\n",
        "            if landmark_info:\n",
        "                enhanced_scene_data[\"landmark_location_info\"] = landmark_info\n",
        "\n",
        "            # 6. 生成 prompt\n",
        "            prompt = self.prompt_manager.format_enhancement_prompt_with_landmark(\n",
        "                scene_data=enhanced_scene_data,\n",
        "                object_list=object_list,\n",
        "                original_description=original_desc\n",
        "            )\n",
        "\n",
        "            # 7. 生成 LLM 回應\n",
        "            self.logger.info(\"Generating LLM response\")\n",
        "            response = self.model_manager.generate_response(prompt)\n",
        "\n",
        "            # 8. 處理不完整回應（重試機制）\n",
        "            response = self._handle_incomplete_response(response, prompt, original_desc)\n",
        "\n",
        "            # 9. 清理 LLM 回應\n",
        "            model_type = self.model_path\n",
        "            raw_cleaned = self.response_processor.clean_response(response, model_type)\n",
        "\n",
        "            # 10. 移除解釋性注釋\n",
        "            cleaned_response = self.response_processor.remove_explanatory_notes(raw_cleaned)\n",
        "\n",
        "            # 11. 事實準確性驗證\n",
        "            try:\n",
        "                cleaned_response = self.quality_validator.verify_factual_accuracy(\n",
        "                    original_desc, cleaned_response, object_list\n",
        "                )\n",
        "            except Exception:\n",
        "                self.logger.warning(\"Fact verification failed; using response without verification\")\n",
        "\n",
        "            # 12. 場景類型一致性確保\n",
        "            scene_type = scene_data.get(\"scene_type\", \"unknown scene\")\n",
        "            word_count = len(cleaned_response.split())\n",
        "            if word_count >= 5 and scene_type.lower() not in cleaned_response.lower():\n",
        "                cleaned_response = self.quality_validator.ensure_scene_type_consistency(\n",
        "                    cleaned_response, scene_type, original_desc\n",
        "                )\n",
        "\n",
        "            # 13. 視角一致性處理\n",
        "            perspective = self.quality_validator.extract_perspective_from_description(original_desc)\n",
        "            if perspective and perspective.lower() not in cleaned_response.lower():\n",
        "                cleaned_response = f\"{perspective}, {cleaned_response[0].lower()}{cleaned_response[1:]}\"\n",
        "\n",
        "            # 14. 最終驗證：如果結果過短，嘗試fallback\n",
        "            final_result = cleaned_response.strip()\n",
        "            if not final_result or len(final_result) < 20:\n",
        "                self.logger.warning(\"Enhanced description too short; attempting fallback\")\n",
        "\n",
        "                # Fallback prompt\n",
        "                fallback_scene_data = enhanced_scene_data.copy()\n",
        "                fallback_scene_data[\"is_fallback\"] = True\n",
        "                fallback_prompt = self.prompt_manager.format_enhancement_prompt_with_landmark(\n",
        "                    scene_data=fallback_scene_data,\n",
        "                    object_list=object_list,\n",
        "                    original_description=original_desc\n",
        "                )\n",
        "\n",
        "                fallback_resp = self.model_manager.generate_response(fallback_prompt)\n",
        "                fallback_cleaned = self.response_processor.clean_response(fallback_resp, model_type)\n",
        "                fallback_cleaned = self.response_processor.remove_explanatory_notes(fallback_cleaned)\n",
        "\n",
        "                final_result = fallback_cleaned.strip()\n",
        "                if not final_result or len(final_result) < 20:\n",
        "                    self.logger.warning(\"Fallback also insufficient; returning original\")\n",
        "                    return original_desc\n",
        "\n",
        "            # 15. display enhanced description\n",
        "            self.logger.info(f\"Scene description enhancement completed successfully ({len(final_result)} chars)\")\n",
        "            return final_result\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Enhancement failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return scene_data.get(\"original_description\", \"Unable to enhance description\")\n",
        "\n",
        "    def _extract_landmark_info(self, scene_data: Dict[str, Any]) -> Optional[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        提取地標資訊，但不構建prompt內容\n",
        "\n",
        "        Args:\n",
        "            scene_data: 場景資料字典\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, str]]: 地標資訊字典，包含name和location，如果沒有地標則返回None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 檢查是否有地標\n",
        "            lm_id_in_data = scene_data.get(\"landmark_id\")\n",
        "            if not lm_id_in_data:\n",
        "                # 從檢測物件中尋找地標\n",
        "                for obj in scene_data.get(\"detected_objects\", []):\n",
        "                    if obj.get(\"is_landmark\") and obj.get(\"landmark_id\"):\n",
        "                        lm_id_in_data = obj[\"landmark_id\"]\n",
        "                        break\n",
        "\n",
        "            # 如果沒有檢測到地標，返回None\n",
        "            if not lm_id_in_data:\n",
        "                return None\n",
        "\n",
        "            # 從landmark_data.py提取地標資訊\n",
        "            if lm_id_in_data in ALL_LANDMARKS:\n",
        "                lm_info = ALL_LANDMARKS[lm_id_in_data]\n",
        "                landmark_name = scene_data.get(\"scene_name\", lm_info.get(\"name\", lm_id_in_data))\n",
        "                landmark_location = lm_info.get(\"location\", \"\")\n",
        "\n",
        "                if landmark_location:\n",
        "                    return {\n",
        "                        \"name\": landmark_name,\n",
        "                        \"location\": landmark_location,\n",
        "                        \"landmark_id\": lm_id_in_data\n",
        "                    }\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting landmark info: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def _prepare_object_statistics(self, scene_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        準備物件統計資訊用於提示詞生成\n",
        "\n",
        "        Args:\n",
        "            scene_data: 場景資料字典\n",
        "\n",
        "        Returns:\n",
        "            str: 格式化的物件統計資訊\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 高信心度閾值\n",
        "            high_confidence_threshold = 0.65\n",
        "\n",
        "            # 優先使用預計算的統計資訊\n",
        "            object_statistics = scene_data.get(\"object_statistics\", {})\n",
        "            object_counts = {}\n",
        "\n",
        "            if object_statistics:\n",
        "                for class_name, stats in object_statistics.items():\n",
        "                    if stats.get(\"count\", 0) > 0 and stats.get(\"avg_confidence\", 0) >= high_confidence_threshold:\n",
        "                        object_counts[class_name] = stats[\"count\"]\n",
        "            else:\n",
        "                # 回退到原有的計算方式\n",
        "                detected_objects = scene_data.get(\"detected_objects\", [])\n",
        "                filtered_objects = []\n",
        "\n",
        "                for obj in detected_objects:\n",
        "                    confidence = obj.get(\"confidence\", 0)\n",
        "                    class_name = obj.get(\"class_name\", \"\")\n",
        "\n",
        "                    # 為特殊類別設置更高閾值\n",
        "                    special_classes = [\"airplane\", \"helicopter\", \"boat\"]\n",
        "                    if class_name in special_classes:\n",
        "                        if confidence < 0.75:\n",
        "                            continue\n",
        "\n",
        "                    if confidence >= high_confidence_threshold:\n",
        "                        filtered_objects.append(obj)\n",
        "\n",
        "                for obj in filtered_objects:\n",
        "                    class_name = obj.get(\"class_name\", \"\")\n",
        "                    if class_name not in object_counts:\n",
        "                        object_counts[class_name] = 0\n",
        "                    object_counts[class_name] += 1\n",
        "\n",
        "            # 格式化物件描述\n",
        "            return \", \".join([\n",
        "                f\"{count} {obj}{'s' if count > 1 else ''}\"\n",
        "                for obj, count in object_counts.items()\n",
        "            ])\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Object statistics preparation failed: {str(e)}\")\n",
        "            return \"objects visible in the scene\"\n",
        "\n",
        "    def _handle_incomplete_response(self, response: str, prompt: str, original_desc: str) -> str:\n",
        "        \"\"\"\n",
        "        處理不完整的回應，必要時重新生成\n",
        "\n",
        "        Args:\n",
        "            response: 原始回應\n",
        "            prompt: 使用的提示詞\n",
        "            original_desc: 原始描述\n",
        "\n",
        "        Returns:\n",
        "            str: 處理後的回應\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 檢查回應完整性\n",
        "            is_complete, issue = self.quality_validator.validate_response_completeness(response)\n",
        "\n",
        "            max_retries = 3\n",
        "            attempts = 0\n",
        "\n",
        "            while not is_complete and attempts < max_retries:\n",
        "                self.logger.warning(f\"Incomplete response detected ({issue}), retrying... Attempt {attempts+1}/{max_retries}\")\n",
        "\n",
        "                # 重新生成\n",
        "                response = self.model_manager.generate_response(prompt)\n",
        "                is_complete, issue = self.quality_validator.validate_response_completeness(response)\n",
        "                attempts += 1\n",
        "\n",
        "            if not response or len(response.strip()) < 10:\n",
        "                self.logger.warning(\"Generated response was empty or too short, returning original description\")\n",
        "                return original_desc\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Incomplete response handling failed: {str(e)}\")\n",
        "            return response  # 返回原始回應\n",
        "\n",
        "    def verify_detection(self,\n",
        "                        detected_objects: List[Dict],\n",
        "                        clip_analysis: Dict[str, Any],\n",
        "                        scene_type: str,\n",
        "                        scene_name: str,\n",
        "                        confidence: float) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        驗證並可能修正YOLO的檢測結果\n",
        "\n",
        "        Args:\n",
        "            detected_objects: YOLO檢測到的物體列表\n",
        "            clip_analysis: CLIP分析結果\n",
        "            scene_type: 識別的場景類型\n",
        "            scene_name: 場景名稱\n",
        "            confidence: 場景分類的信心度\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含驗證結果和建議的字典\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Starting detection verification\")\n",
        "\n",
        "            # 格式化驗證提示\n",
        "            prompt = self.prompt_manager.format_verification_prompt(\n",
        "                detected_objects=detected_objects,\n",
        "                clip_analysis=clip_analysis,\n",
        "                scene_type=scene_type,\n",
        "                scene_name=scene_name,\n",
        "                confidence=confidence\n",
        "            )\n",
        "\n",
        "            # 調用LLM進行驗證\n",
        "            verification_result = self.model_manager.generate_response(prompt)\n",
        "\n",
        "            # 清理回應\n",
        "            cleaned_result = self.response_processor.clean_response(verification_result, self.model_path)\n",
        "\n",
        "            # 解析驗證結果\n",
        "            result = {\n",
        "                \"verification_text\": cleaned_result,\n",
        "                \"has_errors\": \"appear accurate\" not in cleaned_result.lower(),\n",
        "                \"corrected_objects\": None\n",
        "            }\n",
        "\n",
        "            self.logger.info(\"Detection verification completed\")\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Detection verification failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return {\n",
        "                \"verification_text\": \"Verification failed\",\n",
        "                \"has_errors\": False,\n",
        "                \"corrected_objects\": None\n",
        "            }\n",
        "\n",
        "    def handle_no_detection(self, clip_analysis: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        處理YOLO未檢測到物體的情況\n",
        "\n",
        "        Args:\n",
        "            clip_analysis: CLIP分析結果\n",
        "\n",
        "        Returns:\n",
        "            str: 生成的場景描述\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Handling no detection scenario\")\n",
        "\n",
        "            # 格式化無檢測提示\n",
        "            prompt = self.prompt_manager.format_no_detection_prompt(clip_analysis)\n",
        "\n",
        "            # 調用LLM生成描述\n",
        "            description = self.model_manager.generate_response(prompt)\n",
        "\n",
        "            # 清理回應\n",
        "            cleaned_description = self.response_processor.clean_response(description, self.model_path)\n",
        "\n",
        "            self.logger.info(\"No detection handling completed\")\n",
        "            return cleaned_description\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"No detection handling failed: {str(e)}\"\n",
        "            self.logger.error(error_msg)\n",
        "            self.logger.error(traceback.format_exc())\n",
        "            return \"Unable to generate scene description\"\n",
        "\n",
        "    def reset_context(self):\n",
        "        \"\"\"重置LLM模型上下文\"\"\"\n",
        "        try:\n",
        "            self.model_manager.reset_context()\n",
        "            self.logger.info(\"LLM context reset completed\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Context reset failed: {str(e)}\")\n",
        "\n",
        "    def get_call_count(self) -> int:\n",
        "        \"\"\"\n",
        "        獲取模型調用次數\n",
        "\n",
        "        Returns:\n",
        "            int: 調用次數\n",
        "        \"\"\"\n",
        "        return self.model_manager.get_call_count()\n",
        "\n",
        "    def get_model_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        獲取模型和組件資訊\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: 包含所有組件狀態的綜合資訊\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                \"model_manager\": self.model_manager.get_model_info(),\n",
        "                \"prompt_manager\": self.prompt_manager.get_template_info(),\n",
        "                \"response_processor\": self.response_processor.get_processor_info(),\n",
        "                \"quality_validator\": self.quality_validator.get_validator_info(),\n",
        "                \"facade_status\": \"initialized\"\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to get component info: {str(e)}\")\n",
        "            return {\"facade_status\": \"error\", \"error_message\": str(e)}\n",
        "\n",
        "    def is_model_loaded(self) -> bool:\n",
        "        \"\"\"\n",
        "        檢查模型是否已載入\n",
        "\n",
        "        Returns:\n",
        "            bool: 模型載入狀態\n",
        "        \"\"\"\n",
        "        return self.model_manager.is_model_loaded()\n",
        "\n",
        "    def get_current_device(self) -> str:\n",
        "        \"\"\"\n",
        "        獲取當前運行設備\n",
        "\n",
        "        Returns:\n",
        "            str: 當前設備名稱\n",
        "        \"\"\"\n",
        "        return self.model_manager.get_current_device()\n",
        "\n",
        "    def _detect_scene_type(self, detected_objects: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        基於物件分佈和模式檢測場景類型\n",
        "\n",
        "        Args:\n",
        "            detected_objects: 檢測到的物件列表\n",
        "\n",
        "        Returns:\n",
        "            str: 檢測到的場景類型\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # 預設場景類型\n",
        "            scene_type = \"intersection\"\n",
        "\n",
        "            # 計算物件數量\n",
        "            object_counts = {}\n",
        "            for obj in detected_objects:\n",
        "                class_name = obj.get(\"class_name\", \"\")\n",
        "                if class_name not in object_counts:\n",
        "                    object_counts[class_name] = 0\n",
        "                object_counts[class_name] += 1\n",
        "\n",
        "            # 人數統計\n",
        "            people_count = object_counts.get(\"person\", 0)\n",
        "\n",
        "            # 交通工具統計\n",
        "            car_count = object_counts.get(\"car\", 0)\n",
        "            bus_count = object_counts.get(\"bus\", 0)\n",
        "            truck_count = object_counts.get(\"truck\", 0)\n",
        "            total_vehicles = car_count + bus_count + truck_count\n",
        "\n",
        "            # 簡單的場景類型檢測邏輯\n",
        "            if people_count > 8 and total_vehicles < 2:\n",
        "                scene_type = \"pedestrian_crossing\"\n",
        "            elif people_count > 5 and total_vehicles > 2:\n",
        "                scene_type = \"busy_intersection\"\n",
        "            elif people_count < 3 and total_vehicles > 3:\n",
        "                scene_type = \"traffic_junction\"\n",
        "\n",
        "            return scene_type\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Scene type detection failed: {str(e)}\")\n",
        "            return \"intersection\""
      ],
      "metadata": {
        "id": "O0llM--2sXbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbe3e40-4105-485f-8a5a-fae0ce13f035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing llm_enhancer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoMFwi652rCU",
        "outputId": "6fba25f0-ba09-4178-d96c-35ff78b809c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile app.py\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import uuid\n",
        "# import spaces\n",
        "\n",
        "# from detection_model import DetectionModel\n",
        "# from color_mapper import ColorMapper\n",
        "# from evaluation_metrics import EvaluationMetrics\n",
        "# from style import Style\n",
        "# from image_processor import ImageProcessor\n",
        "# from video_processor import VideoProcessor\n",
        "# from llm_enhancer import LLMEnhancer\n",
        "\n",
        "# Initialize Processors with LLM support\n",
        "image_processor = None\n",
        "video_processor = None\n",
        "\n",
        "def initialize_processors():\n",
        "    global image_processor, video_processor\n",
        "\n",
        "    try:\n",
        "        print(\"Attempting to initialize ImageProcessor with LLM support...\")\n",
        "        image_processor = ImageProcessor(use_llm=True, llm_model_path=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "        print(\"ImageProcessor initialized successfully with LLM\")\n",
        "\n",
        "        # 添加診斷檢查\n",
        "        if hasattr(image_processor, 'scene_analyzer'):\n",
        "            if image_processor.scene_analyzer is not None:\n",
        "                print(f\"scene_analyzer initialized: {type(image_processor.scene_analyzer)}\")\n",
        "                if hasattr(image_processor.scene_analyzer, 'use_llm'):\n",
        "                    print(f\"scene_analyzer.use_llm available: {image_processor.scene_analyzer.use_llm}\")\n",
        "            else:\n",
        "                print(\"WARNING: scene_analyzer is None after initialization\")\n",
        "        else:\n",
        "            print(\"WARNING: scene_analyzer attribute not found in image_processor\")\n",
        "\n",
        "        video_processor = VideoProcessor(image_processor)\n",
        "        print(\"VideoProcessor initialized successfully\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing processors with LLM: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Create fallback processor without LLM\n",
        "        try:\n",
        "            print(\"Attempting fallback initialization without LLM...\")\n",
        "            image_processor = ImageProcessor(use_llm=False, enable_places365=False)\n",
        "            video_processor = VideoProcessor(image_processor)\n",
        "            print(\"Fallback processors initialized successfully without LLM and Places365\")\n",
        "            return True\n",
        "\n",
        "        except Exception as fallback_error:\n",
        "            print(f\"Fatal error: Cannot initialize processors: {fallback_error}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            image_processor = None\n",
        "            video_processor = None\n",
        "            return False\n",
        "\n",
        "# Initialize processors\n",
        "initialization_success = initialize_processors()\n",
        "if not initialization_success:\n",
        "    print(\"WARNING: Failed to initialize processors. Application may not function correctly.\")\n",
        "\n",
        "# Helper Function\n",
        "def get_all_classes():\n",
        "    \"\"\"Gets all available COCO classes.\"\"\"\n",
        "    # Try to get from a loaded model first\n",
        "    if image_processor and image_processor.model_instances:\n",
        "         for model_instance in image_processor.model_instances.values():\n",
        "              if model_instance and model_instance.is_model_loaded:\n",
        "                   try:\n",
        "                        # Ensure class_names is a dict {id: name}\n",
        "                        if isinstance(model_instance.class_names, dict):\n",
        "                             return sorted([(int(idx), name) for idx, name in model_instance.class_names.items()])\n",
        "                   except Exception as e:\n",
        "                        print(f\"Error getting class names from model: {e}\")\n",
        "\n",
        "    # Fallback to standard COCO (ensure keys are ints)\n",
        "    default_classes = {\n",
        "        0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',\n",
        "        6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',\n",
        "        11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',\n",
        "        16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear',\n",
        "        22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',\n",
        "        27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard',\n",
        "        32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',\n",
        "        36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',\n",
        "        40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',\n",
        "        46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',\n",
        "        51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair',\n",
        "        57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet',\n",
        "        62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard',\n",
        "        67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink',\n",
        "        72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors',\n",
        "        77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
        "    }\n",
        "    return sorted(default_classes.items())\n",
        "\n",
        "# @spaces.GPU(duration=180)\n",
        "def handle_image_upload(image, model_name, confidence_threshold, filter_classes=None, use_llm=True, enable_landmark=True):\n",
        "    \"\"\"Processes a single uploaded image.\"\"\"\n",
        "    # Enhanced safety check for image_processor\n",
        "    if image_processor is None:\n",
        "        error_msg = \"Image processor is not initialized. Please restart the application or check system dependencies.\"\n",
        "        print(f\"ERROR: {error_msg}\")\n",
        "\n",
        "        # Create error plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.text(0.5, 0.5, \"Initialization Error\\nProcessor Not Available\",\n",
        "                color=\"red\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        return (None, error_msg, {}, fig, f\"<div style='color: red; font-weight: bold;'>Error: {error_msg}</div>\",\n",
        "                \"<div style='color: red;'>Error: System not initialized</div>\",\n",
        "                [[\"System Error\"]], [[\"System Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "    # Additional safety check for processor attributes\n",
        "    if not hasattr(image_processor, 'use_llm'):\n",
        "        error_msg = \"Image processor is corrupted. Missing required attributes.\"\n",
        "        print(f\"ERROR: {error_msg}\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.text(0.5, 0.5, \"Processor Error\\nCorrupted State\",\n",
        "                color=\"red\", ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        return (None, error_msg, {}, fig, f\"<div style='color: red; font-weight: bold;'>Error: {error_msg}</div>\",\n",
        "                \"<div style='color: red;'>Error: Processor corrupted</div>\",\n",
        "                [[\"Processor Error\"]], [[\"Processor Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "    print(f\"DIAGNOSTIC: Image upload handled with enable_landmark={enable_landmark}, use_llm={use_llm}\")\n",
        "    print(f\"Processing image with model: {model_name}, confidence: {confidence_threshold}, use_llm: {use_llm}, enable_landmark: {enable_landmark}\")\n",
        "    try:\n",
        "        image_processor.use_llm = use_llm\n",
        "\n",
        "        # 確保 scene_analyzer 不是 None\n",
        "        if hasattr(image_processor, 'scene_analyzer') and image_processor.scene_analyzer is not None:\n",
        "            if hasattr(image_processor.scene_analyzer, 'use_llm'):\n",
        "                image_processor.scene_analyzer.use_llm = use_llm\n",
        "                print(f\"Updated existing scene_analyzer use_llm setting to: {use_llm}\")\n",
        "\n",
        "            # 檢查並設置 landmark detection\n",
        "            if hasattr(image_processor.scene_analyzer, 'use_landmark_detection'):\n",
        "                # 設置所有相關標記\n",
        "                image_processor.scene_analyzer.use_landmark_detection = enable_landmark\n",
        "                image_processor.scene_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 確保處理器也設置了這選項\n",
        "                image_processor.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置更深層次的組件\n",
        "                if hasattr(image_processor.scene_analyzer, 'scene_describer') and image_processor.scene_analyzer.scene_describer is not None:\n",
        "                    image_processor.scene_analyzer.scene_describer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置CLIP分析器上的標記\n",
        "                if hasattr(image_processor.scene_analyzer, 'clip_analyzer') and image_processor.scene_analyzer.clip_analyzer is not None:\n",
        "                    if hasattr(image_processor.scene_analyzer.clip_analyzer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.clip_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 檢查並設置LLM增強器\n",
        "                if hasattr(image_processor.scene_analyzer, 'llm_enhancer') and image_processor.scene_analyzer.llm_enhancer is not None:\n",
        "                    if hasattr(image_processor.scene_analyzer.llm_enhancer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.llm_enhancer.enable_landmark = enable_landmark\n",
        "                        print(f\"Updated LLM enhancer enable_landmark to: {enable_landmark}\")\n",
        "\n",
        "                print(f\"Updated all landmark detection settings to: {enable_landmark}\")\n",
        "        else:\n",
        "            print(\"WARNING: scene_analyzer is None or not available\")\n",
        "            if hasattr(image_processor, 'enable_landmark'):\n",
        "                image_processor.enable_landmark = enable_landmark\n",
        "\n",
        "                # 設置更深層次的組別\n",
        "                if hasattr(image_processor.scene_analyzer, 'scene_describer'):\n",
        "                    image_processor.scene_analyzer.scene_describer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 設置CLIP分析器上的標記\n",
        "                if hasattr(image_processor.scene_analyzer, 'clip_analyzer'):\n",
        "                    if hasattr(image_processor.scene_analyzer.clip_analyzer, 'enable_landmark'):\n",
        "                        image_processor.scene_analyzer.clip_analyzer.enable_landmark = enable_landmark\n",
        "\n",
        "                # 如果有LLM增強器，也設置它\n",
        "                if hasattr(image_processor.scene_analyzer, 'llm_enhancer'):\n",
        "                    image_processor.scene_analyzer.llm_enhancer.enable_landmark = enable_landmark\n",
        "                    print(f\"Updated LLM enhancer enable_landmark to: {enable_landmark}\")\n",
        "\n",
        "                print(f\"Updated all landmark detection settings to: {enable_landmark}\")\n",
        "\n",
        "        class_ids_to_filter = None\n",
        "        if filter_classes:\n",
        "            class_ids_to_filter = []\n",
        "            available_classes_dict = dict(get_all_classes())\n",
        "            name_to_id = {name: id for id, name in available_classes_dict.items()}\n",
        "            for class_str in filter_classes:\n",
        "                class_name_or_id = class_str.split(\":\")[0].strip()\n",
        "                class_id = -1\n",
        "                try:\n",
        "                    class_id = int(class_name_or_id)\n",
        "                    if class_id not in available_classes_dict:\n",
        "                        class_id = -1\n",
        "                except ValueError:\n",
        "                    if class_name_or_id in name_to_id:\n",
        "                        class_id = name_to_id[class_name_or_id]\n",
        "                    elif class_str in name_to_id: # Check full string \"id: name\"\n",
        "                        class_id = name_to_id[class_str]\n",
        "\n",
        "                if class_id != -1:\n",
        "                    class_ids_to_filter.append(class_id)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not parse class filter: {class_str}\")\n",
        "            print(f\"Filtering image results for class IDs: {class_ids_to_filter}\")\n",
        "\n",
        "        # Call the existing image processing logic\n",
        "        print(f\"DEBUG: app.py 傳遞 enable_landmark={enable_landmark} 到 process_image\")\n",
        "        result_image, result_text, stats = image_processor.process_image(\n",
        "            image,\n",
        "            model_name,\n",
        "            confidence_threshold,\n",
        "            class_ids_to_filter,\n",
        "            enable_landmark\n",
        "        )\n",
        "\n",
        "        # Format stats for JSON display\n",
        "        formatted_stats = image_processor.format_json_for_display(stats)\n",
        "\n",
        "        # Prepare visualization data for the plot\n",
        "        plot_figure = None\n",
        "        if stats and \"class_statistics\" in stats and stats[\"class_statistics\"]:\n",
        "            available_classes_dict = dict(get_all_classes())\n",
        "            viz_data = image_processor.prepare_visualization_data(stats, available_classes_dict)\n",
        "            if \"error\" not in viz_data:\n",
        "                 plot_figure = EvaluationMetrics.create_enhanced_stats_plot(viz_data)\n",
        "            else:\n",
        "                 fig, ax = plt.subplots(figsize=(8, 6))\n",
        "                 ax.text(0.5, 0.5, viz_data[\"error\"], ha='center', va='center', fontsize=12)\n",
        "                 ax.axis('off')\n",
        "                 plot_figure = fig\n",
        "        else:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            ax.text(0.5, 0.5, \"No detection data for plot\", ha='center', va='center', fontsize=12)\n",
        "            ax.axis('off')\n",
        "            plot_figure = fig\n",
        "\n",
        "        # Extract scene analysis info\n",
        "        scene_analysis = stats.get(\"scene_analysis\", {})\n",
        "        scene_desc = scene_analysis.get(\"description\", \"Scene analysis requires detected objects.\")\n",
        "        # Ensure scene_desc is a string before adding HTML\n",
        "        if not isinstance(scene_desc, str):\n",
        "            scene_desc = str(scene_desc)\n",
        "\n",
        "        def clean_description(desc):\n",
        "            if not desc:\n",
        "                return \"\"\n",
        "\n",
        "            # 先過濾問答格式\n",
        "            if \"Questions:\" in desc:\n",
        "                desc = desc.split(\"Questions:\")[0].strip()\n",
        "            if \"Answers:\" in desc:\n",
        "                desc = desc.split(\"Answers:\")[0].strip()\n",
        "\n",
        "            # 然後按行過濾代碼和其他非敘述內容\n",
        "            lines = desc.split('\\n')\n",
        "            clean_lines = []\n",
        "            skip_block = False\n",
        "\n",
        "            for line in lines:\n",
        "                # 檢測問題格式\n",
        "                if re.match(r'^\\d+\\.\\s+(What|How|Why|When|Where|Who|The)', line):\n",
        "                    continue\n",
        "\n",
        "                # 檢查需要跳過的行\n",
        "                if line.strip().startswith(':param') or line.strip().startswith('\"\"\"'):\n",
        "                    continue\n",
        "                if line.strip().startswith(\"Exercise\") or \"class SceneDescriptionSystem\" in line:\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "                if ('def generate_scene_description' in line or\n",
        "                    'def enhance_scene_descriptions' in line or\n",
        "                    'def __init__' in line):\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "                if line.strip().startswith('#TEST'):\n",
        "                    skip_block = True\n",
        "                    continue\n",
        "\n",
        "                if skip_block and line.strip() == \"\":\n",
        "                    skip_block = False\n",
        "\n",
        "                # 如果不需要跳過\n",
        "                if not skip_block:\n",
        "                    clean_lines.append(line)\n",
        "\n",
        "            cleaned_text = '\\n'.join(clean_lines)\n",
        "\n",
        "            # 如果清理後為空，返回原始描述的第一段作為保險\n",
        "            if not cleaned_text.strip():\n",
        "                paragraphs = [p.strip() for p in desc.split('\\n\\n') if p.strip()]\n",
        "                if paragraphs:\n",
        "                    return paragraphs[0]\n",
        "                return desc\n",
        "\n",
        "            return cleaned_text\n",
        "\n",
        "        # 獲取和處理場景描述\n",
        "        scene_analysis = stats.get(\"scene_analysis\", {})\n",
        "        print(\"Processing scene_analysis:\", scene_analysis.keys())\n",
        "\n",
        "        # 獲取原始描述\n",
        "        scene_desc = scene_analysis.get(\"description\", \"Scene analysis requires detected objects.\")\n",
        "        if not isinstance(scene_desc, str):\n",
        "            scene_desc = str(scene_desc)\n",
        "\n",
        "        print(f\"Original scene description (first 50 chars): {scene_desc[:50]}...\")\n",
        "\n",
        "        # determine original description\n",
        "        clean_scene_desc = clean_description(scene_desc)\n",
        "        print(f\"Cleaned scene description (first 50 chars): {clean_scene_desc[:50]}...\")\n",
        "\n",
        "        if not clean_scene_desc.strip():\n",
        "            clean_scene_desc = scene_desc\n",
        "\n",
        "        scene_desc_html = f\"<div>{clean_scene_desc}</div>\"\n",
        "\n",
        "        # 獲取LLM增強描述並且確保設置默認值為空字符串而非 None，不然會有None type Error\n",
        "        enhanced_description = scene_analysis.get(\"enhanced_description\", \"\")\n",
        "        if enhanced_description is None:\n",
        "            enhanced_description = \"\"\n",
        "\n",
        "        if not enhanced_description or not enhanced_description.strip():\n",
        "            print(\"WARNING: LLM enhanced description is empty!\")\n",
        "\n",
        "        # bedge & label\n",
        "        llm_badge = \"\"\n",
        "        description_to_show = \"\"\n",
        "\n",
        "        # 在 Original Scene Analysis 折疊區顯示原始的描述\n",
        "        if use_llm and enhanced_description:\n",
        "            llm_badge = '<span style=\"display:inline-block; margin-left:8px; padding:3px 10px; border-radius:12px; background: linear-gradient(90deg, #38b2ac, #4299e1); color:white; font-size:0.7rem; font-weight:bold; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); border: 1px solid rgba(255, 255, 255, 0.2);\">LLM Enhanced</span>'\n",
        "            description_to_show = enhanced_description\n",
        "\n",
        "        else:\n",
        "            llm_badge = '<span style=\"display:inline-block; margin-left:8px; padding:3px 10px; border-radius:12px; background-color:#718096; color:white; font-size:0.7rem; font-weight:bold;\">Basic</span>'\n",
        "            description_to_show = clean_scene_desc\n",
        "\n",
        "        # 使用LLM敘述時會有徽章標籤在標題上\n",
        "        scene_description_html = f'''\n",
        "        <div>\n",
        "            <div class=\"section-heading\" style=\"font-size:1.2rem; margin-top:15px;\">Scene Description {llm_badge}\n",
        "                <span style=\"font-size:0.8rem; color:#666; font-weight:normal; display:block; margin-top:2px;\">\n",
        "                    {('(Enhanced by AI language model)' if use_llm and enhanced_description else '(Based on object detection)')}\n",
        "                </span>\n",
        "            </div>\n",
        "            <div style=\"padding:15px; background-color:#ffffff; border-radius:8px; border:1px solid #e2e8f0; margin-bottom:20px; box-shadow:0 1px 3px rgba(0,0,0,0.05);\">\n",
        "                {description_to_show}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # 原始描述只在使用 LLM 且有增強描述時在折疊區顯示\n",
        "        original_desc_visibility = \"block\" if use_llm and enhanced_description else \"none\"\n",
        "        original_desc_html = f'''\n",
        "        <div id=\"original_scene_analysis_accordion\" style=\"display: {original_desc_visibility};\">\n",
        "            <div style=\"padding:15px; background-color:#f0f0f0; border-radius:8px; border:1px solid #e2e8f0;\">\n",
        "                {clean_scene_desc}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # Prepare activities list\n",
        "        activities_list = scene_analysis.get(\"possible_activities\", [])\n",
        "        if not activities_list:\n",
        "            activities_list_data = [[\"No specific activities inferred\"]] # Data for Dataframe\n",
        "        else:\n",
        "            activities_list_data = [[activity] for activity in activities_list]\n",
        "\n",
        "        # Prepare safety concerns list\n",
        "        safety_concerns_list = scene_analysis.get(\"safety_concerns\", [])\n",
        "        if not safety_concerns_list:\n",
        "            safety_data = [[\"No safety concerns detected\"]] # Data for Dataframe\n",
        "        else:\n",
        "            safety_data = [[concern] for concern in safety_concerns_list]\n",
        "\n",
        "        zones = scene_analysis.get(\"functional_zones\", {})\n",
        "        lighting = scene_analysis.get(\"lighting_conditions\", {\"time_of_day\": \"unknown\", \"confidence\": 0})\n",
        "\n",
        "        # 如果描述為空，記錄警告\n",
        "        if not clean_scene_desc.strip():\n",
        "            print(\"WARNING: Scene description is empty after cleaning!\")\n",
        "        if not enhanced_description.strip():\n",
        "            print(\"WARNING: LLM enhanced description is empty!\")\n",
        "\n",
        "        return (result_image, result_text, formatted_stats, plot_figure,\n",
        "            scene_description_html, original_desc_html,\n",
        "            activities_list_data, safety_data, zones, lighting)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in handle_image_upload: {e}\")\n",
        "        import traceback\n",
        "        error_msg = f\"Error processing image: {str(e)}\\n{traceback.format_exc()}\"\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.text(0.5, 0.5, \"Processing Error\", color=\"red\", ha=\"center\", va=\"center\")\n",
        "        ax.axis('off')\n",
        "        # Ensure return structure matches outputs even on error\n",
        "        return (None, error_msg, {}, fig, f\"<div>Error: {str(e)}</div>\", \"Error\",\n",
        "            [[\"Error\"]], [[\"Error\"]], {}, {\"time_of_day\": \"error\", \"confidence\": 0})\n",
        "\n",
        "def download_video_from_url(video_url, max_duration_minutes=10):\n",
        "    \"\"\"\n",
        "    Downloads a video from a YouTube URL and returns the local path to the downloaded file.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): URL of the YouTube video to download\n",
        "        max_duration_minutes (int): Maximum allowed video duration in minutes\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Path to the downloaded video file or None, Error message or None)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a temporary directory to store the video\n",
        "        temp_dir = tempfile.gettempdir()\n",
        "        output_filename = f\"downloaded_{uuid.uuid4().hex}.mp4\"\n",
        "        output_path = os.path.join(temp_dir, output_filename)\n",
        "\n",
        "        # Check if it's a YouTube URL\n",
        "        if \"youtube.com\" in video_url or \"youtu.be\" in video_url:\n",
        "            # Import yt-dlp here to avoid dependency if not needed\n",
        "            import yt_dlp\n",
        "\n",
        "            # Setup yt-dlp options\n",
        "            ydl_opts = {\n",
        "                'format': 'best[ext=mp4]/best',  # Best quality MP4 or best available format\n",
        "                'outtmpl': output_path,\n",
        "                'noplaylist': True,\n",
        "                'quiet': False,  # Set to True to reduce output\n",
        "                'no_warnings': False,\n",
        "            }\n",
        "\n",
        "            # First extract info to check duration\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                print(f\"Extracting info from YouTube URL: {video_url}\")\n",
        "                info_dict = ydl.extract_info(video_url, download=False)\n",
        "\n",
        "                # Check if video exists\n",
        "                if not info_dict:\n",
        "                    return None, \"Could not retrieve video information. Please check the URL.\"\n",
        "\n",
        "                video_title = info_dict.get('title', 'Unknown Title')\n",
        "                duration = info_dict.get('duration', 0)\n",
        "\n",
        "                print(f\"Video title: {video_title}\")\n",
        "                print(f\"Video duration: {duration} seconds\")\n",
        "\n",
        "                # Check video duration\n",
        "                if duration > max_duration_minutes * 60:\n",
        "                    return None, f\"Video is too long ({duration} seconds). Maximum duration is {max_duration_minutes} minutes.\"\n",
        "\n",
        "                # Download the video\n",
        "                print(f\"Downloading YouTube video: {video_title}\")\n",
        "                ydl.download([video_url])\n",
        "\n",
        "            # Verify the file exists and has content\n",
        "            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "                return None, \"Download failed: Empty or missing file.\"\n",
        "\n",
        "            print(f\"Successfully downloaded video to: {output_path}\")\n",
        "            return output_path, None\n",
        "        else:\n",
        "            return None, \"Only YouTube URLs are supported at this time. Please enter a valid YouTube URL.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        print(f\"Error downloading video: {e}\\n{error_details}\")\n",
        "        return None, f\"Error downloading video: {str(e)}\"\n",
        "\n",
        "\n",
        "# @spaces.GPU\n",
        "def handle_video_upload(video_input, video_url, input_type, model_name, confidence_threshold, process_interval):\n",
        "    \"\"\"Handles video upload or URL input and calls the VideoProcessor.\"\"\"\n",
        "\n",
        "    print(f\"Received video request: input_type={input_type}\")\n",
        "    video_path = None\n",
        "\n",
        "    # Handle based on input type\n",
        "    if input_type == \"upload\" and video_input:\n",
        "        print(f\"Processing uploaded video file\")\n",
        "        video_path = video_input\n",
        "    elif input_type == \"url\" and video_url:\n",
        "        print(f\"Processing video from URL: {video_url}\")\n",
        "        # Download video from URL\n",
        "        video_path, error_message = download_video_from_url(video_url)\n",
        "        if error_message:\n",
        "            error_html = f\"<div class='video-summary-content-wrapper'><pre>{error_message}</pre></div>\"\n",
        "            return None, error_html, {\"error\": error_message}\n",
        "    else:\n",
        "        print(\"No valid video input provided.\")\n",
        "        return None, \"<div class='video-summary-content-wrapper'><pre>Please upload a video file or provide a valid video URL.</pre></div>\", {}\n",
        "\n",
        "    print(f\"Starting video processing with: model={model_name}, confidence={confidence_threshold}, interval={process_interval}\")\n",
        "    try:\n",
        "        # Call the VideoProcessor method\n",
        "        output_video_path, summary_text, stats_dict = video_processor.process_video_file(\n",
        "            video_path=video_path,\n",
        "            model_name=model_name,\n",
        "            confidence_threshold=confidence_threshold,\n",
        "            process_interval=int(process_interval) # Ensure interval is int\n",
        "        )\n",
        "        print(f\"Video processing function returned: path={output_video_path}, summary length={len(summary_text)}\")\n",
        "\n",
        "        # Wrap processing summary in HTML tags for consistent styling with scene understanding page\n",
        "        summary_html = f\"<div class='video-summary-content-wrapper'><pre>{summary_text}</pre></div>\"\n",
        "\n",
        "        # Format statistics for better display\n",
        "        formatted_stats = {}\n",
        "        if stats_dict and isinstance(stats_dict, dict):\n",
        "            formatted_stats = stats_dict\n",
        "\n",
        "        return output_video_path, summary_html, formatted_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in handle_video_upload: {e}\")\n",
        "        import traceback\n",
        "        error_msg = f\"Error processing video: {str(e)}\\n{traceback.format_exc()}\"\n",
        "        error_html = f\"<div class='video-summary-content-wrapper'><pre>{error_msg}</pre></div>\"\n",
        "        return None, error_html, {\"error\": str(e)}\n",
        "\n",
        "\n",
        "# Create Gradio Interface\n",
        "def create_interface():\n",
        "    \"\"\"Creates the Gradio interface with Tabs.\"\"\"\n",
        "    css = Style.get_css()\n",
        "    available_models = DetectionModel.get_available_models()\n",
        "    model_choices = [model[\"model_file\"] for model in available_models]\n",
        "    class_choices_formatted = [f\"{id}: {name}\" for id, name in get_all_classes()] # Use formatted choices\n",
        "\n",
        "    with gr.Blocks(css=css, theme=gr.themes.Soft(primary_hue=\"teal\", secondary_hue=\"blue\")) as demo:\n",
        "\n",
        "        # Header\n",
        "        with gr.Group(elem_classes=\"app-header\"):\n",
        "              gr.HTML(\"\"\"\n",
        "                    <div style=\"text-align: center; width: 100%; padding: 2rem 0 3rem 0; background: linear-gradient(135deg, #f0f9ff, #e1f5fe);\">\n",
        "                        <h1 style=\"font-size: 3.5rem; margin-bottom: 0.5rem; background: linear-gradient(90deg, #38b2ac, #4299e1); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-weight: bold; font-family: 'Arial', sans-serif;\">VisionScout</h1>\n",
        "                        <h2 style=\"color: #4A5568; font-size: 1.2rem; font-weight: 400; margin-top: 0.5rem; margin-bottom: 1.5rem; font-family: 'Arial', sans-serif;\">Object Detection and Scene Understanding</h2>\n",
        "                        <div style=\"display: flex; justify-content: center; gap: 10px; margin: 0.5rem 0;\"><div style=\"height: 3px; width: 80px; background: linear-gradient(90deg, #38b2ac, #4299e1);\"></div></div>\n",
        "                        <div style=\"display: flex; justify-content: center; gap: 25px; margin-top: 1.5rem;\">\n",
        "                            <div style=\"padding: 8px 15px; border-radius: 20px; background: rgba(66, 153, 225, 0.15); color: #2b6cb0; font-weight: 500; font-size: 0.9rem;\"><span style=\"margin-right: 6px;\">🖼️</span> Image Analysis</div>\n",
        "                            <div style=\"padding: 8px 15px; border-radius: 20px; background: rgba(56, 178, 172, 0.15); color: #2b6cb0; font-weight: 500; font-size: 0.9rem;\"><span style=\"margin-right: 6px;\">🎬</span> Video Analysis</div>\n",
        "                        </div>\n",
        "                         <div style=\"margin-top: 20px; padding: 10px 15px; background-color: rgba(255, 248, 230, 0.9); border-left: 3px solid #f6ad55; border-radius: 6px; max-width: 600px; margin-left: auto; margin-right: auto; text-align: left;\">\n",
        "                             <p style=\"margin: 0; font-size: 0.9rem; color: #805ad5; font-weight: 500;\">\n",
        "                                 <span style=\"margin-right: 5px;\">📱</span> iPhone users: HEIC images may not be supported.\n",
        "                                 <a href=\"https://cloudconvert.com/heic-to-jpg\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">Convert HEIC to JPG</a> before uploading if needed.\n",
        "                             </p>\n",
        "                         </div>\n",
        "                    </div>\n",
        "                \"\"\")\n",
        "\n",
        "        # Main Content with Tabs\n",
        "        with gr.Tabs(elem_classes=\"tabs\"):\n",
        "\n",
        "            # Tab 1: Image Processing\n",
        "            with gr.Tab(\"Image Processing\"):\n",
        "                current_image_model = gr.State(\"yolov8m.pt\") # State for image model selection\n",
        "                with gr.Row(equal_height=False): # Allow columns to have different heights\n",
        "                    # Left Column: Image Input & Controls\n",
        "                    with gr.Column(scale=4, elem_classes=\"input-panel\"):\n",
        "                        with gr.Group():\n",
        "                            gr.HTML('<div class=\"section-heading\">Upload Image</div>')\n",
        "                            image_input = gr.Image(type=\"pil\", label=\"Upload an image\", elem_classes=\"upload-box\")\n",
        "\n",
        "                            with gr.Accordion(\"Image Analysis Settings\", open=False):\n",
        "                                image_model_dropdown = gr.Dropdown(\n",
        "                                    choices=model_choices,\n",
        "                                    value=\"yolov8m.pt\", # Default for images\n",
        "                                    label=\"Select Model\",\n",
        "                                    info=\"Choose speed vs. accuracy (n=fast, m=balanced, x=accurate)\"\n",
        "                                )\n",
        "                                # Display model info\n",
        "                                image_model_info = gr.Markdown(DetectionModel.get_model_description(\"yolov8m.pt\"))\n",
        "\n",
        "                                image_confidence = gr.Slider(\n",
        "                                    minimum=0.1, maximum=0.9, value=0.25, step=0.05,\n",
        "                                    label=\"Confidence Threshold\",\n",
        "                                    info=\"Minimum confidence for displaying a detected object\"\n",
        "                                )\n",
        "\n",
        "                                use_llm = gr.Checkbox(\n",
        "                                    label=\"Use LLM for enhanced scene descriptions\",\n",
        "                                    value=True,\n",
        "                                    info=\"Provides more detailed and natural language descriptions (may increase processing time)\"\n",
        "                                )\n",
        "\n",
        "                                use_landmark_detection = gr.Checkbox(\n",
        "                                    label=\"Use CLIP for Landmark Detection\",\n",
        "                                    value=False,\n",
        "                                    info=\"Detect famous landmarks, monuments, and tourist attractions that standard object detection cannot recognize (increases processing time)\"\n",
        "                                )\n",
        "\n",
        "                                with gr.Accordion(\"Filter Classes\", open=False):\n",
        "                                     gr.HTML('<div class=\"section-heading\" style=\"font-size: 1rem;\">Common Categories</div>')\n",
        "                                     with gr.Row():\n",
        "                                         people_btn = gr.Button(\"People\", size=\"sm\")\n",
        "                                         vehicles_btn = gr.Button(\"Vehicles\", size=\"sm\")\n",
        "                                         animals_btn = gr.Button(\"Animals\", size=\"sm\")\n",
        "                                         objects_btn = gr.Button(\"Common Objects\", size=\"sm\")\n",
        "                                     image_class_filter = gr.Dropdown(\n",
        "                                         choices=class_choices_formatted, # Use formatted choices\n",
        "                                         multiselect=True,\n",
        "                                         label=\"Select Classes to Display\",\n",
        "                                         info=\"Leave empty to show all detected objects\"\n",
        "                                     )\n",
        "\n",
        "                        image_detect_btn = gr.Button(\"Analyze Image\", variant=\"primary\", elem_classes=\"detect-btn\")\n",
        "\n",
        "                        with gr.Group(elem_classes=\"how-to-use\"):\n",
        "                             gr.HTML('<div class=\"section-heading\">How to Use (Image)</div>')\n",
        "                             gr.Markdown(\"\"\"\n",
        "                                1. Upload an image or use the camera\n",
        "                                2. *(Optional)* Adjust settings like confidence threshold or model size (n, m = balanced, x = accurate)\n",
        "                                3. In **Analysis Settings**, you can:\n",
        "                                    * Uncheck **Use LLM** to skip enhanced descriptions (faster)\n",
        "                                    * Check **Use CLIP for Landmark Detection** to identify famous landmarks like museums, monuments, and tourist attractions *(may take longer)*\n",
        "                                    * Filter object classes to focus on specific types of objects *(optional)*\n",
        "                                4. Click **Analyze Image** button\n",
        "\n",
        "                                **💡 Tip:** For landmark recognition (e.g. Louvre Museum), make sure to enable **CLIP for Landmark Detection** in the settings above.\n",
        "                                \"\"\")\n",
        "\n",
        "\n",
        "                        # Image Examples\n",
        "                        gr.Examples(\n",
        "                            examples=[\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_01.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_04.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_05.jpg\",\n",
        "                                \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/landmark_Louvre_01.jpg\",\n",
        "                                ],\n",
        "                            inputs=image_input,\n",
        "                            label=\"Example Images\"\n",
        "                         )\n",
        "\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div style=\"text-align: center; margin-top: 8px; padding: 6px; background-color: #f8f9fa; border-radius: 4px; border: 1px solid #e2e8f0;\">\n",
        "                                <p style=\"font-size: 12px; color: #718096; margin: 0;\">\n",
        "                                    📷 Sample images sourced from <a href=\"https://unsplash.com\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">Unsplash</a>\n",
        "                                </p>\n",
        "                            </div>\n",
        "                        \"\"\")\n",
        "\n",
        "                    # Right Column: Image Results\n",
        "                    with gr.Column(scale=6, elem_classes=\"output-panel\"):\n",
        "                        with gr.Tabs(elem_classes=\"tabs\"):\n",
        "                            with gr.Tab(\"Detection Result\"):\n",
        "                                image_result_image = gr.Image(type=\"pil\", label=\"Detection Result\")\n",
        "                                gr.HTML('<div class=\"section-heading\">Detection Details</div>')\n",
        "                                image_result_text = gr.Textbox(label=None, lines=10, elem_id=\"detection-details\", container=False)\n",
        "\n",
        "                            with gr.Tab(\"Scene Understanding\"):\n",
        "                                gr.HTML('<div class=\"section-heading\">Scene Analysis</div>')\n",
        "                                gr.HTML(\"\"\"\n",
        "                                    <details class=\"info-details\" style=\"margin: 5px 0 15px 0;\">\n",
        "                                        <summary style=\"padding: 8px; background-color: #f0f7ff; border-radius: 6px; border-left: 3px solid #4299e1; font-weight: bold; cursor: pointer; color: #2b6cb0;\">\n",
        "                                            🔍 The AI Vision Scout Report: Click for important notes about this analysis\n",
        "                                        </summary>\n",
        "                                        <div style=\"margin-top: 8px; padding: 10px; background-color: #f8f9fa; border-radius: 6px; border: 1px solid #e2e8f0;\">\n",
        "                                            <p style=\"font-size: 13px; color: #718096; margin: 0;\">\n",
        "                                                <b>About this analysis:</b> This analysis is the model's best guess based on visible objects.\n",
        "                                                Like human scouts, it sometimes gets lost or sees things that aren't there (but don't we all?).\n",
        "                                                Consider this an educated opinion rather than absolute truth. For critical applications, always verify with human eyes! 🧐\n",
        "                                            </p>\n",
        "                                        </div>\n",
        "                                    </details>\n",
        "                                \"\"\")\n",
        "\n",
        "                                gr.HTML('''\n",
        "                                    <div style=\"margin-top: 5px; padding: 6px 10px; background-color: #f0f9ff; border-radius: 4px; border-left: 3px solid #63b3ed; font-size: 12px; margin-bottom: 10px;\">\n",
        "                                        <p style=\"margin: 0; color: #4a5568;\">\n",
        "                                            <b>Note:</b> AI descriptions may vary slightly with each generation, reflecting the creative nature of AI. This is similar to how a person might use different words each time they describe the same image. Processing time may be longer during first use or when analyzing complex scenes, as the LLM enhancement requires additional computational resources.\n",
        "                                        </p>\n",
        "                                    </div>\n",
        "                                    ''')\n",
        "                                image_scene_description_html = gr.HTML(label=None, elem_id=\"scene_analysis_description_text\")\n",
        "\n",
        "                                # 使用LLM增強敘述時也會顯示原本敘述內容\n",
        "                                with gr.Accordion(\"Original Scene Analysis\", open=False, elem_id=\"original_scene_analysis_accordion\"):\n",
        "                                    image_llm_description = gr.HTML(label=None, elem_id=\"original_scene_description_text\")\n",
        "\n",
        "                                with gr.Row():\n",
        "                                     with gr.Column(scale=1):\n",
        "                                         gr.HTML('<div class=\"section-heading\" style=\"font-size:1rem; text-align:left;\">Possible Activities</div>')\n",
        "                                         image_activities_list = gr.Dataframe(headers=[\"Activity\"], datatype=[\"str\"], row_count=5, col_count=1, wrap=True)\n",
        "\n",
        "                                     with gr.Column(scale=1):\n",
        "                                         gr.HTML('<div class=\"section-heading\" style=\"font-size:1rem; text-align:left;\">Safety Concerns</div>')\n",
        "                                         image_safety_list = gr.Dataframe(headers=[\"Concern\"], datatype=[\"str\"], row_count=5, col_count=1, wrap=True)\n",
        "\n",
        "                                gr.HTML('<div class=\"section-heading\">Functional Zones</div>')\n",
        "                                image_zones_json = gr.JSON(label=None, elem_classes=\"json-box\")\n",
        "\n",
        "                                gr.HTML('<div class=\"section-heading\">Lighting Conditions</div>')\n",
        "                                image_lighting_info = gr.JSON(label=None, elem_classes=\"json-box\")\n",
        "\n",
        "                            with gr.Tab(\"Statistics\"):\n",
        "                                with gr.Row():\n",
        "                                    with gr.Column(scale=3, elem_classes=\"plot-column\"):\n",
        "                                        gr.HTML('<div class=\"section-heading\">Object Distribution</div>')\n",
        "                                        image_plot_output = gr.Plot(label=None, elem_classes=\"large-plot-container\")\n",
        "                                    with gr.Column(scale=2, elem_classes=\"stats-column\"):\n",
        "                                        gr.HTML('<div class=\"section-heading\">Detection Statistics</div>')\n",
        "                                        image_stats_json = gr.JSON(label=None, elem_classes=\"enhanced-json-display\")\n",
        "\n",
        "            # Tab 2: Video Processing\n",
        "            with gr.Tab(\"Video Processing\"):\n",
        "                with gr.Row(equal_height=False):\n",
        "                    # Left Column: Video Input & Controls\n",
        "                    with gr.Column(scale=4, elem_classes=\"input-panel\"):\n",
        "                        with gr.Group():\n",
        "                            gr.HTML('<div class=\"section-heading\">Video Input</div>')\n",
        "\n",
        "                            # Add input type selection\n",
        "                            video_input_type = gr.Radio(\n",
        "                                [\"upload\", \"url\"],\n",
        "                                label=\"Input Method\",\n",
        "                                value=\"upload\",\n",
        "                                info=\"Choose how to provide the video\"\n",
        "                            )\n",
        "\n",
        "                            # File upload (will be shown/hidden based on selection)\n",
        "                            with gr.Group(elem_id=\"upload-video-group\"):\n",
        "                                video_input = gr.Video(\n",
        "                                    label=\"Upload a video file (MP4, AVI, MOV)\",\n",
        "                                    sources=[\"upload\"],\n",
        "                                    visible=True\n",
        "                                )\n",
        "\n",
        "                            # URL input (will be shown/hidden based on selection)\n",
        "                            with gr.Group(elem_id=\"url-video-group\"):\n",
        "                                video_url_input = gr.Textbox(\n",
        "                                    label=\"Enter video URL (YouTube or direct video link)\",\n",
        "                                    placeholder=\"https://www.youtube.com/watch?v=...\",\n",
        "                                    visible=False,\n",
        "                                    elem_classes=\"custom-video-url-input\"\n",
        "                                )\n",
        "                                gr.HTML(\"\"\"\n",
        "                                    <div style=\"padding: 8px; margin-top: 5px; background-color: #fff8f8; border-radius: 4px; border-left: 3px solid #f87171; font-size: 12px;\">\n",
        "                                        <p style=\"margin: 0; color: #4b5563;\">\n",
        "                                            Note: Currently only YouTube URLs are supported. Maximum video duration is 10 minutes. Due to YouTube's anti-bot protection, some videos may not be downloadable. For protected videos, please upload a local video file instead.\n",
        "                                        </p>\n",
        "                                    </div>\n",
        "                                \"\"\")\n",
        "\n",
        "                            with gr.Accordion(\"Video Analysis Settings\", open=True):\n",
        "                                video_model_dropdown = gr.Dropdown(\n",
        "                                    choices=model_choices,\n",
        "                                    value=\"yolov8n.pt\", # Default 'n' for video\n",
        "                                    label=\"Select Model (Video)\",\n",
        "                                    info=\"Faster models (like 'n') are recommended\"\n",
        "                                )\n",
        "                                video_confidence = gr.Slider(\n",
        "                                    minimum=0.1, maximum=0.9, value=0.4, step=0.05,\n",
        "                                    label=\"Confidence Threshold (Video)\"\n",
        "                                )\n",
        "                                video_process_interval = gr.Slider(\n",
        "                                    minimum=1, maximum=60, value=10, step=1, # Allow up to 60 frame interval\n",
        "                                    label=\"Processing Interval (Frames)\",\n",
        "                                    info=\"Analyze every Nth frame (higher value = faster)\"\n",
        "                                )\n",
        "                        video_process_btn = gr.Button(\"Process Video\", variant=\"primary\", elem_classes=\"detect-btn\")\n",
        "\n",
        "                        with gr.Group(elem_classes=\"how-to-use\"):\n",
        "                            gr.HTML('<div class=\"section-heading\">How to Use (Video)</div>')\n",
        "                            gr.Markdown(\"\"\"\n",
        "                            1. Choose your input method: Upload a file or enter a URL.\n",
        "                            2. Adjust settings if needed (using a faster model and larger interval is recommended for longer videos).\n",
        "                            3. Click \"Process Video\". **Processing can take a significant amount of time.**\n",
        "                            4. The annotated video and summary will appear on the right when finished.\n",
        "                            \"\"\")\n",
        "\n",
        "                        # Add video examples\n",
        "                        gr.HTML('<div class=\"section-heading\">Example Videos</div>')\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div style=\"padding: 10px; background-color: #f0f7ff; border-radius: 6px; margin-bottom: 15px;\">\n",
        "                                <p style=\"font-size: 14px; color: #4A5568; margin: 0;\">\n",
        "                                    Upload any video containing objects that YOLO can detect. For testing, find sample videos\n",
        "                                    <a href=\"https://www.pexels.com/search/videos/street/\" target=\"_blank\" style=\"color: #3182ce; text-decoration: underline;\">here</a>.\n",
        "                                </p>\n",
        "                            </div>\n",
        "                        \"\"\")\n",
        "\n",
        "                    # Right Column: Video Results\n",
        "                    with gr.Column(scale=6, elem_classes=\"output-panel video-result-panel\"):\n",
        "                        gr.HTML(\"\"\"\n",
        "                            <div class=\"section-heading\">Video Result</div>\n",
        "                            <details class=\"info-details\" style=\"margin: 5px 0 15px 0;\">\n",
        "                                <summary style=\"padding: 8px; background-color: #f0f7ff; border-radius: 6px; border-left: 3px solid #4299e1; font-weight: bold; cursor: pointer; color: #2b6cb0;\">\n",
        "                                    🎬 Video Processing Notes\n",
        "                                </summary>\n",
        "                                <div style=\"margin-top: 8px; padding: 10px; background-color: #f8f9fa; border-radius: 6px; border: 1px solid #e2e8f0;\">\n",
        "                                    <p style=\"font-size: 13px; color: #718096; margin: 0;\">\n",
        "                                        The processed video includes bounding boxes around detected objects. For longer videos,\n",
        "                                        consider using a faster model (like YOLOv8n) and a higher frame interval to reduce processing time.\n",
        "                                    </p>\n",
        "                                </div>\n",
        "                            </details>\n",
        "                        \"\"\")\n",
        "                        video_output = gr.Video(label=\"Processed Video\", elem_classes=\"video-output-container\") # Output for the processed video file\n",
        "\n",
        "                        gr.HTML('<div class=\"section-heading\">Processing Summary</div>')\n",
        "                        # 使用HTML顯示影片的摘要\n",
        "                        video_summary_text = gr.HTML(\n",
        "                            label=None,\n",
        "                            elem_id=\"video-summary-html-output\"\n",
        "                        )\n",
        "\n",
        "                        gr.HTML('<div class=\"section-heading\">Aggregated Statistics</div>')\n",
        "                        video_stats_json = gr.JSON(label=None, elem_classes=\"video-stats-display\") # Display statistics\n",
        "\n",
        "        # Event Listeners\n",
        "        # Image Model Change Handler\n",
        "        image_model_dropdown.change(\n",
        "            fn=lambda model: (model, DetectionModel.get_model_description(model)),\n",
        "            inputs=[image_model_dropdown],\n",
        "            outputs=[current_image_model, image_model_info] # Update state and description\n",
        "        )\n",
        "\n",
        "        # Image Filter Buttons\n",
        "        available_classes_list = get_all_classes() # Get list of (id, name)\n",
        "        people_classes_ids = [0]\n",
        "        vehicles_classes_ids = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "        animals_classes_ids = list(range(14, 24))\n",
        "        common_objects_ids = [39, 41, 42, 43, 44, 45, 56, 57, 60, 62, 63, 67, 73] # Bottle, cup, fork, knife, spoon, bowl, chair, couch, table, tv, laptop, phone, book\n",
        "\n",
        "        people_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in people_classes_ids], outputs=image_class_filter)\n",
        "        vehicles_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in vehicles_classes_ids], outputs=image_class_filter)\n",
        "        animals_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in animals_classes_ids], outputs=image_class_filter)\n",
        "        objects_btn.click(lambda: [f\"{id}: {name}\" for id, name in available_classes_list if id in common_objects_ids], outputs=image_class_filter)\n",
        "\n",
        "        video_input_type.change(\n",
        "            fn=lambda input_type: [\n",
        "                # Show/hide file upload\n",
        "                gr.update(visible=(input_type == \"upload\")),\n",
        "                # Show/hide URL input\n",
        "                gr.update(visible=(input_type == \"url\"))\n",
        "            ],\n",
        "            inputs=[video_input_type],\n",
        "            outputs=[video_input, video_url_input]\n",
        "        )\n",
        "\n",
        "        image_detect_btn.click(\n",
        "            fn=handle_image_upload,\n",
        "            inputs=[image_input, image_model_dropdown, image_confidence, image_class_filter, use_llm, use_landmark_detection ],\n",
        "            outputs=[\n",
        "                image_result_image, image_result_text, image_stats_json, image_plot_output,\n",
        "                image_scene_description_html, image_llm_description, image_activities_list, image_safety_list, image_zones_json,\n",
        "                image_lighting_info\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        video_process_btn.click(\n",
        "            fn=handle_video_upload,\n",
        "            inputs=[\n",
        "                video_input,\n",
        "                video_url_input,\n",
        "                video_input_type,\n",
        "                video_model_dropdown,\n",
        "                video_confidence,\n",
        "                video_process_interval\n",
        "            ],\n",
        "            outputs=[video_output, video_summary_text, video_stats_json]\n",
        "        )\n",
        "\n",
        "        # Footer\n",
        "        gr.HTML(\"\"\"\n",
        "            <div class=\"footer\" style=\"padding: 25px 0; text-align: center; background: linear-gradient(to right, #f5f9fc, #e1f5fe); border-top: 1px solid #e2e8f0; margin-top: 30px;\">\n",
        "                <div style=\"margin-bottom: 15px;\">\n",
        "                    <p style=\"font-size: 14px; color: #4A5568; margin: 5px 0;\">Powered by YOLOv8, CLIP, Places365, Meta Llama3.2 and Ultralytics • Created with Gradio</p>\n",
        "                </div>\n",
        "                <div style=\"display: flex; align-items: center; justify-content: center; gap: 20px; margin-top: 15px;\">\n",
        "                    <p style=\"font-family: 'Arial', sans-serif; font-size: 14px; font-weight: 500; letter-spacing: 2px; background: linear-gradient(90deg, #38b2ac, #4299e1); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin: 0; text-transform: uppercase; display: inline-block;\">EXPLORE THE CODE →</p>\n",
        "                    <a href=\"https://github.com/Eric-Chung-0511/Learning-Record/tree/main/Data%20Science%20Projects/VisionScout\" target=\"_blank\" style=\"text-decoration: none;\">\n",
        "                        <img src=\"https://img.shields.io/badge/GitHub-VisionScout-4299e1?logo=github&style=for-the-badge\">\n",
        "                    </a>\n",
        "                </div>\n",
        "            </div>\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_interface = create_interface()\n",
        "\n",
        "    demo_interface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikiFwTh3WG75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e5a66c-e9af-48d5-9e82-657286e17331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# %%writefile requirements.txt\n",
        "# torch>=2.0.0\n",
        "# torchvision>=0.15.0\n",
        "# ultralytics>=8.0.0\n",
        "# opencv-python>=4.7.0\n",
        "# pillow>=9.4.0\n",
        "# numpy>=1.23.5\n",
        "# matplotlib>=3.7.0\n",
        "# gradio>=3.32.0\n",
        "# git+https://github.com/openai/CLIP.git\n",
        "# yt-dlp>=2023.3.4\n",
        "# requests>=2.28.1\n",
        "# transformers\n",
        "# accelerate\n",
        "# bitsandbytes\n",
        "# sentencepiece\n",
        "# huggingface_hub>=0.19.0\n",
        "# urllib3>=1.26.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# files.download('detection_model.py')\n",
        "# files.download('color_mapper.py')\n",
        "# files.download('visualization_helper.py')\n",
        "# files.download('evaluation_metrics.py')\n",
        "# files.download('style.py')\n",
        "# files.download('scene_type.py')\n",
        "# files.download('confidence_templates.py')\n",
        "# files.download('scene_detail_templates.py')\n",
        "# files.download('object_template_fillers.py')\n",
        "# files.download('safety_templates.py')\n",
        "# files.download('activity_templates.py')\n",
        "# files.download('object_categories.py')\n",
        "# files.download('lighting_conditions.py')\n",
        "# files.download('viewpoint_templates.py')\n",
        "# files.download('cultural_templates.py')\n",
        "# files.download('region_analyzer.py')\n",
        "# files.download('object_extractor.py')\n",
        "# files.download('scene_viewpoint_analyzer.py')\n",
        "# files.download('zone_evaluator.py')\n",
        "# files.download('scene_zone_identifier.py')\n",
        "# files.download('functional_zone_identifier.py')\n",
        "# files.download('spatial_analyzer.py')\n",
        "# files.download('places365_model.py')\n",
        "# files.download('viewpoint_detector.py')\n",
        "# files.download('template_manager.py')\n",
        "# files.download('object_description_generator.py')\n",
        "# files.download('cultural_context_analyzer.py')\n",
        "# files.download('text_formatter.py')\n",
        "# files.download('enhanced_scene_describer.py')\n",
        "# files.download('configuration_manager.py')\n",
        "# files.download('feature_extractor.py')\n",
        "# files.download('indoor_outdoor_classifier.py')\n",
        "# files.download('lighting_condition_analyzer.py')\n",
        "# files.download('lighting_analyzer.py')\n",
        "# files.download('scene_description.py')\n",
        "# files.download('clip_prompts.py')\n",
        "# files.download('clip_analyzer.py')\n",
        "# files.download('landmark_data.py')\n",
        "# files.download('landmark_activities.py')\n",
        "# files.download('clip_model_manager.py')\n",
        "# files.download('landmark_data_manager.py')\n",
        "# files.download('image_analyzer.py')\n",
        "# files.download('confidence_manager.py')\n",
        "# files.download('result_cache_manager.py')\n",
        "# files.download('clip_zero_shot_classifier.py')\n",
        "# files.download('component_initializer.py')\n",
        "# files.download('scene_scoring_engine.py')\n",
        "# files.download('landmark_processing_manager.py')\n",
        "# files.download('scene_analysis_coordinator.py')\n",
        "# files.download('scene_analyzer.py')\n",
        "# files.download('image_processor.py')\n",
        "# files.download('video_processor.py')\n",
        "# files.download('model_manager.py')\n",
        "# files.download('prompt_template_manager.py')\n",
        "# files.download('response_processor.py')\n",
        "# files.download('text_quality_validator.py')\n",
        "# files.download('llm_enhancer.py')\n",
        "# files.download('app.py')\n",
        "\n",
        "# files.download('requirements.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2BfiNRvG0pHw",
        "outputId": "8626ed2a-ed1a-434d-e631-f681531dd97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0580fd0d-9da0-4c46-8412-93b001a5beed\", \"image_processor.py\", 29741)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_82e0f6b5-31b0-428d-9d42-4639eac7ca72\", \"video_processor.py\", 18584)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_045ab2a5-8080-417d-9816-5c892cb20fd1\", \"model_manager.py\", 11190)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_487e2fcd-eaa8-4dd9-af71-4034d92b87d7\", \"prompt_template_manager.py\", 26734)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f9007d5c-30dc-45bb-8bc0-ae96808d374b\", \"response_processor.py\", 45291)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_44ed271b-e0da-4e0c-a680-9329756710df\", \"text_quality_validator.py\", 19850)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55359271-8ac0-47a4-883a-2e734c63116d\", \"llm_enhancer.py\", 19504)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de3334ba-e0c3-42f9-aa92-63e7d2cb2381\", \"app.py\", 50563)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4df2c49a-d679-4424-a6a5-9697ccf99e2b\", \"requirements.txt\", 298)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVswpsr-Wfr8"
      },
      "outputs": [],
      "source": [
        "#    examples=[\n",
        "#                                 \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/room_01.jpg\",\n",
        "#                                 \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_04.jpg\",\n",
        "#                                 \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/street_05.jpg\",\n",
        "#                                 \"/content/drive/Othercomputers/我的 MacBook Pro/Learning/VisionScout/test_images/landmark_Louvre_01.jpg\",\n",
        "#                                 ],"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}